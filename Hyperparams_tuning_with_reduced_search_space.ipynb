{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briag1/ParsingEval/blob/main/Hyperparams_tuning_with_reduced_search_space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1ZV8IJFGT9T",
        "outputId": "e60303e1-188a-4248-b68a-b38752525df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available. Using GPU.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# @title device\n",
        "def get_device():\n",
        "  if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "      print(\"CUDA is available. Using GPU.\")\n",
        "  else:\n",
        "      device = torch.device(\"cpu\")\n",
        "      print(\"CUDA is not available. Using CPU.\")\n",
        "  return device\n",
        "device=get_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV_LSRYqGMO2"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qh5nnjRIFe0h"
      },
      "outputs": [],
      "source": [
        "# @title code\n",
        "from os import makedirs\n",
        "import torch\n",
        "import math\n",
        "import os\n",
        "import string\n",
        "import shutil\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_x(value):\n",
        "\n",
        "    if isinstance(value, str):\n",
        "        return float(value.split(\"/\")[0])\n",
        "    elif isinstance(value, float):\n",
        "        return value\n",
        "\n",
        "def get_y(value):\n",
        "\n",
        "    if isinstance(value, str):\n",
        "        return float(value.split(\"/\")[1])\n",
        "    elif isinstance(value, float):\n",
        "        return value\n",
        "\n",
        "def read_dataframe(name):\n",
        "  if not os.path.exists(name+\".pkl\"):\n",
        "    print(\"reading dataframe: \"+name+\".xlsx\")\n",
        "    df=pd.read_excel(name+\".xlsx\")\n",
        "    df.to_pickle(name+\".pkl\")\n",
        "  else:\n",
        "    print(\"using already read daframe\")\n",
        "\n",
        "def get_vocab(poses,vocab):\n",
        "  for pos in poses:\n",
        "    if pos not in vocab and not any(isinstance(n, float) and math.isnan(n) for n in pos):\n",
        "        vocab[pos]=len(vocab)+1\n",
        "  return vocab\n",
        "\n",
        "def get_fix_time_encoding(df):\n",
        "\n",
        "  df['month_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.month / 12)\n",
        "  df['month_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.month / 12)\n",
        "\n",
        "  df['day_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.day / 31)\n",
        "  df['day_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.day / 31)\n",
        "\n",
        "  df['hour_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.hour / 24)\n",
        "  df['hour_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.hour / 24)\n",
        "\n",
        "  df['minute_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.minute / 60)\n",
        "  df['minute_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.minute / 60)\n",
        "\n",
        "  df['second_sin'] = np.sin(2 * np.pi * df[\"start time\"].dt.second / 60)\n",
        "  df['second_cos'] = np.cos(2 * np.pi * df[\"start time\"].dt.second / 60)\n",
        "def get_time_data(df):\n",
        "  df['month'] =  df[\"start time\"].dt.month\n",
        "  df['day'] =  df[\"start time\"].dt.day\n",
        "  df['hour'] =  df[\"start time\"].dt.hour\n",
        "  df['minute'] = df[\"start time\"].dt.minute\n",
        "  df['second'] = df[\"start time\"].dt.second\n",
        "  return df\n",
        "\n",
        "\n",
        "def tokenize_pos(pos,vocab):\n",
        "\n",
        "  if math.isnan(pos[0]) and math.isnan(pos[1]):\n",
        "    return len(vocab)\n",
        "  else:\n",
        "    return vocab[pos]\n",
        "\n",
        "def get_coordinates(df,input_position,full_dataset):\n",
        "\n",
        "  if full_dataset:\n",
        "    df['x'] = df['latitude']\n",
        "    df['y'] = df['longitude']\n",
        "  else:\n",
        "    df['x'] = df['location(latitude/lontitude)'].apply(get_x)\n",
        "    df['y'] = df['location(latitude/lontitude)'].apply(get_y)\n",
        "\n",
        "\n",
        "  if input_position:\n",
        "    df['x_normalised']=(df['x']-df['x'].mean())/(df['x'].std())\n",
        "    df['y_normalised']=(df['y']-df['y'].mean())/df['y'].std()\n",
        "\n",
        "  return df\n",
        "\n",
        "def get_joined_coordinates(df):\n",
        "\n",
        "  df['pos']= list(zip(df['x'],df['y']))\n",
        "  poses=df['pos'].unique()\n",
        "\n",
        "  return poses\n",
        "\n",
        "def get_col_to_keep_and_drop(fixed_time_encoding,input_position,full_dataset):\n",
        "  col_to_drop_in_df=['date', 'end time','pos']\n",
        "  col_to_drop_in_dict=['x','y', 'time_to_end', 'time_to_next','start time', 'user id']\n",
        "  col_to_add_to_dict=[]\n",
        "  col_in_input=[]\n",
        "  if not full_dataset:\n",
        "    col_to_drop_in_df+=['location(latitude/lontitude)']\n",
        "  else:\n",
        "    col_to_drop_in_df+=['latitude','longitude']\n",
        "  if fixed_time_encoding:\n",
        "    col_to_drop_in_df+=[]\n",
        "    col_to_drop_in_dict+=['month_sin', 'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'second_sin', 'second_cos']\n",
        "    col_in_input+=['month_sin', 'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'second_sin', 'second_cos']\n",
        "  else:\n",
        "    col_to_add_to_dict+=['month','day','hour','minute','second']\n",
        "  if input_position:\n",
        "    col_to_drop_in_dict += ['x_normalised', 'y_normalised']\n",
        "    col_in_input+=['x_normalised', 'y_normalised']\n",
        "  return col_to_drop_in_df,col_to_drop_in_dict,col_in_input,col_to_add_to_dict\n",
        "\n",
        "def process_user_data(df_user,vocab,col_in_input,col_to_drop_in_dict,col_to_add_to_dict,with_repeated_connections):\n",
        "  #get the time to next connection\n",
        "  df_user[\"time_to_next\"] =  df_user[\"start time\"].diff(-1).dt.total_seconds()\n",
        "  dict_user=df_user.to_dict('list')\n",
        "  #create input\n",
        "  dict_user[\"pos_id\"],dict_user[\"pos_id_target\"]=torch.tensor(dict_user[\"pos_id\"][:-1]),torch.tensor(dict_user[\"pos_id\"][1:])\n",
        "\n",
        "  if col_in_input:\n",
        "    dict_user[\"input\"]=torch.tensor([dict_user[col] for col in col_in_input]).T\n",
        "    dict_user[\"input\"]=dict_user[\"input\"][:-1]\n",
        "\n",
        "  if col_to_add_to_dict:\n",
        "    for col in col_to_add_to_dict:\n",
        "      dict_user[col]=torch.tensor(dict_user[col])\n",
        "      dict_user[col]=dict_user[col][:-1]\n",
        "\n",
        "  dict_user[\"time_target\"]=torch.tensor([dict_user[\"time_to_end\"],dict_user[\"time_to_next\"]]).T\n",
        "  dict_user[\"time_target\"]=dict_user[\"time_target\"][:-1]\n",
        "  for e in col_to_drop_in_dict:\n",
        "    dict_user.pop(e)\n",
        "\n",
        "  if not with_repeated_connections:\n",
        "    dict_user=combine_repeated_connections_in_sequence_user(dict_user)\n",
        "    dict_user=delete_end_of_sequence_repeated_connections(dict_user)\n",
        "  return dict_user\n",
        "\n",
        "def delete_end_of_sequence_repeated_connections(dict_user):\n",
        "  if dict_user['pos_id'][-1]==dict_user[\"pos_id_target\"][-1]:\n",
        "    for key in dict_user:\n",
        "      dict_user[key]=dict_user[key][:-1]\n",
        "  return dict_user\n",
        "\n",
        "\n",
        "def combine_repeated_connections_in_sequence_user(dict_user):\n",
        "  index=0\n",
        "  while index < len(dict_user[\"pos_id\"])-1:\n",
        "    if dict_user[\"pos_id\"][index]==dict_user[\"pos_id_target\"][index]:\n",
        "      dict_user[\"pos_id_target\"][index]=dict_user[\"pos_id_target\"][index+1]\n",
        "      dict_user[\"time_target\"][index]=dict_user[\"time_target\"][index+1]\n",
        "      for key in dict_user:\n",
        "        dict_user[key]=torch.cat((dict_user[key][:index+1],dict_user[key][index+2:]))\n",
        "    else:\n",
        "      index+=1\n",
        "\n",
        "\n",
        "  return dict_user\n",
        "\n",
        "\n",
        "def normalize_output(list_users):\n",
        "  #get means and stds\n",
        "  time_targets=torch.cat([dict_user[\"time_target\"] for dict_user in list_users],dim=0)\n",
        "  time_targets_mean=time_targets.mean(dim=0)\n",
        "  time_targets_std=time_targets.std(dim=0)\n",
        "  #normalize\n",
        "  for i in range(len(list_users)):\n",
        "    list_users[i][\"time_target\"]=(list_users[i][\"time_target\"]-time_targets_mean)/time_targets_std\n",
        "  return list_users\n",
        "\n",
        "\n",
        "\n",
        "def process_dataframe(name,vocab,fixed_time_encoding,input_position,full_dataset,with_repeated_connections,min_sequence_size,format=\".pkl\"):\n",
        "  df= pd.read_pickle(name+format)\n",
        "  df=df.sort_values('start time')\n",
        "  df=df.drop(['month'],axis=1)\n",
        "\n",
        "  df=get_coordinates(df,input_position,full_dataset)\n",
        "\n",
        "  poses=get_joined_coordinates(df)\n",
        "  vocab=get_vocab(poses,vocab)\n",
        "  df['pos_id'] = df['pos'].apply(lambda pos: tokenize_pos(pos,vocab))\n",
        "\n",
        "  df['time_to_end']=df['end time']-df['start time']\n",
        "  df['time_to_end']=df['time_to_end'].dt.total_seconds()\n",
        "  if fixed_time_encoding:\n",
        "    df=get_fix_time_encoding(df)\n",
        "  else:\n",
        "    df=get_time_data(df)\n",
        "\n",
        "  col_to_drop_in_df,col_to_drop_in_dict,col_in_input,col_to_add_to_dict=get_col_to_keep_and_drop(fixed_time_encoding,input_position,full_dataset)\n",
        "  df=df.drop(col_to_drop_in_df, axis=1)\n",
        "\n",
        "  df_user_group = df.groupby('user id')\n",
        "  list_users=[]\n",
        "  for user, df_user in df_user_group:\n",
        "    if len(df_user)>=min_sequence_size and not df_user['x'].isnull().values.any():\n",
        "        prossessed_user_data=process_user_data(df_user,vocab,col_in_input,col_to_drop_in_dict,col_to_add_to_dict,with_repeated_connections)\n",
        "        if prossessed_user_data[\"pos_id\"].shape[0]>=min_sequence_size-1:\n",
        "          list_users.append(prossessed_user_data)\n",
        "  list_users=normalize_output(list_users)\n",
        "\n",
        "  return list_users,vocab\n",
        "\n",
        "def runcmd(cmd, verbose = False, *args, **kwargs):\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout = subprocess.PIPE,\n",
        "        stderr = subprocess.PIPE,\n",
        "        text = True,\n",
        "        shell = True\n",
        "    )\n",
        "    std_out, std_err = process.communicate()\n",
        "    if verbose:\n",
        "        print(std_out.strip(), std_err)\n",
        "    pass\n",
        "\n",
        "def get_raw_data(directory,src_directory,full_dataset):\n",
        "  if  full_dataset:\n",
        "    shutil.copytree(src_directory,directory)#telecomDataset6mont\n",
        "  else:\n",
        "    runcmd('wget http://sguangwang.com/dataset/telecom.zip', verbose = False)\n",
        "    runcmd('unzip /content/telecom.zip')\n",
        "\n",
        "def get_processed_dataset(load_dataset_path):\n",
        "  saved_list_user_path = os.path.join(load_dataset_path,\"list_users\")\n",
        "  saved_vocab_path = os.path.join(load_dataset_path,\"vocab\")\n",
        "  print(\"loading already preprocessed data: \")\n",
        "  print(saved_list_user_path)\n",
        "  print(saved_vocab_path)\n",
        "  list_users=torch.load(saved_list_user_path)\n",
        "  vocab=torch.load(saved_vocab_path)\n",
        "  return list_users,vocab\n",
        "\n",
        "def process_raw_data(src_directory_raw_data,directory_raw_data,fixed_time_encoding,input_position,full_dataset,with_repeated_connections,min_sequence_size):\n",
        "  list_users=[]\n",
        "  vocab={}\n",
        "  if not os.path.exists(directory_raw_data):\n",
        "    print('getting raw data at: '+src_directory_raw_data)\n",
        "    get_raw_data(directory_raw_data,src_directory_raw_data,full_dataset)\n",
        "  for name in os.listdir(directory_raw_data):\n",
        "    if not name.endswith(\".pkl\"):\n",
        "      complete_name=os.path.join(directory_raw_data,\".\".join(name.split(\".\")[:-1]))\n",
        "      print(\"processing dataframe: \"+complete_name)\n",
        "      read_dataframe(complete_name)\n",
        "      new_list_users,vocab= process_dataframe(complete_name,vocab,fixed_time_encoding=fixed_time_encoding,input_position=input_position,full_dataset=full_dataset,with_repeated_connections=with_repeated_connections,min_sequence_size=min_sequence_size)\n",
        "      list_users+=new_list_users\n",
        "  return list_users,vocab\n",
        "\n",
        "def split_long_sequences(list_users,max_sequence_length):\n",
        "  new_list_users=[]\n",
        "  for i in range(len(list_users)):\n",
        "    seq_length=list_users[i][\"input\"].shape[0]\n",
        "    if seq_length>=max_sequence_length:\n",
        "      nb_of_seq=seq_length//max_sequence_length\n",
        "      rest=seq_length%max_sequence_length\n",
        "      list_splitted_seq=nb_of_seq*[{}]\n",
        "      rest_splitted={}\n",
        "      for key in list_users[i]:\n",
        "        for j in range(nb_of_seq):\n",
        "          list_splitted_seq[j][key]=list_users[i][key][max_sequence_length*j:max_sequence_length*(j+1)]\n",
        "        if rest>2:\n",
        "          rest_splitted[key]= list_users[i][key][-rest:]\n",
        "      new_list_users=new_list_users+list_splitted_seq\n",
        "      if len(rest_splitted)>0:\n",
        "        new_list_users+=[rest_splitted]\n",
        "    else:\n",
        "      new_list_users.append(list_users[i])\n",
        "\n",
        "  return new_list_users\n",
        "\n",
        "\n",
        "\n",
        "def save_processed_data(list_users,vocab,path_to_save_dataset):\n",
        "    print(\"creating directory: \"+path_to_save_dataset)\n",
        "    os.makedirs(path_to_save_dataset,exist_ok=True)\n",
        "    print(\"saving processed data at: \")\n",
        "    save_list_user_path = os.path.join(path_to_save_dataset,\"list_users\")\n",
        "    save_vocab_path = os.path.join(path_to_save_dataset,\"vocab\")\n",
        "    print(save_list_user_path)\n",
        "    print(save_vocab_path)\n",
        "    torch.save(list_users,save_list_user_path)\n",
        "    torch.save(vocab,save_vocab_path)\n",
        "\n",
        "def get_processed_data(src_directory_raw_data,directory_raw_data,fixed_time_encoding,input_position,full_dataset,spliting_long_sequences,with_repeated_connections,max_sequence_length=100,min_sequence_size=1,save=False,path_to_save_dataset=\"/content/drive/MyDrive/telecomDataset6month\",download=False,load_dataset_path=\"/content/drive/MyDrive/telecomDataset6month\"):\n",
        "  if not download:\n",
        "    list_users,vocab = get_processed_dataset(load_dataset_path)\n",
        "  else:\n",
        "    list_users,vocab=process_raw_data(src_directory_raw_data,directory_raw_data,fixed_time_encoding,input_position,full_dataset,with_repeated_connections,min_sequence_size=min_sequence_size)\n",
        "  if spliting_long_sequences:\n",
        "    print(\"spliting sequences longuer than : \"+str(max_sequence_length)+ \" steps\")\n",
        "    list_users=split_long_sequences(list_users,max_sequence_length)\n",
        "  if save:\n",
        "    save_processed_data(list_users,vocab,path_to_save_dataset)\n",
        "  return list_users,vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSRA1WX8UcsV",
        "outputId": "1c9a00e3-a1d9-40fe-a6f8-c0c0c2f1ea96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        }
      ],
      "source": [
        "list_users,vocab=get_processed_data(src_directory_raw_data=\"drive/MyDrive/Shanghai-Telcome-Six-Months-DataSet\",\n",
        "                                    directory_raw_data='/content/dataset-telecom-6month',\n",
        "                                    fixed_time_encoding=False,\n",
        "                                    input_position=True,\n",
        "                                    full_dataset=True,\n",
        "                                    spliting_long_sequences=False,\n",
        "                                    with_repeated_connections=False,\n",
        "                                    max_sequence_length=100,\n",
        "                                    min_sequence_size=2,\n",
        "                                    save=False,\n",
        "                                    path_to_save_dataset=\"/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3\",\n",
        "                                    download=False,\n",
        "                                    load_dataset_path=\"/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oCMGZR2yP72"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "sum_len=0\n",
        "len_list=[]\n",
        "for user in list_users:\n",
        "  len_list.append(len(user['pos_id']))\n",
        "  sum_len+=len(user['pos_id'])\n",
        "print(sum_len/len(list_users))\n",
        "len_array=np.array(len_list)\n",
        "print(len_array.mean(),len_array.std(),len_array.max(),len_array.min())\n",
        "plt.hist(len_array,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkzulva2d2ae"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "sum_len=0\n",
        "len_list=[]\n",
        "for user in list_users:\n",
        "  len_list.append(len(user['pos_id']))\n",
        "  sum_len+=len(user['pos_id'])\n",
        "print(sum_len/len(list_users))\n",
        "len_array=np.array(len_list)\n",
        "print(len_array.mean(),len_array.std(),len_array.max(),len_array.min())\n",
        "plt.hist(len_array,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K35diHP9eSr2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "sum_len=0\n",
        "len_list=[]\n",
        "for user in list_users:\n",
        "  len_list.append(len(user['pos_id']))\n",
        "  sum_len+=len(user['pos_id'])\n",
        "print(sum_len/len(list_users))\n",
        "len_array=np.array(len_list)\n",
        "print(len_array.mean(),len_array.std(),len_array.max(),len_array.min())\n",
        "plt.hist(len_array,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKc-6WsExyck"
      },
      "outputs": [],
      "source": [
        "nb_repeated_end_of_sequence=0\n",
        "len_1=0\n",
        "for user in list_users:\n",
        "  if len(user['pos_id'])==1:\n",
        "    len_1+=1\n",
        "    if user['pos_id'][-1]==user['pos_id_target'][-1]:\n",
        "      nb_repeated_end_of_sequence+=1\n",
        "print(nb_repeated_end_of_sequence/len_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dLZ5FSAdylO"
      },
      "outputs": [],
      "source": [
        "nb_repeated_end_of_sequence=0\n",
        "len_1=0\n",
        "for user in list_users:\n",
        "  if len(user['pos_id'])==1:\n",
        "    len_1+=1\n",
        "    if user['pos_id'][-1]==user['pos_id_target'][-1]:\n",
        "      nb_repeated_end_of_sequence+=1\n",
        "print(nb_repeated_end_of_sequence/len_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5D9IoBtGX6R"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDvAwpD4GrJu"
      },
      "source": [
        "## Reproducibility seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p5d4mp9GDah"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "import string\n",
        "import random\n",
        "def get_reproducible_seeds(name=\"ProjectLong\",nb_seeds=100):\n",
        "    # Calculate SHA-256 hash\n",
        "    sha256_hash = hashlib.sha256(name.encode()).hexdigest()\n",
        "    # Define character sets\n",
        "    digits = string.digits\n",
        "    # Use the hash to seed the random number generator\n",
        "    hash_as_int = int(sha256_hash, 16)\n",
        "    random.seed(hash_as_int)\n",
        "    # Generate a random list of seed of desired length\n",
        "    reproducibility_seeds = [random.randint(0,10000) for _ in range(nb_seeds)]\n",
        "\n",
        "    return reproducibility_seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn8U0p9TGJXK"
      },
      "outputs": [],
      "source": [
        "reproducibility_seed=get_reproducible_seeds()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_mzoE-MHqLa"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nhxCSLNHsd9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class VariableLengthDatasetWithPosID(Dataset):\n",
        "    def __init__(self, time_series, transform=None):\n",
        "        self.times_series=time_series\n",
        "    def __len__(self):\n",
        "        return len(self.times_series)\n",
        "    def __getitem__(self, idx):\n",
        "        user_dict=self.times_series[idx]\n",
        "        return  user_dict\n",
        "\n",
        "def create_dataset(list_users,split=[0.8,0.1,0.1]):\n",
        "  dataset=VariableLengthDatasetWithPosID(list_users)\n",
        "  generator = torch.Generator().manual_seed(reproducibility_seed)\n",
        "  dataset_list=torch.utils.data.random_split(dataset,[0.8,0.1,0.1],generator)\n",
        "  return dataset_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRGgl2XnIhDQ"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nke01dG-KJxO"
      },
      "outputs": [],
      "source": [
        "def collate_fn_padd(batch_dict):\n",
        "    '''\n",
        "    Padds batch of variable length\n",
        "\n",
        "    note: it converts things ToTensor manually here since the ToTensor transform\n",
        "    assume it takes in images rather than arbitrary tensors.\n",
        "    '''\n",
        "\n",
        "\n",
        "    dict_batch={key: [d[key] for d in batch_dict] for key in batch_dict[0]}\n",
        "    dict_batch[\"lengths\"] = torch.tensor([ user[\"input\"].shape[0] for user in batch_dict ])\n",
        "    if \"input\" in dict_batch:\n",
        "      dict_batch[\"input\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"input\"],batch_first=True,padding_value=0)\n",
        "    dict_batch[\"month\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"month\"],batch_first=True,padding_value=0)\n",
        "    dict_batch[\"day\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"day\"],batch_first=True,padding_value=0)\n",
        "    dict_batch[\"hour\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"hour\"],batch_first=True,padding_value=24)\n",
        "    dict_batch[\"minute\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"minute\"],batch_first=True,padding_value=60)\n",
        "    dict_batch[\"second\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"second\"],batch_first=True,padding_value=60)\n",
        "\n",
        "    dict_batch[\"time_target\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"time_target\"],batch_first=True,padding_value=-1)\n",
        "    dict_batch[\"pos_id\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"pos_id\"],batch_first=True,padding_value=len(vocab))\n",
        "    dict_batch[\"pos_id_target\"] = torch.nn.utils.rnn.pad_sequence(dict_batch[\"pos_id_target\"],batch_first=True,padding_value=len(vocab))\n",
        "    #print(dict_batch[\"input\"])\n",
        "    return dict_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Yl1E6gY8_P"
      },
      "source": [
        "## Instanciate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHpriSipY7Kz"
      },
      "outputs": [],
      "source": [
        "dataset_list=create_dataset(list_users)\n",
        "train_dataset=dataset_list[0]\n",
        "valid_dataset=dataset_list[1]\n",
        "test_dataset=dataset_list[2]\n",
        "train_dataloader=DataLoader(train_dataset,batch_size=128,collate_fn=collate_fn_padd,shuffle=True)\n",
        "valid_dataloader=DataLoader(valid_dataset,batch_size=256,collate_fn=collate_fn_padd,shuffle=False)\n",
        "test_dataloader=DataLoader(test_dataset,batch_size=256,collate_fn=collate_fn_padd,shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9HodJbvKeMe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptycyS7FWE4b"
      },
      "source": [
        "## Transformer Encoder followed by LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oeWr0HDhJfo"
      },
      "source": [
        "### transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3_bACPajeQx"
      },
      "outputs": [],
      "source": [
        "def get_mask(bath_size,sequence_length,lengths,device):\n",
        "  mask=torch.zeros(bath_size,sequence_length).to(device)\n",
        "  for i, length in enumerate(lengths):\n",
        "    mask[i,length:]=float('-inf')\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsaggvjghDsq"
      },
      "source": [
        "#### Positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yFXZxqeHMwi"
      },
      "outputs": [],
      "source": [
        "from torch import nn, Tensor\n",
        "class VanillaPositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = (x.transpose(0,1) + self.pe[:x.transpose(0,1).size(0)]).transpose(0,1)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX-kk1ScG-_n"
      },
      "outputs": [],
      "source": [
        "class LearnablePositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self,d_model: int, dropout: float = 0.1, max_len: int = 500):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.positional_embedding=nn.Embedding(num_embeddings=max_len,embedding_dim= d_model)\n",
        "    @property\n",
        "    def device(self):\n",
        "      return next(self.parameters()).device\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[batch_size,seq_len, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x += self.positional_embedding(torch.arange(0,x.shape[1]).to(self.device))\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzKYvfaWG6cH"
      },
      "outputs": [],
      "source": [
        "def get_PositionalEncoding(d_model: int, dropout: float = 0.1, max_len: int = 2000, learnable=False):\n",
        "  if learnable:\n",
        "    return LearnablePositionalEncoding(d_model, dropout, max_len)\n",
        "  else:\n",
        "    return VanillaPositionalEncoding(d_model, dropout, max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-pr0W6xhOkZ"
      },
      "source": [
        "#### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SZQnLdN4UxY"
      },
      "outputs": [],
      "source": [
        "class Encoder_Decoder_Transformer(nn.Module):\n",
        "    def __init__(self,d_model,num_layers=3,nhead=10,dropout=0.1,batch_first=True):\n",
        "      super().__init__()\n",
        "      self.transformer=torch.nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, num_decoder_layers=num_layers,  dropout=dropout, batch_first=batch_first)\n",
        "    def forward(self,x,mask,src_key_padding_mask,is_causal):\n",
        "      return self.transformer(x,\n",
        "                       x,\n",
        "                       src_mask=mask,\n",
        "                       tgt_mask=mask,\n",
        "                       memory_mask=mask,\n",
        "                       src_key_padding_mask=src_key_padding_mask,\n",
        "                       tgt_key_padding_mask=src_key_padding_mask,\n",
        "                       memory_key_padding_mask=src_key_padding_mask,\n",
        "                       src_is_causal=is_causal,\n",
        "                       tgt_is_causal=is_causal,\n",
        "                       memory_is_causal=is_causal)\n",
        "\n",
        "\n",
        "\n",
        "def get_Transformer_architecture(d_model,encoder_only=False,num_layers=3,nhead=10,dropout=0.1,batch_first=True):\n",
        "  if encoder_only:\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,batch_first=batch_first)\n",
        "    return nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "  else:\n",
        "    return Encoder_Decoder_Transformer(d_model,num_layers,nhead,dropout,batch_first=batch_first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCkeqmkhRnT"
      },
      "source": [
        "### feature embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmqQtP0UhZqg"
      },
      "outputs": [],
      "source": [
        "class TimeStampEmbedding(nn.Module):\n",
        "  def __init__(self,embedding_dim,dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.month_embedding = nn.Embedding(num_embeddings=13,embedding_dim=embedding_dim)\n",
        "    self.day_embedding = nn.Embedding(num_embeddings=32,embedding_dim=embedding_dim)\n",
        "    self.hour_embedding = nn.Embedding(num_embeddings=25,embedding_dim=embedding_dim)\n",
        "    self.minute_embedding = nn.Embedding(num_embeddings=61,embedding_dim=embedding_dim)\n",
        "    self.second_embedding = nn.Embedding(num_embeddings=61,embedding_dim=embedding_dim)\n",
        "\n",
        "  def forward(self,dict_batch):\n",
        "    embedding= self.month_embedding(dict_batch['month'])\n",
        "    embedding=+ self.day_embedding(dict_batch['day'])\n",
        "    embedding=+ self.hour_embedding(dict_batch['hour'])\n",
        "    embedding=+ self.minute_embedding(dict_batch['minute'])\n",
        "    embedding=+ self.second_embedding(dict_batch['second'])\n",
        "    return self.dropout(embedding)\n",
        "class StationIdEmbedding(nn.Module):\n",
        "  def __init__(self,embedding_dim,nb_of_pos_ids,dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.stationIdEmbedding=nn.Embedding(num_embeddings=nb_of_pos_ids,embedding_dim=embedding_dim)\n",
        "  def forward(self,dict_batch):\n",
        "    embedding=self.stationIdEmbedding(dict_batch[\"pos_id\"])\n",
        "    return self.dropout(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCp5Pz6uy-FG"
      },
      "outputs": [],
      "source": [
        "class StationIdEmbedding(nn.Module):\n",
        "  def __init__(self,embedding_dim,nb_of_pos_ids,dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.stationIdEmbedding=nn.Embedding(num_embeddings=nb_of_pos_ids,embedding_dim=embedding_dim)\n",
        "  def forward(self,dict_batch):\n",
        "    embedding=self.stationIdEmbedding(dict_batch[\"pos_id\"])\n",
        "    return self.dropout(embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bbp1dVXWQs3"
      },
      "source": [
        "#### graph_deepLearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqW174iJrhFC",
        "outputId": "5a842e0e-c440-4f8e-9165-2d7d369e2fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting libpysal\n",
            "  Downloading libpysal-4.10-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.10/dist-packages (from libpysal) (4.12.3)\n",
            "Requirement already satisfied: geopandas>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from libpysal) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from libpysal) (1.25.2)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.10/dist-packages (from libpysal) (23.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from libpysal) (1.5.3)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from libpysal) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.10/dist-packages (from libpysal) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from libpysal) (1.11.4)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from libpysal) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from libpysal) (1.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.10->libpysal) (2.5)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.10.0->libpysal) (1.9.5)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.10.0->libpysal) (3.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->libpysal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->libpysal) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27->libpysal) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->libpysal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->libpysal) (3.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (23.2.0)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas>=0.10.0->libpysal) (67.7.2)\n",
            "Installing collected packages: libpysal\n",
            "Successfully installed libpysal-4.10\n"
          ]
        }
      ],
      "source": [
        "!pip install libpysal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQvAPDZyWNtg",
        "outputId": "dae6b552-625d-4b07-9217-0a02beb17ffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.3.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.0\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.25.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=9e7c26fdbff6752a628ebf8ffa24bb476f148bd5f70e941729c552141388750a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  torch_version = str(torch.__version__)\n",
        "  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  !pip install torch-scatter -f $scatter_src\n",
        "  !pip install torch-sparse -f $sparse_src\n",
        "  !pip install torch-geometric\n",
        "  !pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdSTBOc3sKsV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from libpysal.cg import voronoi_frames\n",
        "from libpysal import weights, examples\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn import GCNConv\n",
        "import numpy as np\n",
        "\n",
        "def get_net(vocab):\n",
        "  x_array=[key[0] for key in vocab]\n",
        "  y_array=[key[1] for key in vocab]\n",
        "  coordinates=np.column_stack((x_array,y_array))\n",
        "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
        "  delaunay = weights.Rook.from_dataframe(cells)\n",
        "  delaunay_graph = delaunay.to_networkx()\n",
        "  positions = dict(zip(delaunay_graph.nodes, coordinates))\n",
        "  nx.set_node_attributes(delaunay_graph,positions,\"coordinates\")\n",
        "  distance=np.linalg.norm(np.concatenate([delaunay_graph.nodes[index[0]][\"coordinates\"][None,:] for index in delaunay_graph.edges], axis=0)-np.concatenate([delaunay_graph.nodes[index[1]][\"coordinates\"][None,:] for index in delaunay_graph.edges], axis=0), axis=1)\n",
        "  nx.set_edge_attributes(delaunay_graph,dict(zip(delaunay_graph.edges,distance)),\"distance\")\n",
        "  net=from_networkx(delaunay_graph)\n",
        "  return net\n",
        "\n",
        "class GCN(nn.Module):\n",
        "  def __init__(self, hidden_dim1, hidden_dim2, output_dim,vocab,dropout,device):\n",
        "    super(GCN, self).__init__()\n",
        "    net=get_net(vocab)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "    self.edge_index=edge_index = net.edge_index.long().to(device)\n",
        "    self.distance= net.distance.float().to(device)\n",
        "    self.coordinates=net.coordinates.float().to(device)\n",
        "    mean_distance=self.distance.mean()\n",
        "    std_distance=self.distance.std()\n",
        "    self.distance=(((self.distance-mean_distance)/std_distance)+1)/2\n",
        "\n",
        "    mean_coordinates=self.coordinates.mean(dim=0)\n",
        "    std_coordinates=self.coordinates.std(dim=0)\n",
        "    self.coordinates=(self.coordinates-mean_coordinates.unsqueeze(0))/std_coordinates.unsqueeze(0)\n",
        "    self.conv1 = GCNConv(2, hidden_dim1)\n",
        "    self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "    self.conv3 = GCNConv(hidden_dim2, output_dim)\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "  def forward(self, dic_batch):\n",
        "    x = self.conv1(self.coordinates, self.edge_index,self.distance)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "    x = self.conv2(x, self.edge_index,self.distance)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.conv3(x, self.edge_index,self.distance)\n",
        "    x=torch.cat((x,torch.zeros(1,x.shape[1]).to(self.device)),dim=0)\n",
        "    embedding=x[dic_batch[\"pos_id\"]]\n",
        "    return self.dropout(embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQfII-W5lETE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kozXR4sW0W0Y"
      },
      "source": [
        " #### Combine feature embeddng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6mU1qWOjRP3"
      },
      "outputs": [],
      "source": [
        "class Feature_embedding(nn.Module):\n",
        "\n",
        "  def __init__(self,d_model,nb_of_pos_ids,use_gcn,vocab,hidden_dim1, hidden_dim2,batch_first,concatenate_features,keep_input_positions,dropout,device):\n",
        "    super().__init__()\n",
        "    self.num_features=2+use_gcn\n",
        "    self.concatenate_features=concatenate_features\n",
        "    self.embedding_dim=d_model\n",
        "    self.keep_input_positions=keep_input_positions\n",
        "    if keep_input_positions:\n",
        "      self.embedding_dim=self.embedding_dim-2\n",
        "    if self.concatenate_features:\n",
        "      self.embedding_dim=int(self.embedding_dim/self.num_features)\n",
        "\n",
        "    list_feature_embedding=[StationIdEmbedding(self.embedding_dim,nb_of_pos_ids,dropout),TimeStampEmbedding(self.embedding_dim,dropout)]\n",
        "    if use_gcn:\n",
        "      list_feature_embedding.append(GCN(hidden_dim1, hidden_dim2, self.embedding_dim, vocab, dropout,device))\n",
        "    self.list_feature_embedding=nn.ModuleList(list_feature_embedding)\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "  def forward(self,dic_batch):\n",
        "    if self.concatenate_features:\n",
        "      list_embeddings=[]\n",
        "      for feature_emebdding in self.list_feature_embedding:\n",
        "        list_embeddings.append(feature_emebdding(dic_batch))\n",
        "      embedding=torch.cat(list_embeddings,dim=2)\n",
        "    else:\n",
        "      embedding=torch.zeros(*dic_batch[\"pos_id\"].shape,self.embedding_dim).to(self.device)\n",
        "      for feature_emebdding in self.list_feature_embedding:\n",
        "        embedding+=feature_emebdding(dic_batch)\n",
        "    if self.keep_input_positions:\n",
        "      embedding=torch.cat((dic_batch[\"input\"],embedding),dim=2)\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svMRI0xeji-7"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSt_zuJRKgBh"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self,d_model):\n",
        "    super().__init__()\n",
        "    self.dim_perceptron=2*d_model\n",
        "    self.linear_perceptron_in=nn.Linear(d_model,self.dim_perceptron)\n",
        "    self.linear_perceptron_out=nn.Linear(self.dim_perceptron,d_model)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_perceptron_out(F.relu(self.linear_perceptron_in(x)))\n",
        "\n",
        "\n",
        "class Transformer_LSTM_Layer(nn.Module):\n",
        "  def __init__(self,d_model,output_regression_size,output_classfication_size,num_layers,lstm_layer_with_perceptron,lstm_layer_with_layer_norm,dropout,batch_first):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lstm=LSTM(input_size=d_model, hidden_size=d_model,batch_first=batch_first,num_layers=1,dropout=dropout)\n",
        "    self.lstm_layer_with_perceptron=lstm_layer_with_perceptron\n",
        "    self.lstm_layer_with_layer_norm=lstm_layer_with_layer_norm\n",
        "    if self.lstm_layer_with_layer_norm:\n",
        "      self.layer_normalisation=torch.nn.LayerNorm(d_model)\n",
        "    if self.lstm_layer_with_perceptron:\n",
        "      self.mlp=MLP(d_model)\n",
        "    self.dropout=nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self,x,batch_sizes,sorted_indices,unsorted_indices,lengths):\n",
        "    x=self.lstm(x)[0].data+x.data\n",
        "    x=torch.torch.nn.utils.rnn.PackedSequence(x, batch_sizes, sorted_indices, unsorted_indices)\n",
        "    if self.lstm_layer_with_layer_norm:\n",
        "      x,_=torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0.0)\n",
        "      x=self.layer_normalisation(x)\n",
        "      x=self.dropout(x)\n",
        "      x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    if self.lstm_layer_with_perceptron:\n",
        "      x=x.data\n",
        "      x=self.mlp(x)+x\n",
        "      x=torch.torch.nn.utils.rnn.PackedSequence(x, batch_sizes, sorted_indices, unsorted_indices)\n",
        "      if self.layer_normalisation:\n",
        "        x,_=torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0.0)\n",
        "        x=self.layer_normalisation(x)\n",
        "        x=self.dropout(x)\n",
        "        x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class  Transformer_encoder_LSTM_decoder(nn.Module):\n",
        "  def __init__(self,d_model,nb_of_pos_ids,output_regression_size,output_classfication_size,num_layers_lstm,lstm_layer_with_perceptron,lstm_layer_with_layer_norm,num_layers_transformer,encoder_only,nhead,learnable_pos_encoding,new_station_binary_classification,use_gcn,vocab,hidden_dim1, hidden_dim2,max_len,dropout,batch_first,concatenate_features,keep_input_positions,device):\n",
        "    super().__init__()\n",
        "    self.dropout=nn.Dropout(p=dropout)\n",
        "    self.layer_normalisation=torch.nn.LayerNorm(d_model)\n",
        "    self.feature_embedding=Feature_embedding(d_model,nb_of_pos_ids,use_gcn,vocab,hidden_dim1, hidden_dim2,batch_first,concatenate_features,keep_input_positions,dropout,device)\n",
        "\n",
        "    self.num_layers_transformer=num_layers_transformer\n",
        "    if num_layers_transformer>0:\n",
        "      self.pos_encoder = get_PositionalEncoding(d_model, dropout, max_len,learnable_pos_encoding)\n",
        "      self.transformer_model=get_Transformer_architecture(d_model,encoder_only,num_layers_transformer,nhead,dropout,batch_first)\n",
        "\n",
        "    self.num_layers_lstm=num_layers_lstm\n",
        "    if num_layers_lstm>0:\n",
        "      self.transformer_lstm__list = nn.ModuleList([Transformer_LSTM_Layer(d_model,output_regression_size,output_classfication_size,num_layers_lstm,lstm_layer_with_perceptron,lstm_layer_with_layer_norm,dropout,batch_first) for layer in range(num_layers_lstm)])\n",
        "    self.linear_reg=nn.Linear(d_model,output_regression_size)\n",
        "    self.classifier=nn.Linear(d_model,output_classfication_size)\n",
        "\n",
        "    self.new_station_binary_classification=new_station_binary_classification\n",
        "    if self.new_station_binary_classification:\n",
        "      self.binary_classifier=nn.Linear(d_model,1)\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "\n",
        "  def forward(self,dic_batch,reg):\n",
        "    if self.num_layers_transformer>0:\n",
        "      x=self.feature_embedding(dic_batch)\n",
        "      x=self.pos_encoder(x)\n",
        "      with torch.no_grad():\n",
        "        mask_x = get_mask(x.shape[0],x.shape[1],dic_batch[\"lengths\"],self.device)\n",
        "        causal_mask=torch.nn.Transformer.generate_square_subsequent_mask(x.shape[1],device=self.device)\n",
        "      x=self.transformer_model(x,causal_mask,mask_x,is_causal=True)\n",
        "    if self.num_layers_lstm>0:\n",
        "      if self.num_layers_transformer>0:\n",
        "        x+=self.feature_embedding(dic_batch)\n",
        "      else:\n",
        "        x=self.feature_embedding(dic_batch)\n",
        "\n",
        "    x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=dic_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    batch_sizes=x.batch_sizes\n",
        "    sorted_indices=x.sorted_indices\n",
        "    unsorted_indices=x.unsorted_indices\n",
        "    if self.num_layers_lstm>0:\n",
        "      for transformer_lstm in self.transformer_lstm__list:\n",
        "        x=transformer_lstm(x,batch_sizes,sorted_indices,unsorted_indices,dic_batch[\"lengths\"])\n",
        "    x=F.relu(x.data)\n",
        "    out={}\n",
        "    out[\"next_station\"]=torch.nn.utils.rnn.PackedSequence(self.classifier(x), batch_sizes, sorted_indices, unsorted_indices)\n",
        "    if reg:\n",
        "      out[\"time_regression\"]=torch.nn.utils.rnn.PackedSequence(torch.exp(self.linear_reg(x)), batch_sizes, sorted_indices, unsorted_indices)\n",
        "    if self.new_station_binary_classification:\n",
        "      out[\"new_station\"]=  torch.nn.utils.rnn.PackedSequence( self.binary_classifier(x), batch_sizes, sorted_indices, unsorted_indices)\n",
        "    return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZpbR8rG8kBn"
      },
      "source": [
        "## Baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn0xR-ME8tRX"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class  Baseline_model(nn.Module):\n",
        "  def __init__(self,nb_of_pos_ids):\n",
        "    super().__init__()\n",
        "    self.nb_of_pos_ids=nb_of_pos_ids\n",
        "  def forward(self,dic_batch,reg):\n",
        "    out={}\n",
        "    out[\"next_station\"]=  torch.nn.utils.rnn.pack_padded_sequence(F.one_hot(dic_batch[\"pos_id\"],self.nb_of_pos_ids).float(), lengths=dic_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "QYH5OMnmELSa",
        "outputId": "83f006af-4f8a-4b34-c44c-00e8caad3615"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Total_loss.__init__() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-75bac174ad5a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Total_loss.__init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "model=Baseline_model(len(vocab)+1)\n",
        "criterion=Total_loss(False)\n",
        "evaluate(model,valid_dataloader,criterion,device,reg=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28s2GCFETdYS"
      },
      "source": [
        "# Trainning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ujoc4c2mQh_"
      },
      "outputs": [],
      "source": [
        "# @title loss\n",
        "from torch import nn\n",
        "class Loss_next_station_classification(nn.Module):\n",
        "  def __init__(self, ) -> None:\n",
        "    super().__init__()\n",
        "    self.criterion=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "\n",
        "  def forward(self, out, target_pos_ids, index_training_element):\n",
        "    loss_classification=self.criterion(out.data[index_training_element],target_pos_ids.data[index_training_element])\n",
        "    return loss_classification\n",
        "\n",
        "class Loss_time_regression(nn.Module):\n",
        "  def __init__(self, ) -> None:\n",
        "    super().__init__()\n",
        "    self.criterion = nn.MSELoss(reduction='none')\n",
        "  def forward(self,out,dict_batch):\n",
        "    time_targets=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"time_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    mask_time_targets = (time_targets.data != -1)\n",
        "    loss_regression=self.criterion(out.data,time_targets.data)\n",
        "    loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "    return loss_regression\n",
        "\n",
        "class Loss_new_station_binary_classification(nn.Module):\n",
        "  def __init__(self, ) -> None:\n",
        "    super().__init__()\n",
        "    self.criterion =  nn.BCEWithLogitsLoss()\n",
        "  def forward(self,out,target):\n",
        "    loss_classification=self.criterion(out.data.squeeze(),target.float())\n",
        "    return loss_classification\n",
        "\n",
        "def get_repetition_labels(target_pos_ids,pos_ids):\n",
        "\n",
        "  return (target_pos_ids.data==pos_ids.data).type(torch.LongTensor)\n",
        "\n",
        "def upsampling_strategy(target, epoch, epochs_new_station_only,pourcentage_of_repeat_training_elment):\n",
        "\n",
        "    index_non_repeat =(target==0).nonzero()\n",
        "    coeff=pourcentage_of_repeat_training_elment/(1-pourcentage_of_repeat_training_elment)\n",
        "    index_for_training= index_non_repeat\n",
        "    if epoch>= epochs_new_station_only:\n",
        "      index_repeat = target.nonzero().squeeze()\n",
        "      nb_non_repeat= index_non_repeat.shape[0]\n",
        "      slice_repeat=index_repeat[torch.randperm(index_repeat.shape[0])[:int(coeff*nb_non_repeat)]].squeeze()\n",
        "      index_for_training = torch.cat((index_non_repeat.squeeze(),slice_repeat))\n",
        "    return index_for_training.squeeze()\n",
        "\n",
        "\n",
        "class Total_loss(nn.Module):\n",
        "  def __init__(self,new_station_binary_classification) -> None:\n",
        "    super().__init__()\n",
        "    self.loss_next_station_classification = Loss_next_station_classification()\n",
        "    self.loss_time_regression = Loss_time_regression()\n",
        "    self.new_station_binary_classification=new_station_binary_classification\n",
        "    if self.new_station_binary_classification:\n",
        "      self.loss_new_station_binary_classification=Loss_new_station_binary_classification()\n",
        "\n",
        "  def forward(self, out, dict_batch, upsampling,upsampling_strategy, reg=False):\n",
        "    loss={}\n",
        "    target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    if self.new_station_binary_classification or upsampling:\n",
        "      pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "      target=get_repetition_labels(target_pos_ids,pos_ids)\n",
        "    else:\n",
        "      pos_ids=None\n",
        "      target=None\n",
        "\n",
        "    if upsampling:\n",
        "      index_training_element=upsampling_strategy(target)\n",
        "    else:\n",
        "      index_training_element=torch.arange(0,target_pos_ids.data.shape[0])\n",
        "\n",
        "    loss[\"classification\"]=self.loss_next_station_classification(out[\"next_station\"],target_pos_ids,index_training_element)\n",
        "    loss[\"total\"]=loss[\"classification\"]\n",
        "    if self.new_station_binary_classification:\n",
        "      loss[\"new_station\"]=self.loss_new_station_binary_classification(out[\"new_station\"],target)\n",
        "      loss[\"total\"]+=loss[\"new_station\"]\n",
        "\n",
        "    if reg:\n",
        "      loss[\"time_regression\"]=self.loss_time_regression(out[\"time_regression\"],dict_batch)\n",
        "      loss[\"total\"]+=loss[\"time_regression\"]\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IHCyYC32ToKU"
      },
      "outputs": [],
      "source": [
        "# @title evaluation\n",
        "from torch import autocast\n",
        "def evaluate(model,dataloader,upsampling,criterion,device,reg=True):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc=0\n",
        "    nb_points=0\n",
        "    valid_results={}\n",
        "    for dict_batch in dataloader:\n",
        "      for key in dict_batch:\n",
        "        if key!=\"lengths\":\n",
        "          dict_batch[key]=dict_batch[key].to(device)\n",
        "      with autocast(device_type=device.type):\n",
        "        out=model(dict_batch,reg=reg)\n",
        "        valid_result=criterion(out,dict_batch,upsampling,None,reg=reg)\n",
        "        valid_results=get_sum_valid_results(valid_results,valid_result)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "        acc+=(out[\"next_station\"].data.argmax(dim=1)==target_pos_ids.data).sum().item()\n",
        "        nb_points+=out[\"next_station\"].data.shape[0]\n",
        "    valid_results=get_mean_valid_results(valid_results,nb_points)\n",
        "    valid_results[\"acc\"]=acc/nb_points\n",
        "\n",
        "    return valid_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yLu25E-eTcbT"
      },
      "outputs": [],
      "source": [
        "# @title training\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import autocast\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "def train(\n",
        "          epochs_classifcation_only,\n",
        "          epochs_complete_problem,\n",
        "          input_size,\n",
        "          num_heads,\n",
        "          d_model,\n",
        "          nb_of_pos_ids,\n",
        "          num_layers_lstm,\n",
        "          lstm_layer_with_perceptron,\n",
        "          lstm_layer_with_layer_norm,\n",
        "          num_layers_transformer,\n",
        "          encoder_only,\n",
        "          output_regression_size,\n",
        "          output_classfication_size,\n",
        "          nb_batchs,\n",
        "          dropout,\n",
        "          max_len,\n",
        "          weight_decay,\n",
        "          lr,\n",
        "          learnable_pos_encoding,\n",
        "          new_station_binary_classification,\n",
        "          use_gcn,\n",
        "          vocab,hidden_dim1, hidden_dim2,\n",
        "          batch_first,\n",
        "          concatenate_features,\n",
        "          keep_input_positions,\n",
        "          upsampling,\n",
        "          upsampling_strategy,\n",
        "          epochs_new_station_only,\n",
        "          pourcentage_of_repeat_training_elment,\n",
        "          save_best_model,\n",
        "          path_best_model,\n",
        "          batch_size,\n",
        "          device):\n",
        "\n",
        "  epochs=epochs_complete_problem+ epochs_classifcation_only\n",
        "  model=Transformer_encoder_LSTM_decoder(d_model=d_model,\n",
        "                                         nb_of_pos_ids=nb_of_pos_ids,\n",
        "                                         output_regression_size=output_regression_size,\n",
        "                                         output_classfication_size=output_classfication_size,\n",
        "                                         num_layers_lstm=num_layers_lstm,\n",
        "                                         lstm_layer_with_perceptron=lstm_layer_with_perceptron,\n",
        "                                         lstm_layer_with_layer_norm=lstm_layer_with_perceptron,\n",
        "                                         num_layers_transformer=num_layers_transformer,\n",
        "                                         encoder_only=encoder_only,\n",
        "                                         nhead=num_heads,\n",
        "                                         learnable_pos_encoding=learnable_pos_encoding,\n",
        "                                         new_station_binary_classification=new_station_binary_classification,\n",
        "                                         use_gcn=use_gcn,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=hidden_dim1,\n",
        "                                         hidden_dim2=hidden_dim2,\n",
        "                                         max_len=max_len,\n",
        "                                         dropout=dropout,\n",
        "                                         batch_first = batch_first,\n",
        "                                         concatenate_features = concatenate_features,\n",
        "                                         keep_input_positions = keep_input_positions,device=device\n",
        "                                         ).to(device)\n",
        "  if save_best_model:\n",
        "    os.makedirs(path_best_model,exist_ok =True)\n",
        "  optimizer_encoder = optim.Adam( model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "  criterion = Total_loss( new_station_binary_classification = new_station_binary_classification)\n",
        "  train_losses, valid_results = {},{}\n",
        "  best_results={}\n",
        "  for epoch in range(epochs):\n",
        "    reg=epoch >= epochs_classifcation_only\n",
        "    epoch_losses={}\n",
        "    model.train()\n",
        "    i=0\n",
        "    for dict_batch in train_dataloader:\n",
        "      optimizer_encoder.zero_grad()\n",
        "      i+=1\n",
        "      if i>=nb_batchs:\n",
        "        break\n",
        "      dict_batch=set_dic_to(dict_batch,device)\n",
        "      with autocast(device_type=device.type):\n",
        "        out=model(dict_batch, reg)\n",
        "        loss=criterion(out, dict_batch,upsampling,lambda target: upsampling_strategy(target,epoch,epochs_new_station_only,pourcentage_of_repeat_training_elment) ,reg)\n",
        "        loss[\"total\"].backward()\n",
        "        optimizer_encoder.step()\n",
        "      epoch_losses=update_epoch_losses(epoch_losses,loss)\n",
        "      dict_batch.clear()\n",
        "      loss.clear()\n",
        "      out.clear()\n",
        "      del out, loss,dict_batch\n",
        "    epoch_loss=get_epoch_loss(epoch_losses,batch_size)\n",
        "    train_losses=update_train_losses(train_losses,epoch_loss,epoch)\n",
        "    valid_result = evaluate(model,valid_dataloader,upsampling,criterion,device)\n",
        "    best_results = update_best(model,valid_result,best_results,save_best_model,path_best_model)\n",
        "    valid_results = update_valid_results(valid_results,valid_result)\n",
        "    print_results(epoch_loss,valid_result,epoch)\n",
        "\n",
        "  return best_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8OL2WGr7cGZW"
      },
      "outputs": [],
      "source": [
        "# @title utils\n",
        "\n",
        "def set_dic_to(dict_batch,device):\n",
        "  for key in dict_batch:\n",
        "    if key!=\"lengths\":\n",
        "      dict_batch[key]=dict_batch[key].to(device)\n",
        "  return dict_batch\n",
        "\n",
        "def is_better(valid_result,best_result,key):\n",
        "  match key:\n",
        "    case \"acc\":\n",
        "      return valid_result>best_result\n",
        "    case _:\n",
        "      return valid_result<best_result\n",
        "\n",
        "def update_best(model,valid_result,best_results,save_best_model,path_best_model):\n",
        "  if best_results:\n",
        "    for key in valid_result:\n",
        "      if is_better(valid_result[key],best_results[key],key):\n",
        "        best_results[key]=valid_result[key]\n",
        "        if save_best_model:\n",
        "          save_model(model,path_best_model,key)\n",
        "  else:\n",
        "    for key in valid_result:\n",
        "      best_results[key]=valid_result[key]\n",
        "      if save_best_model:\n",
        "        save_model(model,path_best_model,key)\n",
        "  return best_results\n",
        "\n",
        "def save_model(model,path_best_model,key):\n",
        "  path=os.path.join(path_best_model,key)\n",
        "  torch.save(model.state_dict(), path+\".pth\")\n",
        "\n",
        "def get_sum_valid_results(valid_result,valid_result_batch):\n",
        "  if valid_result:\n",
        "    for key in valid_result_batch:\n",
        "      valid_result[key]+=valid_result_batch[key].item()\n",
        "  else:\n",
        "    for key in valid_result_batch:\n",
        "      valid_result[key]=valid_result_batch[key].item()\n",
        "  return valid_result\n",
        "\n",
        "def get_mean_valid_results(sum_valid_result,nb_element):\n",
        "  for key in sum_valid_result:\n",
        "    sum_valid_result[key]/=nb_element\n",
        "\n",
        "  return sum_valid_result\n",
        "\n",
        "def update_epoch_losses(dict_of_list,dic):\n",
        "  if dict_of_list:\n",
        "    for key in dic:\n",
        "      dict_of_list[key].append(dic[key].item())\n",
        "  else:\n",
        "    for key in dic:\n",
        "      dict_of_list[key]=[dic[key].item()]\n",
        "  return dict_of_list\n",
        "\n",
        "def update_valid_results(dict_of_list,dic):\n",
        "  if dict_of_list:\n",
        "    for key in dic:\n",
        "      dict_of_list[key].append(dic[key])\n",
        "  else:\n",
        "    for key in dic:\n",
        "      dict_of_list[key]=[dic[key]]\n",
        "  return dict_of_list\n",
        "\n",
        "def get_epoch_loss(epoch_losses,batch_size):\n",
        "\n",
        "  epoch_loss={}\n",
        "  for key in epoch_losses:\n",
        "    epoch_loss[key]=np.array(epoch_losses[key]).mean()/batch_size\n",
        "  return epoch_loss\n",
        "\n",
        "def print_results(epoch_loss,valid_result,epoch):\n",
        "\n",
        "  print(\"\\nepoch: \",epoch)\n",
        "  print(\"train :\", end=\"\\t\")\n",
        "  for key in epoch_loss:\n",
        "    print(key,epoch_loss[key], end=\"\\t\")\n",
        "  print(\"\\nvalid :\", end=\"\\t\")\n",
        "  for key in valid_result:\n",
        "    print(key,valid_result[key], end=\"\\t\")\n",
        "\n",
        "def update_train_losses(train_losses,epoch_loss,epoch):\n",
        "\n",
        "  if train_losses:\n",
        "    for key in epoch_loss:\n",
        "      if key in train_losses:\n",
        "        train_losses[key].append(epoch_loss[key])\n",
        "      else:\n",
        "        train_losses[key]=[float('nan')]*(epoch+1)+[epoch_loss[key]]\n",
        "  else:\n",
        "    for key in epoch_loss:\n",
        "      train_losses[key]=[epoch_loss[key]]\n",
        "  return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF4FEU_h1YtX"
      },
      "source": [
        "## Instance of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HL0AZ-YJChyE"
      },
      "outputs": [],
      "source": [
        "# @title Titre par défaut\n",
        "model=train(\n",
        "          epochs_classifcation_only=100,\n",
        "          epochs_complete_problem =100,\n",
        "          input_size=2,\n",
        "          num_heads=12,\n",
        "          d_model=1200,\n",
        "          nb_of_pos_ids=len(vocab)+1,\n",
        "          num_layers_lstm=6,\n",
        "          lstm_layer_with_perceptron=False,\n",
        "          lstm_layer_with_layer_norm=False,\n",
        "          num_layers_transformer=6,\n",
        "          encoder_only=True,\n",
        "          output_regression_size=2,\n",
        "          output_classfication_size=len(vocab)+1,\n",
        "          nb_batchs=100,\n",
        "          dropout=0.1,\n",
        "          max_len=100,\n",
        "          weight_decay=0,\n",
        "          lr=3e-4,\n",
        "          learnable_pos_encoding=True,\n",
        "          new_station_binary_classification=False,\n",
        "          use_gcn=False,\n",
        "          vocab=vocab, hidden_dim1=128, hidden_dim2=256,\n",
        "          batch_first= True,\n",
        "          concatenate_features = False,\n",
        "          keep_input_positions = False,\n",
        "          upsampling=False,\n",
        "          upsampling_strategy=upsampling_strategy,\n",
        "          epochs_new_station_only=0,\n",
        "          pourcentage_of_repeat_training_elment=0.1,\n",
        "          save_best_model=True,\n",
        "          path_best_model=\"test_0.5\",\n",
        "          device=device,\n",
        "          batch_size=64\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fL5dCWywLoZ"
      },
      "source": [
        "# hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYy2A_VUOvPY"
      },
      "source": [
        "##model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHxNOtpIczjP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "from libpysal.cg import voronoi_frames\n",
        "from libpysal import weights, examples\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.nn.models import GCN,GAT,GraphSAGE\n",
        "import numpy as np\n",
        "\n",
        "def get_net(vocab):\n",
        "  x_array=[key[0] for key in vocab]\n",
        "  y_array=[key[1] for key in vocab]\n",
        "  coordinates=np.column_stack((x_array,y_array))\n",
        "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
        "  delaunay = weights.Rook.from_dataframe(cells)\n",
        "  delaunay_graph = delaunay.to_networkx()\n",
        "  positions = dict(zip(delaunay_graph.nodes, coordinates))\n",
        "  nx.set_node_attributes(delaunay_graph,positions,\"coordinates\")\n",
        "  distance=np.linalg.norm(np.concatenate([delaunay_graph.nodes[index[0]][\"coordinates\"][None,:] for index in delaunay_graph.edges], axis=0)-np.concatenate([delaunay_graph.nodes[index[1]][\"coordinates\"][None,:] for index in delaunay_graph.edges], axis=0), axis=1)\n",
        "  nx.set_edge_attributes(delaunay_graph,dict(zip(delaunay_graph.edges,distance)),\"distance\")\n",
        "  net=from_networkx(delaunay_graph)\n",
        "  return net\n",
        "def get_layer(layer_type):\n",
        "  print(layer_type)\n",
        "  match layer_type:\n",
        "    case \"GraphSAGE\":\n",
        "      return GraphSAGE\n",
        "    case \"GCNConv\":\n",
        "      return GCN\n",
        "    case \"GAT\":\n",
        "      return GAT\n",
        "\n",
        "class GCN_embedding(nn.Module):\n",
        "  def __init__(self,output_dim,layer_type,num_layers_gcn,hidden_channels,activation_gcn,norm,net,device,normalize_features_independantly,dropout):\n",
        "    super(GCN_embedding, self).__init__()\n",
        "    self.normalize_features_independantly=normalize_features_independantly\n",
        "    if self.normalize_features_independantly:\n",
        "      self.layer_normalisation=torch.nn.LayerNorm(output_dim)\n",
        "    self.edge_index=edge_index = net.edge_index.long().to(device)\n",
        "    self.distance= net.distance.float().to(device)\n",
        "    self.coordinates=net.coordinates.float().to(device)\n",
        "    mean_distance=self.distance.mean()\n",
        "    std_distance=self.distance.std()\n",
        "    self.distance=(((self.distance-mean_distance)/std_distance)+1)/2\n",
        "\n",
        "    mean_coordinates=self.coordinates.mean(dim=0)\n",
        "    std_coordinates=self.coordinates.std(dim=0)\n",
        "    self.coordinates=(self.coordinates-mean_coordinates.unsqueeze(0))/std_coordinates.unsqueeze(0)\n",
        "    self.model=get_layer(layer_type)(in_channels=2, out_channels=output_dim, act=activation_gcn, norm=norm, num_layers=num_layers_gcn, hidden_channels=hidden_channels,dropout=dropout)\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "  def forward(self, dic_batch):\n",
        "    x = self.model(self.coordinates,self.edge_index,self.distance)\n",
        "    x=torch.cat((x,torch.zeros(1,x.shape[1]).to(self.device)),dim=0)\n",
        "    embedding=x[dic_batch[\"pos_id\"]]\n",
        "    if self.normalize_features_independantly:\n",
        "      embedding=self.layer_normalisation(embedding)\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHalywx1i82o"
      },
      "outputs": [],
      "source": [
        "class TimeStampEmbedding(nn.Module):\n",
        "  def __init__(self,embedding_dim,normalize_features_independantly):\n",
        "    super().__init__()\n",
        "    #self.dropout = nn.Dropout(p=dropout)\n",
        "    self.month_embedding = nn.Embedding(num_embeddings=13,embedding_dim=embedding_dim)\n",
        "    self.day_embedding = nn.Embedding(num_embeddings=32,embedding_dim=embedding_dim)\n",
        "    self.hour_embedding = nn.Embedding(num_embeddings=25,embedding_dim=embedding_dim)\n",
        "    self.minute_embedding = nn.Embedding(num_embeddings=61,embedding_dim=embedding_dim)\n",
        "    self.second_embedding = nn.Embedding(num_embeddings=61,embedding_dim=embedding_dim)\n",
        "    self.normalize_features_independantly=normalize_features_independantly\n",
        "    if self.normalize_features_independantly:\n",
        "      self.layer_normalisation=torch.nn.LayerNorm(embedding_dim)\n",
        "  def forward(self,dict_batch):\n",
        "    embedding= self.month_embedding(dict_batch['month'])\n",
        "    embedding=+ self.day_embedding(dict_batch['day'])\n",
        "    embedding=+ self.hour_embedding(dict_batch['hour'])\n",
        "    embedding=+ self.minute_embedding(dict_batch['minute'])\n",
        "    embedding=+ self.second_embedding(dict_batch['second'])\n",
        "    if self.normalize_features_independantly:\n",
        "      embedding = self.layer_normalisation(embedding)\n",
        "    return embedding\n",
        "class StationIdEmbedding(nn.Module):\n",
        "  def __init__(self,embedding_dim,nb_of_pos_ids,normalize_features_independantly):\n",
        "    super().__init__()\n",
        "    self.normalize_features_independantly=normalize_features_independantly\n",
        "    if self.normalize_features_independantly:\n",
        "      self.layer_normalisation=torch.nn.LayerNorm(embedding_dim)\n",
        "    self.stationIdEmbedding=nn.Embedding(num_embeddings=nb_of_pos_ids,embedding_dim=embedding_dim)\n",
        "  def forward(self,dict_batch):\n",
        "    embedding=self.stationIdEmbedding(dict_batch[\"pos_id\"])\n",
        "    if self.normalize_features_independantly:\n",
        "      embedding = self.layer_normalisation(embedding)\n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht0do-5IZMvA"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Feature_embedding(nn.Module):\n",
        "\n",
        "  def __init__(self,config,net,device):\n",
        "    super().__init__()\n",
        "    self.num_features=2+config[\"use_gcn\"]\n",
        "    self.concatenate_features=config[\"concatenate_features\"]\n",
        "    self.embedding_dim=config[\"d_model\"]\n",
        "    if self.concatenate_features:\n",
        "      self.embedding_dim=int(self.embedding_dim/self.num_features)\n",
        "\n",
        "    list_feature_embedding=[StationIdEmbedding(self.embedding_dim,config[\"nb_of_pos_ids\"],config[\"normalize_features_independantly\"]),TimeStampEmbedding(self.embedding_dim,config[\"normalize_features_independantly\"])]\n",
        "    if config[\"use_gcn\"]:\n",
        "      list_feature_embedding.append(GCN_embedding( self.embedding_dim,config[\"layer_type\"],config[\"num_layers_gcn\"],config[\"hidden_channels\"],config[\"activation_gcn\"],config[\"norm\"],net,device,config[\"normalize_features_independantly\"],config['dropout']))\n",
        "    self.list_feature_embedding=nn.ModuleList(list_feature_embedding)\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "  def forward(self,dic_batch):\n",
        "    if self.concatenate_features:\n",
        "      list_embeddings=[]\n",
        "      for feature_emebdding in self.list_feature_embedding:\n",
        "        list_embeddings.append(feature_emebdding(dic_batch))\n",
        "      embedding=torch.cat(list_embeddings,dim=2)\n",
        "    else:\n",
        "      embedding=torch.zeros(*dic_batch[\"pos_id\"].shape,self.embedding_dim).to(self.device)\n",
        "      for feature_emebdding in self.list_feature_embedding:\n",
        "        embedding+=feature_emebdding(dic_batch)\n",
        "\n",
        "    return embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhN3oIqdSY5H"
      },
      "outputs": [],
      "source": [
        "class Encoder_Decoder_Transformer(nn.Module):\n",
        "    def __init__(self,d_model,num_layers_transformer,num_heads,dropout_transformers,activation_transformers,batch_first=True):\n",
        "      super().__init__()\n",
        "      self.transformer=torch.nn.Transformer(d_model=d_model, nhead=num_heads, num_encoder_layers=num_layers_transformer, num_decoder_layers=num_layers_transformer, dropout=dropout_transformers,activation=get_activation(activation_transformers), batch_first=batch_first)\n",
        "    def forward(self,x,mask,src_key_padding_mask,is_causal):\n",
        "      return self.transformer(x,\n",
        "                       x,\n",
        "                       src_mask=mask,\n",
        "                       tgt_mask=mask,\n",
        "                       memory_mask=mask,\n",
        "                       src_key_padding_mask=src_key_padding_mask,\n",
        "                       tgt_key_padding_mask=src_key_padding_mask,\n",
        "                       memory_key_padding_mask=src_key_padding_mask,\n",
        "                       src_is_causal=is_causal,\n",
        "                       tgt_is_causal=is_causal,\n",
        "                       memory_is_causal=is_causal)\n",
        "\n",
        "def get_Transformer_architecture(d_model,encoder_only,num_layers_transformer,num_heads,dropout_transformers,activation_transformers,batch_first=True):\n",
        "  if encoder_only:\n",
        "    encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads,batch_first=batch_first,activation=get_activation(activation_transformers),dropout=dropout_transformers)\n",
        "    return nn.TransformerEncoder(encoder_layer, num_layers=num_layers_transformer)\n",
        "  else:\n",
        "    return Encoder_Decoder_Transformer(d_model,num_layers_transformer,num_heads,dropout_transformers,activation_transformers,batch_first=batch_first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oy3XI4E5iCDi"
      },
      "outputs": [],
      "source": [
        "# @title Model\n",
        "from torch import nn\n",
        "from torch.nn import Embedding, LSTM\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self,d_model,activation_lstm):\n",
        "    super().__init__()\n",
        "    self.dim_perceptron=2*d_model\n",
        "    self.linear_perceptron_in=nn.Linear(d_model,self.dim_perceptron)\n",
        "    self.linear_perceptron_out=nn.Linear(self.dim_perceptron,d_model)\n",
        "    self.activation=get_activation(activation_lstm)\n",
        "  def forward(self,x):\n",
        "    return self.linear_perceptron_out(self.activation(self.linear_perceptron_in(x)))\n",
        "\n",
        "\n",
        "class Transformer_LSTM_Layer(nn.Module):\n",
        "  def __init__(self,d_model,output_regression_size,output_classfication_size,num_layers,lstm_layer_with_perceptron,lstm_layer_with_layer_norm,dropout,activation_lstm,batch_first):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lstm=LSTM(input_size=d_model, hidden_size=d_model,batch_first=batch_first,num_layers=1,dropout=dropout)\n",
        "    self.lstm_layer_with_perceptron=lstm_layer_with_perceptron\n",
        "    self.lstm_layer_with_layer_norm=lstm_layer_with_layer_norm\n",
        "    if self.lstm_layer_with_layer_norm:\n",
        "      self.layer_normalisation=torch.nn.LayerNorm(d_model)\n",
        "    if self.lstm_layer_with_perceptron:\n",
        "      self.mlp=MLP(d_model,activation_lstm)\n",
        "    self.dropout=nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self,x,batch_sizes,sorted_indices,unsorted_indices,lengths):\n",
        "    x=self.lstm(x)[0].data+x.data\n",
        "    x=torch.torch.nn.utils.rnn.PackedSequence(x, batch_sizes, sorted_indices, unsorted_indices)\n",
        "    if self.lstm_layer_with_layer_norm:\n",
        "      x,_=torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0.0)\n",
        "      x=self.layer_normalisation(x)\n",
        "      x=self.dropout(x)\n",
        "      x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    if self.lstm_layer_with_perceptron:\n",
        "      x=x.data\n",
        "      x=self.mlp(x)+x\n",
        "      x=torch.torch.nn.utils.rnn.PackedSequence(x, batch_sizes, sorted_indices, unsorted_indices)\n",
        "      if self.lstm_layer_with_layer_norm:\n",
        "        x,_=torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True, padding_value=0.0)\n",
        "        x=self.layer_normalisation(x)\n",
        "        x=self.dropout(x)\n",
        "        x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=lengths,batch_first=True, enforce_sorted=False)\n",
        "    return x\n",
        "class Abs(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "  def forward(self,x):\n",
        "    return torch.abs(x)\n",
        "\n",
        "class Exp(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "  def forward(self,x):\n",
        "    return torch.exp(x)\n",
        "\n",
        "class Sig(nn.Module):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "  def forward(self,x):\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "def get_positive_function(config):\n",
        "  match config[\"positive_function\"]:\n",
        "    case \"relu\":\n",
        "      return nn.ReLU()\n",
        "    case \"abs\":\n",
        "      return Abs()\n",
        "    case \"exp\":\n",
        "      return Exp()\n",
        "    case \"sig\":\n",
        "      return Sig()\n",
        "\n",
        "\n",
        "def get_activation(activation):\n",
        "  match activation:\n",
        "    case \"ReLU\":\n",
        "      return nn.ReLU()\n",
        "    case \"Tanh\":\n",
        "      return nn.Tanh()\n",
        "    case \"LeakyReLU\":\n",
        "      return nn.LeakyReLU()\n",
        "    case \"SiLU\":\n",
        "      return nn.SiLU()\n",
        "    case \"GELU\":\n",
        "      return nn.GELU()\n",
        "    case \"ELU\":\n",
        "      return nn.ELU()\n",
        "    case \"Mish\":\n",
        "      return nn.Mish()\n",
        "    case \"ReLU6\":\n",
        "      return nn.ReLU6()\n",
        "    case \"PReLU\":\n",
        "      return nn.PReLU()\n",
        "    case \"SELU\":\n",
        "      return nn.SELU()\n",
        "    case \"CELU\":\n",
        "      return nn.CELU()\n",
        "    case \"Hardsigmoid\":\n",
        "      return nn.Hardsigmoid()\n",
        "    case \"Softplus\":\n",
        "      return nn.Softplus()\n",
        "    case \"Hardshrink\":\n",
        "      return nn.Hardshrink()\n",
        "    case \"Sigmoid\":\n",
        "      return nn.Sigmoid()\n",
        "    case \"Hardtanh\":\n",
        "      return nn.Hardtanh()\n",
        "    case \"Tanhshrink\":\n",
        "      return nn.Tanhshrink()\n",
        "    case \"RReLU\":\n",
        "      return nn.RReLU()\n",
        "    case \"Softshrink\":\n",
        "      return nn.Softshrink()\n",
        "    case \"Softsign\":\n",
        "      return nn.Softsign()\n",
        "    case \"LogSigmoid\":\n",
        "      return nn.LogSigmoid()\n",
        "    case \"Softmin\":\n",
        "      return nn.Softmin()\n",
        "    case \"Hardswish\":\n",
        "      return nn.Hardswish()\n",
        "\n",
        "class  Transformer_encoder_LSTM_decoder(nn.Module):\n",
        "  def __init__(self,config,net,device):\n",
        "    super().__init__()\n",
        "    self.dropout=nn.Dropout(p=config[\"dropout\"])\n",
        "\n",
        "    self.normalize_features_globally=config[\"normalize_features_globally\"]\n",
        "    if self.normalize_features_globally:\n",
        "      self.global_layer_normalisation=torch.nn.LayerNorm(config[\"d_model\"])\n",
        "    self.feature_embedding=Feature_embedding(config,net,device)\n",
        "    self.activation=get_activation(config[\"activation\"])\n",
        "    if config[\"reg\"]:\n",
        "      self.positive_function=get_positive_function(config)\n",
        "    self.transformers_model=config[\"transformers_model\"]\n",
        "    if self.transformers_model>0:\n",
        "      self.num_layers_transformer=config[\"num_layers_transformer\"]\n",
        "      self.pos_encoder = get_PositionalEncoding(config[\"d_model\"], config[\"dropout_transformers\"], 100,config[\"learnable_pos_encoding\"])\n",
        "      self.transformer_model=get_Transformer_architecture(config[\"d_model\"],config[\"encoder_only\"],config[\"num_layers_transformer\"],config[\"num_heads\"],config[\"dropout_transformers\"],config[\"activation_transformers\"],True,)\n",
        "\n",
        "    self.lstm_model=config[\"lstm_model\"]\n",
        "    if self.lstm_model>0:\n",
        "      self.num_layers_lstm=config[\"num_layers_lstm\"]\n",
        "      self.transformer_lstm__list = nn.ModuleList([Transformer_LSTM_Layer(config[\"d_model\"],2,config[\"nb_of_pos_ids\"],config[\"num_layers_lstm\"],config[\"lstm_layer_with_perceptron\"],config[\"lstm_layer_with_layer_norm\"],config[\"dropout_lstm\"],config[\"activation_lstm\"],True) for layer in range(config[\"num_layers_lstm\"])])\n",
        "    self.linear_reg=nn.Linear(config[\"d_model\"],2)\n",
        "    self.classifier=nn.Linear(config[\"d_model\"],config[\"nb_of_pos_ids\"])\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "\n",
        "  def forward(self,dic_batch,reg):\n",
        "    if self.transformers_model:\n",
        "      x=self.feature_embedding(dic_batch)\n",
        "      if self.normalize_features_globally:\n",
        "        x= self.global_layer_normalisation(x)\n",
        "      x=self.dropout(x)\n",
        "      x=self.pos_encoder(x)\n",
        "      with torch.no_grad():\n",
        "        mask_x = get_mask(x.shape[0],x.shape[1],dic_batch[\"lengths\"],self.device)\n",
        "        causal_mask=torch.nn.Transformer.generate_square_subsequent_mask(x.shape[1],device=self.device)\n",
        "      x=self.transformer_model(x,causal_mask,mask_x,is_causal=True)\n",
        "    if self.lstm_model:\n",
        "      if self.transformers_model:\n",
        "        x+=self.feature_embedding(dic_batch)\n",
        "      else:\n",
        "        x=self.feature_embedding(dic_batch)\n",
        "      if self.normalize_features_globally:\n",
        "        x= self.global_layer_normalisation(x)\n",
        "      x=self.dropout(x)\n",
        "    x=torch.nn.utils.rnn.pack_padded_sequence(x, lengths=dic_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    batch_sizes=x.batch_sizes\n",
        "    sorted_indices=x.sorted_indices\n",
        "    unsorted_indices=x.unsorted_indices\n",
        "    if self.lstm_model>0:\n",
        "      for transformer_lstm in self.transformer_lstm__list:\n",
        "        x=transformer_lstm(x,batch_sizes,sorted_indices,unsorted_indices,dic_batch[\"lengths\"])\n",
        "    x=self.activation(x.data)\n",
        "    out={}\n",
        "    out[\"next_station\"]=torch.nn.utils.rnn.PackedSequence(self.classifier(x), batch_sizes, sorted_indices, unsorted_indices)\n",
        "    if reg:\n",
        "      out[\"time_regression\"]=torch.nn.utils.rnn.PackedSequence(self.positive_function(self.linear_reg(x)), batch_sizes, sorted_indices, unsorted_indices)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNtPp4XO1fz"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG3BJIKMGsM-"
      },
      "outputs": [],
      "source": [
        "from torch import autocast\n",
        "def evaluate(model,dataloader,device,reg=False):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc=0\n",
        "    nb_points=0\n",
        "    valid_results={}\n",
        "    for dict_batch in dataloader:\n",
        "      for key in dict_batch:\n",
        "        if key!=\"lengths\":\n",
        "          dict_batch[key]=dict_batch[key].to(device)\n",
        "      with autocast(device_type=device.type):\n",
        "        out=model(dict_batch,reg=reg)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "        acc+=(out[\"next_station\"].data.argmax(dim=1)==target_pos_ids.data).sum().item()\n",
        "        nb_points+=out[\"next_station\"].data.shape[0]\n",
        "    acc=acc/nb_points\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoDnxzqRWr-5"
      },
      "outputs": [],
      "source": [
        "# @title loss\n",
        "from torch import nn\n",
        "class Loss_next_station_classification(nn.Module):\n",
        "  def __init__(self, ) -> None:\n",
        "    super().__init__()\n",
        "    self.criterion=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, out, target_pos_ids):\n",
        "    loss_classification=self.criterion(out.data,target_pos_ids.data)\n",
        "    return loss_classification\n",
        "\n",
        "class Loss_time_regression(nn.Module):\n",
        "  def __init__(self, ) -> None:\n",
        "    super().__init__()\n",
        "    self.criterion = nn.MSELoss(reduction='none')\n",
        "  def forward(self,out,dict_batch):\n",
        "    time_targets=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"time_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    mask_time_targets = (time_targets.data != -1)\n",
        "    loss_regression=self.criterion(out.data,time_targets.data)\n",
        "    loss_regression = (loss_regression * mask_time_targets.float()).mean()\n",
        "    return loss_regression\n",
        "\n",
        "class Total_loss(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.loss_next_station_classification = Loss_next_station_classification()\n",
        "    self.loss_time_regression = Loss_time_regression()\n",
        "\n",
        "  def forward(self, out, dict_batch, reg=False):\n",
        "    target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "    loss_classification=self.loss_next_station_classification(out[\"next_station\"],target_pos_ids)\n",
        "    loss_total=loss_classification\n",
        "    if reg:\n",
        "      loss_time_regression=self.loss_time_regression(out[\"time_regression\"],dict_batch)\n",
        "      loss_total+=loss_time_regression\n",
        "    return loss_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ibzvugSLizvL"
      },
      "outputs": [],
      "source": [
        "# @title utils\n",
        "\n",
        "def f_unpack_dict(dct):\n",
        "    res = {}\n",
        "    for (k, v) in dct.items():\n",
        "        if isinstance(v, dict):\n",
        "            res = {**res, **f_unpack_dict(v)}\n",
        "        else:\n",
        "            res[k] = v\n",
        "\n",
        "    return res\n",
        "\n",
        "def get_file_name(name,path=\".\"):\n",
        "  exist=True\n",
        "  idx=0\n",
        "  while exist:\n",
        "    file_path=os.path.join(path,name+\"_\"+str(idx))\n",
        "    exist=os.path.exists(file_path)\n",
        "    idx+=1\n",
        "  return file_path\n",
        "\n",
        "\n",
        "def get_last_file_name(name,path=\".\"):\n",
        "  exist=True\n",
        "  idx=0\n",
        "  file_path=None\n",
        "  while exist:\n",
        "    last_file=file_path\n",
        "    file_path=os.path.join(path,name+\"_\"+str(idx))\n",
        "    exist=os.path.exists(file_path)\n",
        "    idx+=1\n",
        "  return last_file\n",
        "\n",
        "def get_file_name_2(name,path=\".\"):\n",
        "  exist=True\n",
        "  i=1\n",
        "  for file_or_folder in os.listdir(path):\n",
        "    if os.path.isfile(os.path.join(path,file_or_folder)) and file_or_folder.startswith(name):\n",
        "        idx=file_or_folder.split(\"_\")[-2]\n",
        "        if idx.isdigit():\n",
        "          i=max(i,int(idx)+1)\n",
        "  return os.path.join(path,name+\"_\"+str(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7DWtAusO6ue"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Bfn1b1O7cH"
      },
      "source": [
        "## hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkCi3L-UKKtv",
        "outputId": "02ede7ee-852f-4b7e-bada-634c30e020ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray[tune]\n",
            "  Downloading ray-2.9.3-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.5.3)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (14.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.25.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n",
            "Installing collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.9.3 tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"ray[tune]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNO-AvQjH03u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch.optim as optim\n",
        "from ray import train, tune\n",
        "from ray.tune.schedulers import ASHAScheduler,AsyncHyperBandScheduler\n",
        "from ray.util.accelerators import NVIDIA_TESLA_V100\n",
        "from hyperopt import hp,Trials\n",
        "import ray\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "\n",
        "def get_model(config,net,device):\n",
        "  return Transformer_encoder_LSTM_decoder(config,net=net,device=device\n",
        "                                          ).to(device)\n",
        "\n",
        "def update_best_acc(model,valid_acc,best_acc,nb_epochs_without_improvement):\n",
        "    if valid_acc > best_acc :\n",
        "      nb_epochs_without_improvement=0\n",
        "      best_acc=valid_acc\n",
        "    else:\n",
        "      nb_epochs_without_improvement+=1\n",
        "    return best_acc,nb_epochs_without_improvement\n",
        "def get_LRScheduler(optimizer,config,epochs):\n",
        "  match config[\"scheduler\"]:\n",
        "    case None:\n",
        "      return None\n",
        "    case \"StepLR\":\n",
        "      return optim.lr_scheduler.StepLR(optimizer,step_size=config[\"step_size\"],gamma=config[\"gamma\"])\n",
        "    case \"ReduceLROnPlateau\":\n",
        "      return optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=config[\"factor\"],patience=config[\"patience\"],threshold=config[\"threshold\"],cooldown=config[\"cooldown\"])\n",
        "    case \"ExponentialLR\":\n",
        "      return optim.lr_scheduler.ExponentialLR(optimizer,gamma=config[\"gamma\"])\n",
        "    case \"CosineAnnealingLR\":\n",
        "      return optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=config[\"T_max\"],eta_min=config[\"eta_min\"])\n",
        "    case \"CyclicLR\":\n",
        "      return optim.lr_scheduler.CyclicLR(optimizer,base_lr=config[\"base_lr\"],max_lr=config[\"max_lr\"],step_size_up=config[\"step_size_up\"],mode=config[\"mode\"],cycle_momentum=False)\n",
        "\n",
        "def get_otimizer(parameters,config):\n",
        "  match config[\"optimizer\"]:\n",
        "    case \"Adam\":\n",
        "      return optim.Adam(parameters,lr=config[\"lr\"],betas=(config[\"beta_1\"],config[\"beta_2\"]),eps=config[\"eps\"],weight_decay=config[\"weight_decay\"],amsgrad=config[\"amsgrad\"])\n",
        "    case \"AdamW\":\n",
        "      return optim.AdamW(parameters,lr=config[\"lr\"],weight_decay=config[\"weight_decay\"],amsgrad=config[\"amsgrad\"])\n",
        "    case \"SGD\":\n",
        "      return optim.SGD(parameters,lr=config[\"lr\"],momentum=config[\"momentum\"],weight_decay=config[\"weight_decay\"],nesterov=config[\"nesterov\"])\n",
        "    case \"RMSprop\":\n",
        "      return optim.RMSprop(parameters,lr=config[\"lr\"],alpha=config[\"alpha\"],eps=config[\"eps\"],weight_decay=config[\"weight_decay\"],momentum=config[\"momentum\"],centered=config[\"centered\"])\n",
        "def apply_lr_scheduler(lr_scheduler,acc,config):\n",
        "  match config[\"scheduler\"]:\n",
        "    case \"ReduceLROnPlateau\":\n",
        "      lr_scheduler.step(acc)\n",
        "    case None:\n",
        "      pass\n",
        "    case _:\n",
        "      lr_scheduler.step()\n",
        "\n",
        "def train_(config,model,dataloaders):\n",
        "    print(config)\n",
        "    device=get_device()\n",
        "    epochs= config[\"epochs_classifcation_only\"]\n",
        "    if config[\"reg\"]:\n",
        "      epochs+=config[\"epochs_complete_problem\"]\n",
        "    optimizer_encoder = get_otimizer(model.parameters(),config)\n",
        "    lr_scheduler=get_LRScheduler(optimizer_encoder,config,epochs)\n",
        "    criterion = Total_loss()\n",
        "    best_acc=-1\n",
        "    nb_epochs_without_improvement=0\n",
        "    for epoch in range(epochs):\n",
        "      reg=epoch >= config[\"epochs_classifcation_only\"]\n",
        "      epoch_losses=[]\n",
        "      model.train()\n",
        "      i=0\n",
        "      for dict_batch in dataloaders[\"train\"]:\n",
        "        optimizer_encoder.zero_grad()\n",
        "        i+=1\n",
        "        if i>=config[\"nb_batchs\"]:\n",
        "          break\n",
        "        dict_batch=set_dic_to(dict_batch,device)\n",
        "        with autocast(device_type=device.type):\n",
        "          out=model(dict_batch, reg)\n",
        "          loss=criterion(out,dict_batch, reg)\n",
        "          if loss.isnan():\n",
        "            print(\"loss is undifined\")\n",
        "            return -1\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer_encoder.step()\n",
        "\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "        dict_batch.clear()\n",
        "        out.clear()\n",
        "        del out, loss, dict_batch\n",
        "      epoch_loss=np.array(epoch_losses).mean()\n",
        "      valid_acc = evaluate(model,dataloaders[\"valid\"],device)\n",
        "      apply_lr_scheduler(lr_scheduler,valid_acc,config)\n",
        "      best_acc, nb_epochs_without_improvement = update_best_acc(model,valid_acc,best_acc,nb_epochs_without_improvement)\n",
        "      if config[\"early_stopping\"]< nb_epochs_without_improvement:\n",
        "        return best_acc\n",
        "\n",
        "      print(\"epoch: \", epoch, \"loss : \", epoch_loss, \"acc: \", valid_acc)\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "def get_datasets():\n",
        "    list_users,vocab=get_processed_data(src_directory_raw_data=\"drive/MyDrive/Shanghai-Telcome-Six-Months-DataSet\",\n",
        "                                      directory_raw_data='/content/dataset-telecom-6month',\n",
        "                                      fixed_time_encoding=False,\n",
        "                                      input_position=True,\n",
        "                                      full_dataset=True,\n",
        "                                      spliting_long_sequences=False,\n",
        "                                      with_repeated_connections=False,\n",
        "                                      max_sequence_length=100,\n",
        "                                      min_sequence_size=2,\n",
        "                                      save=False,\n",
        "                                      path_to_save_dataset=\"/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3\",\n",
        "                                      download=False,\n",
        "                                      load_dataset_path=\"/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3\",)\n",
        "    net=get_net(vocab)\n",
        "    reproducibility_seed=get_reproducible_seeds()[0]\n",
        "    dataset=VariableLengthDatasetWithPosID(list_users)\n",
        "    generator = torch.Generator().manual_seed(reproducibility_seed)\n",
        "    dataset_list=torch.utils.data.random_split(dataset,[0.8,0.1,0.1],generator)\n",
        "    return dataset_list,net,len(vocab)+1\n",
        "\n",
        "def get_dataloaders(datasets,batch_size):\n",
        "    train_dataset=datasets[0]\n",
        "    valid_dataset=datasets[1]\n",
        "    train_dataloader=DataLoader(train_dataset,batch_size=batch_size,collate_fn=collate_fn_padd,shuffle=True)\n",
        "    valid_dataloader=DataLoader(valid_dataset,batch_size=256,collate_fn=collate_fn_padd,shuffle=False)\n",
        "    return {\"train\":train_dataloader,\"valid\":valid_dataloader}\n",
        "\n",
        "def eval_config(config,data=None,net=None):\n",
        "    device=get_device()\n",
        "    config=f_unpack_dict(config)\n",
        "    dataloaders=get_dataloaders(data,config[\"batch_size\"])\n",
        "    if config[\"use_gcn\"]:\n",
        "      model=get_model(config,net,device)\n",
        "    else:\n",
        "      model=get_model(config,None,device)\n",
        "    best_acc = train_(config,model,dataloaders)\n",
        "    return {\"valid_accuracy\": best_acc}\n",
        "\n",
        "def run_xp(xp_name,storage_path,algo,num_samples=10, max_num_epochs=10, gpus_per_trial=1, test=True):\n",
        "  os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
        "  print(os.environ[\"OMP_NUM_THREADS\"])\n",
        "  datasets,net,nb_of_pos_ids=get_datasets()\n",
        "  ray.shutdown()\n",
        "  config_dict= {\n",
        "        \"max_len\":100,\n",
        "        \"nb_of_pos_ids\":nb_of_pos_ids,\n",
        "        \"batch_size\":2**hp.uniformint(\"batch_size\",4,7),\n",
        "        \"nb_batchs\":12*hp.uniformint(\"nb_batchs\",1,15),\n",
        "        \"early_stopping\":5,\n",
        "        \"epochs_classifcation_only\":50,\n",
        "        \"reg_choice\":hp.choice(\"reg_choice\",\n",
        "                        [\n",
        "                            {\"reg\":True,\"epochs_complete_problem\":hp.uniformint(\"epochs_complete_problem\",0,50)},\n",
        "                            {\"reg\":False},\n",
        "                        ]),\n",
        "        \"learning_rate_scheduler_choice\": hp.choice(\n",
        "          \"learning_rate_scheduler_choice\",\n",
        "          [\n",
        "              {\n",
        "                  \"scheduler\": \"StepLR\",\n",
        "                  \"step_size\": hp.uniformint(\"step_size\", 1, 30),\n",
        "                  \"gamma\": hp.uniform(\"gamma_slr\", 0, 0.99),\n",
        "              },\n",
        "              {\n",
        "                  \"scheduler\": \"ReduceLROnPlateau\",\n",
        "                  \"factor\": hp.uniform(\"factor\", 0, 0.9),\n",
        "                  \"patience\": hp.uniformint(\"patience\", 1, 10),\n",
        "                  \"threshold\": hp.loguniform(\"threshold\",-12,-1),\n",
        "                  \"cooldown\":hp.uniformint(\"cooldown\",0,10)\n",
        "              },\n",
        "              {\n",
        "                  \"scheduler\":\"ExponentialLR\",\n",
        "                  \"gamma\":hp.uniform(\"gamma_elr\", 0, 0.9),\n",
        "              },\n",
        "            {\"scheduler\": None}  # No scheduler\n",
        "        ]\n",
        "    ),\n",
        "      \"optimizer\": \"AdamW\", \"lr\": hp.loguniform(\"lr\", -15, -2),\"weight_decay\":hp.loguniform(\"weight_decay_adam\",-21,-1),\"amsgrad\":hp.choice(\"amsgrad\",[True,False]),\n",
        "      \"input_size\":2,\n",
        "      \"d_model\":24*hp.uniformint(\"d_model\",1,34),\n",
        "      \"dropout\":hp.uniform(\"dropout\",0,0.5),\n",
        "      \"normalize_features_independantly\":hp.choice(\"normalize_features_independantly\",[True,False]),\n",
        "      \"normalize_features_globally\":hp.choice(\"normalize_features_globally\",[True,False]),\n",
        "      \"concatenate_features\":hp.choice(\"concatenate_features\",[True,False]),\n",
        "      \"use_gcn_choice\":hp.choice(\"use_gcn_choice\",\n",
        "                        [\n",
        "                            {\"use_gcn\":True,\n",
        "                             \"layer_type\":hp.choice(\"layer_type\",[\"GCNConv\",\"GraphSAGE\",\"GAT\"]),\n",
        "                             \"num_layers_gcn\":hp.uniformint(\"num_layers_gcn\",1,10),\n",
        "                             \"activation_gcn\": hp.choice(\"activation_gcn\",\n",
        "                              ['swish', 'ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']\n",
        "                             ),\n",
        "                             \"norm\": hp.choice(\"norm\",\n",
        "                                               ['BatchNorm', 'GraphNorm', 'LayerNorm', 'PairNorm', 'InstanceNorm']\n",
        "                             ),\n",
        "                             \"dropout_gcn\":hp.uniform(\"dropout_gcn\",0,0.5),\n",
        "                             \"hidden_channels\":2**hp.uniformint(\"hidden_channels\",4,9)\n",
        "                             },\n",
        "                            {\"use_gcn\":False}\n",
        "                        ]),\n",
        "      \"activation\": hp.choice(\n",
        "                \"activation\",\n",
        "                 ['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),\n",
        "      \"positive_function\":hp.choice(\"positive_function\",[\"relu\",\"exp\",\"abs\",\"sig\"]),\n",
        "      \"transformers_model\":True,\n",
        "      \"num_layers_transformer\":hp.uniformint(\"num_layers_transformer\",1,5),\n",
        "      \"encoder_only\":hp.choice(\"encoder_only\",[True,False]),\n",
        "      \"num_heads\":3*2**hp.uniformint('num_heads', 0, 3),\n",
        "      \"learnable_pos_encoding\": hp.choice(\"learnable_pos_encoding\",[True,False]),\n",
        "      \"activation_transformers\": hp.choice(\"activation_transformers\",['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),\n",
        "      \"dropout_transformers\":hp.uniform(\"dropout_transformers\",0,0.5),\n",
        "\n",
        "      \"lstm_model_choice\": hp.choice(\"lstm_model_choice\",\n",
        "                                     [{\"lstm_model\":True,\n",
        "                                       \"num_layers_lstm\":hp.uniformint(\"num_layers_lstm\",1,5),\n",
        "                                       \"lstm_layer_with_perceptron\":\n",
        "                                        hp.choice(\"lstm_layer_with_perceptron\",\n",
        "                                         [{\"lstm_layer_with_perceptron\":True,\n",
        "                                           \"activation_lstm\":hp.choice(\"activation_lstm\",['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),},\n",
        "                                          {\"lstm_layer_with_perceptron\":False,\n",
        "                                           \"activation_lstm\":None}]),\n",
        "                                       \"lstm_layer_with_layer_norm\":hp.choice(\"lstm_layer_with_layer_norm\",[True,False]),\n",
        "                                       \"dropout_lstm\":hp.uniform(\"dropout_lstm\",0,0.5),\n",
        "                                       },\n",
        "                                      {\"lstm_model\":False}])}\n",
        "  if algo==None:\n",
        "    algo = HyperOptSearch(space=config_dict, metric=\"valid_accuracy\", mode=\"max\", random_state_seed=get_reproducible_seeds()[0])\n",
        "  trainable_with_gpu = tune.with_resources(eval_config, {\"cpu\": 2, \"gpu\": 1})\n",
        "  tuner = tune.Tuner(\n",
        "        tune.with_parameters(trainable_with_gpu,data=datasets,net=net),\n",
        "        tune_config=tune.TuneConfig(\n",
        "                                search_alg=algo,\n",
        "                                max_concurrent_trials=1,\n",
        "                                num_samples=1 if test else num_samples,\n",
        "                                    ),\n",
        "        run_config=train.RunConfig(\n",
        "            name=xp_name,\n",
        "            storage_path=storage_path,\n",
        "            verbose=0)\n",
        "    )\n",
        "  # To enable GPUs, use this instead:\n",
        "  results = tuner.fit()\n",
        "  return results, algo\n",
        "\n",
        "\n",
        "def save_config_xps_to_drive(xps_name,drive_path,xp_size,xps_number,accuracy_target,max_num_epochs):\n",
        "  dic_config={\n",
        "      \"xps_name\":xps_name,\n",
        "      \"xp_size\":xp_size,\n",
        "      \"xps_number\":xps_number,\n",
        "      \"current_xp\": -1,\n",
        "      \"best_xp\": {\"idx\":-1, \"valid_accuracy\": -1}\n",
        "  }\n",
        "  xps_path=os.path.join(drive_path,xps_name)\n",
        "  xps_configs= os.path.join(xps_path,\"xps_configs\")\n",
        "  os.makedirs(xps_path,exist_ok=True)\n",
        "  if not os.path.exists(xps_configs):\n",
        "    torch.save(dic_config,xps_configs)\n",
        "  return xps_path,xps_configs\n",
        "\n",
        "\n",
        "def update_config_dictionnary(xps_configs,best_results,num_xp):\n",
        "\n",
        "  config_dic=torch.load(xps_configs)\n",
        "  config_dic[\"current_xp\"]=num_xp\n",
        "  if config_dic[\"best_xp\"][\"valid_accuracy\"]<best_results:\n",
        "    config_dic[\"best_xp\"][\"valid_accuracy\"]=best_results\n",
        "    config_dic[\"best_xp\"][\"idx\"]=num_xp\n",
        "  torch.save(config_dic,xps_configs)\n",
        "\n",
        "\n",
        "\n",
        "def update_and_save(xp_name,xps_path,xps_configs,storage_path,results,algo,num_xp,accuracy_target):\n",
        "  best_results=results.get_best_result(metric='valid_accuracy',mode='max').metrics['valid_accuracy']\n",
        "  accarucy_target_not_reached= best_results< accuracy_target\n",
        "  update_config_dictionnary(xps_configs,best_results,num_xp)\n",
        "  shutil.copytree(os.path.join(storage_path,xp_name),os.path.join(xps_path,xp_name),dirs_exist_ok=True)\n",
        "  if num_xp>=1:\n",
        "    shutil.rmtree(os.path.join(xps_path,\"xp_num_\"+str(num_xp-1)))\n",
        "  shutil.rmtree(os.path.join(storage_path,xp_name))\n",
        "  return accarucy_target_not_reached\n",
        "\n",
        "\n",
        "def run_all_xp(xps_name=\"hyperparameter_tuning_projet_long\", num_xp=0,algo=None, xp_size=10, xps_number=10, accuracy_target=0.98, max_num_epochs=30, storage_path='/content/',drive_path=\"/content/drive/MyDrive\"):\n",
        "    accarucy_target_not_reached=True\n",
        "    num_xp=num_xp\n",
        "    xps_path,xps_configs=save_config_xps_to_drive(xps_name,drive_path,xp_size,xps_number,accuracy_target,max_num_epochs)\n",
        "    while num_xp<xps_number and accarucy_target_not_reached:\n",
        "      xp_name= \"xp_num_\"+str(num_xp)\n",
        "      results,algo=run_xp(xp_name,storage_path,algo,num_samples=xp_size, max_num_epochs=max_num_epochs, gpus_per_trial=1, test=False)\n",
        "      accarucy_target_not_reached=update_and_save(xp_name,xps_path,xps_configs,storage_path,results,algo,num_xp,accuracy_target)\n",
        "      num_xp+=1\n",
        "    return,results,algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPhHgHrMlJUr",
        "outputId": "26076737-6c10-4dbc-ed14-34e3e0332aee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "xps_path=os.path.join(\"/content/drive/MyDrive\",\"hyperparameter_tuning_projet_long\")\n",
        "os.path.exists(xps_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpTBoYuDN21J"
      },
      "source": [
        "# test hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "s6BMsccMiKY1"
      },
      "outputs": [],
      "source": [
        "# @title test tuning\n",
        "from hyperopt import hp, pyll\n",
        "datasets,net,nb_of_pos_ids=get_datasets()\n",
        "space={\n",
        "        \"max_len\":100,\n",
        "        \"nb_of_pos_ids\":nb_of_pos_ids,\n",
        "        \"batch_size\":2**hp.uniformint(\"batch_size\",4,7),\n",
        "        \"nb_batchs\":12*hp.uniformint(\"nb_batchs\",1,16),\n",
        "        \"early_stopping\":hp.uniformint(\"early_stopping\",1,10),\n",
        "        \"epochs_classifcation_only\":hp.uniformint(\"epochs_classifcation_only\",1,80),\n",
        "        \"reg_choice\":hp.choice(\"reg_choice\",\n",
        "                        [\n",
        "                            {\"reg\":True,\"epochs_complete_problem\":hp.uniformint(\"epochs_complete_problem\",0,50)},\n",
        "                            {\"reg\":False},\n",
        "                        ]),\n",
        "        \"learning_rate_scheduler_choice\": hp.choice(\n",
        "          \"learning_rate_scheduler_choice\",\n",
        "          [\n",
        "              {\n",
        "                  \"scheduler\": \"StepLR\",\n",
        "                  \"step_size\": hp.uniformint(\"step_size\", 1, 30),\n",
        "                  \"gamma\": hp.uniform(\"gamma_slr\", 0, 0.99),\n",
        "              },\n",
        "              {\n",
        "                  \"scheduler\": \"ReduceLROnPlateau\",\n",
        "                  \"factor\": hp.uniform(\"factor\", 0, 0.9),\n",
        "                  \"patience\": hp.uniformint(\"patience\", 1, 10),\n",
        "                  \"threshold\": hp.loguniform(\"threshold\",-12,-1),\n",
        "                  \"cooldown\":hp.uniformint(\"cooldown\",0,10)\n",
        "              },\n",
        "              {\n",
        "                  \"scheduler\":\"ExponentialLR\",\n",
        "                  \"gamma\":hp.uniform(\"gamma_elr\", 0, 0.9),\n",
        "              },\n",
        "            {\"scheduler\": None}  # No scheduler\n",
        "        ]\n",
        "    ),\n",
        "      \"optimizer\": hp.choice(\"optimizer\",[\"Adam\",\"AdamW\"]), \"lr\": hp.loguniform(\"lr\", -17, -2),\"beta_1\":hp.uniform(\"beta_1\", 0.8, 1), \"beta_2\" : hp.uniform(\"beta_2\", 0.95, 1),\"eps\": hp.loguniform(\"eps_adam\", -20, -12),\"weight_decay\":hp.loguniform(\"weight_decay_adam\",-20,-1),\"amsgrad\":hp.choice(\"amsgrad\",[True,False]),\n",
        "      \"input_size\":2,\n",
        "      \"d_model\":24*hp.uniformint(\"d_model\",1,60),\n",
        "      \"dropout\":hp.uniform(\"dropout\",0,1),\n",
        "      \"normalize_features_independantly\":hp.choice(\"normalize_features_independantly\",[True,False]),\n",
        "      \"normalize_features_globally\":hp.choice(\"normalize_features_globally\",[True,False]),\n",
        "      \"concatenate_features\":hp.choice(\"concatenate_features\",[True,False]),\n",
        "      \"use_gcn_choice\":hp.choice(\"use_gcn_choice\",\n",
        "                        [\n",
        "                            {\"use_gcn\":True,\n",
        "                             \"layer_type\":hp.choice(\"layer_type\",[\"GCNConv\",\"GraphSAGE\",\"GAT\"]),\n",
        "                             \"num_layers_gcn\":hp.uniformint(\"num_layers_gcn\",1,10),\n",
        "                             \"activation_gcn\": hp.choice(\"activation_gcn\",\n",
        "                              ['swish', 'ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']\n",
        "                             ),\n",
        "                             \"norm\": hp.choice(\"norm\",\n",
        "                                               ['BatchNorm', 'GraphNorm', 'LayerNorm', 'PairNorm', 'InstanceNorm']\n",
        "                             ),\n",
        "                             \"dropout_gcn\":hp.uniform(\"dropout_gcn\",0,1),\n",
        "                             \"hidden_channels\":2**hp.uniformint(\"hidden_channels\",6,11)\n",
        "                             },\n",
        "\n",
        "                        ]),\n",
        "      \"activation\": hp.choice(\n",
        "                \"activation\",\n",
        "                 ['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),\n",
        "      \"positive_function\":hp.choice(\"positive_function\",[\"relu\",\"exp\",\"abs\",\"sig\"]),\n",
        "      \"transformers_model\":True,\n",
        "      \"num_layers_transformer\":hp.uniformint(\"num_layers_transformer\",1,6),\n",
        "      \"encoder_only\":hp.choice(\"encoder_only\",[True,False]),\n",
        "      \"num_heads\":3*2**hp.uniformint('num_heads', 0, 3),\n",
        "      \"learnable_pos_encoding\": hp.choice(\"learnable_pos_encoding\",[True,False]),\n",
        "      \"activation_transformers\": hp.choice(\"activation_transformers\",['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),\n",
        "      \"dropout_transformers\":hp.uniform(\"dropout_transformers\",0,1),\n",
        "\n",
        "      \"lstm_model_choice\": hp.choice(\"lstm_model_choice\",\n",
        "                                     [{\"lstm_model\":True,\n",
        "                                       \"num_layers_lstm\":hp.uniformint(\"num_layers_lstm\",1,6),\n",
        "                                       \"lstm_layer_with_perceptron\":\n",
        "                                        hp.choice(\"lstm_layer_with_perceptron\",\n",
        "                                         [{\"lstm_layer_with_perceptron\":True,\n",
        "                                           \"activation_lstm\":hp.choice(\"activation_lstm\",['ReLU6', 'PReLU', 'SELU', 'ELU', 'Mish', 'CELU', 'ReLU', 'Hardsigmoid', 'Tanh', 'LeakyReLU', 'Softplus', 'Hardshrink','Sigmoid', 'Hardtanh', 'SiLU', 'Tanhshrink', 'RReLU', 'Softshrink', 'Softsign', 'LogSigmoid', 'Softmin', 'GELU', 'Hardswish']),},\n",
        "                                          {\"lstm_layer_with_perceptron\":False,\n",
        "                                           \"activation_lstm\":None}]),\n",
        "                                       \"lstm_layer_with_layer_norm\":hp.choice(\"lstm_layer_with_layer_norm\",[True,False]),\n",
        "                                       \"dropout_lstm\":hp.uniform(\"dropout_lstm\",0,1),\n",
        "                                       },\n",
        "                                      {\"lstm_model\":False}])}\n",
        "config=pyll.stochastic.sample(space)\n",
        "#print(config)\n",
        "eval_config(config,data=datasets,net=net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEF-Ae5AHtQB"
      },
      "outputs": [],
      "source": [
        "run_xp('test',\"/content/test\",None,num_samples=1, max_num_epochs=1, gpus_per_trial=1, test=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi533mpake8q",
        "outputId": "92d2e0d6-5083-46f2-8bea-1f88d15d805d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/convert.py:278: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  data_dict[key] = torch.as_tensor(value)\n",
            "2024-03-10 15:58:48,418\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 15:59:03,888\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 15:59:03,892\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_0        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_0\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_0`\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.351885955804556 and num_layers=1\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'LeakyReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 240, 'dropout': 0.3308533620831129, 'dropout_transformers': 0.10530742664412235, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 8, 'factor': 0.22615437911339334, 'patience': 4, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.15438065049384908, 'lr': 0.0034272191380994447, 'dropout_lstm': 0.351885955804556, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'GELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ReLU6', 'dropout_gcn': 0.3569564862177346, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 5, 'use_gcn': True, 'weight_decay': 0.001930154578734693}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.891819767330004 acc:  0.001496103432105933\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.61094215641851 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.554037446561067 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.3910945394764775 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.4209853669871455 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.406524699667226 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.3644989262456475 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  7.346557783043903 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  8 loss :  7.3267995792886484 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  9 loss :  7.312584172124448 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  10 loss :  7.307940047720204 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'RReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.18675068587957377, 'dropout_transformers': 0.3595031969540146, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 1.5020153742089604e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.0782963876709552e-06}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.952223309499775 acc:  0.0020320210794274613\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.742134708130431 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.592309769042238 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.491322140493793 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.416580006034074 acc:  0.006029073532367193\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.361758286367634 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.327085943279152 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  7.301226658735446 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  8 loss :  7.281539437299717 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  9 loss :  7.282145083307506 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m GCNConv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.04776205521636728 and num_layers=1\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.12898822103770274, 'dropout_transformers': 0.07317228017938249, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.2380489027418383, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.002929487539519571, 'dropout_lstm': 0.04776205521636728, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Softshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'LogSigmoid', 'dropout_gcn': 0.47232527547133546, 'hidden_channels': 64, 'layer_type': 'GCNConv', 'norm': 'PairNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 3.091844816879973e-05}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.658536049498229 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.4163601739065985 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.382635184696743 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.384850053226247 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.368576666888068 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.36049573161021 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.3626523218235045 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Tanh', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': True, 'd_model': 360, 'dropout': 0.4068032169894544, 'dropout_transformers': 0.21990275770604306, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.03938924132288652, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 35, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 8.797209644513267e-06}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  9.700031453912908 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  8.765425942160867 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  8.144506801258434 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.901640545238148 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.674770962108266 acc:  0.0024786191188620682\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.706066218289462 acc:  0.0011611549025299778\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4884235046925847 and num_layers=1\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Softsign', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': False, 'd_model': 792, 'dropout': 0.35107325126754746, 'dropout_transformers': 0.0702825014820036, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7333551390392534, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 0.0018692153030350851, 'dropout_lstm': 0.4884235046925847, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softplus', 'dropout_gcn': 0.21221964608572902, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'InstanceNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 9.655507887512738e-05}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.526675327714667 acc:  0.009199919612352902\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  6.685379838368979 acc:  0.1520443025255119\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  5.5978735958237245 acc:  0.20755643882723354\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  4.651146627334227 acc:  0.2441774780608713\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  4.014069726668208 acc:  0.24268137462876538\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  3.6575067703982436 acc:  0.2945314070071232\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  3.43363194867789 acc:  0.29908670700935625\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  3.2657878944672736 acc:  0.31302056583971594\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  8 loss :  3.1206540343273117 acc:  0.33204564231963024\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  9 loss :  2.9959304246557763 acc:  0.3474086148761807\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  10 loss :  2.9548626635448043 acc:  0.3508697496817989\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  11 loss :  2.7835277390767295 acc:  0.35625125605698593\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  12 loss :  2.702949835593442 acc:  0.3660540830225755\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  13 loss :  2.670229061540351 acc:  0.3608288859611906\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  14 loss :  2.6131308811256684 acc:  0.3635754639037135\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  15 loss :  2.6136879518807654 acc:  0.37130160998593215\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  16 loss :  2.5122181636741363 acc:  0.37489672420338077\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  17 loss :  2.510549206331552 acc:  0.3743384766540875\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  18 loss :  2.4811981054673713 acc:  0.38414130361967713\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  19 loss :  2.435591890151242 acc:  0.3803005604805395\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  20 loss :  2.4053212274988014 acc:  0.3910412433289418\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  21 loss :  2.361987099590072 acc:  0.387379139405578\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  22 loss :  2.296965940889106 acc:  0.3985440903914432\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  23 loss :  2.2364868255982917 acc:  0.4014246477457964\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  24 loss :  2.1079573502023536 acc:  0.4013576580398812\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  25 loss :  2.14072446794395 acc:  0.40146930754973986\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  26 loss :  2.1133953289813308 acc:  0.40271978206015674\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  27 loss :  2.09514781222286 acc:  0.4026081325502981\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  28 loss :  2.058506001909095 acc:  0.40403724627648885\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  29 loss :  2.0298134777919357 acc:  0.4065158653953509\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  30 loss :  2.034773188901235 acc:  0.401625616863542\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  31 loss :  1.9588187947330704 acc:  0.4064488756894357\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  32 loss :  1.9671249849250518 acc:  0.40807895853337206\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  33 loss :  1.951262415173542 acc:  0.40935176294576064\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  34 loss :  1.9868915756064724 acc:  0.404684813433669\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  35 loss :  1.9509752572300922 acc:  0.4091731237299868\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  36 loss :  1.9242729882159866 acc:  0.4052877207869057\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  37 loss :  1.8821684567325085 acc:  0.40343433892325214\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  38 loss :  1.8662702362221408 acc:  0.40301007078578927\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'SELU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': False, 'd_model': 720, 'dropout': 0.4405757567491284, 'dropout_transformers': 0.21767555969668295, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.01505466658724738, 'scheduler': 'StepLR', 'step_size': 12, 'lr': 0.05923789305851488, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 31, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Hardtanh', 'dropout_gcn': 0.17789976084435616, 'hidden_channels': 64, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 3.8719120840699155e-08}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Softshrink', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': False, 'd_model': 192, 'dropout': 0.224725764957397, 'dropout_transformers': 0.41581494230155663, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 0.008019626644587035, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0017068902246654622}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.6657806316404855 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.424649547984582 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.354896964007661 acc:  0.0048455887278654845\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.340285148329407 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.322537636938896 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.325821039330869 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.314562666507167 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  7.299486102038667 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'LeakyReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.23862372665920106, 'dropout_transformers': 0.16822241873594856, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8805804239782127, 'scheduler': 'StepLR', 'step_size': 11, 'lr': 0.01918005616597375, 'dropout_lstm': 0.12265102397059996, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'SiLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'activation_gcn': 'GELU', 'dropout_gcn': 0.3312299098933155, 'hidden_channels': 32, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 8.515801470599703e-06}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12265102397059996 and num_layers=1\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  7.856042272261991 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.304978257827177 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.269775288705607 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.257794321948335 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.258833812393305 acc:  0.005560145590960856\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.2352835604252705 acc:  0.0061183931402541145\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.237831323201419 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  7.224393695365381 acc:  0.0061183931402541145\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Hardtanh', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.008983290547588452, 'dropout_transformers': 0.42279173878058113, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.47138544665608634, 'scheduler': 'ExponentialLR', 'lr': 0.04317843376262235, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 4, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.08220982562802928}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  8.468741462105198 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  7.287837414992483 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  7.279620060167814 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  7.258524729076185 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  7.232986465253328 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  7.2346875592281945 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  7.2641269633644505 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  7.238318764536005 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanhshrink', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': False, 'd_model': 168, 'dropout': 0.2834358787564809, 'dropout_transformers': 0.18831007898008334, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8438250640580393, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 4.10486923010962e-07, 'dropout_lstm': 0.23765197480638028, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softmin', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0028592866634322444}\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23765197480638028 and num_layers=1\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  0 loss :  8.091187409951653 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  1 loss :  8.08701518555762 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  2 loss :  8.068031284171091 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  3 loss :  8.084559836857755 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  4 loss :  8.083657472905978 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  5 loss :  8.068970707100881 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  6 loss :  8.075658173628256 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  7 loss :  8.06440319813473 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  8 loss :  8.084796999541807 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  9 loss :  8.079370915050237 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  10 loss :  8.077347077114482 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  11 loss :  8.07778846042257 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  12 loss :  8.07484288954399 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  13 loss :  8.06796673653831 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  14 loss :  8.065799746714847 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  15 loss :  8.061054793881699 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  16 loss :  8.071017057123319 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  17 loss :  8.070187400764143 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  18 loss :  8.075575754676066 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  19 loss :  8.06931091362322 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  20 loss :  8.060262727065824 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  21 loss :  8.065896181993082 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  22 loss :  8.061051704514195 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  23 loss :  8.061765932701004 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=3581)\u001b[0m epoch:  24 loss :  8.055510964192136 acc:  0.0006475671571801799\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 16:24:28,464\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 16:24:43,587\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 16:24:43,589\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_1        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_1\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_1`\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3839730900124464 and num_layers=1\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'LeakyReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 168, 'dropout': 0.01834855461248658, 'dropout_transformers': 0.09168808713381432, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8931843056885272, 'scheduler': 'ExponentialLR', 'lr': 0.02947138104242833, 'dropout_lstm': 0.3839730900124464, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Softshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardshrink', 'dropout_gcn': 0.38965632820385276, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'BatchNorm', 'num_layers_gcn': 10, 'use_gcn': True, 'weight_decay': 1.7400482213099208e-07}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.8568569765252585 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.392314603773214 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.286440792730299 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.278176065218651 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.240898326291877 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.24893039768025 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardsigmoid', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': False, 'd_model': 264, 'dropout': 0.19275515597834686, 'dropout_transformers': 0.1773049989318886, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.26215764606577713, 'scheduler': 'ExponentialLR', 'lr': 0.0010181387276466194, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 13, 'reg': True, 'transformers_model': True, 'activation_gcn': 'ReLU6', 'dropout_gcn': 0.17695542717377044, 'hidden_channels': 128, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 9, 'use_gcn': True, 'weight_decay': 0.00015129629232672986}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.647406474403713 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.418354324672533 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.367618664451268 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.319842608078666 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.328784921894902 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.318441059278405 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  7.324154045270837 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  7.335452266361402 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  7.341698418492856 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.32969834865691566 and num_layers=1\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.20452309705094546, 'dropout_transformers': 0.3225236367445611, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7734896597011514, 'scheduler': 'StepLR', 'step_size': 3, 'lr': 0.00022473415354181788, 'dropout_lstm': 0.32969834865691566, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.5750105157114694e-05}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.674260210483633 acc:  0.010495053926713262\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  6.985581742956283 acc:  0.09959136279391734\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  6.17788756147344 acc:  0.1742625549873836\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  5.425945302273365 acc:  0.22414755599222919\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  4.952856449370689 acc:  0.25989772904896946\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  4.539329036753228 acc:  0.2816247236674631\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  4.23574905699872 acc:  0.30478083201214745\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  4.02569262017595 acc:  0.31699528839068397\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  3.889113593608775 acc:  0.32972333251457026\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  9 loss :  3.7605221220787537 acc:  0.3372485094790434\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  10 loss :  3.670042423491782 acc:  0.3440814594823929\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  11 loss :  3.583226650319201 acc:  0.35229886340798966\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  12 loss :  3.485862564533315 acc:  0.35913181341133915\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  13 loss :  3.4023533171795783 acc:  0.3637987629234308\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  14 loss :  3.373740262173592 acc:  0.3680637742000313\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  15 loss :  3.276968088555843 acc:  0.36873367125918316\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  16 loss :  3.2320022025006883 acc:  0.3747180849876069\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  17 loss :  3.2632094647022005 acc:  0.37476274479155036\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  18 loss :  3.2398399799428086 acc:  0.3784025188129424\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  19 loss :  3.1995795736921595 acc:  0.3788267869504053\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  20 loss :  3.17298135858901 acc:  0.38340441685461\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  21 loss :  3.103184603630228 acc:  0.3823549114619387\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  22 loss :  3.1114381323469447 acc:  0.383984994305875\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  23 loss :  3.1025611593368208 acc:  0.38371703548221425\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  24 loss :  3.0706369318860642 acc:  0.3850344996985463\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  25 loss :  3.0720006455766393 acc:  0.3885179644061363\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  26 loss :  3.082533750128239 acc:  0.3883393251903624\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  27 loss :  3.085014764298784 acc:  0.38762476832726706\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  28 loss :  3.0024188630124358 acc:  0.3893218408771186\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  29 loss :  3.030470051663987 acc:  0.38983542862246834\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  30 loss :  3.000649259445515 acc:  0.3908626041131679\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  31 loss :  3.03574601132819 acc:  0.39041600607373333\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  32 loss :  3.0314671283072614 acc:  0.3918674497018958\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  33 loss :  3.033308282811591 acc:  0.39271598597682156\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  34 loss :  3.0249391565931605 acc:  0.39307326440836926\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  35 loss :  2.9776889212588045 acc:  0.39432373891878614\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  36 loss :  2.9908094862674144 acc:  0.3936315119576625\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  37 loss :  2.972658689985884 acc:  0.3944353884286448\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  38 loss :  2.9777449851340436 acc:  0.39448004823258825\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  39 loss :  2.964615279055656 acc:  0.3941897595069558\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  40 loss :  2.96042925753492 acc:  0.39365384185963426\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  41 loss :  3.0026948654905277 acc:  0.39485965656610766\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  42 loss :  2.968625154901058 acc:  0.39485965656610766\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  43 loss :  2.9693846144574754 acc:  0.3951722751937119\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  44 loss :  2.980391502380371 acc:  0.39550722372328784\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  45 loss :  2.941883457467911 acc:  0.39541790411540095\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  46 loss :  2.9667831075952407 acc:  0.39644507960610054\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  47 loss :  2.973250850718072 acc:  0.3963111001942701\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  48 loss :  2.950702220835584 acc:  0.3960654712725811\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  49 loss :  2.939876657851199 acc:  0.3963334300962419\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'RReLU', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 408, 'dropout': 0.16664423322701327, 'dropout_transformers': 0.09120875894063268, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.620360774706505, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 2.109985700033354e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanhshrink', 'dropout_gcn': 0.40504120567068025, 'hidden_channels': 512, 'layer_type': 'GCNConv', 'norm': 'PairNorm', 'num_layers_gcn': 7, 'use_gcn': True, 'weight_decay': 6.779219710921644e-08}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  8.051456082251764 acc:  0.0006698970591519103\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.998221169748614 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.952041595212875 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.915775295995897 acc:  0.0025902686287207198\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.880357243937831 acc:  0.003371815197731282\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.845968412583874 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  7.822891164595081 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  7.785524678999378 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  7.767260499154368 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  9 loss :  7.740579921968521 acc:  0.005314516669271822\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  10 loss :  7.715470753946612 acc:  0.005359176473215282\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  11 loss :  7.687924914206228 acc:  0.006274702454056227\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  12 loss :  7.672842767161708 acc:  0.006252372552084496\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  13 loss :  7.657634122910038 acc:  0.005984413728423732\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  14 loss :  7.640405913322202 acc:  0.006096063238282384\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  15 loss :  7.626457149751725 acc:  0.0063416921599714175\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  16 loss :  7.6193880234995195 acc:  0.006364022061943148\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  17 loss :  7.620526473752914 acc:  0.006386351963914879\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  18 loss :  7.594858240312146 acc:  0.006564991179688721\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  19 loss :  7.587904244084512 acc:  0.006408681865886608\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  20 loss :  7.575199893213088 acc:  0.00652033137574526\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  21 loss :  7.576475531055081 acc:  0.006587321081660451\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  22 loss :  7.551663272611557 acc:  0.00649800147377353\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  23 loss :  7.550998967693698 acc:  0.006564991179688721\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  24 loss :  7.539600261565178 acc:  0.006743630395462564\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  25 loss :  7.518703479151572 acc:  0.00710090882701025\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  26 loss :  7.516694225803498 acc:  0.007234888238840631\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  27 loss :  7.511331819718884 acc:  0.00714556863095371\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  28 loss :  7.508803887521067 acc:  0.007324207846727553\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  29 loss :  7.495581251575101 acc:  0.007636826474331778\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  30 loss :  7.50129364690473 acc:  0.007994104905879464\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  31 loss :  7.489150721027005 acc:  0.008172744121653306\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  32 loss :  7.482277184147988 acc:  0.008597012259116183\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  33 loss :  7.469864482264365 acc:  0.008797981376861755\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  34 loss :  7.480893015092419 acc:  0.00911060000446598\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  35 loss :  7.475081529924946 acc:  0.009601857847844049\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  36 loss :  7.457434177398682 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  37 loss :  7.471340585524036 acc:  0.010562043632628453\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  38 loss :  7.455354364456669 acc:  0.011142621083893441\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  39 loss :  7.450324784555743 acc:  0.011321260299667284\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  40 loss :  7.439455989099318 acc:  0.01163387892727151\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  41 loss :  7.451596721526115 acc:  0.01172319853515843\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  42 loss :  7.436406852353004 acc:  0.012080476966706116\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  43 loss :  7.4373872264739 acc:  0.012460085300225531\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  44 loss :  7.436856417502127 acc:  0.01299600294754706\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  45 loss :  7.426816780336441 acc:  0.013241631869236095\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  46 loss :  7.416643284213158 acc:  0.013353281379094745\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  47 loss :  7.418616953203755 acc:  0.013822209320501083\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  48 loss :  7.413779067993164 acc:  0.014112498046133577\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  49 loss :  7.4156887546662364 acc:  0.014693075497398567\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'LeakyReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.39157684373361623, 'dropout_transformers': 0.2141668796224508, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5448112900361404, 'scheduler': 'ExponentialLR', 'lr': 0.0006827415678005502, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softshrink', 'dropout_gcn': 0.3307966621926169, 'hidden_channels': 128, 'layer_type': 'GCNConv', 'norm': 'LayerNorm', 'num_layers_gcn': 7, 'use_gcn': True, 'weight_decay': 0.023696926068443442}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.596373276538159 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.327386890549257 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.2739316699016525 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.293985372566315 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.247419047068401 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.289437920214182 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  7.243196045059755 acc:  0.003438804903646473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24901146005644376 and num_layers=1\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'RReLU', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 216, 'dropout': 0.43759535220262225, 'dropout_transformers': 0.27297184335365693, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3028036681167195, 'scheduler': 'StepLR', 'step_size': 27, 'lr': 5.155488148806924e-06, 'dropout_lstm': 0.24901146005644376, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Mish', 'dropout_gcn': 0.09195057445041316, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 0.00026412534004035827}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  8.176879385243291 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  8.174130522686502 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  8.151302337646484 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  8.13742558852486 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  8.145187212073285 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  8.13143771627675 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  8.125557401905889 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  8.114030920940897 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  8.114037596661111 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  9 loss :  8.10756840913192 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  10 loss :  8.10205488619597 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  11 loss :  8.091269368710725 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  12 loss :  8.080366051715353 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  13 loss :  8.07606784157131 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  14 loss :  8.064626465673031 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  15 loss :  8.070446802222211 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  16 loss :  8.06271391329558 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  17 loss :  8.03867646922236 acc:  0.0011834848045017081\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  18 loss :  8.040955958159074 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  19 loss :  8.026335260142451 acc:  0.0012058147064734385\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  20 loss :  8.038476923237676 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  21 loss :  8.015449586121932 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  22 loss :  8.016789146091627 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  23 loss :  7.990310544553011 acc:  0.001496103432105933\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  24 loss :  7.98802489819734 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  25 loss :  7.985189562258513 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  26 loss :  7.990693548451299 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  27 loss :  7.989045371179995 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  28 loss :  7.981551833774732 acc:  0.0017417323537949668\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  29 loss :  7.977349322775136 acc:  0.0017194024518232365\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  30 loss :  7.965310573577881 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  31 loss :  7.983494572017504 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  32 loss :  7.9768921810647715 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  33 loss :  7.9688162596329395 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  34 loss :  7.9553022384643555 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  35 loss :  7.957850746486498 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  36 loss :  7.969449644503386 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  37 loss :  7.955614235090173 acc:  0.0019650313735122705\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  38 loss :  7.958356504854948 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  39 loss :  7.964258131773575 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  40 loss :  7.959502116493557 acc:  0.0020320210794274613\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  41 loss :  7.950513694597327 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  42 loss :  7.943481362384299 acc:  0.002076680883370922\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  43 loss :  7.9503340306489365 acc:  0.0020320210794274613\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  44 loss :  7.9450794510219405 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  45 loss :  7.945935477381167 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  46 loss :  7.940746763478154 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  47 loss :  7.950324639030125 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  48 loss :  7.932322543600331 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  49 loss :  7.928300152654233 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'CELU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 240, 'dropout': 0.3941720206926777, 'dropout_transformers': 0.4609157904715164, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 8, 'factor': 0.7378062229042041, 'patience': 10, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.027540520726462677, 'lr': 0.006807219490086402, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 48, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.3670567244561893e-07}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  8.117880827944044 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.716545192288681 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.544521405663289 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.43595698182012 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.398634071081457 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.370174730327768 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  7.323192180042535 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  7.306956170310436 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  7.274305390640044 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  9 loss :  7.299570003025968 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  10 loss :  7.295596532418695 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  11 loss :  7.275765600338788 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'Tanhshrink', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 408, 'dropout': 0.4185031090895594, 'dropout_transformers': 0.07587267046289448, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.24118668814128758, 'scheduler': 'ExponentialLR', 'lr': 4.580376222688693e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'SELU', 'dropout_gcn': 0.22385802494644047, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 1.1561154786213669e-09}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  8.01722040376463 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  8.009111351066537 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  8.00702942001236 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  8.007453601677101 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  8.00717492537065 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  8.007135894748714 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  6 loss :  8.006846868074858 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  7 loss :  8.006878249295108 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  8 loss :  8.007093713000105 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  9 loss :  8.007102562830998 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Hardsigmoid', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': False, 'd_model': 144, 'dropout': 0.23420868581878163, 'dropout_transformers': 0.09509169052721556, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.14807287633019764, 'scheduler': 'ExponentialLR', 'lr': 0.008875921063060942, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardswish', 'dropout_gcn': 0.1607353672487391, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 10, 'use_gcn': True, 'weight_decay': 1.0389445290294071e-07}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.9345227786472865 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.515927273886544 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.357246698651995 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.379116344451904 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.352880055563791 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.350842394147601 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Hardsigmoid', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.3759937007287698, 'dropout_transformers': 0.20979182572512495, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.0018253708553199364, 'dropout_lstm': 0.2266328798963439, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Softplus', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanh', 'dropout_gcn': 0.12236677241478511, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'PairNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 0.005899097919057207}\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2266328798963439 and num_layers=1\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  0 loss :  7.416847728123175 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  1 loss :  7.319793304550314 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  2 loss :  7.3094570168824955 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  3 loss :  7.304258449055324 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  4 loss :  7.29687814623396 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=10506)\u001b[0m epoch:  5 loss :  7.297992291851578 acc:  0.003438804903646473\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 17:06:20,373\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 17:06:35,189\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 17:06:35,191\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_2        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_2\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_2`\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48302290230585493 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'Softsign', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 48, 'dropout': 0.09506613328743097, 'dropout_transformers': 0.32149113081430036, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6485194651290492, 'scheduler': 'StepLR', 'step_size': 2, 'lr': 0.0002617397335834688, 'dropout_lstm': 0.48302290230585493, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 1, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00012544366727378452}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.275556686076712 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  8.0381047370586 acc:  0.0017194024518232365\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.9190783399216675 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  7.8298597944543715 acc:  0.002099010785342652\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  7.773433198320105 acc:  0.002210660295201304\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  7.744083069740458 acc:  0.002277650001116495\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  7.691977318297041 acc:  0.0024339593149186075\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  7.680425664211842 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  7.611566431978916 acc:  0.0024339593149186075\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  7.634257397753127 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  7.671952014273786 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  7.611197045508852 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  7.616052353635747 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  7.596288336084244 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  7.611009212250405 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  7.572060057457457 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  7.601006933983336 acc:  0.002724248040551102\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  7.614537381111307 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  7.610999026197068 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  7.610120671860715 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  7.596913895708449 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  7.601485790090358 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  7.601453588363972 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  7.67182214209374 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  7.581623828157466 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  7.655245567889923 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  7.600272604759703 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4949008960616998 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 672, 'dropout': 0.4919623830688768, 'dropout_transformers': 0.02034306998237919, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9860525136032905, 'scheduler': 'StepLR', 'step_size': 23, 'lr': 0.00012358054116552142, 'dropout_lstm': 0.4949008960616998, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.6368818683652885e-06}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.347035061685663 acc:  0.016635776968939107\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  7.574624889775326 acc:  0.08793515396467409\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  6.687993185143721 acc:  0.18241296920706518\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  5.779324827696148 acc:  0.23075720697586138\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  5.153496945531745 acc:  0.2609695643436125\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  4.856119903765227 acc:  0.28153540405957617\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  4.414687046251799 acc:  0.3044458834825715\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  4.2017553254177695 acc:  0.3268651050621888\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  4.095641535206845 acc:  0.3331174776142733\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  3.8620766865579705 acc:  0.3431436035995802\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  3.756466581946925 acc:  0.35678717370430746\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  3.733322075793618 acc:  0.36169975213808814\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  3.61077107379311 acc:  0.36210169037357925\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  3.469580186040778 acc:  0.37223946586874485\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  3.4256193211204127 acc:  0.3790500859701226\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  3.356168370497854 acc:  0.37746466293012976\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  3.357843461789583 acc:  0.38201996293236273\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  3.2309927488628185 acc:  0.3850344996985463\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  3.1812585931075246 acc:  0.3917781300940089\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  3.1750996614757336 acc:  0.3942120894089275\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  3.0403678392109117 acc:  0.3988790389210191\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 \n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m loss :  \n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m 3.0096027048010576 acc:  0.40287609137395886\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  3.0240124401293302 acc:  0.4021838644128352\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  3.006660258142572 acc:  0.4001741732353795\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  2.9550623040450246 acc:  0.39974990509791664\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  2.956835257379632 acc:  0.40752071098407877\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  2.8913571106760125 acc:  0.4016479467655137\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  2.84041001420272 acc:  0.40836924725900453\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  2.861749109468962 acc:  0.407833329611683\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  2.807985702313875 acc:  0.41111582520152734\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  2.811081667950279 acc:  0.4117857222606793\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  2.805866651786001 acc:  0.41513520755643885\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  2.752242250191538 acc:  0.4148225889288346\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  2.758970953288831 acc:  0.41404104235982403\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  2.7456709610788446 acc:  0.4168322801062903\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  2.6692585643969085 acc:  0.4140857021637675\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  2.7104793435648866 acc:  0.4191545899113503\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  2.6830122395565636 acc:  0.4185516825581136\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  2.6563776568362587 acc:  0.4189982805975482\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  2.60358323423486 acc:  0.4187973114798026\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  2.681755314375225 acc:  0.42042739432373893\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  2.636304295690436 acc:  0.4220351472657035\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  2.5674150504563986 acc:  0.4249603644240002\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  2.6090644522717126 acc:  0.42252640510908157\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  2.5531300017708225 acc:  0.42603219971864326\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  2.5480302986345795 acc:  0.4227720340307706\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  2.5470488937277542 acc:  0.4269700556014559\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  2.514386746757909 acc:  0.4263671482482192\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  2.5071105505290783 acc:  0.4267690864837103\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  2.5135961030658924 acc:  0.4231293124623183\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  8.558626282842535 acc:  0.41897595069557647\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  3.729419110950671 acc:  0.4261885090324454\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4995154709818789 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Hardshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 672, 'dropout': 0.47980410140855057, 'dropout_transformers': 0.0023039197429331575, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9310843233951526, 'scheduler': 'StepLR', 'step_size': 25, 'lr': 5.105097948135802e-05, 'dropout_lstm': 0.4995154709818789, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 38, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.3076389394532483e-09}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.573374411934301 acc:  0.012214456378536498\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  7.913732443357769 acc:  0.03767054462630909\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.498321046327289 acc:  0.0973583725967443\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  6.9321797119943716 acc:  0.15394234419310898\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  6.281017544395045 acc:  0.19784293146953086\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  5.741660645133571 acc:  0.22964071187727486\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  5.248039697345934 acc:  0.2556550476743407\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  5.016012066288998 acc:  0.2753946810173503\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  4.712287047034816 acc:  0.2906236741620704\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  4.47667966139944 acc:  0.30382064622736304\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  4.541155227861906 acc:  0.31514190652703034\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  4.253928515785619 acc:  0.3241855168255811\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  4.112592822627017 acc:  0.33700288055735433\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  4.048301892531546 acc:  0.3430989437956367\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  3.973174918325324 acc:  0.34707366634660475\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  3.9135392189025877 acc:  0.353839626644039\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  3.8706820211912456 acc:  0.3538172967420673\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  3.7752330729835912 acc:  0.3629948864524485\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  3.7499474952095433 acc:  0.3666346604738405\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  3.687446187671862 acc:  0.37087734184846927\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  3.5804569043611227 acc:  0.3757452604783065\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  3.5936425861559416 acc:  0.37873746734251834\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  3.550422904365941 acc:  0.380010271754907\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  3.4578066072965923 acc:  0.3809257977357479\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  3.437516784667969 acc:  0.3857937163655852\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  3.3822115998519093 acc:  0.3873121496996628\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  3.399729575608906 acc:  0.39130920215260256\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  3.3524419257515357 acc:  0.3901703771520443\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  3.289367427323994 acc:  0.39483732666413596\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  3.2465055591181704 acc:  0.39794118303820647\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  3.295912140294125 acc:  0.394748007056249\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  3.1960457977495698 acc:  0.399883884509747\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  3.2291353777835243 acc:  0.39878971931313223\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  3.1914402233926875 acc:  0.4012013487260791\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  3.1906153101670114 acc:  0.40388093696268673\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  3.2004760365737113 acc:  0.4035013286291673\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  3.0955538850081594 acc:  0.40421588549226267\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  3.052990710107904 acc:  0.403858607060715\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  3.055501701957301 acc:  0.40892749480829776\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  2.994771806817306 acc:  0.4092177835339303\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  3.0341090378008393 acc:  0.4068508139249269\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  3.0911820411682127 acc:  0.40720809235647454\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  3.0076676418906763 acc:  0.40854788647477835\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  3.0448773961318167 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  2.9755219484630384 acc:  0.41265658843757674\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  2.9464759927046926 acc:  0.41339347520264386\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  2.9026772750051397 acc:  0.41625170265502537\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  2.9069419710259687 acc:  0.41493423843869326\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  2.9187213671834846 acc:  0.41712256883192284\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  2.859224033355713 acc:  0.4158051046155907\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  19.935646255392776 acc:  0.36578612419891476\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  4.560328287827341 acc:  0.39218006832950003\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  4.281633201398347 acc:  0.4007547506866445\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  4.136815708561947 acc:  0.40419355559029096\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4938554968480045 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Hardswish', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 672, 'dropout': 0.4943367716741284, 'dropout_transformers': 0.014475647249882387, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 1, 'factor': 0.02196817428216241, 'patience': 10, 'scheduler': 'ReduceLROnPlateau', 'threshold': 9.41660336346162e-06, 'lr': 4.41197896125534e-05, 'dropout_lstm': 0.4938554968480045, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 40, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.1561969610190293e-09}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.78502548075168 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  8.17732172814485 acc:  0.012147466672621307\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.901131826026417 acc:  0.024339593149186076\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  7.787938117980957 acc:  0.044548154433602036\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  7.422864192000059 acc:  0.08391577160976263\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  6.944729163267902 acc:  0.12462318290422705\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  6.624742356416221 acc:  0.16162383047138423\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  6.188591288628979 acc:  0.19299734274166536\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  5.939703259512643 acc:  0.20976709912243485\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  5.542166074859762 acc:  0.2317173927606458\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  5.431909659198511 acc:  0.25074246924056004\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  5.285962630655164 acc:  0.26476564767880667\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  5.093019198034411 acc:  0.2677801844449903\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  5.011654657738231 acc:  0.26967822611258735\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  5.112382701624219 acc:  0.2710850099368064\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  5.005655192883215 acc:  0.2728714020945448\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  5.018980155481357 acc:  0.2736082888596119\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  4.902997103806968 acc:  0.2748587633700288\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  4.996100577238564 acc:  0.27631020699819125\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  5.000976119086007 acc:  0.27767233101846683\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  4.907218282467851 acc:  0.2787664962150816\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  4.957499588761374 acc:  0.2792800839604314\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  5.029326124726055 acc:  0.2793470736663466\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  4.887186587413895 acc:  0.27974901190183776\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  5.1191698591285775 acc:  0.27977134180380947\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  4.988990841624893 acc:  0.279726681999866\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  4.933459718650747 acc:  0.27979367170578123\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  4.999449522695809 acc:  0.2798829913136681\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  4.91336434355406 acc:  0.2800169707254985\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  4.932416062488734 acc:  0.2799276511176116\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  5.013661983971284 acc:  0.2798829913136681\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  4.959412935738252 acc:  0.28003930062747023\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  4.805676912592951 acc:  0.27999464082352676\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  4.894660680093498 acc:  0.28003930062747023\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  4.965016115491635 acc:  0.2801062903333854\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  4.929456069090656 acc:  0.2801509501373289\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  4.887770648314574 acc:  0.2801286202353572\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  4.911141669638803 acc:  0.28003930062747023\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  4.861153052231976 acc:  0.2800839604314137\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  4.946603549975101 acc:  0.2800839604314137\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  5.01072896752402 acc:  0.28003930062747023\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3982964302529492 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Hardshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.47875861007010395, 'dropout_transformers': 0.001056604010270197, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9892408182937804, 'scheduler': 'StepLR', 'step_size': 30, 'lr': 6.162707580225076e-05, 'dropout_lstm': 0.3982964302529492, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.920594698740128e-09}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.881314488461143 acc:  0.007033919121095058\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  8.00455278095446 acc:  0.016166849027532768\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.704320290214137 acc:  0.0313511823683094\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  7.451351321370978 acc:  0.07518477993881607\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  7.107926940917968 acc:  0.11834848045017082\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  6.681114131525943 acc:  0.16993055400486792\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  6.059872958534642 acc:  0.20896322265145256\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  5.793237500441702 acc:  0.2356251256056986\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  5.406748244636937 acc:  0.25849094522475047\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  5.129042876394172 acc:  0.28091016680436776\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  4.859707629053216 acc:  0.29307996337896075\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  4.653158589413292 acc:  0.3062322756403099\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  4.488343605242277 acc:  0.3189379898622245\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  4.425978309229801 acc:  0.3282048991804926\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  4.251550405903866 acc:  0.3352611482035594\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  4.120266680968435 acc:  0.34126789183395484\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  4.071992949435585 acc:  0.3499765536029297\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  4.017778988888389 acc:  0.35819395752852645\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  3.875104530234086 acc:  0.3632405153741375\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  3.8670283091695685 acc:  0.3671259183172186\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  3.684775774102462 acc:  0.37159189871156467\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  3.6258443154786764 acc:  0.37726369381238417\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  3.5484205220874987 acc:  0.37829086930308375\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  3.476589009636327 acc:  0.38123841636335215\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  3.5255261822750694 acc:  0.3842752830315075\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  3.4977813545026275 acc:  0.3892995109751468\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  3.451038142254478 acc:  0.3906169751914789\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  3.4326460888511257 acc:  0.39153250117231986\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  3.411122269379465 acc:  0.39307326440836926\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  3.3823908103139777 acc:  0.39573052274300513\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  3.292496869438573 acc:  0.39564120313511825\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  3.251704364073904 acc:  0.40108969921622045\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  3.2533924956070748 acc:  0.4001071835294643\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  3.1861160403803774 acc:  0.4009110600004466\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  3.23499833157188 acc:  0.40557800951253825\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  3.1871732536115145 acc:  0.40691780363084207\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  3.1572259877857407 acc:  0.4051314114731036\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  3.1254654758854916 acc:  0.40691780363084207\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  3.0864893561915347 acc:  0.406672174709153\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  3.088930694680465 acc:  0.41066922716209275\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  3.040490797946328 acc:  0.41256726882968986\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  3.033826652326082 acc:  0.41169640265279234\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  3.0380027745899403 acc:  0.4142420114775696\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  3.032255840301514 acc:  0.41165174284884887\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  2.951700070029811 acc:  0.41323716588884174\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  3.0008272923921284 acc:  0.41522452716432573\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  2.968360393925717 acc:  0.4154478261840431\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  2.9459992609525982 acc:  0.41573811490967555\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  3.0025667341131914 acc:  0.41634102226291225\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  2.9222308610614975 acc:  0.41785945559698995\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  5.937691962091546 acc:  0.40582363843422725\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  4.162018808565642 acc:  0.41256726882968986\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  3.994882583618164 acc:  0.41631869236094055\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  4.018880467665823 acc:  0.4142643413795413\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  54 loss :  3.978845345346551 acc:  0.4168769399102338\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4145860362751082 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Mish', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.4774059345215137, 'dropout_transformers': 0.031348393792711995, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9887138711964137, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 9.939420944917358e-07, 'dropout_lstm': 0.4145860362751082, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 9.421639828896222e-09}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.100130049120478 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  8.093325174155355 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  8.086120308948164 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  8.088500664013775 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  8.08475459924265 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  8.07796304366168 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  8.072566208719206 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  8.069327146065335 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  8.066430941349319 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  8.064953227003082 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  8.057688284320992 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  8.055165110515947 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  8.049179117218786 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  8.047918776504131 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  8.039042977725758 acc:  0.0006698970591519103\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  8.034495349691696 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  8.026466041052041 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  8.025172850664925 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  8.017335623252292 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  8.010774820792575 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  8.006391373001227 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  7.997064818855093 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  7.9963193620954245 acc:  0.0012058147064734385\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  7.992312038646025 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  7.982192740720861 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  7.9690174495472625 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  7.961573312262527 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  7.95645843233381 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  7.943166596548898 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  7.941001447308965 acc:  0.002232990197173034\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  7.925988493847246 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  7.912782011913652 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  7.905199191149543 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  7.899868600508746 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  7.883066005065661 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  7.872296898304915 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  7.8628263313229345 acc:  0.003684433825335507\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  7.840284467745228 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  7.834321358624627 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  7.814952686053364 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  7.8062794468983885 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  7.792438194531353 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  7.781136204214657 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  7.773451103883631 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  7.760191392497856 acc:  0.005269856865328361\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  7.7456989689033575 acc:  0.005381506375187013\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  7.735113444448519 acc:  0.005493155885045665\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  7.709698047958502 acc:  0.0056271352968760464\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  7.705547336770707 acc:  0.005761114708706429\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  7.688690814651361 acc:  0.005649465198847777\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  9.319818352450843 acc:  0.005225197061384901\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  8.89232761318944 acc:  0.00515820735546971\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  8.80615717623414 acc:  0.00515820735546971\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  8.77073370508787 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4113590082702857 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softplus', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 744, 'dropout': 0.2878184730369306, 'dropout_transformers': 0.040858527434671194, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 1, 'factor': 0.8200856692298591, 'patience': 2, 'scheduler': 'ReduceLROnPlateau', 'threshold': 2.3740073111010183e-05, 'lr': 1.3394809372498067e-05, 'dropout_lstm': 0.4113590082702857, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 15, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.3392079764892756e-06}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.286376380387631 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  7.841967345616005 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.576894403169941 acc:  0.008016434807851193\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  7.419088840484619 acc:  0.016747426478797758\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  7.311851229747581 acc:  0.024250273541299154\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  7.190428432805578 acc:  0.03845209119531965\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  7.070547247732152 acc:  0.05383739365384186\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  6.963789372470792 acc:  0.06884308777884465\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  6.878083234392731 acc:  0.08467498827680146\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  6.737943404213676 acc:  0.09851952749927428\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  6.554004085796505 acc:  0.11586986133130875\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  6.383352106509928 acc:  0.1297367304557533\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  6.394526193927786 acc:  0.14072304222584464\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  6.20560782714929 acc:  0.1535180760556461\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  6.112473772890741 acc:  0.16171315007927115\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  6.067929909881933 acc:  0.17098005939753924\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  5.990328631587535 acc:  0.18087220597101578\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  5.895168498907675 acc:  0.18629837215014627\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  5.828910036459981 acc:  0.19295268293772191\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  5.797923293193626 acc:  0.19730701382220933\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  5.757927974509127 acc:  0.20507781970837147\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  5.756846951372797 acc:  0.20900788245539603\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  5.647447245081044 acc:  0.2119330996136927\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  5.460330195933081 acc:  0.21492530647790456\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  5.550220444215743 acc:  0.21704664716521893\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  5.453797562828277 acc:  0.22093205010830003\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  5.506732687603828 acc:  0.2230533907956144\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  5.427684557504494 acc:  0.2270951030524976\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  5.403939618744664 acc:  0.2281222785431972\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  5.444700475511604 acc:  0.2321863207020521\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  5.330555512252467 acc:  0.23194069178036308\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  5.315042145425381 acc:  0.23513386776232054\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  5.286321662657754 acc:  0.23665230109639818\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  5.2516842940666155 acc:  0.2390192707054016\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  5.215076767532519 acc:  0.24062702364736618\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  5.259814827135822 acc:  0.2411629412946877\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  5.1677457353922245 acc:  0.24384252953129537\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  5.164361650051351 acc:  0.24428912757072996\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  5.186466034564226 acc:  0.2458522207087511\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  5.238805300696602 acc:  0.24759395306254606\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  5.243858601127923 acc:  0.24835316972958488\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  5.0875320900751895 acc:  0.24920170600451064\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  5.185767430832932 acc:  0.25016189178929504\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  5.169689411557586 acc:  0.2502288814952102\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  5.1376713640863 acc:  0.25172498492731615\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  5.162424247358098 acc:  0.2531987584574504\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  5.133443462116093 acc:  0.2536006966929415\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  5.036985044372814 acc:  0.25465020208561284\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  5.06957739957884 acc:  0.25523077953687784\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  5.038013919105743 acc:  0.255297769242793\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  8.035468325268623 acc:  0.2460755197284684\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  6.445208906461406 acc:  0.24620949914029877\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  6.393418748951491 acc:  0.24634347855212915\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  6.309539544515769 acc:  0.2467454167876203\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  54 loss :  6.33585063838426 acc:  0.247102695219168\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43186679821727514 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.4625860131892625, 'dropout_transformers': 0.14115466591035342, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9787567498808057, 'scheduler': 'StepLR', 'step_size': 28, 'lr': 0.00010617509843213127, 'dropout_lstm': 0.43186679821727514, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 8.855676611684024e-07}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.039696684507566 acc:  0.013018332849518791\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  7.35070374747303 acc:  0.06694504611124757\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  6.844906343477908 acc:  0.13619007212558337\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  6.040348739267509 acc:  0.1972846839202376\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  5.53964955561629 acc:  0.23995712658821428\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  5.042805214908635 acc:  0.25891521336221335\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  4.60015193769865 acc:  0.283210146707456\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  4.33053428213173 acc:  0.30574101779693186\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  4.233604092464269 acc:  0.31511957662505863\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  4.095252676544902 acc:  0.3292990643771074\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  3.8942272462577465 acc:  0.34207176830493713\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  3.8526733545499425 acc:  0.3491056874260322\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  3.652263868634946 acc:  0.35267847174150907\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  3.6064325181123253 acc:  0.3592657928231695\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  3.4875141549333235 acc:  0.36672398008172746\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  3.3870903487517454 acc:  0.37440546636000266\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  3.4219903054638445 acc:  0.375454971752674\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  3.3120923331964796 acc:  0.3802335707746243\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  3.2753671998175506 acc:  0.3817743340106737\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  3.262159594865603 acc:  0.38338208695263826\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  3.2271311283111572 acc:  0.3914208516624612\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  3.122257932324276 acc:  0.39251501685907597\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  3.094404242863165 acc:  0.3947926668601925\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  3.067024090579737 acc:  0.3922917178393587\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  3.105523227531219 acc:  0.39704798695933724\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  2.994702967527871 acc:  0.3952392648996271\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  2.924655479805492 acc:  0.3996829153920014\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  2.9785193282867146 acc:  0.4010227095103053\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  2.9131729981609595 acc:  0.40153629725565504\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  2.9232683961636554 acc:  0.4043052051001496\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  2.8401128276486265 acc:  0.40836924725900453\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  2.8376656046537594 acc:  0.41066922716209275\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  2.8330195975080827 acc:  0.4090168144161847\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  2.8364813517187244 acc:  0.40836924725900453\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  2.7730631494076454 acc:  0.4096643815733649\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  2.8048522918023795 acc:  0.40991001049505393\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  2.7396478418991945 acc:  0.41087019627983834\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  2.785221360554205 acc:  0.4118750418685662\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  2.7009267840430002 acc:  0.41381774334010674\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  2.741564461003954 acc:  0.4154478261840431\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  2.7031262879059694 acc:  0.4170332492240359\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  2.6838956859624274 acc:  0.4139293928499654\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  2.724475862823914 acc:  0.41667597079248825\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  2.662050071163712 acc:  0.4133264854967287\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  2.626170454738296 acc:  0.4159167541254494\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  2.6682514141653186 acc:  0.4189982805975482\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  2.624019034555025 acc:  0.4204720541276824\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  2.6420662770761507 acc:  0.420338074715852\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  2.5681273157351483 acc:  0.42058370363754105\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  2.5714652504876394 acc:  0.4175691668713574\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  4.486956097255243 acc:  0.408659535984637\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  3.727312941417516 acc:  0.4177924658910747\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  3.6524475846335154 acc:  0.4173905276555836\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  3.638388130152337 acc:  0.41919924971529376\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  54 loss :  3.6247067206373838 acc:  0.4219458276578166\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  55 loss :  3.67936589116248 acc:  0.4224817453051381\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  56 loss :  3.6354758784035655 acc:  0.4230176629524596\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  57 loss :  3.5982147265817517 acc:  0.4238438693254137\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  58 loss :  3.608970905018744 acc:  0.42346426099189427\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  59 loss :  3.5900324594194646 acc:  0.42489337471808497\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  60 loss :  3.5581175233716165 acc:  0.42507201393385885\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  61 loss :  3.4869674722724984 acc:  0.4244691065806221\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  62 loss :  3.585333960078587 acc:  0.42377687961949845\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  63 loss :  3.5239200436066245 acc:  0.4255856016792086\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  64 loss :  3.5747711658477783 acc:  0.42605452962061496\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  65 loss :  3.5487212644559203 acc:  0.42741665364089054\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  66 loss :  3.5102580306685973 acc:  0.42545162226737826\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  67 loss :  3.5763896536604265 acc:  0.4268137462876538\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  68 loss :  3.516246263111863 acc:  0.42663510707187996\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  69 loss :  3.497512422989462 acc:  0.42574191099301073\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  70 loss :  3.5526757151166968 acc:  0.4255856016792086\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  71 loss :  3.461857238662577 acc:  0.42819820020990107\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  72 loss :  3.4942914793424515 acc:  0.4269477256994842\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  73 loss :  3.520647597090106 acc:  0.42723801442511666\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  74 loss :  3.4501940736146732 acc:  0.4283098497197597\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  75 loss :  3.440928864701886 acc:  0.42728267422906013\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3035380004777843 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.31452836904348236, 'dropout_transformers': 0.13470346099768687, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 4, 'factor': 0.49121603560687493, 'patience': 7, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00045583150797639247, 'lr': 0.00014312359413428769, 'dropout_lstm': 0.3035380004777843, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 43, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.6801001508526987e-06}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  7.784486526200752 acc:  0.030725945113100953\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  6.954153497679894 acc:  0.1083223544648639\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  6.042190251230192 acc:  0.18223432999129133\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  5.345555369593516 acc:  0.23837170354822143\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  4.776890806791161 acc:  0.26400643101176785\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  4.443499386811457 acc:  0.2914275506330527\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  4.1002634873911115 acc:  0.30866623495522855\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  3.896789414542062 acc:  0.32987964182837237\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  3.810418978458693 acc:  0.3314427349663935\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  3.5539345741271973 acc:  0.3550677712524842\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  3.474707673577701 acc:  0.3617667418440033\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  3.426636711889956 acc:  0.3653395261594802\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  3.3706455551275685 acc:  0.36739387714087934\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  3.3019013204494443 acc:  0.37690641538083647\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  3.2801988305163983 acc:  0.38003260165687874\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  3.2620917809109726 acc:  0.38081414822588927\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  3.1801364822547975 acc:  0.3839180045999598\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  3.1306326489488616 acc:  0.38628497420896324\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  3.1404927658433675 acc:  0.3904606658776768\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  3.0607920674716724 acc:  0.39231404774133044\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  3.0560956582301806 acc:  0.39351986244780385\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  3.005455936704363 acc:  0.39698099725342206\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  3.0002017982867586 acc:  0.39952660607819934\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  3.0016514994517096 acc:  0.4025858026483264\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  2.9860999844655267 acc:  0.4008440702945314\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  2.892751417240175 acc:  0.4016479467655137\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  2.903920596387206 acc:  0.40330035951142174\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  2.9219635374405803 acc:  0.40403724627648885\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  2.9131697907167324 acc:  0.4041488957863475\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  2.9031636173985587 acc:  0.40506442176718843\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  2.893061589793999 acc:  0.40640421588549225\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  2.9138890635065673 acc:  0.4064935354933792\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  2.858694827857138 acc:  0.40850322667083494\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  2.834439712412217 acc:  0.40932943304378894\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  2.81608896696267 acc:  0.4094410825536476\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  2.8307670264684854 acc:  0.41064689726012105\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  2.816248517076508 acc:  0.41160708304490545\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  2.8657166777538654 acc:  0.41080320657392316\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  2.805510080161215 acc:  0.4104235982404037\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  2.8247549934547487 acc:  0.40986535069111046\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  2.83363886039798 acc:  0.4108478663778666\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  2.7807497577506957 acc:  0.41183038206462275\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  2.749686880271976 acc:  0.41176339235870757\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  2.758526940305694 acc:  0.4103342786325168\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  2.718306651636332 acc:  0.4125226090257464\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  2.8142244435158097 acc:  0.41160708304490545\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  2.8048735786886776 acc:  0.4125449389277181\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  2.733575500360056 acc:  0.4124556193198312\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  2.8205860262157536 acc:  0.41301386686912445\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  2.8021381422251213 acc:  0.41285755755532233\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  4.743363979483853 acc:  0.402206194314807\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  3.924938181869122 acc:  0.4066498448071813\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  3.847138985866258 acc:  0.4081906080432307\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  3.991916135579598 acc:  0.40988768059308217\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4472187317194874 and num_layers=1\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=21340)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 672, 'dropout': 0.4499734506126374, 'dropout_transformers': 0.13137301920984235, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.4168773933005001, 'scheduler': 'StepLR', 'step_size': 30, 'lr': 1.2851115021366461e-05, 'dropout_lstm': 0.4472187317194874, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 30, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.990256507940538e-07}\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  0 loss :  8.487780434268338 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  1 loss :  8.155496463909016 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  2 loss :  7.972387390536862 acc:  0.0029028872563249446\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  3 loss :  7.815963435006308 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  4 loss :  7.736968934119164 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  5 loss :  7.6768455205263795 acc:  0.004689279414063372\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  6 loss :  7.621651676151302 acc:  0.005761114708706429\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  7 loss :  7.55032695423473 acc:  0.006542661277716991\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  8 loss :  7.494907295787251 acc:  0.007346537748699283\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  9 loss :  7.470276182348078 acc:  0.00844070294531407\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  10 loss :  7.4524864683618075 acc:  0.011499899515441126\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  11 loss :  7.3943065930079745 acc:  0.014045508340218386\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  12 loss :  7.356029217059795 acc:  0.016568787263023917\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  13 loss :  7.324238883865463 acc:  0.02083379853962441\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  14 loss :  7.307162741681079 acc:  0.0239153250117232\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  15 loss :  7.274570018261462 acc:  0.02911819217113637\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  16 loss :  7.189274054307204 acc:  0.034432708840408194\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  17 loss :  7.184023810433341 acc:  0.03903266864658464\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  18 loss :  7.127716874742841 acc:  0.045619989728245096\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  19 loss :  7.139990713212874 acc:  0.0485675367885135\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  20 loss :  7.051910337034639 acc:  0.05477524953665453\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  21 loss :  6.981461401585932 acc:  0.05930821963691579\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  22 loss :  7.001076034732632 acc:  0.0650470044436505\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  23 loss :  6.936183375912113 acc:  0.07009356228926154\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  24 loss :  6.939689916330618 acc:  0.07393430542839917\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  25 loss :  6.881342774504549 acc:  0.0811691936672398\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  26 loss :  6.863383286482804 acc:  0.08456333876694282\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  27 loss :  6.810021863950716 acc:  0.09383024808521091\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  28 loss :  6.7411001912363755 acc:  0.09943505348011522\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  29 loss :  6.718088360099526 acc:  0.10492820936516088\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  30 loss :  6.744823035660324 acc:  0.10867963289641158\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  31 loss :  6.625927538304896 acc:  0.11111359221133019\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  32 loss :  6.721993229605935 acc:  0.11356988142822053\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  33 loss :  6.646905355520182 acc:  0.11879507848960542\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  34 loss :  6.545450884145456 acc:  0.12046982113748521\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  35 loss :  6.594158616099325 acc:  0.12357367751155572\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  36 loss :  6.54701962170901 acc:  0.12605229663041778\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  37 loss :  6.485248128850977 acc:  0.12886586427885582\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  38 loss :  6.520365348229041 acc:  0.1316571020253221\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  39 loss :  6.460481880428074 acc:  0.1346716387915057\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  40 loss :  6.455386995435594 acc:  0.13728423732219816\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  41 loss :  6.533254946862067 acc:  0.14250943438358304\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  42 loss :  6.501439381312657 acc:  0.1445191255610388\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  43 loss :  6.413846549454269 acc:  0.14626085791483376\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  44 loss :  6.402297363414631 acc:  0.14882879664158274\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  45 loss :  6.421485867533651 acc:  0.15052586919143424\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  46 loss :  6.410581175263945 acc:  0.15289283880043766\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  47 loss :  6.369735924514024 acc:  0.15488020007592165\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  48 loss :  6.358558858191217 acc:  0.1586539535091441\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  49 loss :  6.32940198324777 acc:  0.16135587164772347\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  50 loss :  7.708340191340946 acc:  0.16055199517674118\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  51 loss :  7.486354157641218 acc:  0.16231605743250788\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  52 loss :  7.437190029170964 acc:  0.16564321282629568\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  53 loss :  7.470695498939994 acc:  0.1652189446888328\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  54 loss :  7.467431351855085 acc:  0.16995288390683966\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  55 loss :  7.307469337970227 acc:  0.17082375008373712\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  56 loss :  7.4096241130695475 acc:  0.17524507067413975\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  57 loss :  7.3409730704514295 acc:  0.17566933881160263\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  58 loss :  7.336624272219785 acc:  0.17761204028314315\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  59 loss :  7.312508613079578 acc:  0.17982270057834446\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  60 loss :  7.261488010833314 acc:  0.1807382265591854\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  61 loss :  7.3685077387136175 acc:  0.18158676283411115\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  62 loss :  7.3598764526260485 acc:  0.18230131969720653\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  63 loss :  7.305931794893492 acc:  0.18288189714847153\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  64 loss :  7.2486189695505 acc:  0.18386441283522764\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  65 loss :  7.289477638431363 acc:  0.184913918227899\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  66 loss :  7.113106807628712 acc:  0.1855838152870509\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  67 loss :  7.223234726832463 acc:  0.18611973293437242\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  68 loss :  7.274086405347277 acc:  0.18732554764084586\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  69 loss :  7.147630551478246 acc:  0.18768282607239353\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  70 loss :  7.348824464357817 acc:  0.18871000156309314\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  71 loss :  7.174484876485971 acc:  0.1897818368577362\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  72 loss :  7.129982714886432 acc:  0.19040707411294464\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  73 loss :  7.2584415815926935 acc:  0.19089833195632272\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  74 loss :  7.2246559116390205 acc:  0.19089833195632272\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  75 loss :  7.165539831548304 acc:  0.19257307460420248\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  76 loss :  7.139479587128112 acc:  0.19268472411406115\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  77 loss :  7.203882600877669 acc:  0.19351093048701518\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  78 loss :  7.1738200554480915 acc:  0.19431480695799747\n",
            "\u001b[36m(eval_config pid=21340)\u001b[0m epoch:  79 loss :  7.169053024345344 acc:  0.19525266284081014\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 18:31:40,375\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 18:31:54,547\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 18:31:54,549\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_3        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_3\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_3`\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13136606724099803 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Softmin', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 816, 'dropout': 0.3438531616179985, 'dropout_transformers': 0.14165092081334543, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 0.0004420097344922277, 'dropout_lstm': 0.13136606724099803, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.231115356342549e-06}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  7.533016605911968 acc:  0.026170645110867963\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  6.65168462289828 acc:  0.12477949221802916\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  5.345523395270945 acc:  0.23254359913359982\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  4.391495143141702 acc:  0.26728892660161224\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  3.85149136881962 acc:  0.3090011834848045\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  3.5210009089140133 acc:  0.3290087756514749\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  3.2909327221808033 acc:  0.3435902016390148\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  3.0009961083670644 acc:  0.35428622468347365\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  2.981705583144571 acc:  0.3683094031217203\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  2.9166000245887544 acc:  0.37538798204675883\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  2.743757167709208 acc:  0.38041220999039815\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  2.647771238166595 acc:  0.38557041734586783\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  2.6184648286516423 acc:  0.3938548109773798\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  2.6030266719443778 acc:  0.39124221244668733\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  2.5193903033978473 acc:  0.3953062546055423\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  2.4854819952884566 acc:  0.4027644418641002\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  2.3918003701718056 acc:  0.40484112274747114\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  2.382712305149185 acc:  0.4076546903959092\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  2.2651931526504945 acc:  0.41046825804434717\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  2.273535960188536 acc:  0.4090838041220999\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  2.2444745101661328 acc:  0.4088381752004109\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  2.2166068475937175 acc:  0.4122546502020856\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  2.129501318263116 acc:  0.40950807225956276\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  2.149818887220365 acc:  0.4127682379474354\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  2.054591495300008 acc:  0.41227698010405733\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  2.1157979062784498 acc:  0.41089252618181005\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  2.051229651843276 acc:  0.41743518745952707\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  2.024639290069865 acc:  0.4127459080454637\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  1.9691737154933895 acc:  0.41596141392939284\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  1.995244353731102 acc:  0.41419735167362615\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  1.9084997823305219 acc:  0.41258959873166157\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  1.9414768430674187 acc:  0.417770135989103\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  1.9142408181573742 acc:  0.41384007324207844\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  1.8670441023657256 acc:  0.41279056784940715\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  1.8416898250579834 acc:  0.4127459080454637\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  1.806895182511517 acc:  0.4168099502043186\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  1.7543389295863214 acc:  0.415202197262354\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4456332286951031 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'ELU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.3051023074058299, 'dropout_transformers': 0.27717582117318007, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.5152221102552028, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 4.8629247907774085e-06, 'dropout_lstm': 0.4456332286951031, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.013053419209456e-07}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  8.510446297194429 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  8.396446633481693 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  8.306835425828032 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  8.213391763721397 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  8.147647811981019 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  8.0585247799308 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  7.999227832177442 acc:  0.002925217158296675\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  7.957651221109722 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  7.898235229674928 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  7.840937386015932 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  7.762457770501782 acc:  0.005649465198847777\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  7.724898986473769 acc:  0.0063416921599714175\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  7.672033635442128 acc:  0.0067882901994060245\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  7.6343437411827955 acc:  0.007368867650671014\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  7.572839816887222 acc:  0.008038764709822925\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  7.5450359675698655 acc:  0.008262063729540227\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  7.511488160687293 acc:  0.009289239220239822\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  7.445208555210137 acc:  0.01098631177009133\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  7.4595398446043095 acc:  0.01232610588839515\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  7.462422596480319 acc:  0.014469776477681263\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  7.4095887309776804 acc:  0.015429962262465667\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  7.403203798625284 acc:  0.016524127459080454\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  7.379238131517422 acc:  0.016993055400486793\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  7.381918584515235 acc:  0.018042560793158118\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  7.354115734557192 acc:  0.019248375499631556\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  7.320437636917936 acc:  0.020342540696246345\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  7.344694859967261 acc:  0.0221512627559565\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  7.315268884875818 acc:  0.02337940736440167\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  7.299488318894437 acc:  0.024428912757072995\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  7.272516653209389 acc:  0.025679387267489896\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  7.270514442535218 acc:  0.02719782060156756\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  7.251670172114572 acc:  0.02844829511198446\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  7.222343878831692 acc:  0.02864926422973003\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  7.256586471717514 acc:  0.030390996583525\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  7.213492847488312 acc:  0.03157448138802671\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  7.20095893437277 acc:  0.03286961570238707\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  7.168473072394639 acc:  0.03371815197731282\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  7.203009716764895 acc:  0.035370564723220865\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  7.1416805490048345 acc:  0.03550454413505125\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  7.139800734148768 acc:  0.036688028939552954\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  7.137055339927445 acc:  0.03764821472433736\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  7.139221182840313 acc:  0.038541410803206576\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  7.156217009721402 acc:  0.03945693678404752\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  7.100167777010067 acc:  0.04026081325502981\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  7.04183544227463 acc:  0.041444298059531516\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  7.044585068068819 acc:  0.04160060737333363\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  7.096291901822576 acc:  0.04343165933501552\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  7.047569192098286 acc:  0.044391845119799926\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  7.111817873880534 acc:  0.045865618649934124\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  7.081154400716999 acc:  0.047652010807672555\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  9.022537976681829 acc:  0.043677288256704555\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  8.335946765488494 acc:  0.043163700511354756\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  52 loss :  8.29450008255279 acc:  0.042962731393609184\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  53 loss :  8.284085236623616 acc:  0.04314137060938302\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  54 loss :  8.193781912683727 acc:  0.043610298550789364\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18277793578830526 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 624, 'dropout': 0.4948613522047571, 'dropout_transformers': 0.047406444433991904, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9715754455123032, 'scheduler': 'StepLR', 'step_size': 26, 'lr': 0.00010561099548622995, 'dropout_lstm': 0.18277793578830526, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 10, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.3532302299641776e-06}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  8.041938437036722 acc:  0.009490208337985397\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  7.518158326666039 acc:  0.043744277962619746\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  7.102873905595526 acc:  0.099122434852511\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  6.534678016800478 acc:  0.1419511868342898\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  5.870922766536115 acc:  0.1799343500882031\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  5.545114899256143 acc:  0.22564365942433512\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  5.129689814096474 acc:  0.24545028247325995\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  4.7937422890261 acc:  0.2728490721925731\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  4.609231380094965 acc:  0.2835450952370319\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  4.318182301808553 acc:  0.29600518053725744\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  4.217774836413832 acc:  0.30227988299131364\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  3.987820806273495 acc:  0.3176875153518076\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  3.9315856077584876 acc:  0.32755733202331244\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  3.9134574022637794 acc:  0.3380077261460822\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  3.7126853293683157 acc:  0.3503115021325056\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  3.7052476147571243 acc:  0.3492619967398343\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  3.572300908077194 acc:  0.3559386374293817\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  3.456972285925624 acc:  0.35937744233302815\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  3.49940625443516 acc:  0.3618560614518902\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  3.4934946312961808 acc:  0.3663220418462363\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  3.467023786292019 acc:  0.3723511153786035\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  3.3336798168090453 acc:  0.37712971440055376\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  3.2873125076293945 acc:  0.3754773016546457\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  3.2500547759504204 acc:  0.3807248286180024\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  3.1943444430109964 acc:  0.3868432217582565\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  3.2729317423809006 acc:  0.3857713864636134\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  3.1699446913707687 acc:  0.38887524283768393\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  3.131885341851108 acc:  0.3872228300917759\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  3.1041221130325134 acc:  0.39137619185851774\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  3.0837410559137184 acc:  0.3975392448027153\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  3.0795863048139824 acc:  0.39760623450863053\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  3.026232874537089 acc:  0.39622178058638324\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  3.0388109253113527 acc:  0.3975169149007436\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  3.0244223985327294 acc:  0.3996605854900297\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  2.96312611361584 acc:  0.39939262666636893\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  2.9093531341437835 acc:  0.4013576580398812\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  2.960665475891297 acc:  0.4015586271576268\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  2.8838553773351463 acc:  0.4039255967666302\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  2.8577565170196166 acc:  0.4068061541209834\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  2.927449941635132 acc:  0.4096643815733649\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  2.818405993013497 acc:  0.40792264921956994\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  2.8324343842196176 acc:  0.4105575776522341\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  2.803168833973896 acc:  0.41044592814237546\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  2.785311334104423 acc:  0.40774401000379606\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  2.8066984228340974 acc:  0.4110041756916687\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  2.77339062058782 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  2.765472975121923 acc:  0.41384007324207844\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  2.717553000852286 acc:  0.4152468570662975\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  2.7280638648802977 acc:  0.41692159971417725\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  2.704547451203128 acc:  0.4167876203023469\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  4.32296889374055 acc:  0.4064935354933792\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  3.9378795250352607 acc:  0.41265658843757674\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  52 loss :  3.7820658051823997 acc:  0.4112051448094143\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  53 loss :  3.8496577021587326 acc:  0.415202197262354\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3249174116888139 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.06724681533227633, 'dropout_transformers': 0.1208493852023012, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 6.6332456692384125e-06, 'dropout_lstm': 0.3249174116888139, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.2047127209201305e-08}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  8.384172388615498 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  8.165192432985961 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  7.998930639893044 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  7.876461793448179 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  7.790254079658567 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  7.7162647356513805 acc:  0.0031708460799857088\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  7.641237473669853 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  7.585073933346581 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  7.549139510584242 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  7.4981581454968635 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  7.469980742185171 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  7.425080852654144 acc:  0.005470825983073934\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  7.429698998691472 acc:  0.00585043431659335\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  7.38119097338378 acc:  0.006230042650112766\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  7.372153915521753 acc:  0.007257218140812362\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  7.332013173867728 acc:  0.009534868141928858\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  7.305675077074357 acc:  0.010651363240515374\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  7.265539464149766 acc:  0.011164950985865172\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  7.293878835576181 acc:  0.012661054417971105\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  7.264211785702305 acc:  0.014782395105285487\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  7.180108947608307 acc:  0.015809570595985083\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  7.164035360321744 acc:  0.017975571087242927\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  7.175990614272256 acc:  0.02076680883370922\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  7.157761351752828 acc:  0.022910479422995334\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  7.160501847740348 acc:  0.02670656275818949\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  7.127028592670237 acc:  0.02864926422973003\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  7.086303772817131 acc:  0.03152982158408325\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  7.027287679774161 acc:  0.03389679119308666\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  7.046194702614355 acc:  0.03693365786124199\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  7.005335713160857 acc:  0.0411316794319273\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  6.988060772873973 acc:  0.04472679364937588\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  6.9777341070975964 acc:  0.04847821718062658\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  6.8932744055303905 acc:  0.0523189603197642\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  6.879047939795574 acc:  0.05787910591072505\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  6.844410070026194 acc:  0.06006743630395463\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  6.805221408378077 acc:  0.06556059218900029\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  6.822172146717101 acc:  0.07054016032869616\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  6.786613781033582 acc:  0.07478284170332493\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  6.732784507838824 acc:  0.07873523435232119\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  6.684084466395487 acc:  0.0824196681776567\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  6.687219277593016 acc:  0.08733224661143738\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  6.649638845720364 acc:  0.09148560837817922\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  6.641032561091066 acc:  0.0944108255364759\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  6.672534021712441 acc:  0.09892146573476543\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  6.535793642961342 acc:  0.10124377553982539\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  6.517437447118395 acc:  0.10468258044347185\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  6.459689271359044 acc:  0.10740682848402296\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  6.4447563149546845 acc:  0.10968447848513944\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  6.427368841098465 acc:  0.11216309760400152\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  6.453248846621913 acc:  0.11571355201750665\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  7.81321152475954 acc:  0.11010874662260232\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  7.4887489362527395 acc:  0.11330192260455976\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  52 loss :  7.547771595816576 acc:  0.11734363486144296\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  53 loss :  7.448423240020985 acc:  0.11997856329410714\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  54 loss :  7.387775319223185 acc:  0.12120670790255231\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  55 loss :  7.395139694213867 acc:  0.12471250251211397\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  56 loss :  7.3996173989681795 acc:  0.1267221936895697\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  57 loss :  7.274120323530591 acc:  0.12962508094589464\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  58 loss :  7.345164379090753 acc:  0.13074157604448117\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  59 loss :  7.252392747019994 acc:  0.13440367996784494\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  60 loss :  7.443524029418712 acc:  0.13661434026304625\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  61 loss :  7.32188746037374 acc:  0.1400531451666927\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  62 loss :  7.297941717482705 acc:  0.14349195007033919\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  63 loss :  7.244043124541071 acc:  0.14413951722751936\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  64 loss :  7.137450018001877 acc:  0.14572494026751223\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  65 loss :  7.27324725653379 acc:  0.14802492017060045\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  66 loss :  7.142693730711027 acc:  0.14983364223031062\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  67 loss :  7.138221354884956 acc:  0.15237925105508787\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  68 loss :  7.117782163255997 acc:  0.15394234419310898\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  69 loss :  7.001852243001224 acc:  0.15657727262577317\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  70 loss :  7.109081872546946 acc:  0.15845298439139852\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  71 loss :  7.21436176955245 acc:  0.16086461380434539\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  72 loss :  7.016171171464993 acc:  0.16294129468771631\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28474731249573326 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'LogSigmoid', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 720, 'dropout': 0.3685605833636331, 'dropout_transformers': 0.25674047210316275, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.0433654566444151, 'scheduler': 'StepLR', 'step_size': 24, 'lr': 0.12918973204548329, 'dropout_lstm': 0.28474731249573326, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 37, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0005291197044137646}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4487368858733206 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.45335554038458487, 'dropout_transformers': 0.1550292893382258, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 5, 'factor': 0.0001703930088358674, 'patience': 7, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0018072287515277542, 'lr': 2.3140061076331447e-05, 'dropout_lstm': 0.4487368858733206, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 43, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.0345624484887906e-05}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  8.323628228861136 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  7.873939790925779 acc:  0.005805774512649889\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  7.648894079915293 acc:  0.01239309559431034\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  7.491839105432684 acc:  0.017752272067525623\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  7.359370925209739 acc:  0.029430810798740593\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  7.1886822026926325 acc:  0.05044324855413885\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  7.019326813571103 acc:  0.06768193287631467\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  6.816080516868538 acc:  0.09807292945983967\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  6.588570601456649 acc:  0.12453386329634013\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  6.475276503529582 acc:  0.12455619319831186\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  6.482697823664525 acc:  0.12455619319831186\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  6.4772971793488185 acc:  0.12455619319831186\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  6.454696815330665 acc:  0.12460085300225532\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  6.5337947465323065 acc:  0.12466784270817051\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  6.448747431481634 acc:  0.12466784270817051\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  6.461918347365373 acc:  0.12477949221802916\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  6.48181020963442 acc:  0.12477949221802916\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  6.459194996973851 acc:  0.12486881182591608\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  6.496941409744583 acc:  0.12489114172788782\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  6.48375716909662 acc:  0.12482415202197263\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  6.503949912277968 acc:  0.12484648192394436\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  6.494281595403498 acc:  0.12486881182591608\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  6.456575857175814 acc:  0.12491347162985955\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  6.4584630652741115 acc:  0.12489114172788782\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  6.490908536044034 acc:  0.12489114172788782\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  6.518729876805018 acc:  0.12486881182591608\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  6.457918967400397 acc:  0.12477949221802916\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  6.468392462163538 acc:  0.12486881182591608\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 312, 'dropout': 0.15281885109219973, 'dropout_transformers': 0.05922870538772418, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8013076672217504, 'scheduler': 'StepLR', 'step_size': 29, 'lr': 0.0003449874299457624, 'dropout_lstm': 0.006963939305531797, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 32, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.372384702834215e-07}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.006963939305531797 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  7.718835362764162 acc:  0.005269856865328361\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  7.346097478242678 acc:  0.00649800147377353\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  7.121283780748599 acc:  0.044324855413884735\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  6.8225647088523225 acc:  0.08011968827456847\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  6.434593075903777 acc:  0.10890293191612889\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  6.056678593715775 acc:  0.142018176540205\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  5.496078397626075 acc:  0.17370430743809034\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  5.1609861694763755 acc:  0.1989817564700891\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  4.872577281755822 acc:  0.23133778442712635\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  4.580361831968076 acc:  0.25114440747605116\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  4.216765775858799 acc:  0.27195587611370386\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  3.978198067050114 acc:  0.28269655896210616\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  3.882786877801485 acc:  0.2952682937721903\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  3.6820053229822176 acc:  0.30944778152423913\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  3.554127174003102 acc:  0.3218855369224929\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  3.526470342529154 acc:  0.32206417613826677\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  3.2847099649571927 acc:  0.3326262197708952\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  3.299393061165498 acc:  0.34008440702945314\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  3.2059436624295246 acc:  0.34819016144519127\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  3.27537156933936 acc:  0.35430855458544536\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  3.209719978760336 acc:  0.3547774825268517\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  3.1287954655763146 acc:  0.36192305115780543\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  3.0458758211581505 acc:  0.36759484625862493\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  3.020208184964189 acc:  0.3714132594957908\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  2.8494182602267397 acc:  0.3707656923386106\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  2.968884041376203 acc:  0.3785364982247728\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  2.8932203956853564 acc:  0.37726369381238417\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  2.8481105142664687 acc:  0.38099278744166315\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  2.8141829677831347 acc:  0.38572672665966995\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  2.8172054780977906 acc:  0.38903155215148605\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  2.6614805237155092 acc:  0.3932519036241431\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  2.8777145537260536 acc:  0.3935421923497756\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  2.7591436600016657 acc:  0.39544023401737266\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  2.708608447948349 acc:  0.4015809570595985\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  2.5519372637026776 acc:  0.40124600853002257\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  2.641704701931677 acc:  0.4029654109818458\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  2.668541158471152 acc:  0.4043275350021213\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  2.626775397318546 acc:  0.4061139271598598\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  2.600830911475921 acc:  0.40727508206238977\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  2.5662507453811503 acc:  0.407007123238729\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  2.605906301569716 acc:  0.40772168010182436\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  2.537020400305775 acc:  0.4113614541232164\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  2.5926404467252926 acc:  0.41207601098631175\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  2.559233583022501 acc:  0.4145099703012304\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  2.4523099315500705 acc:  0.4117857222606793\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  2.4886849750982267 acc:  0.4136837639282764\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  2.506191225809472 acc:  0.41692159971417725\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  2.434287653905209 acc:  0.4122546502020856\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  2.4771596884059015 acc:  0.4146886095170042\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  2.468024312892807 acc:  0.41649733157671437\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  3.878363611542176 acc:  0.41413036196771097\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  3.744821318956179 acc:  0.4127012482415202\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36807632135382384 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'ReLU6', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.4236397583190712, 'dropout_transformers': 0.1106874617714919, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 0.0030331599014896678, 'dropout_lstm': 0.36807632135382384, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.192611057108053e-06}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  7.6818819450119795 acc:  0.05642766228256258\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  6.692099894507456 acc:  0.13688229908670702\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  5.9698005369154075 acc:  0.1886876716611214\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  5.461204544972565 acc:  0.1972846839202376\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  5.194783582525738 acc:  0.20172833441261193\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  4.746975745184947 acc:  0.20132639617712078\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  4.562208159495208 acc:  0.20083513833374272\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  4.486789283105883 acc:  0.20614965500301455\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  4.303015777620218 acc:  0.21278163588861845\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  4.1811487997992565 acc:  0.2181854721657772\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  3.9381147441217457 acc:  0.2200388540294308\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  3.845342409812798 acc:  0.22343299912913384\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  3.7962177648382673 acc:  0.2296630417792466\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  3.7865274477813204 acc:  0.22950673246544448\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  3.7544657133393367 acc:  0.2427037045307371\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  3.615358380948083 acc:  0.24801822120000894\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  3.4345349134024925 acc:  0.25170265502534445\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  3.4358547865334206 acc:  0.2586025947346091\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  3.3792349443597307 acc:  0.26422973003148514\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  3.288415411771354 acc:  0.2663064109148561\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  3.217581126649501 acc:  0.27785097023424066\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  3.249985755500147 acc:  0.2768461246455128\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  3.2153508259078203 acc:  0.2861130339637809\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  3.152642500602593 acc:  0.2912712413192506\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  3.1231215444661804 acc:  0.295379943282049\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  3.0449126009213723 acc:  0.29698769622401355\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  2.9289463455394165 acc:  0.291985798182346\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  2.940315254664017 acc:  0.3025478418149744\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  3.0561208684565657 acc:  0.3057856776008753\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  3.0167865793583757 acc:  0.3083982761315678\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  2.895279371132285 acc:  0.3095594310340978\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  2.842105816986601 acc:  0.31241765848647923\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  2.888025122173762 acc:  0.3142263805461894\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  2.8628256118903725 acc:  0.3128419266239421\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  2.861809015274048 acc:  0.31942924770560255\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  2.816966646808689 acc:  0.3233369805506554\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  2.7645174810441873 acc:  0.3292320746711922\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  2.7697799044140314 acc:  0.324364156041355\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  2.7711467904559637 acc:  0.3235826094723444\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  2.7350478778451177 acc:  0.3284951879061251\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  2.745075561232486 acc:  0.32706607417993433\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  2.8125322269181074 acc:  0.32407386731572246\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  2.7352513337539412 acc:  0.3306165285934395\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  2.7449138204930192 acc:  0.32992430163231584\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  2.7337049791368386 acc:  0.3265301565326128\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  2.696241534362405 acc:  0.3306388584954112\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  2.6506664187221203 acc:  0.3332067972221602\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  2.640437140303143 acc:  0.3360203648705982\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  2.62641418586343 acc:  0.33749413840073245\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  2.6260456675190036 acc:  0.3382086952638278\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  3.6354612213070108 acc:  0.32985731192640066\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  3.670660366446285 acc:  0.33749413840073245\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  52 loss :  3.5871573949264266 acc:  0.332313601143291\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  53 loss :  3.6369220685150663 acc:  0.3377844271263649\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  54 loss :  3.637887890056028 acc:  0.33986110800973585\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  55 loss :  3.631896241236541 acc:  0.34455038742379923\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  56 loss :  3.7185837131435586 acc:  0.3443047585021102\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  57 loss :  3.6141318870803056 acc:  0.34318826340352365\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  58 loss :  3.6342090752165195 acc:  0.33972712859790544\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  59 loss :  3.5479852385440114 acc:  0.3407319741866333\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  60 loss :  3.5572749356092035 acc:  0.3403970256570574\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  61 loss :  3.490405826245324 acc:  0.3464037692874528\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  62 loss :  3.5077084565566756 acc:  0.3488153987003997\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  63 loss :  3.5886642367152843 acc:  0.3491503472299757\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  64 loss :  3.450896562156031 acc:  0.3434562222271844\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  65 loss :  3.5179617324117887 acc:  0.34184846928521984\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  66 loss :  3.4988340684923074 acc:  0.34517562467900764\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  67 loss :  3.514669232449289 acc:  0.34689502713083087\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  68 loss :  3.552422592195414 acc:  0.3502668423285622\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  69 loss :  3.5223579043048923 acc:  0.34787754281758704\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.448211321629359 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.2658760496573009, 'dropout_transformers': 0.24292985463551653, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6547226603222032, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.001187794341727599, 'dropout_lstm': 0.448211321629359, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.818543910910043e-05}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  7.443559283594931 acc:  0.009199919612352902\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  7.117660682432113 acc:  0.034008440702945314\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  6.601220352418961 acc:  0.08835942210213697\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  5.5527877992199315 acc:  0.17886251479356005\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  4.737893106091407 acc:  0.23535716678203783\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  4.060137844085693 acc:  0.26342585356050285\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  3.624114022716399 acc:  0.2845499408257598\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  3.397126407008017 acc:  0.29926534622513007\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  3.2452154882492557 acc:  0.3197195364312351\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  3.0647606265160343 acc:  0.3341669830069446\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  10 loss :  2.9623386982948547 acc:  0.34216108791282407\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  11 loss :  2.8889560830208563 acc:  0.34825715115110645\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  12 loss :  2.828601304946407 acc:  0.3596900609606324\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  13 loss :  2.7483460003329863 acc:  0.3738248889087377\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  14 loss :  2.716363640754454 acc:  0.37601321930196724\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  15 loss :  2.693239616578625 acc:  0.38175200410870197\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  16 loss :  2.6513302049329206 acc:  0.3895004800928924\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  17 loss :  2.564115979594569 acc:  0.402206194314807\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  18 loss :  2.5022913863581997 acc:  0.4054663600026796\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  19 loss :  2.4499309778213503 acc:  0.40756537078802224\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  20 loss :  2.4196414024599138 acc:  0.407252752160418\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  21 loss :  2.4559928724842686 acc:  0.41015563941674293\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  22 loss :  2.3687504422280097 acc:  0.41321483598687003\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  23 loss :  2.4130181989362165 acc:  0.41493423843869326\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  24 loss :  2.3088817711799376 acc:  0.4151128776544671\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  25 loss :  2.3459354031470516 acc:  0.41890896098966124\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  26 loss :  2.3270068930041408 acc:  0.4214322399124668\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  27 loss :  2.2768245658566877 acc:  0.4232856217761204\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  28 loss :  2.2587370326442104 acc:  0.42009244579416294\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  29 loss :  2.2487160736514675 acc:  0.42098564187303217\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  30 loss :  2.272256189007913 acc:  0.42435745707076344\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  31 loss :  2.221382301084457 acc:  0.422079807069647\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  32 loss :  2.2137332470186295 acc:  0.42567492128709555\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  33 loss :  2.230479940291374 acc:  0.4271710247192015\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  34 loss :  2.1843751876584947 acc:  0.4327981600160775\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  35 loss :  2.1758131334858555 acc:  0.432262242368756\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  36 loss :  2.1689069424906084 acc:  0.43148069579974546\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  37 loss :  2.139869333851722 acc:  0.4339593149186075\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  38 loss :  2.103042116472798 acc:  0.4334457271732577\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  39 loss :  2.1222239540469263 acc:  0.43420494384029656\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  40 loss :  2.1118627394399336 acc:  0.434584552173816\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  41 loss :  2.0768071959095615 acc:  0.43349038697720116\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  42 loss :  2.0804548025131226 acc:  0.43503115021325056\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  43 loss :  2.0667540688668526 acc:  0.4358573565862046\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  44 loss :  2.0892663863397414 acc:  0.43467387178170286\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  45 loss :  2.0376246890714094 acc:  0.4372641404104236\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  46 loss :  2.0956912763657107 acc:  0.43708550119464973\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  47 loss :  2.0281656903605305 acc:  0.4370408413907063\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  48 loss :  2.029116299075465 acc:  0.43445057276198557\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  49 loss :  2.024772999363561 acc:  0.4358796864881763\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  50 loss :  3.1278810931790257 acc:  0.43735346001831055\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  51 loss :  3.1139776706695557 acc:  0.4379340374695755\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  52 loss :  3.0156476036194833 acc:  0.4390728624701338\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  53 loss :  3.011168009235013 acc:  0.4394078109997097\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  54 loss :  3.0140277308802452 acc:  0.4376214188419713\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  55 loss :  3.043973470503284 acc:  0.43840296541098184\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  56 loss :  2.9876502098575717 acc:  0.44012236786280506\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  57 loss :  3.030243453671855 acc:  0.43949713060759665\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  58 loss :  3.0464543050335298 acc:  0.4402340173726637\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  59 loss :  2.9449251251835977 acc:  0.44150682178505235\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  60 loss :  2.986154813151206 acc:  0.43936315119576624\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  61 loss :  2.9742099746581045 acc:  0.44045731639238106\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  62 loss :  2.9941151449757237 acc:  0.4403903266864658\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  63 loss :  2.9610551264978224 acc:  0.4417971105106849\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  64 loss :  2.985310028445336 acc:  0.4438737913940558\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  65 loss :  2.9544379603478217 acc:  0.4421097291382891\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  66 loss :  2.940706854481851 acc:  0.4421767188442043\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  67 loss :  2.9463430512335993 acc:  0.4415291516870241\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  68 loss :  2.97413750310098 acc:  0.4411718732554764\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  69 loss :  2.9254560485962897 acc:  0.44206506933434564\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2762220113891003 and num_layers=1\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=42630)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 360, 'dropout': 0.26116961672473477, 'dropout_transformers': 0.3671638101350774, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.576195809198437, 'scheduler': 'StepLR', 'step_size': 8, 'lr': 0.0012538223841012035, 'dropout_lstm': 0.2762220113891003, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Hardtanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 10, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.592953498184075e-05}\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  0 loss :  7.556607464838295 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  1 loss :  7.431798908297576 acc:  0.002344639707031686\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  2 loss :  7.407759972790766 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  3 loss :  7.397724924140802 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  4 loss :  7.392517734506277 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  5 loss :  7.3458867792310665 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  6 loss :  7.329785807838653 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  7 loss :  7.342266993815673 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  8 loss :  7.313382457754465 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=42630)\u001b[0m epoch:  9 loss :  7.296496700308176 acc:  0.005001898041667597\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 19:51:35,035\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 19:51:49,483\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 19:51:49,484\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_4        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_4\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_4`\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35143685329930685 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.11755847073077369, 'dropout_transformers': 0.3057191508007018, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3846357023516324, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.005275982960861348, 'dropout_lstm': 0.35143685329930685, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 49, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0005173324688319929}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.525738539096124 acc:  0.01297367304557533\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.096011307425128 acc:  0.04611124757162316\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  6.359978932820394 acc:  0.1411473103633075\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  5.5033564224928435 acc:  0.1875041868566197\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  4.986928554352172 acc:  0.20322443784471786\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  4.4686167896864655 acc:  0.2054574280418909\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  4.276170850513938 acc:  0.21034767657369985\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 72, 'dropout': 0.03619818021131141, 'dropout_transformers': 0.35953166006749376, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.08893921534086686, 'dropout_lstm': 0.4372117331611033, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Tanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.19523832603037092}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4372117331611033 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.40297600530809 acc:  0.006051403434338924\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.028814131213773 acc:  0.01038340441685461\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  6.865513976927726 acc:  0.009445548534041935\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  6.814328393628521 acc:  0.009445548534041935\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  6.7755461692810055 acc:  0.010807672554317487\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.340303950155935 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  7.352220147655856 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  7.355152216265278 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  8 loss :  7.357634332103114 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  9 loss :  7.354564660595309 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.2527732161947014, 'dropout_transformers': 0.20168553889677843, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.15148211257895633, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 0.014053473136426593, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 33, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.092968743887636e-05}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  8.618343907017861 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.48132388822494 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  7.357926304109635 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  7.3305044235721715 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  7.302496264057774 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.295015836531116 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  7.307469198780675 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  7.292952011477563 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20109631189942853 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.2135259807810757, 'dropout_transformers': 0.4003117953103801, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7413029520849147, 'scheduler': 'ExponentialLR', 'lr': 0.0008268571870904207, 'dropout_lstm': 0.20109631189942853, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 29, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.01634570292520084}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.165698291691205 acc:  0.08268762700131746\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  5.403438973972816 acc:  0.1888216510729518\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  4.316364686907702 acc:  0.27878882611705336\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  3.7784294463295973 acc:  0.3032847285800415\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  3.5281875497512236 acc:  0.33845432418551685\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  3.260704686623493 acc:  0.3586852153719045\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  3.168828567475763 acc:  0.3695598776321372\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  3.097899622589577 acc:  0.3740705178304267\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  8 loss :  2.9841210478134736 acc:  0.37965299332335933\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  9 loss :  2.984801630937416 acc:  0.3815510349909564\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  10 loss :  2.926643744679808 acc:  0.38414130361967713\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  11 loss :  2.958398899049249 acc:  0.38650827322868053\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  12 loss :  2.9595349781385814 acc:  0.38836165509233417\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  13 loss :  2.9537988455240964 acc:  0.3883169952883907\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  14 loss :  2.891778700224316 acc:  0.38918786146528817\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  15 loss :  2.923660984476104 acc:  0.38983542862246834\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  16 loss :  2.8814842427959877 acc:  0.38947815019092064\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  17 loss :  2.8707460010324723 acc:  0.38999173793627046\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  18 loss :  2.8813985304068064 acc:  0.39077328450528104\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  19 loss :  2.904295778456535 acc:  0.39054998548556374\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  20 loss :  2.925147642616097 acc:  0.3904606658776768\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  21 loss :  2.90010460460459 acc:  0.3907062947993658\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  22 loss :  2.92379796231976 acc:  0.39079561440725274\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  23 loss :  2.882534624056052 acc:  0.3907062947993658\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  24 loss :  2.9107177384937084 acc:  0.391108233034857\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  25 loss :  2.8776533549068537 acc:  0.39101891342697004\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  26 loss :  2.8553101343052987 acc:  0.39099658352499833\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  27 loss :  2.860308818234742 acc:  0.3911975526427439\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  28 loss :  2.882392417383558 acc:  0.3911975526427439\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  29 loss :  2.9054160190902594 acc:  0.3911305629368287\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  30 loss :  2.8803926715414034 acc:  0.3910412433289418\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  31 loss :  2.9080743971671765 acc:  0.3911305629368287\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  32 loss :  2.847865108315271 acc:  0.39124221244668733\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  33 loss :  2.925654758933846 acc:  0.39115289283880045\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  34 loss :  2.917324492039571 acc:  0.391108233034857\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  35 loss :  2.880017704636086 acc:  0.39117522274077215\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  36 loss :  2.8993537407794983 acc:  0.3911305629368287\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  37 loss :  2.8964666683255262 acc:  0.39115289283880045\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardtanh', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 384, 'dropout': 0.3283753860924308, 'dropout_transformers': 0.2312707084665835, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 10, 'factor': 0.5501379726134739, 'patience': 1, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.3556887514889871, 'lr': 4.1088680728197283e-07, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0007185915606588426}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  8.175260144079516 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  8.161627044220884 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  8.150900052693077 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  8.13985894825644 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  8.131972644143476 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  8.123700330357352 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  8.117087301379906 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  8.107178134118726 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  8 loss :  8.101132869720459 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  9 loss :  8.093408064927884 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  10 loss :  8.082859687462538 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  11 loss :  8.0745977727239 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  12 loss :  8.065012606318126 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  13 loss :  8.058136634484022 acc:  0.0011834848045017081\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  14 loss :  8.050253277053375 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  15 loss :  8.042965020962104 acc:  0.0014067838242190116\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  16 loss :  8.034275828721281 acc:  0.0014514436281624723\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  17 loss :  8.031429496353972 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  18 loss :  8.023167453126279 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  19 loss :  8.018886549030235 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  20 loss :  8.014173096525456 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  21 loss :  8.01220507821637 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  22 loss :  8.008211204391754 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  23 loss :  8.000152867711233 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  24 loss :  7.992672277781778 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  25 loss :  7.988519602906918 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  26 loss :  7.979830924622313 acc:  0.002277650001116495\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  27 loss :  7.976644738705573 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  28 loss :  7.9724365251506875 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  29 loss :  7.969730597056315 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  30 loss :  7.9671686480859085 acc:  0.0024786191188620682\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  31 loss :  7.965110470434863 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  32 loss :  7.963626133467623 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  33 loss :  7.956945165188727 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  34 loss :  7.957591048257793 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  35 loss :  7.953361516941094 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  36 loss :  7.949121569445033 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  37 loss :  7.9467323754362 acc:  0.0028805573543532145\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  38 loss :  7.9441113671856725 acc:  0.0028805573543532145\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  39 loss :  7.943621227127349 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  40 loss :  7.94347061225754 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  41 loss :  7.937327085140937 acc:  0.002992206864211866\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  42 loss :  7.937141013002681 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  43 loss :  7.933318646368153 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  44 loss :  7.938990401650617 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  45 loss :  7.930587417351272 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  46 loss :  7.930148284592314 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  47 loss :  7.931647018044295 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  48 loss :  7.927951293077298 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  49 loss :  7.928776392679729 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.07727071494945559 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.16076125580011255, 'dropout_transformers': 0.16388874148420207, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7296125901052692, 'scheduler': 'StepLR', 'step_size': 6, 'lr': 0.0004817049099515965, 'dropout_lstm': 0.07727071494945559, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'LogSigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 15, 'reg': True, 'transformers_model': True, 'activation_gcn': 'SiLU', 'dropout_gcn': 0.049186096259053014, 'hidden_channels': 32, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 1, 'use_gcn': True, 'weight_decay': 0.0023990385252261365}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.501146392661984 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.293658685283501 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  7.3027417559583645 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  7.274312207678787 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  7.240569864000593 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.305095892994344 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.46879329030674655 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'CELU', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': False, 'd_model': 624, 'dropout': 0.35770031028184623, 'dropout_transformers': 0.48513433264790473, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6809469080431109, 'scheduler': 'StepLR', 'step_size': 10, 'lr': 0.02079692342505266, 'dropout_lstm': 0.46879329030674655, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.47849592808225e-08}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  8.240129207397674 acc:  0.06569457160083067\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.1283311443729 acc:  0.09943505348011522\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  6.378440320074975 acc:  0.1468860951700422\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 120, 'dropout': 0.18717958464267556, 'dropout_transformers': 0.2406963915684307, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.04187097851589178, 'scheduler': 'ExponentialLR', 'lr': 0.004067666306222755, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'CELU', 'dropout_gcn': 0.0165177445484459, 'hidden_channels': 16, 'layer_type': 'GAT', 'norm': 'LayerNorm', 'num_layers_gcn': 1, 'use_gcn': True, 'weight_decay': 9.814129757701833e-06}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.9866437911987305 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.953148798509077 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  7.7764573097229 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  7.7711661078713155 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  7.851933089169589 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.811768011613325 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3592150257979735 and num_layers=1\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'LogSigmoid', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 720, 'dropout': 0.2671760123766716, 'dropout_transformers': 0.19032810329621433, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.496851166761099, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.001885332967648025, 'dropout_lstm': 0.3592150257979735, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'ReLU6', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 6, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.726896480778703e-05}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.948126430971077 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.788612268057214 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  7.667368136256574 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  7.58743409076369 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  7.503788861883692 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.459180780203946 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  7.410375106765564 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  7.380524020597159 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'ReLU6', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.29175644001017237, 'dropout_transformers': 0.3002942495039991, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 2.4856344515891507e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.018636486308819377}\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  0 loss :  7.799344675357525 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  1 loss :  7.47563957801232 acc:  0.011231940691780363\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  2 loss :  7.2862675520089955 acc:  0.03045798628944019\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  3 loss :  7.1598503296191875 acc:  0.03865306031306522\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  4 loss :  7.081173885785616 acc:  0.04858986669048523\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  5 loss :  7.028813094359178 acc:  0.0557800951253824\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  6 loss :  6.988485266612126 acc:  0.06142956032423018\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  7 loss :  6.948234330690824 acc:  0.06582855101266105\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  8 loss :  6.915371792133038 acc:  0.06951298483799656\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  9 loss :  6.8829805520864635 acc:  0.0759439966058549\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  10 loss :  6.852704444298378 acc:  0.08413907062947994\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  11 loss :  6.8212525000939 acc:  0.08907397896523234\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  12 loss :  6.791293103878314 acc:  0.09237880445704844\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  13 loss :  6.7603446813730095 acc:  0.0948574235759105\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  14 loss :  6.732470152928279 acc:  0.09706808387111181\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  15 loss :  6.699582444704496 acc:  0.10146707455954268\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  16 loss :  6.670661031282865 acc:  0.10450394122769802\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  17 loss :  6.642057345463679 acc:  0.10749614809190988\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  18 loss :  6.609035759705764 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  19 loss :  6.580618102733905 acc:  0.11182814907442556\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  20 loss :  6.547586719806378 acc:  0.11517763437018512\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  21 loss :  6.513572997313279 acc:  0.11743295446932989\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  22 loss :  6.485710389797504 acc:  0.11747761427327334\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  23 loss :  6.4521240197695215 acc:  0.11799120201862313\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  24 loss :  6.417465899540828 acc:  0.12013487260790925\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  25 loss :  6.386776267565214 acc:  0.12105039858875019\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  26 loss :  6.354886982991145 acc:  0.1253154098653507\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  27 loss :  6.317916070497953 acc:  0.12846392604336468\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  28 loss :  6.286556049493643 acc:  0.1320143804568698\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  29 loss :  6.247465284054096 acc:  0.13250563830024786\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  30 loss :  6.2171500059274525 acc:  0.1352522162427707\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  31 loss :  6.183111359522893 acc:  0.1352522162427707\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  32 loss :  6.147045616003183 acc:  0.138289082910926\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  33 loss :  6.107907625345083 acc:  0.13851238193064333\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  34 loss :  6.076223083642813 acc:  0.1418841971283746\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  35 loss :  6.037997487875131 acc:  0.14288904271710248\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  36 loss :  6.003259860552275 acc:  0.14534533193399282\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  37 loss :  5.965647631425124 acc:  0.14789094075877007\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  38 loss :  5.929619506689218 acc:  0.14853850791595025\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  39 loss :  5.894704638994657 acc:  0.15032490007368868\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  40 loss :  5.854216069441575 acc:  0.15242391085903134\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  41 loss :  5.819467144746047 acc:  0.15369671527141995\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  42 loss :  5.7828456731942985 acc:  0.15488020007592165\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  43 loss :  5.744043064117432 acc:  0.1546792309581761\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  44 loss :  5.708563914665809 acc:  0.15666659223366008\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  45 loss :  5.668395596284133 acc:  0.15927919076435254\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  46 loss :  5.631466344686655 acc:  0.15816269566576602\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  47 loss :  5.595064882131723 acc:  0.15992675792153271\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  48 loss :  5.559176012185904 acc:  0.159904428019561\n",
            "\u001b[36m(eval_config pid=62604)\u001b[0m epoch:  49 loss :  5.5176065518305855 acc:  0.16088694370631712\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 20:44:22,127\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 20:44:36,328\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 20:44:36,330\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_5        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_5\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_5`\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3293871038514281 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 456, 'dropout': 0.07266906133920159, 'dropout_transformers': 0.3904479455693327, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6907463133520679, 'scheduler': 'ExponentialLR', 'lr': 9.512721851361545e-07, 'dropout_lstm': 0.3293871038514281, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 35, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Hardsigmoid', 'dropout_gcn': 0.48517833001315425, 'hidden_channels': 16, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 2, 'use_gcn': True, 'weight_decay': 3.804073017398374e-06}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  8.112232783368526 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  8.092942376173179 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  8.08322939981941 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  8.072546929803513 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  8.067307443109177 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  8.062211939396748 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  8.060161106459057 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  7 loss :  8.060777747904071 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  8 loss :  8.058948677004748 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  9 loss :  8.056259184393264 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  10 loss :  8.05904737501654 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  11 loss :  8.059978903704927 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  12 loss :  8.055294124224714 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  13 loss :  8.056320405188407 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  14 loss :  8.053397386128665 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  15 loss :  8.061351736083285 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  16 loss :  8.05629329099 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  17 loss :  8.059461579068017 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  18 loss :  8.05300575358267 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.38198661215791296 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.39678315228417826, 'dropout_transformers': 0.263568563890213, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5673346444820138, 'scheduler': 'StepLR', 'step_size': 7, 'lr': 0.0001926940701022216, 'dropout_lstm': 0.38198661215791296, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.004740523607723396}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  8.204933547973633 acc:  0.005761114708706429\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.76476674761091 acc:  0.006765960297434294\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.547832243783134 acc:  0.010182435299109036\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  7.4105129786900115 acc:  0.019918272558783468\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  7.328990949903216 acc:  0.020923118147511334\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  7.2715204783848355 acc:  0.03778219413616774\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  7.137235954829625 acc:  0.04725007257218141\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  7 loss :  7.1406931332179475 acc:  0.06692271620927584\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  8 loss :  7.170148440769741 acc:  0.07288480003572784\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  9 loss :  6.940360191890171 acc:  0.07826630641091485\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  10 loss :  6.719587053571429 acc:  0.08554585445369894\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  11 loss :  6.710680457523891 acc:  0.08853806131791081\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  12 loss :  6.600863647460938 acc:  0.09671080543956412\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  13 loss :  6.460099697113037 acc:  0.10834468436683563\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  14 loss :  6.167181124005999 acc:  0.11495433535046781\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  15 loss :  6.266004821232387 acc:  0.1322376794765871\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  16 loss :  6.152444430759975 acc:  0.14192885693231808\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  17 loss :  5.95779356275286 acc:  0.15443360203648707\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  18 loss :  5.995573956625802 acc:  0.15293749860438113\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  19 loss :  5.933240079879761 acc:  0.1545452515463457\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  20 loss :  5.916568715231759 acc:  0.1646160373355961\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  21 loss :  5.604556901114328 acc:  0.1747761427327334\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  22 loss :  5.6441760199410576 acc:  0.17466449322287475\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  23 loss :  5.508253989900862 acc:  0.17805863832257776\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  24 loss :  5.475205503191266 acc:  0.1886206819552062\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  25 loss :  5.592126955304827 acc:  0.19509635352700802\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  26 loss :  5.620946720668248 acc:  0.1987584574503718\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  27 loss :  5.361325856617519 acc:  0.20201862313824442\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  28 loss :  5.500690174102783 acc:  0.21010204765201082\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  29 loss :  5.392558492933001 acc:  0.21416608981086574\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  30 loss :  5.4423122950962615 acc:  0.21758256481254049\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  31 loss :  5.306097936630249 acc:  0.21939128687225062\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  32 loss :  5.174835968017578 acc:  0.21874371971507045\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  33 loss :  4.96202746118818 acc:  0.22358930844293592\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  34 loss :  5.076192378997803 acc:  0.2268048143268651\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  35 loss :  4.886045340129307 acc:  0.22859120648460354\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  36 loss :  5.280330630711147 acc:  0.23031060893642677\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  37 loss :  4.983745901925223 acc:  0.23225331040796732\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  38 loss :  5.047768660954067 acc:  0.23448630060514034\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  39 loss :  5.267677334376744 acc:  0.2368086104102003\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  40 loss :  5.1560796397072926 acc:  0.23830471384230623\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  41 loss :  4.988647283826555 acc:  0.2404930442355358\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  42 loss :  5.125189236232212 acc:  0.24091731237299868\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  43 loss :  5.210518864222935 acc:  0.24105129178482906\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  44 loss :  4.898649181638445 acc:  0.24205613737355694\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  45 loss :  5.047534424918038 acc:  0.2434182613938325\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  46 loss :  5.10340690612793 acc:  0.24522698345354263\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  47 loss :  4.873047753742763 acc:  0.2463658084541009\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  48 loss :  4.883666440418788 acc:  0.24721434472902665\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  49 loss :  4.844327892575945 acc:  0.24667842708170512\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Softmin', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 264, 'dropout': 0.13827114983859284, 'dropout_transformers': 0.33777168286056836, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 4, 'factor': 0.24475479741720993, 'patience': 4, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00018015287737759838, 'lr': 0.009968232825181047, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 21, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LeakyReLU', 'dropout_gcn': 0.28939656144194176, 'hidden_channels': 32, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 2, 'use_gcn': True, 'weight_decay': 0.0012881775601494138}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4246886902953353 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Hardswish', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 360, 'dropout': 0.0013605650986124318, 'dropout_transformers': 0.18204438676651752, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.8971030315371361, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 7.680677314027735e-05, 'dropout_lstm': 0.4246886902953353, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 39, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.2420876258010875e-07}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  7.968337306057114 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.577238525252745 acc:  0.008887300984748677\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.323277565370123 acc:  0.032757966192528416\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  7.116255415491311 acc:  0.060179085813813274\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  6.939450338662389 acc:  0.08099055445146595\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  6.767649242676884 acc:  0.10291851818770516\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  6.599653605955193 acc:  0.11298930397695554\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  7 loss :  6.4429242639656525 acc:  0.13402407163432553\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  8 loss :  6.2779290877192855 acc:  0.1509278074269254\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  9 loss :  6.067614670259407 acc:  0.16320925351137708\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  10 loss :  5.934509662260492 acc:  0.17323537949668402\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  11 loss :  5.753450077700328 acc:  0.17915280351919255\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  12 loss :  5.622017073344035 acc:  0.18672264028760913\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  13 loss :  5.484902582972882 acc:  0.19887010696023044\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  14 loss :  5.292979665549405 acc:  0.19954000401938235\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  15 loss :  5.230330863630916 acc:  0.2119330996136927\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  16 loss :  5.036148657281715 acc:  0.21764955451845566\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  17 loss :  4.908157440553229 acc:  0.22740772168010182\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  18 loss :  4.803708323513169 acc:  0.2359154143313311\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  19 loss :  4.683637578803372 acc:  0.24357457070763458\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  20 loss :  4.639218416558691 acc:  0.24904539669070852\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  21 loss :  4.494156363498734 acc:  0.2561463055177188\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  22 loss :  4.366851214902947 acc:  0.25753075943996606\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  23 loss :  4.3771004734269106 acc:  0.26679766875823413\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  24 loss :  4.281922567321594 acc:  0.27450148493848114\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  25 loss :  4.1654797864247515 acc:  0.2771810731750888\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  26 loss :  4.203520579510425 acc:  0.28135676484380234\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  27 loss :  4.098854866372534 acc:  0.2880780653372932\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  28 loss :  4.029601392975772 acc:  0.2918294888685439\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  29 loss :  3.953810275319111 acc:  0.296451778576692\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  30 loss :  3.8849543232515633 acc:  0.2991313668132997\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  31 loss :  3.901041076843997 acc:  0.30498180112989304\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  32 loss :  3.829075612217547 acc:  0.3068351829935467\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  33 loss :  3.7882285031927636 acc:  0.30911283299466313\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  34 loss :  3.751490929040564 acc:  0.3146059888797088\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  35 loss :  3.6985646845346474 acc:  0.3179778040774401\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  36 loss :  3.6824092146861984 acc:  0.32014380456869795\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  37 loss :  3.630040674324495 acc:  0.32545832123796975\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  38 loss :  3.6063646006296914 acc:  0.3290534354554184\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  39 loss :  3.5475141025451293 acc:  0.3321796217314606\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  40 loss :  3.5519903855151442 acc:  0.3340776633990577\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  41 loss :  3.5006396942828073 acc:  0.3364669629100328\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  42 loss :  3.4678469738328315 acc:  0.3401960565393118\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  43 loss :  3.5074115747428802 acc:  0.33986110800973585\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  44 loss :  3.4151014764624907 acc:  0.3452649442868946\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  45 loss :  3.4006126731275077 acc:  0.3476095839939263\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  46 loss :  3.420231824897858 acc:  0.35024451242659044\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  47 loss :  3.319606128945408 acc:  0.3526338119375656\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  48 loss :  3.340515243001731 acc:  0.3551570908603711\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  49 loss :  3.3195194910807784 acc:  0.3559609673313534\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  50 loss :  4.420467793223369 acc:  0.3602483085099256\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  51 loss :  4.34639443834144 acc:  0.3583056070383851\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  52 loss :  4.3206018367445616 acc:  0.3622803295893531\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  53 loss :  4.3261728487819076 acc:  0.3641783712569502\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  54 loss :  4.271394393530237 acc:  0.36547350557131053\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  55 loss :  4.285750391971634 acc:  0.36953754773016545\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  56 loss :  4.272092457277229 acc:  0.3698055065538262\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  57 loss :  4.216762720820415 acc:  0.3711676305741018\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  58 loss :  4.153716291289732 acc:  0.37246276488846214\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  59 loss :  4.127091752477439 acc:  0.3736909094969073\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  60 loss :  4.227717672485903 acc:  0.37793359087153605\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  61 loss :  4.148713473814079 acc:  0.3768170957729496\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  62 loss :  4.159891315253384 acc:  0.37829086930308375\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  63 loss :  4.181510623679103 acc:  0.3787597972444901\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  64 loss :  4.159206559859126 acc:  0.38219860214813656\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  65 loss :  4.09220668206732 acc:  0.38387334479601637\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  66 loss :  4.092074244855398 acc:  0.383984994305875\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  67 loss :  4.129839842578015 acc:  0.3849451800906594\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  68 loss :  4.084434810891209 acc:  0.38610633499318936\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  69 loss :  4.0482080557260165 acc:  0.38532478842417883\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  70 loss :  4.086399802242417 acc:  0.38742379920952147\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  71 loss :  4.097826926104994 acc:  0.39021503695598775\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  72 loss :  4.06319160059274 acc:  0.39220239823147174\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  73 loss :  4.03361953597471 acc:  0.39211307862358485\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  74 loss :  4.017154501145145 acc:  0.3921577384275283\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  75 loss :  4.042931938745889 acc:  0.3930286046044258\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  76 loss :  4.010514977466629 acc:  0.3961994506844115\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  77 loss :  3.995954869741417 acc:  0.3964227497041288\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  78 loss :  4.025825790612094 acc:  0.39599848156666595\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  79 loss :  3.9504242029534766 acc:  0.3974945849987719\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  80 loss :  3.9876371234296317 acc:  0.3986557399013018\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  81 loss :  3.9984771946826614 acc:  0.39861108009735835\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  82 loss :  3.9883617607943984 acc:  0.4001071835294643\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  83 loss :  3.9021638875984284 acc:  0.39974990509791664\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  84 loss :  4.001736164093018 acc:  0.4021615345108635\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  85 loss :  3.9499506864203027 acc:  0.4016032869615702\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  86 loss :  3.8747122029224075 acc:  0.40307706049170444\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  87 loss :  3.9820189332387534 acc:  0.40330035951142174\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  88 loss :  3.890871435762888 acc:  0.4028314315700154\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1465377556397805 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Mish', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': False, 'd_model': 648, 'dropout': 0.22450431868258813, 'dropout_transformers': 0.2773618759806947, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.2758069608728557, 'scheduler': 'StepLR', 'step_size': 28, 'lr': 0.0566058506719609, 'dropout_lstm': 0.1465377556397805, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.000238583408865439}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 312, 'dropout': 0.33779675574215506, 'dropout_transformers': 0.23529243661532598, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.018202852205054687, 'scheduler': 'ExponentialLR', 'lr': 0.0018879623039254859, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 17, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softmin', 'dropout_gcn': 0.27690924429652797, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'LayerNorm', 'num_layers_gcn': 3, 'use_gcn': True, 'weight_decay': 7.133234549930535e-07}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  7.752485867972686 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.465363890211159 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.4300381892195375 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  7.431039315517817 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  7.4237873398254965 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  7.4075002714852305 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Softsign', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 216, 'dropout': 0.3755639772698449, 'dropout_transformers': 0.445873055650127, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.02936075603902262, 'dropout_lstm': 0.4736558261033489, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'RReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 25, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0756081520321239}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4736558261033489 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Tanhshrink', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 432, 'dropout': 0.038439441106465994, 'dropout_transformers': 0.0752189495556401, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.39880987944432933, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 2.6339252400357853e-05, 'dropout_lstm': 0.2951617995835757, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.4208662453377627e-05}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2951617995835757 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  7.961953834748604 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.620114514525508 acc:  0.008574682357144451\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.253664419684611 acc:  0.03597347207645758\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  6.931489931025975 acc:  0.07076345934841347\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  6.5600646314486655 acc:  0.10347676573699842\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  6.235202144569074 acc:  0.13460464908559053\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  5.922251708070997 acc:  0.1544782618404305\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  7 loss :  5.7219705447344715 acc:  0.1755800192037157\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  8 loss :  5.4788090880488 acc:  0.19319831185941094\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  9 loss :  5.315964389854754 acc:  0.2103923363776433\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  10 loss :  5.109647999347096 acc:  0.2212893285398477\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  11 loss :  4.970814442970384 acc:  0.23138244423106982\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  12 loss :  4.800965974028681 acc:  0.24364156041354978\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  13 loss :  4.689532051623707 acc:  0.25147935600562715\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  14 loss :  4.600605272910964 acc:  0.26027733738248887\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  15 loss :  4.467704014039375 acc:  0.2656365138557042\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  16 loss :  4.413769738774904 acc:  0.26900832905343547\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  17 loss :  4.368252129621909 acc:  0.27063841189737176\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  18 loss :  4.370874186636696 acc:  0.27497041287988744\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  19 loss :  4.340314918840435 acc:  0.27680146484156937\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  20 loss :  4.260301747792203 acc:  0.2793470736663466\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  21 loss :  4.237089026142174 acc:  0.2820266619029542\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  22 loss :  4.211159763201861 acc:  0.28539847710068555\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  23 loss :  4.164606201816612 acc:  0.2867829310229328\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  24 loss :  4.163214985753449 acc:  0.2904003751423531\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  25 loss :  4.146026067330804 acc:  0.2925887055355827\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  26 loss :  4.073004689015133 acc:  0.29459839671303845\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  27 loss :  4.078579627292257 acc:  0.2972333251457026\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  28 loss :  4.041926501502453 acc:  0.29747895406739167\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  29 loss :  3.9982728588748984 acc:  0.30006922269611236\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  30 loss :  3.972855356377615 acc:  0.3011857177946989\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  31 loss :  3.954164753497486 acc:  0.30198959426568117\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  32 loss :  3.9868898727524447 acc:  0.30359734720764575\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  33 loss :  3.9399737337945213 acc:  0.30382064622736304\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  34 loss :  3.9267562577422237 acc:  0.30511578054172345\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  35 loss :  3.929687916393011 acc:  0.3052720898555255\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  36 loss :  3.930120840878554 acc:  0.30667887367974456\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  37 loss :  3.8878650866763693 acc:  0.30670120358171626\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  38 loss :  3.92187345195824 acc:  0.3077730388763593\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  39 loss :  3.8963490439132906 acc:  0.3084875957394547\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  40 loss :  3.8565881218708737 acc:  0.3095817609360695\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  41 loss :  3.8587152857176017 acc:  0.3101400084853628\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  42 loss :  3.869411569246104 acc:  0.31094388495634506\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  43 loss :  3.8346819944784674 acc:  0.31232833887859235\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  44 loss :  3.8567895049780185 acc:  0.3127526070160552\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  45 loss :  3.7938820375523097 acc:  0.31299823593774423\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  46 loss :  3.8060522348108425 acc:  0.3136234731929527\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  47 loss :  3.8234800016376336 acc:  0.31375745260478305\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  48 loss :  3.836149145180071 acc:  0.31514190652703034\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  49 loss :  3.8346964473455722 acc:  0.3149855972132282\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  50 loss :  4.983467491579727 acc:  0.3102739878971931\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  51 loss :  4.911166446309694 acc:  0.3117924212312708\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  52 loss :  4.913595696570168 acc:  0.3132438648594333\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  53 loss :  4.899744463638521 acc:  0.31398075162450034\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2678404530925982 and num_layers=1\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.2732600885089167, 'dropout_transformers': 0.15233159194610477, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 6, 'factor': 0.8941761721781163, 'patience': 8, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.006517438431592051, 'lr': 0.0005688977478552451, 'dropout_lstm': 0.2678404530925982, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.44436456687079784, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 6.620527121043741e-08}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  7.611513849032128 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.325773691726943 acc:  0.010271754906995959\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.165825989286779 acc:  0.023580376482147242\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  6.851763628296933 acc:  0.07351003729093629\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  6.223710633940616 acc:  0.1293124623182904\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  5.60037353483297 acc:  0.17957707165665543\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  4.871571548914505 acc:  0.2333698055065538\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  7 loss :  4.419367131540331 acc:  0.2625773172855771\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  8 loss :  4.095082319388955 acc:  0.28760913739588684\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  9 loss :  3.825415906259569 acc:  0.305316749659469\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  10 loss :  3.612732656931473 acc:  0.3329388383984994\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  11 loss :  3.458974147247056 acc:  0.34689502713083087\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  12 loss :  3.365365012217376 acc:  0.3508027599758837\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  13 loss :  3.3036706932520463 acc:  0.3578590089989505\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  14 loss :  3.2562600192377125 acc:  0.36540651586539535\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  15 loss :  3.177250106455916 acc:  0.37445012616394613\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  16 loss :  3.1438273575346347 acc:  0.3752763325369002\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  17 loss :  3.047576815395032 acc:  0.38438693254136613\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  18 loss :  3.019560826026787 acc:  0.3890762119554295\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  19 loss :  2.901594052880497 acc:  0.39345287274188867\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  20 loss :  2.925907430002245 acc:  0.3965343992139875\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  21 loss :  2.9446482133057157 acc:  0.3992139874505951\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  22 loss :  2.913403418104527 acc:  0.40086640019650316\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  23 loss :  2.8037868394690046 acc:  0.4050420918652167\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  24 loss :  2.8423924244056313 acc:  0.40461782372775384\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  25 loss :  2.794087086693715 acc:  0.4095304021615345\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  26 loss :  2.7900593240382308 acc:  0.41044592814237546\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  27 loss :  2.7752003790968556 acc:  0.41433133108545656\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  28 loss :  2.676192186646542 acc:  0.41399638255588056\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  29 loss :  2.7532392558404957 acc:  0.41752450706741395\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  30 loss :  2.6821655338093384 acc:  0.4183953732443115\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  31 loss :  2.657758914818198 acc:  0.4244244467766787\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  32 loss :  2.6753947977292336 acc:  0.4230176629524596\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  33 loss :  2.6841310565754517 acc:  0.4242234776589331\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  34 loss :  2.6542605181871832 acc:  0.42489337471808497\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  35 loss :  2.655493008888374 acc:  0.4250496840318871\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  36 loss :  2.602601067494538 acc:  0.4251836634437175\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  37 loss :  2.6456186407703464 acc:  0.4259428801107563\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  38 loss :  2.6214038234646035 acc:  0.425965210012728\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  39 loss :  2.606041819362317 acc:  0.4264341379541344\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  40 loss :  2.5564460350295244 acc:  0.4302972109952437\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  41 loss :  2.5591455879857983 acc:  0.4308107987405935\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  42 loss :  2.5672256542464433 acc:  0.4316146752115758\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  43 loss :  2.5078126939676575 acc:  0.43353504678114463\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  44 loss :  2.499837917796636 acc:  0.4347855212915615\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  45 loss :  2.5422212107706876 acc:  0.4328204899180493\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  46 loss :  2.4882796618898038 acc:  0.43386999531072057\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  47 loss :  2.5086691137087547 acc:  0.432842819820021\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  48 loss :  2.528620408753217 acc:  0.4365049237433848\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  49 loss :  2.449164596654601 acc:  0.4326418507022754\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.23942583965759678, 'dropout_transformers': 0.2973863851384987, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 6, 'factor': 0.8697260398245894, 'patience': 8, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00984147732680209, 'lr': 0.0006191372133739771, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.44548496958708583, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 4.08866746152759e-09}\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  0 loss :  7.680759593418666 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  1 loss :  7.368892165592738 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  2 loss :  7.340267889840263 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  3 loss :  7.324673584529331 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  4 loss :  7.300027588435582 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  5 loss :  7.300981398991176 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=75976)\u001b[0m epoch:  6 loss :  7.302480070931571 acc:  0.005001898041667597\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 21:54:48,353\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 21:55:02,634\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 21:55:02,636\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_6        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_6\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_6`\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.08068125592597508 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 768, 'dropout': 0.20204198964704126, 'dropout_transformers': 0.3449150229115517, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 2, 'factor': 0.6595196235441989, 'patience': 9, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.020116107551875935, 'lr': 0.0010911025374218794, 'dropout_lstm': 0.08068125592597508, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Hardshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'RReLU', 'dropout_gcn': 0.4292219941679077, 'hidden_channels': 16, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 5, 'use_gcn': True, 'weight_decay': 8.275152661021625e-10}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.529852050845906 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.391560659570209 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.358493263438596 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.323225005198333 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  7.313855753106586 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  7.310744245173567 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  7.3090395119230624 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  7.292565636715646 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22550709338547384 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'RReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 528, 'dropout': 0.17412175297489957, 'dropout_transformers': 0.19838064135090316, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 9, 'factor': 0.26224131909955195, 'patience': 5, 'scheduler': 'ReduceLROnPlateau', 'threshold': 5.319753960742555e-05, 'lr': 0.004548158862865442, 'dropout_lstm': 0.22550709338547384, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'swish', 'dropout_gcn': 0.48927014063460633, 'hidden_channels': 32, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 9, 'use_gcn': True, 'weight_decay': 7.736496070408156e-08}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.810552380301735 acc:  0.005560145590960856\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.326662453738126 acc:  0.013330951477123015\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.195891467007724 acc:  0.011879507848960543\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.053717786615545 acc:  0.03901033874461291\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  6.950179663571444 acc:  0.07420226425205993\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  6.735825148495761 acc:  0.10700489024853181\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  6.332815950567072 acc:  0.1570238706652078\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  6.0187129540876905 acc:  0.18093919567693098\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  5.802092812278054 acc:  0.18996047607351005\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  5.681100932034579 acc:  0.19424781725208226\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  5.561284021897749 acc:  0.2063506241207601\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  5.41597335988825 acc:  0.20876225353370698\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  5.394847176291726 acc:  0.20999039814215215\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  5.253131779757413 acc:  0.2194359466761941\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  5.130360126495361 acc:  0.2252640510908157\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  5.021368807012385 acc:  0.22727374226827143\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  4.776335152712735 acc:  0.23285621776120402\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  4.722780921242454 acc:  0.23861733246991046\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  4.582356626337225 acc:  0.2435075810017194\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  4.440955075350675 acc:  0.24824152021972623\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  4.337458328767256 acc:  0.2592055020878458\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  4.049611958590421 acc:  0.26239867806980327\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  4.115768085826527 acc:  0.26532389522809996\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  4.0738327286460185 acc:  0.2680034834647076\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  4.085097421299327 acc:  0.2730053815063752\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  4.0244223854758525 acc:  0.2768461246455128\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  4.052955627441406 acc:  0.27767233101846683\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  3.987748991359364 acc:  0.28077618739253735\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  3.902975472536954 acc:  0.2841480025902686\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  3.881146019155329 acc:  0.2847285800415336\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  3.889285347678445 acc:  0.289417859455597\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  3.7853434736078437 acc:  0.28879262220038854\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  3.7808726484125312 acc:  0.2928789942612152\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  3.772975271398371 acc:  0.2958488712234553\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  3.612998832355846 acc:  0.29852845946006296\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  3.777627858248624 acc:  0.30143134671638794\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  3.7351965687491675 acc:  0.3010517383828685\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  3.723206476731734 acc:  0.3015429962262466\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  3.76262075250799 acc:  0.30366433691356093\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  3.657405831597068 acc:  0.30507112073778\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  3.6202696670185435 acc:  0.3062099457383382\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  3.722896684299816 acc:  0.3069914923073488\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  3.6567752144553443 acc:  0.3079070182881897\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  3.558681748130105 acc:  0.3082642967197374\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  3.5966118465770376 acc:  0.31043029721099524\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  3.726338256489147 acc:  0.31125650358394924\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  3.6399874687194824 acc:  0.31237299868253576\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  3.6797899332913486 acc:  0.3140030815264721\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  3.517704876986417 acc:  0.3142040506442177\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  49 loss :  3.626100193370472 acc:  0.31366813299689617\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17228845793452424 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 696, 'dropout': 0.3206722790585691, 'dropout_transformers': 0.22226395207853425, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 7, 'factor': 0.3571618992257808, 'patience': 6, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0036004120305573257, 'lr': 0.00027612290356720436, 'dropout_lstm': 0.17228845793452424, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'PReLU', 'dropout_gcn': 0.0010705252614464367, 'hidden_channels': 256, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 3, 'use_gcn': True, 'weight_decay': 1.5195428095827036e-08}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.859382359877877 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.454966130463974 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.351127209870712 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.327499182327934 acc:  0.005694125002791238\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  7.2533550055130664 acc:  0.009311569122211554\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  7.272814626279085 acc:  0.01435812696782261\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  7.16099388703056 acc:  0.015139673536833173\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  7.078406105870786 acc:  0.03592881227251413\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  6.971547023109768 acc:  0.0530558470848313\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  6.856767654418945 acc:  0.06111694169662595\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  6.755919186965279 acc:  0.0692450260143358\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  6.570648400679879 acc:  0.08909630886720407\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  6.408045333364735 acc:  0.09709041377308354\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  6.316185640252155 acc:  0.11138155103499095\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  6.245489846105161 acc:  0.12134068731438269\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  6.049575743467911 acc:  0.13708326820445257\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  5.923284883084505 acc:  0.14467543487484089\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  5.76951153382011 acc:  0.15809570595985084\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  5.5911246382671855 acc:  0.16229372753053614\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  5.504590967427129 acc:  0.17747806087131276\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  5.4182271542756455 acc:  0.18737020744478933\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  5.279346403868302 acc:  0.1977982716655874\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  5.211356784986413 acc:  0.1986244780385414\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  5.232078220533288 acc:  0.20378268539401112\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  5.126229161801546 acc:  0.2087845834356787\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  5.054008193638014 acc:  0.21019136725989773\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  5.0706038060395615 acc:  0.2139874505950919\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  4.960101086160411 acc:  0.21764955451845566\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  5.111079692840576 acc:  0.22323203001138825\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  4.927154914192531 acc:  0.22352231873702075\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  4.9233677283577295 acc:  0.22515240158095706\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  4.929892768030581 acc:  0.22825625795502757\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  4.812233240708061 acc:  0.2268718040327803\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  4.928152405697366 acc:  0.23037759864234195\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  4.813173895296843 acc:  0.23216399080008038\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  4.798504725746486 acc:  0.23339213540852555\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  4.787208163219949 acc:  0.23582609472344415\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  4.8157422646232275 acc:  0.23736685795949355\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  4.716362911721935 acc:  0.23846102315610834\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  4.5958847688592 acc:  0.2380590849206172\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  4.834342407143635 acc:  0.23975615747046872\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  4.69143357484237 acc:  0.24002411629412948\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  4.619973493658978 acc:  0.24051537413750754\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  4.7207320047461465 acc:  0.24134158051046156\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  4.7233986647232715 acc:  0.24093964227497042\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  4.7219120523203975 acc:  0.24160953933412233\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  4.5229987683503525 acc:  0.24156487953017886\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  4.686674263166345 acc:  0.2430609829622848\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  4.6211874381355615 acc:  0.24509300404171225\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  49 loss :  4.768226975980013 acc:  0.24574057119889245\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.021401173048457706 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'LeakyReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.3044560022875151, 'dropout_transformers': 0.09960567806785092, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.6141674018123261, 'patience': 3, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.11479720568384098, 'lr': 0.01164008748957068, 'dropout_lstm': 0.021401173048457706, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ReLU', 'dropout_gcn': 0.27016944917224384, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'InstanceNorm', 'num_layers_gcn': 7, 'use_gcn': True, 'weight_decay': 1.6424328097293374e-09}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.089013059260481 acc:  0.17658486479244356\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  5.182320716017384 acc:  0.20755643882723354\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  4.520000182976157 acc:  0.21890002902887257\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  4.1432423106694625 acc:  0.2203961324609785\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  3.9657624616461287 acc:  0.2255543398164482\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  3.806475934335741 acc:  0.2291717839358685\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  3.663335994138556 acc:  0.22970770158319004\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  3.510626126143892 acc:  0.21968157559788312\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  3.5639361769466076 acc:  0.22213786481477346\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  3.530639979798915 acc:  0.22220485452068867\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  3.4353425017857955 acc:  0.22785431971953643\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  3.4186937041201833 acc:  0.22943974275952927\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  3.376656758583198 acc:  0.24303865306031305\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  3.2852242760739085 acc:  0.23866199227385393\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  3.236585883770959 acc:  0.22711743295446932\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  3.2388121637247376 acc:  0.23524551727217918\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  3.2189008825916354 acc:  0.2330571868789496\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  3.230830814878819 acc:  0.2310698256034656\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.11536162005590128, 'dropout_transformers': 0.08305475442349479, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 6, 'factor': 0.8677035429882319, 'patience': 9, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0004448595710667834, 'lr': 8.177192131890402e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Sigmoid', 'dropout_gcn': 0.3633357028099718, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'LayerNorm', 'num_layers_gcn': 9, 'use_gcn': True, 'weight_decay': 4.839391394049248e-08}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.995901442588644 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.916898199852477 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.856638147475872 acc:  0.005604805394904317\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.8057205017576825 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  7.764929609095796 acc:  0.006721300493490834\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  7.721408925157912 acc:  0.005917424022508541\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  7.67790077087727 acc:  0.006855279905321215\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  7.645229633818281 acc:  0.006989259317151598\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  7.6062009892565134 acc:  0.010584373534600183\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  7.567968987404032 acc:  0.010495053926713262\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  7.527989133875421 acc:  0.02661724315030257\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  7.49537803771648 acc:  0.028850233347475603\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  7.465508278380049 acc:  0.031060893642676907\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  7.43323341329047 acc:  0.03809481276377197\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  7.392506437098726 acc:  0.043119040707411294\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  7.373508605551212 acc:  0.04597726815979278\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  7.3409657072513665 acc:  0.04861219659245696\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  7.313518554606336 acc:  0.0562936828707322\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  7.291350953122403 acc:  0.05964316816649175\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  7.25513911754527 acc:  0.06533729316928298\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  7.217379103315637 acc:  0.06732465444476698\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  7.20452000232453 acc:  0.07460420248755108\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  7.190660344793441 acc:  0.07795368778331063\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  7.155049313890173 acc:  0.07886921376415157\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  7.141546614626621 acc:  0.08650604023848335\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  7.116119993493912 acc:  0.08820311278833486\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  7.080946333864902 acc:  0.09329433043788937\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  7.060005461916011 acc:  0.09499140298774088\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  7.055245703839241 acc:  0.09650983632181855\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  7.0175990652530755 acc:  0.10117678583391018\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  6.995612114033801 acc:  0.10189134269700556\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  6.985510065200481 acc:  0.10273987897193132\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  6.980235414302095 acc:  0.10881361230824196\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  6.949796179507641 acc:  0.10653596230712548\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  6.931374357101765 acc:  0.10888060201415715\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  6.922518567836031 acc:  0.11305629368287073\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  6.8935501017469045 acc:  0.11243105642766228\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  6.873772824064214 acc:  0.11522229417412858\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  6.87652392083026 acc:  0.11519996427215684\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  6.864169009188388 acc:  0.11899604760735101\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  6.8267575527759305 acc:  0.1185494495679164\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  6.794990285913995 acc:  0.12140767702029788\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  6.809756096373213 acc:  0.12216689368733671\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  6.7776964065876415 acc:  0.12270281133465824\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  6.7909532810779325 acc:  0.12529307996337896\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  6.742028256680103 acc:  0.12616394614027646\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  6.742866637858938 acc:  0.12844159614139294\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  6.733249339651554 acc:  0.1288435343768841\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  6.707613660934124 acc:  0.1298037201616685\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  49 loss :  6.700068991234962 acc:  0.13060759663265079\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.393105242715615 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.2829696194730347, 'dropout_transformers': 0.15129776963597713, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 10, 'factor': 0.41015244313608307, 'patience': 6, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.08307402570199798, 'lr': 0.00015856161129523333, 'dropout_lstm': 0.393105242715615, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softsign', 'dropout_gcn': 0.3111591853633821, 'hidden_channels': 32, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 3, 'use_gcn': True, 'weight_decay': 5.748395065491593e-06}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.610394880805217 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.296887545518472 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.2768146152227695 acc:  0.007971775003907732\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.234985022477701 acc:  0.013956188732331466\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  7.184308307271608 acc:  0.0167027666748543\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  7.155021298099571 acc:  0.028961882857334257\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  7.115046044470558 acc:  0.03179778040774401\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  7.064227547444088 acc:  0.051336444633008065\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  7.0093817710876465 acc:  0.057320858361431797\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  6.946020072614643 acc:  0.06227809659915593\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  6.892067828648527 acc:  0.06038005493155885\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  6.88864885249608 acc:  0.061384900520286716\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  6.859520670393823 acc:  0.06768193287631467\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  6.833805762546163 acc:  0.06839648973941004\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  6.814112481936602 acc:  0.07038385101489404\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  6.789362470868608 acc:  0.07016055199517673\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  6.783394692649304 acc:  0.07429158385994686\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  6.749773938890914 acc:  0.07759640935176294\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  6.719978157903107 acc:  0.08000803876470983\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  6.701702433572689 acc:  0.08561284415961413\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  6.682419582152031 acc:  0.08710894759172007\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  6.640578693067524 acc:  0.08862738092579774\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  6.585077997664331 acc:  0.09057008239733827\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  6.616060888263541 acc:  0.09202152602550075\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  6.581886217627726 acc:  0.09476810396802358\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  6.563676397565385 acc:  0.09724672308688564\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  6.54619703830128 acc:  0.09608556818435567\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  6.468741537819446 acc:  0.09901078534265234\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  6.476125958939673 acc:  0.09968068240180425\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  6.503626729401065 acc:  0.09983699171560637\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  6.461048381429323 acc:  0.10213697161869459\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  6.450458063206202 acc:  0.10249425005024228\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  6.449894743905941 acc:  0.10334278632516804\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  6.456058300716776 acc:  0.1036107451488288\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  6.433757318577296 acc:  0.10240493044235535\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  6.441694353667783 acc:  0.10354375544291361\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  6.414833814325467 acc:  0.1046379206395284\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  6.366036576284489 acc:  0.10347676573699842\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  6.412603754392812 acc:  0.10510684858093473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  6.378875530941386 acc:  0.10416899269812206\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  6.344485175441688 acc:  0.10271754906995959\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  6.358339685789296 acc:  0.10414666279615033\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  6.318414406037666 acc:  0.10515150838487819\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  6.332589471843881 acc:  0.10541946720853895\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  6.354051066116548 acc:  0.10595538485586048\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  6.326697826385498 acc:  0.10629033338543643\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  6.335786503805241 acc:  0.10637965299332336\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  6.335382474979884 acc:  0.10720585936627738\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  6.326620659358065 acc:  0.10756313779782507\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  49 loss :  6.3132222403942695 acc:  0.10937185985753523\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.26581508315419833 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.27465477203148375, 'dropout_transformers': 0.1680128657423158, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.7696770693885421, 'patience': 8, 'scheduler': 'ReduceLROnPlateau', 'threshold': 6.29713406492609e-06, 'lr': 9.458291266836354e-05, 'dropout_lstm': 0.26581508315419833, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.10965856450599126, 'hidden_channels': 16, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 6.305662726725634e-07}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.794666470979389 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  7.370760521135832 acc:  0.0037514235312506978\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  7.307436089766653 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  7.281194701947664 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  7.265826084739284 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  7.235347270965576 acc:  0.013866869124444544\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  7.146566742344906 acc:  0.02056583971596365\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  7.073542760547839 acc:  0.031686130897885356\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  6.936853353600753 acc:  0.053435455418350715\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  6.754116891559802 acc:  0.06243440591295804\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  6.582294765271638 acc:  0.08304490543286515\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  6.381971775858026 acc:  0.09519237210548645\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  6.268125870353297 acc:  0.1043476319138959\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  6.147567879526239 acc:  0.115021325056383\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  6.0077305342021745 acc:  0.12669986378759798\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  5.803375470010858 acc:  0.13471629859544917\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  5.649885880319696 acc:  0.14358126967822613\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  5.616852253361752 acc:  0.15392001429113727\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  5.461193260393645 acc:  0.16171315007927115\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  5.429225791128058 acc:  0.16508496527700242\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  5.207167956703588 acc:  0.17499944175245072\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  5.059169618706954 acc:  0.17917513342116428\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  5.041527735559564 acc:  0.18757117656253489\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  4.948111059791163 acc:  0.19319831185941094\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  4.887447683434737 acc:  0.1992720451957216\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  4.754297090831556 acc:  0.2044302525511913\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  4.828112235822176 acc:  0.2035370564723221\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  4.647600181479203 acc:  0.2062613045128732\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  4.5879467612818665 acc:  0.2122233883393252\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  4.642940573943289 acc:  0.2158408324587455\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  4.567899247219688 acc:  0.21932429716633545\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  4.464618057953684 acc:  0.2231203805015296\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  4.379149923826519 acc:  0.22280776187392537\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  4.372549611643741 acc:  0.22684947413080855\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  4.321493906723825 acc:  0.23044458834825715\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  4.2759312554409625 acc:  0.23037759864234195\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  4.248740931561119 acc:  0.23263291874148673\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  4.1783450176841335 acc:  0.23359310452627113\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  4.2022839822267235 acc:  0.23729986825357838\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  4.115328916750456 acc:  0.23910859031328852\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  4.188496393906442 acc:  0.24288234374651096\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  4.091224948983443 acc:  0.24301632315834135\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  4.159884088917782 acc:  0.24687939619945068\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  4.055111631594206 acc:  0.2502065515932385\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  3.9559194589916027 acc:  0.2497599535538039\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  4.055128215488635 acc:  0.2514346962016837\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  3.9914797431544256 acc:  0.2543152535560369\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  3.983970019691869 acc:  0.2559453363999732\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  4.019396463193392 acc:  0.25634727463546436\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  49 loss :  3.9590016390147964 acc:  0.2589598731661568\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3145092864232036 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.3544267159284486, 'dropout_transformers': 0.0608174733685599, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.18517139700046586, 'scheduler': 'StepLR', 'step_size': 5, 'lr': 0.0004164137802881084, 'dropout_lstm': 0.3145092864232036, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.37646887009333274, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 5, 'use_gcn': True, 'weight_decay': 1.7266491064525017e-07}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.451530925366057 acc:  0.024451242659044727\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  6.735062054225376 acc:  0.09867583681307639\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  5.886088263086912 acc:  0.16023937654913695\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  5.044687463455841 acc:  0.22593394814996762\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  4.375432601495951 acc:  0.27371993836947056\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  4.020130844677196 acc:  0.3013643570104727\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  3.8681549785517846 acc:  0.31080990554451465\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  3.82784631272324 acc:  0.31911662907799837\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  3.733218587747141 acc:  0.32952236339682467\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  3.642533646912134 acc:  0.3338990241832838\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  3.6171958706959955 acc:  0.33691356094946745\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  3.5936018458935393 acc:  0.3383650045776299\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  3.5591378151869573 acc:  0.3403300359511422\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  3.562125242056967 acc:  0.34178147957930466\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  3.549619967196168 acc:  0.343076613893665\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  3.5351455311815276 acc:  0.3435232119330996\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  3.523879672298912 acc:  0.343902820266619\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  3.5450649161298737 acc:  0.34421543889422324\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  3.500476913291867 acc:  0.34479601634548823\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  3.5249564667709734 acc:  0.3452649442868946\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  3.4990948368521297 acc:  0.3452872741888663\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  3.52998019466881 acc:  0.3452872741888663\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  3.4997115656107414 acc:  0.34546591340464017\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  3.5469075691800156 acc:  0.3452872741888663\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  3.4960087788205185 acc:  0.3452872741888663\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  3.5470505441938127 acc:  0.3452202844829511\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  3.4868522992655007 acc:  0.3452872741888663\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  3.5330176894404306 acc:  0.34539892369872494\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4642991032056453 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Hardshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 648, 'dropout': 0.41781825072781487, 'dropout_transformers': 0.11086795068186289, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6995526000139187, 'scheduler': 'StepLR', 'step_size': 9, 'lr': 3.0191680630530223e-06, 'dropout_lstm': 0.4642991032056453, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'SELU', 'dropout_gcn': 0.22548489430575608, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 2, 'use_gcn': True, 'weight_decay': 2.801135269362308e-06}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  8.28673289162772 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  8.290724182128907 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  8.291305215018136 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  8.2931460244315 acc:  0.00022329901971730344\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  8.272100530351912 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  8.279037775312151 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  8.270835304260254 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  8.275362586975097 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  8.27520340510777 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  8.273398780822754 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  8.26796351841518 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  8.269660568237304 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  8.2665100642613 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  8.270173617771693 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  8.271831594194685 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  8.263538197108678 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  8.267373929704938 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  8.261155836922782 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  8.260915456499372 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  8.258201326642718 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  8.249677331107003 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  8.259707287379674 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  8.262563977922712 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  8.253727449689592 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  8.25429322378976 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  8.250305257524763 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  8.258174405779158 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  8.261328588213239 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  8.248173931666782 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  8.248013523646764 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  8.24291444505964 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  8.246170125688826 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  8.241018050057548 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  8.254461996895927 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  8.24177382332938 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  8.244256700788226 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  8.248701340811593 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  8.24242330278669 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  8.248523221697127 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  8.252478299822126 acc:  0.0008708661768974834\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  40 loss :  8.246049908229283 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  41 loss :  8.235790307181222 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  42 loss :  8.247466714041574 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  43 loss :  8.236662401471818 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  44 loss :  8.240479224068778 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  45 loss :  8.246689360482351 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  46 loss :  8.23827852521624 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  47 loss :  8.24470100402832 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  48 loss :  8.239019230433874 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24689690900676325 and num_layers=1\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=93639)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.24281122261877675, 'dropout_transformers': 0.12365117691740052, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8917593344250823, 'scheduler': 'ExponentialLR', 'lr': 0.0015377549761848856, 'dropout_lstm': 0.24689690900676325, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 27, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.4610806714958556e-05}\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  0 loss :  7.474487861955022 acc:  0.11231940691780364\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  1 loss :  5.560170616012022 acc:  0.1972176942143224\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  2 loss :  4.46525219836867 acc:  0.2594511310095349\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  3 loss :  4.017884846193245 acc:  0.28287519817788\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  4 loss :  3.5886481985988388 acc:  0.3145836589777371\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  5 loss :  3.2677412176706704 acc:  0.3288747962396445\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  6 loss :  3.207283347486013 acc:  0.34207176830493713\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  7 loss :  3.00931006741811 acc:  0.36015898890203873\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  8 loss :  2.9415890251297547 acc:  0.3741375075363419\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  9 loss :  2.8137755537607583 acc:  0.38083647812786103\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  10 loss :  2.710693339267409 acc:  0.38878592322979705\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  11 loss :  2.719958348446582 acc:  0.3924256972511891\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  12 loss :  2.7025153076792336 acc:  0.3976732242145457\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  13 loss :  2.563517571931862 acc:  0.40519840117901884\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  14 loss :  2.509454748716699 acc:  0.40935176294576064\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  15 loss :  2.464478792914425 acc:  0.41082553647589487\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  16 loss :  2.459295383418899 acc:  0.4151798673603823\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  17 loss :  2.3839157733572534 acc:  0.4158274345175625\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  18 loss :  2.3862178354378205 acc:  0.41640801196882743\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  19 loss :  2.366542422627828 acc:  0.41884197128374606\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  20 loss :  2.380622444382633 acc:  0.42201281736373175\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  21 loss :  2.299553423042757 acc:  0.42192349775584487\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  22 loss :  2.2879843956016632 acc:  0.4230623227564031\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  23 loss :  2.347165165177311 acc:  0.4232186320702052\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  24 loss :  2.302905237818339 acc:  0.4230399928544314\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  25 loss :  2.26720326205334 acc:  0.4244021168747069\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  26 loss :  2.237089845071356 acc:  0.425384632561463\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  27 loss :  2.2774856894849296 acc:  0.4262331688363888\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  28 loss :  2.3016497672322287 acc:  0.425965210012728\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  29 loss :  2.231714298926204 acc:  0.4263224884442757\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  30 loss :  2.264296459864421 acc:  0.4273273340330036\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  31 loss :  2.254834271339049 acc:  0.4275059732487774\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  32 loss :  2.272376431040017 acc:  0.4283545095237032\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  33 loss :  2.241119244012488 acc:  0.42897974677891165\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  34 loss :  2.1697423975151704 acc:  0.429448674720318\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  35 loss :  2.186649558055832 acc:  0.4289127570729965\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  36 loss :  2.2430636279554252 acc:  0.42824286001384454\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  37 loss :  2.230135274220662 acc:  0.4286447982493357\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  38 loss :  2.29918882789382 acc:  0.4289127570729965\n",
            "\u001b[36m(eval_config pid=93639)\u001b[0m epoch:  39 loss :  2.167684796344803 acc:  0.42842149922961836\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-10 23:46:00,400\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-10 23:46:14,549\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-10 23:46:14,550\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_7        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_7\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_7`\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25365793514655316 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.22585919485981243, 'dropout_transformers': 0.12466197208910665, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8879154786357151, 'scheduler': 'ExponentialLR', 'lr': 0.001526703057546723, 'dropout_lstm': 0.25365793514655316, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00015029778450067682}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.7617465762768765 acc:  0.05696357992988411\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  6.43162534196498 acc:  0.15039188977960385\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  5.219805737673226 acc:  0.21217872853538172\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  4.443772206872197 acc:  0.24817453051381105\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  4.025915388333595 acc:  0.2845052810218163\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  3.6923567480960133 acc:  0.3098050599557868\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  3.5244144908452437 acc:  0.3324029207511779\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  3.424388121750395 acc:  0.3411785722260679\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  3.1085123975398177 acc:  0.3481678315432195\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  3.028681508565353 acc:  0.36696960900341646\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  2.9607279341099626 acc:  0.3832927673447514\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  2.758115433030209 acc:  0.38650827322868053\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  2.893040058976513 acc:  0.3883839849943059\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  2.7511144775455283 acc:  0.39861108009735835\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  2.691011251029322 acc:  0.39894602862693435\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  2.6792493432255116 acc:  0.4059129580421142\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  2.6980034254365046 acc:  0.4081906080432307\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  2.606344768556498 acc:  0.40950807225956276\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  18 loss :  2.55646490040472 acc:  0.41437599088939997\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  19 loss :  2.541910933235944 acc:  0.416363352164884\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  20 loss :  2.5042896553621454 acc:  0.41897595069557647\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  21 loss :  2.5229195619033553 acc:  0.4212759305986647\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  22 loss :  2.4044795682874778 acc:  0.4208739923631735\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  23 loss :  2.3732391191741167 acc:  0.42156621932429716\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  24 loss :  2.508162498474121 acc:  0.42317397226626174\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  25 loss :  2.4241776587599415 acc:  0.42487104481611326\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  26 loss :  2.508796073622623 acc:  0.4250496840318871\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  27 loss :  2.39814082646774 acc:  0.4254069624634348\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  28 loss :  2.401052858869908 acc:  0.4246030859924525\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  29 loss :  2.387791431556314 acc:  0.4258535605028694\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  30 loss :  2.366437600830854 acc:  0.4265904472679365\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  31 loss :  2.394660812313274 acc:  0.42701471540539937\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  32 loss :  2.375311031179913 acc:  0.4266127771699082\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  33 loss :  2.4235640319727234 acc:  0.42743898354286225\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  34 loss :  2.4456676992319397 acc:  0.42701471540539937\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  35 loss :  2.353379174814386 acc:  0.4275506330527209\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  36 loss :  2.372653122675621 acc:  0.4281535404059576\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  37 loss :  2.363990512944884 acc:  0.42766228256257954\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  38 loss :  2.4414729344642767 acc:  0.42822053011187283\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  39 loss :  2.3873352155847063 acc:  0.4283098497197597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  40 loss :  2.3815397953583024 acc:  0.42826518991581625\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  41 loss :  2.3226674532486222 acc:  0.42826518991581625\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  42 loss :  2.3197977199392805 acc:  0.42819820020990107\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  43 loss :  2.3996068259417 acc:  0.42822053011187283\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  44 loss :  2.3040058895692987 acc:  0.42801956099412725\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  45 loss :  2.42263991347814 acc:  0.4288011075631378\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  46 loss :  2.3440843477087507 acc:  0.42884576736708124\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  47 loss :  2.33352535659984 acc:  0.42884576736708124\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  48 loss :  2.4116383528305314 acc:  0.4287341178572226\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  49 loss :  2.351500387919151 acc:  0.4290244065828551\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19913593856792824 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.24776133367731995, 'dropout_transformers': 0.2105592530141508, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6912536642488581, 'scheduler': 'ExponentialLR', 'lr': 0.0025742074952065158, 'dropout_lstm': 0.19913593856792824, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 35, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LogSigmoid', 'dropout_gcn': 0.45339980282816494, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'InstanceNorm', 'num_layers_gcn': 7, 'use_gcn': True, 'weight_decay': 2.5326069544043956e-05}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  6.958904352532812 acc:  0.18252461871692383\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  4.662285758788327 acc:  0.261014224147556\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  3.7056616932512765 acc:  0.31152446240761\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  3.2989177790032813 acc:  0.3500658732108166\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  3.020672801029251 acc:  0.37614719871379765\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  2.8566953331591134 acc:  0.3888975727396557\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  2.70732457666512 acc:  0.3962664403903267\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  2.637263705931514 acc:  0.4027644418641002\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  2.5826757413795196 acc:  0.40423821539423443\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  2.5258063882230277 acc:  0.4068731438268986\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  2.535307125872876 acc:  0.4092177835339303\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  2.511023983897933 acc:  0.41022262912265817\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  2.467621001852564 acc:  0.41026728892660164\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  2.5079978259213 acc:  0.41082553647589487\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  2.517864227294922 acc:  0.41140611392715987\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  2.4841250339186334 acc:  0.4118973717705379\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  2.4971184615629265 acc:  0.411808052162651\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  2.5070679360125436 acc:  0.4115400933389902\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  18 loss :  2.4783473144094628 acc:  0.4118750418685662\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  19 loss :  2.486240595220083 acc:  0.41207601098631175\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  20 loss :  2.474205989435495 acc:  0.4118750418685662\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  21 loss :  2.4613894899207427 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  22 loss :  2.5002490353871543 acc:  0.412143000692227\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  23 loss :  2.5112478014934494 acc:  0.41205368108434004\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  24 loss :  2.48588928831629 acc:  0.4118973717705379\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  25 loss :  2.498547212187066 acc:  0.4119420315744814\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  26 loss :  2.5037907189633475 acc:  0.41203135118236833\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  27 loss :  2.505645496299468 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10010231561909952 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.18099421942942612, 'dropout_transformers': 0.17991263697501522, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8156713419571193, 'scheduler': 'ExponentialLR', 'lr': 0.005916960712104591, 'dropout_lstm': 0.10010231561909952, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 40, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0002921017910367173}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.278292447748319 acc:  0.11560190250764799\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  5.781256742880378 acc:  0.20407297411964362\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  4.409435319228911 acc:  0.242547395216935\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  3.8000067690728416 acc:  0.2849518790612509\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  3.44101834632981 acc:  0.30100707857892506\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  3.1529063876246064 acc:  0.32956702320076814\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  3.003181665716037 acc:  0.3458678516401313\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  2.8880913862040347 acc:  0.35627358595895764\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  2.843440069279201 acc:  0.3662550521403211\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  2.7494674534864827 acc:  0.3759685594980238\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  2.708022846302516 acc:  0.38291315901123196\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  2.633539874788741 acc:  0.3866199227385392\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  2.644594662626025 acc:  0.38804903646472994\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  2.6183381953709564 acc:  0.39233637764330215\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  2.568567333087115 acc:  0.3949489761739946\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  2.563545358013099 acc:  0.39675769823370477\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  2.559505539880672 acc:  0.3974945849987719\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  2.5631528941678328 acc:  0.3974499251948284\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  18 loss :  2.517931570469494 acc:  0.39903534823482123\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  19 loss :  2.5323273128187154 acc:  0.40093338990241834\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  20 loss :  2.5233997727783635 acc:  0.4016479467655137\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  21 loss :  2.566731575509192 acc:  0.4019828952950897\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  22 loss :  2.5329378994417864 acc:  0.402206194314807\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  23 loss :  2.5428043200936115 acc:  0.401625616863542\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  24 loss :  2.53301417323905 acc:  0.40169260656945716\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  25 loss :  2.5376061990227496 acc:  0.40265279235424156\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  26 loss :  2.528871301194312 acc:  0.40307706049170444\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  27 loss :  2.4819428820005607 acc:  0.40285376147198715\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  28 loss :  2.4970712762483407 acc:  0.4028984212759306\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  29 loss :  2.5217950142605203 acc:  0.4028314315700154\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  30 loss :  2.490201436297994 acc:  0.40287609137395886\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  31 loss :  2.471187109678564 acc:  0.40287609137395886\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2291817531635105 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Hardsigmoid', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 336, 'dropout': 0.19838711781432616, 'dropout_transformers': 0.28916877785087963, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.5730024342581277, 'scheduler': 'ExponentialLR', 'lr': 0.0007112725952758572, 'dropout_lstm': 0.2291817531635105, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 47, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0010445639837534683}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.600231527027331 acc:  0.05189469218230132\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  6.435160882849442 acc:  0.13549784516445973\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  5.512749431007787 acc:  0.20706518098385548\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  4.983998454244513 acc:  0.2449813545318536\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  4.662029218673706 acc:  0.26230935846191633\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  4.525266710080598 acc:  0.2712413192506085\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  4.428750811125103 acc:  0.27945872317620524\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  4.381622716000206 acc:  0.2838130540606927\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  4.512563190962139 acc:  0.28448295111984456\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  4.371083126570049 acc:  0.2847062501395619\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  4.400116782439382 acc:  0.28542080700265726\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  4.3730284113633004 acc:  0.28564410602237456\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  4.425205519324855 acc:  0.2861800236696961\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  4.3566406526063615 acc:  0.28624701337561126\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  4.3662159769158615 acc:  0.28642565259138514\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  4.2775734324204295 acc:  0.2863586628854699\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  4.315826950575176 acc:  0.2864033226894134\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  4.419849443435669 acc:  0.2865373021012438\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  18 loss :  4.336365606910304 acc:  0.28644798249335685\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  19 loss :  4.4177933090611505 acc:  0.28644798249335685\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  20 loss :  4.296261762317858 acc:  0.286514972199272\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  21 loss :  4.32571799378646 acc:  0.28644798249335685\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  22 loss :  4.32614823391563 acc:  0.28644798249335685\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1592649143437635 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.29938404026768234, 'dropout_transformers': 0.2556445630415152, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.35011231217735594, 'scheduler': 'ExponentialLR', 'lr': 0.01627940131047381, 'dropout_lstm': 0.1592649143437635, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softplus', 'dropout_gcn': 0.49931270154902485, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'LayerNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 4.977009599283272e-05}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  9.253223916317554 acc:  0.10008262063729541\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  7.489774085105734 acc:  0.148225889288346\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  6.42150948910003 acc:  0.16941696625951813\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  5.898083960756343 acc:  0.18661099077775048\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  5.8462363811249425 acc:  0.18893330058281044\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  5.709651703530169 acc:  0.18924591921041467\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  5.748789969910967 acc:  0.19013911528928387\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  5.909879106156369 acc:  0.1900721255833687\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  5.765514201306282 acc:  0.19013911528928387\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  5.634620737522207 acc:  0.1902284348971708\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  5.713185290072826 acc:  0.1902284348971708\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  5.584120101117073 acc:  0.19025076479914252\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  5.678090673811893 acc:  0.19027309470111425\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  5.68282979599973 acc:  0.19025076479914252\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  5.634708901669117 acc:  0.19027309470111425\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  5.643682621894999 acc:  0.19027309470111425\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  5.655839351897544 acc:  0.19027309470111425\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  5.643702385273386 acc:  0.19027309470111425\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20482727024980574 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.1470030865119585, 'dropout_transformers': 0.025262161576319137, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.5788761022609024, 'scheduler': 'ExponentialLR', 'lr': 0.0026930668395546936, 'dropout_lstm': 0.20482727024980574, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 3, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.109408040222499e-05}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.928429778193085 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  7.765673234429158 acc:  0.0019650313735122705\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  7.680766401156573 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  7.642520340395645 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  7.62420894730259 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  7.615174750207176 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  7.611563548235826 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  7.604552866707386 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3408175468019146 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.2215496096511651, 'dropout_transformers': 0.15277980124902346, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3691067560545723, 'scheduler': 'ExponentialLR', 'lr': 0.0008714400035539075, 'dropout_lstm': 0.3408175468019146, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0054138088165028445}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.82845957882433 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  7.393919956253235 acc:  0.010651363240515374\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  7.263711463974182 acc:  0.027443449523256593\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  7.195740941059158 acc:  0.026215304914811423\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  7.157847858337035 acc:  0.030212357367751155\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  7.152265204004495 acc:  0.032757966192528416\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  7.170281444687441 acc:  0.03273563629055668\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  7.130158171596297 acc:  0.03257932697675457\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  7.130840284278594 acc:  0.032690976486613225\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  7.1055728154010085 acc:  0.03271330638858495\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  7.13750458912677 acc:  0.03271330638858495\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2502401610492202 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'CELU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.2584418436329703, 'dropout_transformers': 0.2454966060176655, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 3.390403057771875e-05, 'dropout_lstm': 0.2502401610492202, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.0641641809573105e-05}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  8.259463843652757 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  8.067079657215183 acc:  0.0017194024518232365\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  7.962871899039058 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  7.816692344212936 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  7.729546959117307 acc:  0.005336846571243553\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  7.62864781234224 acc:  0.005984413728423732\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  7.569561732017387 acc:  0.007033919121095058\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  7.485174373044806 acc:  0.009512538239957126\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  7.468782538074558 acc:  0.011097961279949982\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  9 loss :  7.401721897771803 acc:  0.016010539713730655\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  10 loss :  7.395039041163558 acc:  0.016926065694571602\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  11 loss :  7.336259882328874 acc:  0.01880177746019695\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  12 loss :  7.349903963379941 acc:  0.024451242659044727\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  13 loss :  7.299568386401161 acc:  0.025210459326083557\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  14 loss :  7.213694273415259 acc:  0.02858227452381484\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  15 loss :  7.229307344404318 acc:  0.03441037893843646\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  16 loss :  7.203008829537085 acc:  0.0370899671750441\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  17 loss :  7.1553554049992965 acc:  0.039412276980104057\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  18 loss :  7.123837664975959 acc:  0.04365495835473282\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  19 loss :  7.095138695280431 acc:  0.045553000022329905\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  20 loss :  7.0143509800151245 acc:  0.04803161914119197\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  21 loss :  7.055859767784507 acc:  0.052921867673000916\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  22 loss :  7.04496535608324 acc:  0.05296652747694438\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  23 loss :  6.910108986547438 acc:  0.0570305696357993\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  24 loss :  6.972522711349746 acc:  0.0668110666994172\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  25 loss :  6.933689408383127 acc:  0.06937900542616618\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  26 loss :  6.933232857009112 acc:  0.07004890248531809\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  27 loss :  6.808076599896965 acc:  0.07359935689882321\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  28 loss :  6.888932591777737 acc:  0.07904785297992542\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  29 loss :  6.678374225810423 acc:  0.08208471964808074\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  30 loss :  6.725560018571756 acc:  0.08233034856976978\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  31 loss :  6.670780270786609 acc:  0.08556818435567068\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  32 loss :  6.622221267829507 acc:  0.08905164906326062\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  33 loss :  6.620882705106574 acc:  0.09157492798606615\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  34 loss :  6.525591575493247 acc:  0.09302637161422861\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  35 loss :  6.429420002436234 acc:  0.09930107406828484\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  36 loss :  6.441127615459894 acc:  0.10119911573588192\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  37 loss :  6.461585489370055 acc:  0.10233794073644016\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  38 loss :  6.402534298977609 acc:  0.10557577652234107\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  39 loss :  6.400959515975694 acc:  0.1108233034856977\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  40 loss :  6.427387706304001 acc:  0.11653975839046067\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  41 loss :  6.365394818580757 acc:  0.11772324319496237\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  42 loss :  6.36281565488395 acc:  0.11792421231270794\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  43 loss :  6.247164912142996 acc:  0.12815130741576045\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  44 loss :  6.214648044715493 acc:  0.1346716387915057\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  45 loss :  6.170559786133847 acc:  0.13627939173347028\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  46 loss :  6.117346925250555 acc:  0.145992899091173\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  47 loss :  6.085469577272059 acc:  0.14112498046133579\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  48 loss :  6.08694364256778 acc:  0.1462161981108903\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  49 loss :  6.000464863696341 acc:  0.147399682915392\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m GCNConv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12247684025378468 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softsign', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.3183435737220369, 'dropout_transformers': 0.049738070988202904, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7821206822083046, 'scheduler': 'ExponentialLR', 'lr': 0.007549887189556344, 'dropout_lstm': 0.12247684025378468, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 32, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Hardtanh', 'dropout_gcn': 0.4228349120516458, 'hidden_channels': 512, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 0.009321658034370996}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.93022868944251 acc:  0.0031931759819574393\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  7.5603223676266875 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  7.445136712945026 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  7.2928745642952295 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  7.247811752816905 acc:  0.003952392648996271\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  7.259005567301875 acc:  0.004153361766741844\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  7.21880697167438 acc:  0.006743630395462564\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  7 loss :  7.244000953176747 acc:  0.009244579416296363\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  8 loss :  7.218263315117878 acc:  0.008730991670946564\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Hardswish', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 192, 'dropout': 0.23938586246534785, 'dropout_transformers': 0.09295102380540632, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 0, 'factor': 0.12271964010764863, 'patience': 1, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.005798477530813726, 'lr': 0.024511765970622976, 'dropout_lstm': 0.3743605217895606, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Sigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 44, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 8.833473273553636e-05}\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3743605217895606 and num_layers=1\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  0 loss :  7.771523611169112 acc:  0.0033941450997030122\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  1 loss :  7.415456445593583 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  2 loss :  7.420500529439826 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  3 loss :  7.320869641554983 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  4 loss :  7.270996058614631 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  5 loss :  7.259149947919344 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=121239)\u001b[0m epoch:  6 loss :  7.249860100997122 acc:  0.003438804903646473\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 00:44:22,213\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 00:44:36,046\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 00:44:36,048\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_8        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_8\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_8`\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3131458507885086 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 696, 'dropout': 0.2083994655886317, 'dropout_transformers': 0.2216541258787829, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.8873298374231895, 'scheduler': 'ExponentialLR', 'lr': 0.000581406783041363, 'dropout_lstm': 0.3131458507885086, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 22, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00030591641231492324}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.617872313918355 acc:  0.0037290936292789676\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.401032880087879 acc:  0.005582475492932586\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.286125677768315 acc:  0.008753321572918294\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.1549981776799 acc:  0.022195922559899963\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.150658830304012 acc:  0.014134827948105309\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  6.955184446317014 acc:  0.029006542661277716\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  6.876131641530545 acc:  0.05770046669495121\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  6.721453688969122 acc:  0.08206238974610902\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  6.497209437539644 acc:  0.09291472210436996\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  9 loss :  6.272346024201295 acc:  0.11861643927383159\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  10 loss :  5.849651407972675 acc:  0.14802492017060045\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  11 loss :  5.786238861975269 acc:  0.16193644909898847\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  12 loss :  5.528153299171234 acc:  0.1794207623428533\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  13 loss :  5.337244648799718 acc:  0.18549449567916396\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  14 loss :  5.037073387163821 acc:  0.20139338588303599\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  15 loss :  5.161751390617584 acc:  0.21534957461536744\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  16 loss :  4.968716567921861 acc:  0.2183417814795793\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  17 loss :  4.717386051873181 acc:  0.22678248442489338\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  18 loss :  4.765853970964378 acc:  0.23455329031105554\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  19 loss :  4.6166261289721335 acc:  0.24062702364736618\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  20 loss :  4.619337928629367 acc:  0.24638813835607262\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  21 loss :  4.474114816879558 acc:  0.2517696447312596\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  22 loss :  4.557764271709407 acc:  0.2547395216934998\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  23 loss :  4.450131423005434 acc:  0.25482884130138667\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  24 loss :  4.394260707302628 acc:  0.25692785208672936\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  25 loss :  4.432808381374751 acc:  0.2598307393430543\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  26 loss :  4.391318381389725 acc:  0.2613491726771319\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  27 loss :  4.476293574983829 acc:  0.2627782864033227\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  28 loss :  4.344159859363164 acc:  0.2650112766004957\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  29 loss :  4.251900409983698 acc:  0.2651452560123261\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  30 loss :  4.407583236694336 acc:  0.26728892660161224\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  31 loss :  4.263568853663507 acc:  0.2683607618962553\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  32 loss :  4.280959659647719 acc:  0.2686063908179443\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  33 loss :  4.238920436841306 acc:  0.2691199785632941\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  34 loss :  4.305334300638359 acc:  0.27045977268159793\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  35 loss :  4.252442789969043 acc:  0.26983453542638947\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  36 loss :  4.279680004743772 acc:  0.27104035013286293\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  37 loss :  4.232640235223503 acc:  0.27128597905455193\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  38 loss :  4.32803632165784 acc:  0.2722015050353929\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  39 loss :  4.296092652828894 acc:  0.27166558738807134\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  40 loss :  4.298128756407265 acc:  0.2720451957215908\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  41 loss :  4.229855122967301 acc:  0.27135296876046716\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  42 loss :  4.183976202367623 acc:  0.2722015050353929\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  43 loss :  4.1735609736398 acc:  0.2720675256235625\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  44 loss :  4.261468867275203 acc:  0.27260344327088404\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  45 loss :  4.253723810766345 acc:  0.27258111336891233\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  46 loss :  4.219280213953178 acc:  0.2728714020945448\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  47 loss :  4.168961498224847 acc:  0.2730947011142621\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  48 loss :  4.126873535530589 acc:  0.2730947011142621\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  49 loss :  4.287795138136249 acc:  0.27349663934975327\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  50 loss :  5.328779182701467 acc:  0.27354129915369674\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  51 loss :  5.282203845888655 acc:  0.27358595895764015\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  52 loss :  5.296518417162316 acc:  0.2736306187615836\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  53 loss :  5.34094194608314 acc:  0.2736752785655271\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  54 loss :  5.361585097892262 acc:  0.273518969251725\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  55 loss :  5.532489433466831 acc:  0.27354129915369674\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  56 loss :  5.275414090290248 acc:  0.27374226827144227\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  57 loss :  5.343208377606401 acc:  0.27371993836947056\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  58 loss :  5.376626148402134 acc:  0.27401022709510303\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  59 loss :  5.328663329097712 acc:  0.2739655672911596\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  60 loss :  5.350419621601283 acc:  0.2741888663108769\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  61 loss :  5.360738660687598 acc:  0.2741888663108769\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  62 loss :  5.462500823992435 acc:  0.2741888663108769\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  63 loss :  5.3468617835891585 acc:  0.27416653640890515\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  64 loss :  5.2653207533827455 acc:  0.2742111962128486\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  65 loss :  5.351586916736353 acc:  0.2741888663108769\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  66 loss :  5.2349990060396285 acc:  0.2742335261148204\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  67 loss :  5.33270853702153 acc:  0.2742781859187638\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  68 loss :  5.297391454750132 acc:  0.2742111962128486\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  69 loss :  5.341182641893904 acc:  0.2742111962128486\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  70 loss :  5.342914186905477 acc:  0.27430051582073556\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  71 loss :  5.350242449858478 acc:  0.2742781859187638\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Mish', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 336, 'dropout': 0.09133592341949959, 'dropout_transformers': 0.11715076570194165, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 6, 'factor': 0.6854746297388962, 'patience': 5, 'scheduler': 'ReduceLROnPlateau', 'threshold': 8.704128801767946e-05, 'lr': 0.0013077935396758366, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'GELU', 'dropout_gcn': 0.06106375262966443, 'hidden_channels': 32, 'layer_type': 'GCNConv', 'norm': 'PairNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 0.0588220417377016}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.558029301195259 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.3371961490217465 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.313319166022611 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.310916889144714 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.271717071533203 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  7.255246237099889 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  7.285380317504147 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  7.2798526603055285 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  7.283147691244102 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21269774486388573 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 648, 'dropout': 0.2762281162612265, 'dropout_transformers': 0.007890055936593476, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lr': 0.0002438642006944799, 'dropout_lstm': 0.21269774486388573, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 41, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.212848278087511e-06}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.875410543169294 acc:  0.005694125002791238\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.461311408451626 acc:  0.008574682357144451\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.319930226462228 acc:  0.011901837750932273\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.072279044560024 acc:  0.0545296206149655\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  6.803059673309326 acc:  0.07426925395797512\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  6.419888619014195 acc:  0.11524462407610031\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  6.10673588344029 acc:  0.1375968559498024\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  5.861364119393485 acc:  0.17747806087131276\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  5.303244127546038 acc:  0.19639148784136837\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  9 loss :  4.9765764100211 acc:  0.22155728736350846\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  10 loss :  4.699788052695138 acc:  0.22957372217135966\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  11 loss :  4.6711898531232565 acc:  0.23837170354822143\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  12 loss :  4.549591841016497 acc:  0.264073420717683\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  13 loss :  4.1845667430332725 acc:  0.26891900944554853\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  14 loss :  3.982739305496216 acc:  0.2855101266105442\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  15 loss :  4.006187534332275 acc:  0.2898421275930599\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  16 loss :  3.755046592439924 acc:  0.29292365406515863\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  17 loss :  3.7865287031446186 acc:  0.3029497800504656\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  18 loss :  3.617676224027361 acc:  0.3062099457383382\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  19 loss :  3.510437890461513 acc:  0.3215729182948887\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  20 loss :  3.6198108468736923 acc:  0.3219525266284081\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  21 loss :  3.4777688230787005 acc:  0.3287184869258424\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  22 loss :  3.391210971559797 acc:  0.33539512761538975\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  23 loss :  3.34437210219247 acc:  0.3426970055601456\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  24 loss :  3.3504229613712857 acc:  0.34689502713083087\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  25 loss :  3.207924904142107 acc:  0.3402853761471987\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  26 loss :  3.2069943019321987 acc:  0.34921733693589085\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  27 loss :  3.055559308188302 acc:  0.35214255409418754\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  28 loss :  3.1537102358681817 acc:  0.3497532545832124\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  29 loss :  3.1828746931893486 acc:  0.3532367192908023\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  30 loss :  3.083605548313686 acc:  0.36114150458879485\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  31 loss :  2.9830345835004533 acc:  0.36737154723890764\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  32 loss :  3.004305178778512 acc:  0.3701851148873456\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  33 loss :  2.9899376256125314 acc:  0.37436080655605924\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  34 loss :  3.0775938987731934 acc:  0.3670812585132751\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  35 loss :  3.0117945194244387 acc:  0.3730210124377554\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  36 loss :  2.881880644389561 acc:  0.3732443114574727\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  37 loss :  2.9520959309169226 acc:  0.37541031194873054\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  38 loss :  2.889290939058576 acc:  0.379184065381953\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  39 loss :  2.8566222190856934 acc:  0.3799432820489918\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  40 loss :  2.890937614440918 acc:  0.3790500859701226\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  41 loss :  2.851774099894932 acc:  0.37967532322533104\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  42 loss :  2.9215096064976285 acc:  0.3834490766585535\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  43 loss :  2.807126079286848 acc:  0.38291315901123196\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  44 loss :  2.7725792339869906 acc:  0.3840519840117902\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  45 loss :  2.712627829824175 acc:  0.38550342763995266\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  46 loss :  2.74338698387146 acc:  0.3892101913672599\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  47 loss :  2.774261290686471 acc:  0.3929839448004823\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  48 loss :  2.814196300506592 acc:  0.3912645423486591\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  49 loss :  2.7351338182176863 acc:  0.3936091820556908\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  50 loss :  3.733223349707467 acc:  0.3938101511734364\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  51 loss :  3.7489489282880513 acc:  0.39483732666413596\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  52 loss :  3.674290336881365 acc:  0.39367617176160596\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  53 loss :  3.6183834961482457 acc:  0.39427907911484267\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  54 loss :  3.750976814542498 acc:  0.39604314137060936\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  55 loss :  3.6380594185420443 acc:  0.3998392247058035\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  56 loss :  3.57584411076137 acc:  0.4010003796083335\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  57 loss :  3.4939017363956997 acc:  0.4028091016680437\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  58 loss :  3.6124861444745746 acc:  0.40307706049170444\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  59 loss :  3.6691438266209193 acc:  0.40405957617846056\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  60 loss :  3.4470815658569336 acc:  0.40580130853225554\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  61 loss :  3.530818510055542 acc:  0.407252752160418\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  62 loss :  3.5606995241982595 acc:  0.4043721948060648\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  63 loss :  3.472312899998256 acc:  0.40343433892325214\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  64 loss :  3.4967672348022463 acc:  0.40263046245226985\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  65 loss :  3.5053014278411867 acc:  0.4070964428466159\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  66 loss :  3.557597896030971 acc:  0.40455083402183867\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1864833911294741 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 456, 'dropout': 0.3355812817762327, 'dropout_transformers': 0.13487569043590217, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6427774676784119, 'scheduler': 'ExponentialLR', 'lr': 6.782136900125635e-05, 'dropout_lstm': 0.1864833911294741, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 37, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.898752818867508e-07}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.776905580728996 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.37932054134978 acc:  0.005582475492932586\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.296219368942645 acc:  0.006431011767858339\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.278917128298463 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.245384893497499 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  7.263953613633869 acc:  0.004465980394346068\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  7.261147198556852 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  7.249888600421553 acc:  0.004800928923922024\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.03700277171787508 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'LogSigmoid', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.16635300480932494, 'dropout_transformers': 0.19523446093467753, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 8, 'factor': 0.8982314784940164, 'patience': 9, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0007466183185447512, 'lr': 0.11177604324524067, 'dropout_lstm': 0.03700277171787508, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardshrink', 'dropout_gcn': 0.24330003432818428, 'hidden_channels': 16, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 5, 'use_gcn': True, 'weight_decay': 0.0032064327965521987}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 240, 'dropout': 0.36506570646261394, 'dropout_transformers': 0.16551567967895392, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.003747999681346214, 'dropout_lstm': 0.27090828884112267, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softsign', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 10, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.2689487246142409}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.27090828884112267 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.766161037703692 acc:  0.003103856374070518\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.464499562473621 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.339039228730282 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.2826818611662265 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.201336125196037 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  7.1669599565409 acc:  0.0037290936292789676\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  7.07232423556053 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  6.986328391705529 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  6.949727292788231 acc:  0.007301877944755822\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  9 loss :  6.830064765477585 acc:  0.008373713239398879\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  10 loss :  6.800711090281858 acc:  0.005694125002791238\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  11 loss :  6.710420875226037 acc:  0.006631980885603912\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  12 loss :  6.650814872677043 acc:  0.008105754415738116\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Tanhshrink', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 360, 'dropout': 0.29347882188811614, 'dropout_transformers': 0.03526298975872408, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.4434468603235628, 'scheduler': 'ExponentialLR', 'lr': 0.0003090755386857255, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 18, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.8481203348866765e-05}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.778847754841119 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.458813156880123 acc:  0.00982515686756135\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.342065616392754 acc:  0.012661054417971105\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.262575283856459 acc:  0.01951633432329232\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.192252615807762 acc:  0.019717303441037892\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  7.167612176545909 acc:  0.020543509813991917\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  7.1850525829154 acc:  0.021235736775115557\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  7.168406278314725 acc:  0.02136971618694594\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  7.200748692096119 acc:  0.0214143759908894\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  9 loss :  7.18812851167061 acc:  0.0214143759908894\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  10 loss :  7.169061264521639 acc:  0.02136971618694594\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  11 loss :  7.133885491062218 acc:  0.02136971618694594\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  12 loss :  7.1634089107244785 acc:  0.0214143759908894\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  13 loss :  7.1848473347408675 acc:  0.0214143759908894\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  14 loss :  7.145368670074033 acc:  0.02143670589286113\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  15 loss :  7.163732515254491 acc:  0.02143670589286113\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  16 loss :  7.143317699432373 acc:  0.02143670589286113\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  17 loss :  7.080142363696031 acc:  0.0214143759908894\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  18 loss :  7.1438179553394585 acc:  0.02143670589286113\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  19 loss :  7.163088147069367 acc:  0.02143670589286113\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40669387162097065 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'ReLU6', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.19149029316682123, 'dropout_transformers': 0.3255643791746741, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 9, 'factor': 0.54784651753612, 'patience': 3, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.044670491828729474, 'lr': 0.059837833155197695, 'dropout_lstm': 0.40669387162097065, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ReLU6', 'dropout_gcn': 0.3408504682120483, 'hidden_channels': 64, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 10, 'use_gcn': True, 'weight_decay': 1.9535388900072034e-06}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2848152670448947 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.3104455169651287, 'dropout_transformers': 0.3158706585885783, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.1020920265548837, 'scheduler': 'ExponentialLR', 'lr': 0.0019787782761147665, 'dropout_lstm': 0.2848152670448947, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 13, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.7430081919986975e-06}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.44343828988242 acc:  0.006765960297434294\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.178541440230149 acc:  0.007703816180246969\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  7.146206695716698 acc:  0.007904785297992541\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  7.129669876365395 acc:  0.007860125494049082\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  7.136926287537688 acc:  0.00781546569010562\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  7.120927884028508 acc:  0.00781546569010562\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  7.143387264305061 acc:  0.00781546569010562\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  7.1212301220927205 acc:  0.00781546569010562\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12752508541105217 and num_layers=1\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=135969)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'RReLU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 744, 'dropout': 0.12811692101846764, 'dropout_transformers': 0.2825584891021054, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 5, 'factor': 0.33454279009409743, 'patience': 4, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0016092135894030374, 'lr': 0.00017512683418077613, 'dropout_lstm': 0.12752508541105217, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 49, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.0912037976119571e-07}\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  0 loss :  7.65259595317695 acc:  0.021258066677087288\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  1 loss :  7.0317736945989475 acc:  0.06841881964138177\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  2 loss :  6.186942850360434 acc:  0.16926065694571601\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  3 loss :  5.300433817710585 acc:  0.22015050353928947\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  4 loss :  4.693820207173587 acc:  0.2659491324833084\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  5 loss :  4.28090765276028 acc:  0.2856664359243463\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  6 loss :  3.862516676196615 acc:  0.3230466918250229\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  7 loss :  3.6088833608700117 acc:  0.34006207712748143\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  8 loss :  3.470129130450824 acc:  0.35055713105419467\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  9 loss :  3.534928299998509 acc:  0.35334836880066095\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  10 loss :  3.3590655508842175 acc:  0.35879686488176316\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  11 loss :  3.175482334071443 acc:  0.36540651586539535\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  12 loss :  3.280186867895927 acc:  0.369827836455798\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  13 loss :  3.1343942816930874 acc:  0.37047540361297815\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  14 loss :  3.0794501113527604 acc:  0.3785588281267445\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  15 loss :  3.0331893922718427 acc:  0.3798762923430766\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  16 loss :  3.0289371859936316 acc:  0.3867762320523413\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  17 loss :  2.997553302131536 acc:  0.3887412634258536\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  18 loss :  2.9840691435428064 acc:  0.38981309872049663\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  19 loss :  2.9266498198036017 acc:  0.391934439407811\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  20 loss :  2.9371491142811665 acc:  0.3932072438201996\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  21 loss :  2.844232854952339 acc:  0.3949713060759663\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  22 loss :  2.8910127150193428 acc:  0.3955965433311748\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  23 loss :  2.8520622717515205 acc:  0.39680235803764824\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  24 loss :  2.8143363253760882 acc:  0.3984324408815845\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  25 loss :  2.816534434566061 acc:  0.3988567090190474\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  26 loss :  2.7816440786114174 acc:  0.39919165754862335\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  27 loss :  2.910560769889191 acc:  0.39903534823482123\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  28 loss :  2.871419278719953 acc:  0.40028582274523816\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  29 loss :  2.7916616119501243 acc:  0.40035281245115334\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  30 loss :  2.842928753554366 acc:  0.4002411629412947\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  31 loss :  2.830650866486644 acc:  0.4014023178438247\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  32 loss :  2.7765079754909485 acc:  0.4003974722550968\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  33 loss :  2.76308339879713 acc:  0.40012951343143605\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  34 loss :  2.8408068300203513 acc:  0.40050912176495546\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  35 loss :  2.8630873701954616 acc:  0.40115668892213563\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  36 loss :  2.8218154106431337 acc:  0.40111202911819216\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  37 loss :  2.7475462260137076 acc:  0.40209454480494833\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  38 loss :  2.7823123931884766 acc:  0.4011343590201639\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  39 loss :  2.8145670590509897 acc:  0.4014246477457964\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  40 loss :  2.7536732513485975 acc:  0.40124600853002257\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  41 loss :  2.728607720091143 acc:  0.40189357568720274\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  42 loss :  2.7820962585565696 acc:  0.4021615345108635\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  43 loss :  2.7893187890525994 acc:  0.40229551392269386\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  44 loss :  2.7972343450284187 acc:  0.4025634727463546\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  45 loss :  2.8000248852576917 acc:  0.4023178438246656\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  46 loss :  2.8307786006053894 acc:  0.4022285242167787\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  47 loss :  2.807533134030932 acc:  0.4023625036286091\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  48 loss :  2.7869000780673425 acc:  0.4025411428443829\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  49 loss :  2.759589539229415 acc:  0.4026081325502981\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  50 loss :  18.389742592818866 acc:  0.40169260656945716\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  51 loss :  8.725391085821254 acc:  0.4001741732353795\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  52 loss :  7.1877186243770685 acc:  0.399303307058482\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  53 loss :  6.17402937576061 acc:  0.3984324408815845\n",
            "\u001b[36m(eval_config pid=135969)\u001b[0m epoch:  54 loss :  5.875394859386764 acc:  0.3973829354889132\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 01:47:34,997\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 01:47:48,713\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 01:47:48,714\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_9        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_9\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_9`\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m GCNConv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.38253112636905273, 'dropout_transformers': 0.2642799262141535, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.08467818817593553, 'scheduler': 'StepLR', 'step_size': 11, 'lr': 1.6926383140951762e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanhshrink', 'dropout_gcn': 0.14804889778497426, 'hidden_channels': 32, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 0.0016196747321426393}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  8.178211385553533 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  8.165599736300381 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  8.133484927090732 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  8.102550159801137 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  8.053001057017934 acc:  0.0015184333340776633\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  8.008026123046875 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  7.9290077903053975 acc:  0.0029028872563249446\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  7.856849366968328 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  7.8112079446966 acc:  0.004242681374628765\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  7.729416977275502 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  7.714251214807684 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  7.656216317957098 acc:  0.0045106401982895295\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  7.660107439214533 acc:  0.00455530000223299\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  7.653137640519575 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  7.654242385517467 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  7.65868516401811 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  7.657202113758434 acc:  0.004689279414063372\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  7.644254120913419 acc:  0.004800928923922024\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  7.634764021093195 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  7.632839202880859 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  7.6084137829867275 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  21 loss :  7.607619415629994 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  22 loss :  7.636931376023726 acc:  0.00455530000223299\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  23 loss :  7.620846271514893 acc:  0.00455530000223299\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24227724071166984 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 312, 'dropout': 0.345453920009895, 'dropout_transformers': 0.14593165195521157, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.038147765235227206, 'dropout_lstm': 0.24227724071166984, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Hardswish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 27, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0004440440608510742}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  8.308387569177931 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  7.515604054816415 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  7.570909656096842 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  7.5503551402938704 acc:  0.0031485161780139786\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  7.587209919902766 acc:  0.0033941450997030122\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  7.55748346810029 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  7.543575041762022 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  7.56930733172693 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  7.57588142769359 acc:  0.003684433825335507\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  7.592023225588219 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  7.581274634209748 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  7.642239445837859 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  7.585658122445936 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  7.5658748394975035 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1101124771814363 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'LeakyReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.26797824417402283, 'dropout_transformers': 0.22826357004954914, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 0, 'factor': 0.11942543685069673, 'patience': 7, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.21498505467455392, 'lr': 3.9398320774809626e-05, 'dropout_lstm': 0.1101124771814363, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00012470142506103158}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.9557221088003605 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  7.550078483338051 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  7.327558568183412 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  7.213659956100139 acc:  0.0064533416698300695\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  7.145451809497589 acc:  0.016166849027532768\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  7.080871653049551 acc:  0.04436951521782819\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  6.984458274029671 acc:  0.061451890226201906\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  6.859895503267329 acc:  0.07773038876359332\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  6.729581214011984 acc:  0.0968447848513945\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  6.625794806378953 acc:  0.09896612553870889\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  6.617869559754717 acc:  0.10278453877587478\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  6.57339033167413 acc:  0.10305249759953554\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  6.550227652204797 acc:  0.10573208583614319\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  6.542082076377057 acc:  0.10843400397472255\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  6.554934430629649 acc:  0.11102427260344327\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  6.546994422344452 acc:  0.11432909809525936\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  6.532153017977451 acc:  0.11624946966482817\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  6.490799579214542 acc:  0.11640577897863029\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  6.506980368431578 acc:  0.11629412946877163\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  6.503552436828613 acc:  0.11669606770426277\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  6.517583765882127 acc:  0.11738829466538642\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  21 loss :  6.5170615378846515 acc:  0.11741062456735815\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  22 loss :  6.510326213025032 acc:  0.11794654221467968\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  23 loss :  6.487350331976058 acc:  0.11796887211665141\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  24 loss :  6.4743919474013305 acc:  0.11837081035214256\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  25 loss :  6.4925041908913474 acc:  0.11846012996002947\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  26 loss :  6.497973837751023 acc:  0.11832615054819909\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  27 loss :  6.492851490670062 acc:  0.11839314025411428\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  28 loss :  6.512273646415548 acc:  0.11834848045017082\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  29 loss :  6.5034648814099905 acc:  0.11846012996002947\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  30 loss :  6.469139738285795 acc:  0.11832615054819909\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.35243331780607634 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 816, 'dropout': 0.24669987521755554, 'dropout_transformers': 0.20475723219376735, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.44448613375389306, 'scheduler': 'StepLR', 'step_size': 4, 'lr': 0.006536909720196118, 'dropout_lstm': 0.35243331780607634, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 30, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Sigmoid', 'dropout_gcn': 0.20590951996928525, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 9, 'use_gcn': True, 'weight_decay': 2.59661948306373e-07}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.759825186575613 acc:  0.009892146573476543\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  7.250675995119156 acc:  0.0485675367885135\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  6.62517184288271 acc:  0.13272893731996516\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  5.720711940334689 acc:  0.15825201527365296\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  5.242361404049781 acc:  0.17560234910568742\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  4.861989359701833 acc:  0.18739253734676103\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  4.637179694637176 acc:  0.187727485876337\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  4.4791375760109196 acc:  0.1933099613692696\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  4.253488859053581 acc:  0.2019293035303575\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  4.131586139432845 acc:  0.20572538686555167\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  4.04875785304654 acc:  0.2057700466694951\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  3.9121637190541914 acc:  0.2073108099055445\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  3.897800591684157 acc:  0.2109729138289083\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  3.869749975204468 acc:  0.21262532657481634\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  3.7965668170682845 acc:  0.2128932853984771\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  3.811487482440087 acc:  0.21383114128128977\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  3.7646324972952567 acc:  0.21273697608467498\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  3.831449996271441 acc:  0.2136301721635442\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  3.7772329807281495 acc:  0.21320590402608133\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  3.7058345302458733 acc:  0.2119330996136927\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  3.728672521345077 acc:  0.2120000893196079\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Hardshrink', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 696, 'dropout': 0.32724810033466273, 'dropout_transformers': 0.08452614057756282, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8203357255381895, 'scheduler': 'ExponentialLR', 'lr': 0.00046099173993605135, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 38, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.266495621917972e-09}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.028008048273936 acc:  0.07308576915347341\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  5.770750847183356 acc:  0.13330951477123015\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  4.82037091255188 acc:  0.19025076479914252\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  4.250015825784507 acc:  0.2272514123662997\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  3.8879972005090795 acc:  0.2511667373780229\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  3.6366405166497753 acc:  0.2642743898354286\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  3.5081235260522665 acc:  0.28604604425786573\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  3.3871237810920265 acc:  0.3032847285800415\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  3.272431972647915 acc:  0.32677578545430186\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  3.20765003236402 acc:  0.341089252618181\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  3.199415892112155 acc:  0.3503115021325056\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  3.1006614881403305 acc:  0.35745707076345934\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  3.078567777361189 acc:  0.3671035884152469\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  3.0568869735012534 acc:  0.3698055065538262\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  3.044354306549585 acc:  0.374874394301409\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  2.9585692141236377 acc:  0.37887144675434875\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  2.972575359985608 acc:  0.3803898800884264\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  2.972504559685202 acc:  0.38137239577518256\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  2.954902616869502 acc:  0.3835383962664404\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  2.952575891959567 acc:  0.38277917959940155\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  2.945844740426841 acc:  0.3856150771498113\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  21 loss :  2.9355697691941463 acc:  0.38534711832615054\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  22 loss :  2.9461700074812947 acc:  0.38572672665966995\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  23 loss :  2.9198563659892365 acc:  0.3865752629345957\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  24 loss :  2.9248294149126326 acc:  0.38706652077797377\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  25 loss :  2.907750273952965 acc:  0.3880267065627582\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  26 loss :  2.909313105735458 acc:  0.3880267065627582\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  27 loss :  2.935537181982473 acc:  0.3883169952883907\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  28 loss :  2.940133719885049 acc:  0.38822767568050376\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  29 loss :  2.921743541204629 acc:  0.3887189335238818\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  30 loss :  2.935811511608733 acc:  0.3885626242100797\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  31 loss :  2.9375842238674643 acc:  0.38880825313176876\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  32 loss :  2.9162652332241796 acc:  0.3892995109751468\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  33 loss :  2.9454654084534204 acc:  0.38925485117120334\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  34 loss :  2.940120959482273 acc:  0.3893218408771186\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  35 loss :  2.9075842685058335 acc:  0.389120871759373\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  36 loss :  2.9445219741148105 acc:  0.3893441707790903\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  37 loss :  2.9322460919869044 acc:  0.3887635933278253\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  38 loss :  2.9311100575102476 acc:  0.38916553156331646\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  39 loss :  2.9505221603297387 acc:  0.3890538820534578\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  40 loss :  2.9173451972608806 acc:  0.389120871759373\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  41 loss :  2.8976455275751962 acc:  0.38925485117120334\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m GCNConv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1580930159648416 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.2167111192713454, 'dropout_transformers': 0.17695449683160008, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 7, 'factor': 0.7905352424881034, 'patience': 8, 'scheduler': 'ReduceLROnPlateau', 'threshold': 2.4110413565012488e-05, 'lr': 0.00012621117088966487, 'dropout_lstm': 0.1580930159648416, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softshrink', 'dropout_gcn': 0.3049499118979495, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 0.0008857049315707568}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.779528161169777 acc:  0.007592166670388317\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  7.364167925337671 acc:  0.02210660295201304\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  7.190126680992019 acc:  0.030033718151977314\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  6.876296735145677 acc:  0.0791818323917558\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  6.617571165863897 acc:  0.111046602505415\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  6.3550889995736135 acc:  0.13413572114418418\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  6.097346097650663 acc:  0.15963646919590024\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  5.725550846314766 acc:  0.17390527655583593\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  5.535941997044523 acc:  0.18319451577607573\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  5.3303606946703415 acc:  0.2017729942165554\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  5.1068299118901646 acc:  0.22256213295223634\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  4.863711572029222 acc:  0.23917558001920372\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  4.63210816450522 acc:  0.24169885894200924\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  4.590508934477685 acc:  0.24728133443494182\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  4.5611918509846 acc:  0.2606346158140366\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  4.394384689734015 acc:  0.26237634816783156\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  4.301780841719936 acc:  0.266395730522743\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  4.172658728881621 acc:  0.2744344952325659\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  4.036756481922848 acc:  0.28271888886407787\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  4.0263552531390125 acc:  0.2839693633744948\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  3.8977720737457275 acc:  0.2913605609271375\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  21 loss :  3.890099522093652 acc:  0.2973003148516178\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  22 loss :  3.8855814430075633 acc:  0.2978585624009111\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  23 loss :  3.816670511809873 acc:  0.3059866467186209\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  24 loss :  3.781425120125354 acc:  0.31181475113324253\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  25 loss :  3.6612705882166474 acc:  0.315253556036889\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  26 loss :  3.6596974621356373 acc:  0.32014380456869795\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  27 loss :  3.5397566775201073 acc:  0.3212379697653127\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  28 loss :  3.5462089659462515 acc:  0.32952236339682467\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  29 loss :  3.493349186131652 acc:  0.32992430163231584\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  30 loss :  3.4139526864172707 acc:  0.33557376683116363\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  31 loss :  3.514512713526336 acc:  0.33499318937989864\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  32 loss :  3.3615191486519826 acc:  0.3401737266373401\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  33 loss :  3.38134357627009 acc:  0.34611348056182034\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  34 loss :  3.3400107504616323 acc:  0.3479891923274457\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  35 loss :  3.318858710812851 acc:  0.3502668423285622\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  36 loss :  3.306688446394155 acc:  0.3560279570372686\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  37 loss :  3.21673223334299 acc:  0.35334836880066095\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  38 loss :  3.3010172776772944 acc:  0.35372797713418036\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  39 loss :  3.202998785905435 acc:  0.3605162673335864\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  40 loss :  3.261213608191047 acc:  0.3613871335104839\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  41 loss :  3.1258730619726047 acc:  0.36580845410088647\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  42 loss :  3.1063319931567555 acc:  0.3684433825335507\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  43 loss :  3.187641335205293 acc:  0.36719290802313376\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  44 loss :  3.0639891658030765 acc:  0.3712569501819887\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  45 loss :  3.103149027891562 acc:  0.37241810508451867\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  46 loss :  3.1493948681253783 acc:  0.37210548645691444\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  47 loss :  3.091923700252049 acc:  0.37418216734028537\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  48 loss :  3.0553285269670085 acc:  0.37612486881182594\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  49 loss :  3.1434306729007773 acc:  0.37750932273407317\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': True, 'd_model': 144, 'dropout': 0.4065932922061798, 'dropout_transformers': 0.10555121318845288, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3259220478687559, 'scheduler': 'StepLR', 'step_size': 1, 'lr': 0.012234826234442287, 'dropout_lstm': 0.33603636827779854, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'SELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 0, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.03761716262036079}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33603636827779854 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  115.2815236630647 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  19.13190211420474 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  8.603037709775178 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  7.9856661299000615 acc:  0.0023669696090034163\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  7.874470503433891 acc:  0.002232990197173034\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  7.865922844928244 acc:  0.002210660295201304\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  7.846844673156738 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  7.871899791385816 acc:  0.0023669696090034163\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Hardsigmoid', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.11119845618262358, 'dropout_transformers': 0.43441910853054544, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.486861062423179, 'scheduler': 'ExponentialLR', 'lr': 0.0008948087612448744, 'dropout_lstm': 0.06634260266645431, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.8157339235657467e-08}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06634260266645431 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.672063054156904 acc:  0.010629033338543644\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  7.186748985482865 acc:  0.021146417167228634\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  6.944905249010615 acc:  0.03193175981957439\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  6.877205203561222 acc:  0.047093763258379294\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  6.775949169607723 acc:  0.056025724047071436\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  6.7888534610011 acc:  0.061027622088739034\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  6.722851989649925 acc:  0.06178683875577786\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  6.678793262032902 acc:  0.06274702454056226\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  6.694450021791859 acc:  0.06285867405042092\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  6.765150106253744 acc:  0.06308197307013823\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  6.733300994424259 acc:  0.06321595248196861\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  6.710452756961854 acc:  0.06323828238394033\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  6.681100043929925 acc:  0.06330527208985552\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  6.720553758765469 acc:  0.0632829421878838\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  6.683756551822694 acc:  0.06330527208985552\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  6.740685579155674 acc:  0.0632829421878838\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  6.671291203058066 acc:  0.06330527208985552\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  6.709872666527243 acc:  0.0632829421878838\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m GAT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4980330108705078 and num_layers=1\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.44016298575690893, 'dropout_transformers': 0.1587011106612337, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.003422356619225426, 'dropout_lstm': 0.4980330108705078, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 7, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Mish', 'dropout_gcn': 0.395182377200492, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 7, 'use_gcn': True, 'weight_decay': 2.257478290199373e-09}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.1572419564926797, 'dropout_transformers': 0.18645844256711, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7964393702794175, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 0.00034564685058143126, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 44, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.804376095064166e-05}\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  0 loss :  7.365667238073834 acc:  0.07509546033092915\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  1 loss :  6.465879537291446 acc:  0.1225911618247996\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  2 loss :  5.800980567932129 acc:  0.1697742446910658\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  3 loss :  5.188670724125232 acc:  0.20409530402161535\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  4 loss :  4.747849771531961 acc:  0.22338833932519037\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  5 loss :  4.4389317318544546 acc:  0.24739298394480047\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  6 loss :  4.095841064291485 acc:  0.2719112163097604\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  7 loss :  3.9089225793288924 acc:  0.28859165308264295\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  8 loss :  3.734270592867318 acc:  0.3028158006386352\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  9 loss :  3.6238898867267673 acc:  0.3212602996672845\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  10 loss :  3.4733103735972257 acc:  0.3314204050644218\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  11 loss :  3.3918004803738353 acc:  0.34693968693477434\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  12 loss :  3.317648479493998 acc:  0.3552910702722015\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  13 loss :  3.2128399267035017 acc:  0.3707433624366389\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  14 loss :  3.166456578141552 acc:  0.3772413639104124\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  15 loss :  3.1168973688351906 acc:  0.38454324185516825\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  16 loss :  3.0821236149739413 acc:  0.38749078891543665\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  17 loss :  3.026229535119008 acc:  0.3947703369582208\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  18 loss :  3.0016225960295078 acc:  0.39816448205792376\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  19 loss :  2.9985920372655834 acc:  0.40327802960945003\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  20 loss :  2.9180390026609775 acc:  0.40359064823705426\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  21 loss :  2.920130426600828 acc:  0.404684813433669\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  22 loss :  2.876045627109075 acc:  0.4148449188308063\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  23 loss :  2.8522107722395558 acc:  0.4114954335350468\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  24 loss :  2.8491604408975375 acc:  0.4140633722617958\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  25 loss :  2.8637628393658137 acc:  0.41752450706741395\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  26 loss :  2.7839206194473527 acc:  0.42274970412879886\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  27 loss :  2.7585675716400146 acc:  0.42134292030457987\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  28 loss :  2.758359286744716 acc:  0.42243708550119463\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  29 loss :  2.7321263652736856 acc:  0.42391085903132886\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  30 loss :  2.7287683931447693 acc:  0.42603219971864326\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  31 loss :  2.6783055935875844 acc:  0.42603219971864326\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  32 loss :  2.681724293757293 acc:  0.4252506531496327\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  33 loss :  2.693319381293604 acc:  0.4268137462876538\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  34 loss :  2.6410188836566473 acc:  0.42730500413103184\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  35 loss :  2.6147293478755627 acc:  0.4285778085434205\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  36 loss :  2.6440582315800554 acc:  0.4283545095237032\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  37 loss :  2.6524744478322693 acc:  0.4295156644262332\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  38 loss :  2.6259741257813016 acc:  0.43038653060313065\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  39 loss :  2.592474339372021 acc:  0.43324475805551216\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  40 loss :  2.5907237246885138 acc:  0.43442824286001386\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  41 loss :  2.5857992940029857 acc:  0.4347408614876181\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  42 loss :  2.577186588513649 acc:  0.4343612531540987\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  43 loss :  2.5286787162392828 acc:  0.4346068820757877\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  44 loss :  2.5502175032082253 acc:  0.43744277962619743\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  45 loss :  2.524249933533749 acc:  0.4355893977625438\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  46 loss :  2.550326177629374 acc:  0.43422727374226827\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  47 loss :  2.5366010261794267 acc:  0.43596900609606326\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  48 loss :  2.5200552172580006 acc:  0.43485251099747674\n",
            "\u001b[36m(eval_config pid=151880)\u001b[0m epoch:  49 loss :  2.5021176176556086 acc:  0.43625929482169573\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 02:47:08,211\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 02:47:21,975\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 02:47:21,977\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_10       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_10\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_10`\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m GCNConv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'CELU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.05248749532458005, 'dropout_transformers': 0.3760524083554718, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7544171744831277, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 0.0003459615765822386, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardswish', 'dropout_gcn': 0.34940850382984456, 'hidden_channels': 64, 'layer_type': 'GCNConv', 'norm': 'LayerNorm', 'num_layers_gcn': 1, 'use_gcn': True, 'weight_decay': 3.1055534051358038e-06}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.70578853062221 acc:  0.009400888730098474\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.1837937491280695 acc:  0.04198021570685305\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  6.857245622362409 acc:  0.06754795346448429\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  6.509741660526821 acc:  0.10318647701136592\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  6.120844514029367 acc:  0.122970770158319\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  5.820106192997524 acc:  0.14693075497398567\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  5.467392485482352 acc:  0.1716052966527477\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  5.1621397018432615 acc:  0.19433713685996917\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  4.940354129246303 acc:  0.21563986334099994\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  4.760973262786865 acc:  0.23707656923386106\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  4.508702768598284 acc:  0.24670075698367686\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  4.340215587615967 acc:  0.2568385324788424\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  4.195206553595407 acc:  0.27407721680101826\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  4.064361565453666 acc:  0.28251791974633234\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  3.931887095315116 acc:  0.29756827367527855\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  3.9109251090458463 acc:  0.30944778152423913\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  3.8000585419791086 acc:  0.31335551436929193\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  3.6954312460763115 acc:  0.32177388741263424\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  3.6915878704616003 acc:  0.330571868789496\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  3.6124669415610176 acc:  0.3333631065359623\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  3.573723452431815 acc:  0.34059799477480296\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  3.4704897744315013 acc:  0.3473416251702655\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  3.4511393206460137 acc:  0.3509144094857424\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  3.4364417689187188 acc:  0.3554250496840319\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  3.4405904497419084 acc:  0.35893084429359357\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  3.361889832360404 acc:  0.364111381551035\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  3.300140006201608 acc:  0.3727307237121229\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  3.27299588067191 acc:  0.3752316727329567\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  3.2180028574807302 acc:  0.3774200031261863\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  3.216908529826573 acc:  0.38043453989236986\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  3.184138182231358 acc:  0.3807024987160306\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  3.177991247177124 acc:  0.384230623227564\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  3.181629385266985 acc:  0.384811200678829\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  3.1635264601026263 acc:  0.38862961391599493\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  3.1135639122554233 acc:  0.3869325413661434\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  3.12642069544111 acc:  0.3884956345041645\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  3.0577376638139997 acc:  0.39173347029006544\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  3.0987210273742676 acc:  0.3943460688207579\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  3.0734058652605327 acc:  0.3985440903914432\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  2.9806424140930177 acc:  0.4027421119621285\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  3.0454338209969656 acc:  0.40423821539423443\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  3.013115017754691 acc:  0.4057119889243686\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  2.979358550480434 acc:  0.4056896590223969\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  2.966031381062099 acc:  0.4077663399057678\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  3.010044492994036 acc:  0.4074537212781636\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  2.9519485133034844 acc:  0.40832458745506106\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  2.9346121719905307 acc:  0.40736440167027665\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  2.968296548298427 acc:  0.4104235982404037\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  2.9479560715811592 acc:  0.4111828149074426\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  2.9319941793169293 acc:  0.41160708304490545\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'ReLU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 264, 'dropout': 0.09655459636420655, 'dropout_transformers': 0.18632265901093006, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8103238177563501, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 5.3672711992979084e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 50, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.116553235331305e-06}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  8.010312352861677 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.838240364619664 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.7167385373796735 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.61341005052839 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.52515937260219 acc:  0.0037514235312506978\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.472404044015067 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.415495681762695 acc:  0.005537815688989125\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  7.370232486724854 acc:  0.005537815688989125\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  7.330245767320905 acc:  0.00783779559207735\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  7.308842931474958 acc:  0.010539713730656722\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  7.26623649597168 acc:  0.013353281379094745\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  7.2620963232857845 acc:  0.01810955049907331\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  7.200117083958217 acc:  0.021749324520465355\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  7.170803110940116 acc:  0.033204564231963024\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  7.119358130863735 acc:  0.03742491570462006\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  7.0883228302001955 acc:  0.046423866199227386\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  7.034062385559082 acc:  0.0507781970837148\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  6.973691844940186 acc:  0.05718687894960141\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  6.902141121455601 acc:  0.06301498336422304\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  6.870907129560198 acc:  0.06564991179688721\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  6.825270284925188 acc:  0.07181296474108478\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  6.777451774052211 acc:  0.07592166670388317\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  6.746286201477051 acc:  0.07799834758725409\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  6.7253894533429825 acc:  0.08554585445369894\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  6.645451613834926 acc:  0.08697496817988969\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  6.576230090005057 acc:  0.08847107161199562\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  6.510669476645333 acc:  0.09630886720407297\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  6.504124191829137 acc:  0.103097157403479\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  6.455750492640904 acc:  0.10733983877810777\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  6.416490731920515 acc:  0.10999709711274368\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  6.34346102305821 acc:  0.11417278878145724\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  6.258778844560895 acc:  0.11613782015496953\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  6.287504877362933 acc:  0.11881740839157716\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  6.223687716892788 acc:  0.12185427505973248\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  6.1788728850228445 acc:  0.12518143045352031\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  6.0655203001839775 acc:  0.12500279123774646\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  6.077196761540004 acc:  0.12908916329857312\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  6.004657023293632 acc:  0.13226000937855883\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  5.9903993334089005 acc:  0.1337784427126365\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  5.948888560703822 acc:  0.13976285644106023\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  5.878490897587367 acc:  0.14009780497063617\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  5.894006265912737 acc:  0.14425116673737803\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  5.8592822619846885 acc:  0.14992296183819753\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  5.819877188546317 acc:  0.1478462809548266\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  5.798271983010428 acc:  0.15117343634861444\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  5.799119813101632 acc:  0.15193265301565326\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  5.6931322506495885 acc:  0.15633164370408414\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  5.690652356828962 acc:  0.1590335618426635\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  5.611639922005789 acc:  0.16099859321617577\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  5.624659906114851 acc:  0.1624053770403948\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  50 loss :  6.7058337211608885 acc:  0.16249469664828173\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  51 loss :  6.5711274964468815 acc:  0.1651966147868611\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  52 loss :  6.581303596496582 acc:  0.1687247392983945\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  53 loss :  6.5713618414742605 acc:  0.1699082241028962\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  54 loss :  6.566078417641776 acc:  0.17026550253444386\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  55 loss :  6.485074533735003 acc:  0.17386061675189246\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  56 loss :  6.434783921922956 acc:  0.17461983341893128\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  57 loss :  6.421696172441755 acc:  0.17412857557555322\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  58 loss :  6.431767368316651 acc:  0.17796931871469085\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  59 loss :  6.411455794743129 acc:  0.18064890695129848\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  60 loss :  6.420840699332101 acc:  0.1827925775405846\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  61 loss :  6.406803240094866 acc:  0.1833061652859344\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  62 loss :  6.298162501198905 acc:  0.18645468146394836\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  63 loss :  6.290844426836286 acc:  0.1880177746019695\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  64 loss :  6.300553280966622 acc:  0.1876381662684501\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  65 loss :  6.283543477739607 acc:  0.1910323113681531\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  66 loss :  6.235410227094378 acc:  0.1914119197016725\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  67 loss :  6.248590019771031 acc:  0.19237210548645692\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  68 loss :  6.188742160797119 acc:  0.19511868342897976\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  69 loss :  6.20098010471889 acc:  0.1956099412723578\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  70 loss :  6.157114315032959 acc:  0.1958109103901034\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  71 loss :  6.098286805834089 acc:  0.19645847754728357\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  72 loss :  6.117678424290248 acc:  0.1980885603912199\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  73 loss :  6.139108371734619 acc:  0.199651653529241\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  74 loss :  6.082507378714425 acc:  0.20085746823571443\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  75 loss :  6.0989917891366145 acc:  0.20210794274613134\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  76 loss :  6.081930160522461 acc:  0.20367103588415247\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  77 loss :  6.090458638327462 acc:  0.2044302525511913\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  78 loss :  5.984506211962018 acc:  0.2044972422571065\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  79 loss :  6.048437186649868 acc:  0.20532344863006052\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  80 loss :  5.982011672428676 acc:  0.20675256235625125\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  81 loss :  6.043960285186768 acc:  0.20791371725878124\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  82 loss :  6.038228729793004 acc:  0.20925351137708506\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  83 loss :  5.9209135736737935 acc:  0.20844963490610277\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  84 loss :  5.910648850032262 acc:  0.2105486456914454\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  85 loss :  5.98163982118879 acc:  0.21066029520130405\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  86 loss :  5.93895240511213 acc:  0.21304959471227922\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  87 loss :  5.914709118434361 acc:  0.212982605006364\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  88 loss :  5.920218222481864 acc:  0.21514860549762185\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  89 loss :  5.883199664524623 acc:  0.21557287363508473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  90 loss :  5.871042115347726 acc:  0.21572918294888685\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  91 loss :  5.893003654479981 acc:  0.2165777192238126\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  92 loss :  5.820083795275007 acc:  0.218118482459862\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  93 loss :  5.787589468274798 acc:  0.2186320702052118\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  94 loss :  5.887507438659668 acc:  0.21898934863675948\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  95 loss :  5.813271399906704 acc:  0.2214902976575933\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  96 loss :  5.787211309160505 acc:  0.22256213295223634\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  97 loss :  5.791305650983538 acc:  0.22289708148181228\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  98 loss :  5.782893466949463 acc:  0.22336600942321863\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  99 loss :  5.690731062207903 acc:  0.22329901971730345\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Mish', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': False, 'd_model': 768, 'dropout': 0.15616313827944364, 'dropout_transformers': 0.3394549446769595, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8604322944855689, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 1.0306306372849971e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanh', 'dropout_gcn': 0.461751118729514, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 5, 'use_gcn': True, 'weight_decay': 0.00022652979233519677}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  8.088655038313432 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  8.065298774025656 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  8.034308346835049 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  8.008848320354115 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.974582065235484 acc:  0.003684433825335507\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.939824971285733 acc:  0.00520286715941317\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.915567961606112 acc:  0.0063416921599714175\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  7.881357192993164 acc:  0.007212558336868901\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  7.839420318603516 acc:  0.008306723533483688\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  7.790002822875977 acc:  0.009356228926155015\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  7.769570914181796 acc:  0.010137775495165577\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  7.736593203111128 acc:  0.010651363240515374\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  7.714738845825195 acc:  0.011231940691780363\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  7.687880906191739 acc:  0.011321260299667284\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  7.668699698014692 acc:  0.011164950985865172\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  7.655691016804088 acc:  0.011343590201639015\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  7.613379695198753 acc:  0.011410579907554206\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  7.633735396645286 acc:  0.01165620882924324\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  7.606283317912709 acc:  0.011410579907554206\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  7.578822742808949 acc:  0.011142621083893441\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  7.56682673367587 acc:  0.01100864167206306\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  7.542819283225319 acc:  0.01107563137797825\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  7.535831234671853 acc:  0.01033874461291115\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Softmin', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.18159984979176283, 'dropout_transformers': 0.2682503015199265, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6204653951495326, 'scheduler': 'StepLR', 'step_size': 12, 'lr': 9.205403684399903e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 44, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.0378179937130825e-05}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.978754286038673 acc:  0.0019650313735122705\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.650281340388928 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.402517116675942 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.303029108855684 acc:  0.004175691668713575\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.239663326134116 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.220408366898359 acc:  0.008128084317709845\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.188087018869691 acc:  0.013509590692896858\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  7.134114612967281 acc:  0.019181385793716366\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  7.070006467528263 acc:  0.03389679119308666\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  7.003901360398632 acc:  0.04825491816090927\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  6.911672373949471 acc:  0.06326061228591207\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  6.82492954448118 acc:  0.07848960543063216\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  6.727944382166458 acc:  0.0871312774936918\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  6.64559407153372 acc:  0.09416519661478687\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  6.570240352113368 acc:  0.09979233191166291\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  6.4724185103077 acc:  0.1058214054440301\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  6.391154774164749 acc:  0.11359221133019226\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  6.343782311778957 acc:  0.1199562333921354\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  6.251169422925529 acc:  0.12605229663041778\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  6.160025968389996 acc:  0.1296697407498381\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  6.071336511838234 acc:  0.1356318245762901\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  6.008011042061499 acc:  0.14036576379429694\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  5.90372674748049 acc:  0.14382689859991515\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  5.822422286211434 acc:  0.14777929124891143\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  5.795513678405245 acc:  0.15050353928946253\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  5.70504638704203 acc:  0.1534957461536744\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  5.6721275054802325 acc:  0.15608601478239512\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  5.638522350181968 acc:  0.16028403635308042\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  5.5880885689945545 acc:  0.161891789295045\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  5.5682831457105735 acc:  0.1655762231203805\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  5.496472011178227 acc:  0.1664694191992497\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  5.448726831856421 acc:  0.1688140589062814\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  5.409689854767363 acc:  0.17357032802625996\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  5.3449016910488325 acc:  0.17511109126230937\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  5.314002675525213 acc:  0.1780139785186343\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  5.301326129396083 acc:  0.1792644530290512\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  5.279597516787255 acc:  0.1813857937163656\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  5.229272365570068 acc:  0.18299354665833018\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  5.259117296186544 acc:  0.1846236295022665\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  5.179333242319398 acc:  0.18562847509099434\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  5.1936449115559205 acc:  0.18614206283634416\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  5.155490107455496 acc:  0.18835272313154544\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  5.157322406768799 acc:  0.19009445548534043\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  5.096158690371756 acc:  0.19217113636871133\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  5.083755905345335 acc:  0.19277404372194806\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  5.083201804403531 acc:  0.19357792019293035\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  5.031461982403771 acc:  0.19489538440926243\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  5.047697107670671 acc:  0.19650313735122704\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  4.968678918935485 acc:  0.197664292253757\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  5.001098568156614 acc:  0.1990487461760043\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  50 loss :  6.224526874089645 acc:  0.19960699372529755\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  51 loss :  6.095133838007006 acc:  0.1999419422548735\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  52 loss :  6.0430855831857455 acc:  0.20034388049036464\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  53 loss :  6.058141207290908 acc:  0.20150503539289463\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  54 loss :  6.049650927721443 acc:  0.20172833441261193\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  55 loss :  6.029017165555793 acc:  0.20246522117767904\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  56 loss :  6.078182964001671 acc:  0.20376035549203939\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  57 loss :  5.9789879039182505 acc:  0.2041176339235871\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  58 loss :  6.046304476463188 acc:  0.2047205412768238\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  59 loss :  5.937989752171403 acc:  0.2056807270616082\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  60 loss :  5.940412771903862 acc:  0.20628363441484493\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  61 loss :  5.979651960275941 acc:  0.20713217068977066\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  62 loss :  5.96831067133758 acc:  0.20710984078779895\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  63 loss :  5.97917420985335 acc:  0.20724382019962934\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  64 loss :  5.998308666681839 acc:  0.20798070696469642\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  65 loss :  5.946874174021058 acc:  0.20856128441596142\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  66 loss :  5.9528356568288 acc:  0.2089855525534243\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  67 loss :  5.929997533054675 acc:  0.20943215059285888\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  68 loss :  5.872830956669177 acc:  0.20972243931849138\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  69 loss :  5.925359087475275 acc:  0.2102583569658129\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  70 loss :  5.883512925293486 acc:  0.2106826251032758\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  71 loss :  5.843522209232137 acc:  0.21108456333876693\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  72 loss :  5.906093888363595 acc:  0.21162048098608846\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  73 loss :  5.8702769764399125 acc:  0.2117991202018623\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  74 loss :  5.852974544137211 acc:  0.21229037804524037\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  75 loss :  5.8450754860700185 acc:  0.2123127079472121\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  76 loss :  5.876126483335334 acc:  0.21258066677087287\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  77 loss :  5.864081358505508 acc:  0.21307192461425095\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  78 loss :  5.852858632297839 acc:  0.21333988343791171\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  79 loss :  5.852692676802813 acc:  0.21354085255565727\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  80 loss :  5.858492043058751 acc:  0.21423307951678092\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  81 loss :  5.81966544814029 acc:  0.21438938883058303\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  82 loss :  5.849655700942217 acc:  0.21461268785030033\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  83 loss :  5.8120402239136775 acc:  0.21456802804635688\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  84 loss :  5.812834287093858 acc:  0.21459035794832862\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  85 loss :  5.774174666000625 acc:  0.214724337360159\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  86 loss :  5.796012684450311 acc:  0.2148806466739611\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  87 loss :  5.840956760665118 acc:  0.21526025500748053\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  88 loss :  5.849744295669814 acc:  0.21543889422325435\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  89 loss :  5.818670394056935 acc:  0.21541656432128262\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  90 loss :  5.810896542112706 acc:  0.21543889422325435\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  91 loss :  5.801961341146695 acc:  0.2156175334390282\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  92 loss :  5.855177750021724 acc:  0.21577384275283032\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  93 loss :  5.796628143827794 acc:  0.21577384275283032\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.015129882351739954, 'dropout_transformers': 0.25107250902100187, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6663763367226682, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 2.0699298224389933e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.356879782849913e-08}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  8.035946508554312 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.982417345046997 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.931751526319063 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.883227293307964 acc:  0.0024339593149186075\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.839049790455745 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.7981435555678145 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.7601743991558365 acc:  0.0033494852957595515\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  7.72573766708374 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  7.693131920007559 acc:  0.006743630395462564\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  7.6628595462212195 acc:  0.008083424513766384\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  7.6342823028564455 acc:  0.008976620592635598\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  7.60735255754911 acc:  0.009624187749815778\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  7.580241181300237 acc:  0.009959136279391734\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  7.55624309686514 acc:  0.01033874461291115\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  7.530656150671152 acc:  0.01098631177009133\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  7.506108599442702 acc:  0.0117008686331867\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  7.48342740719135 acc:  0.01239309559431034\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  7.4604192733764645 acc:  0.013308621575151286\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  7.438189950356117 acc:  0.014492106379652992\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  7.416674063755916 acc:  0.015474622066409129\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  7.395530961110041 acc:  0.017238684322175825\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  7.375390085807213 acc:  0.018533818636536185\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  7.358197058164157 acc:  0.019694973539066164\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  7.343961033454308 acc:  0.02078913873568095\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  7.332820778626662 acc:  0.021615345108634974\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  7.319330824338473 acc:  0.0226648505013063\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  7.30733500627371 acc:  0.023602706384118974\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  7.2956413599161 acc:  0.02460755197284684\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  7.284202968157254 acc:  0.025500748051716052\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  7.274673678324773 acc:  0.026259964718754886\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  7.262242247508122 acc:  0.026773552464104684\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  7.25166802406311 acc:  0.02728714020945448\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  7.241090836891761 acc:  0.02800169707254985\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  7.230970364350539 acc:  0.028827903445503875\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  7.221435891664945 acc:  0.029430810798740593\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  7.2116727388822115 acc:  0.03043565638746846\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  7.201695867685172 acc:  0.030949244132818257\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  7.192197535588191 acc:  0.03182011030971574\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  7.185482384608342 acc:  0.032333698055065536\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  7.17533513215872 acc:  0.03322689413393475\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  7.166463173352755 acc:  0.03382980148717147\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  7.159330305686364 acc:  0.03452202844829511\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  7.151533849422748 acc:  0.03554920393899471\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  7.142748718995314 acc:  0.036085121586316236\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  7.136082883981558 acc:  0.03655404952772257\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  7.132798924812904 acc:  0.03697831766518545\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  7.125901405627911 acc:  0.03753656521447871\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  7.120827630849985 acc:  0.037983163253913314\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  7.117474610988911 acc:  0.03849675099926311\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  7.112796563368577 acc:  0.03889868923475426\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.14148879289329, 'dropout_transformers': 0.06518202610172782, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5603394800874503, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.00021061924195976434, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'activation_gcn': 'SiLU', 'dropout_gcn': 0.1929063648267506, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 10, 'use_gcn': True, 'weight_decay': 1.215242583870227e-05}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.6560104552735675 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.328034086430327 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.2936996399088105 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.276615376168109 acc:  0.008976620592635598\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.160218451885467 acc:  0.036107451488287964\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  6.733335342813046 acc:  0.08760020543509814\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  6.099379874290304 acc:  0.13056293682870732\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  5.485977497506649 acc:  0.17068977067190674\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  5.05025200133628 acc:  0.19739633343009624\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  4.631528022441458 acc:  0.22104369961815867\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  4.368348096279388 acc:  0.24018042560793157\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  4.119371216347877 acc:  0.259607440323337\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  3.895792494428919 acc:  0.27273742268271445\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  3.752806262767061 acc:  0.28747515798405643\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  3.6202950528327453 acc:  0.29366054083022575\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  3.4682433757376163 acc:  0.30292745014849387\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  3.3683238283116768 acc:  0.3206127325101043\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  3.2993576222277703 acc:  0.32675345555233015\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  3.2822500746300878 acc:  0.3327825290846973\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  3.2457758517975503 acc:  0.33791840653819527\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  3.2362395550342318 acc:  0.3405756648728312\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  3.119536100549901 acc:  0.3449076658553469\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  3.124496079505758 acc:  0.3518969251724985\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  3.070104771472038 acc:  0.3555366991938905\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  3.0309701067336063 acc:  0.36114150458879485\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  2.975975665640324 acc:  0.3669026192975013\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  2.9695885536518505 acc:  0.3712569501819887\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  2.9457693657976516 acc:  0.37534332224281536\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  2.935247091536826 acc:  0.37554429136056094\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  2.917776036769786 acc:  0.38041220999039815\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  2.891321912724921 acc:  0.3853694482281223\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  2.835245284628361 acc:  0.3863966237188219\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  2.8248816551046168 acc:  0.3916441506821785\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  2.8237020056298436 acc:  0.3946586874483621\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  2.8084544983315975 acc:  0.39485965656610766\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  2.796669325930007 acc:  0.3968916776455351\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  2.7464531330352133 acc:  0.3970926467632807\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  2.7471461042444756 acc:  0.3997275751959449\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  2.7255233196502036 acc:  0.4003974722550968\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  2.723174825627753 acc:  0.40294308107987403\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  2.7257575329313886 acc:  0.40388093696268673\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  2.684335510781471 acc:  0.40484112274747114\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  2.728997966076465 acc:  0.4063595560815488\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  2.6746263199664178 acc:  0.4068061541209834\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  2.666148342984788 acc:  0.4081236183373155\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  2.6358063018068356 acc:  0.40955273206350623\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  2.636597029706265 acc:  0.4085925462787218\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  2.6495680656838925 acc:  0.4094187526516759\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  2.6241517066955566 acc:  0.411562423240962\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  2.6202148528809244 acc:  0.41287988745729404\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  50 loss :  3.7012106459191503 acc:  0.41203135118236833\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  51 loss :  3.6759520693028227 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  52 loss :  3.660611259176376 acc:  0.41256726882968986\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  53 loss :  3.631399504681851 acc:  0.4143090011834848\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  54 loss :  3.649487520786042 acc:  0.41321483598687003\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  55 loss :  3.632006401711322 acc:  0.4145992899091173\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  56 loss :  3.64213609188161 acc:  0.4142866712815131\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  57 loss :  3.624745196484505 acc:  0.4152468570662975\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  58 loss :  3.56207027333848 acc:  0.4159167541254494\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  59 loss :  3.5872977693030177 acc:  0.41672063059643166\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  60 loss :  3.637237980010662 acc:  0.41714489873389454\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  61 loss :  3.5704818837186125 acc:  0.4175914967733292\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  62 loss :  3.5647685121982655 acc:  0.41810508451867895\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  63 loss :  3.610671961561162 acc:  0.41667597079248825\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  64 loss :  3.5942715279599455 acc:  0.417770135989103\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  65 loss :  3.5811790659072553 acc:  0.41803809481276377\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  66 loss :  3.59141133186665 acc:  0.41801576491079206\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  67 loss :  3.510453888710509 acc:  0.41848469285219836\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  68 loss :  3.599314994000374 acc:  0.4185070227541701\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  69 loss :  3.537001315583574 acc:  0.4191099301074068\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  70 loss :  3.5542252114478576 acc:  0.4185070227541701\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  71 loss :  3.5795422158342727 acc:  0.41884197128374606\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  72 loss :  3.536810083592192 acc:  0.4195341982448697\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  73 loss :  3.526178613622138 acc:  0.4190206104995199\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  74 loss :  3.490689475485619 acc:  0.419757497264587\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  75 loss :  3.5113669456319605 acc:  0.42062836344148447\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  76 loss :  3.5034046122368347 acc:  0.4204720541276824\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  77 loss :  3.5101011611045676 acc:  0.4208739923631735\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  78 loss :  3.5154075470376522 acc:  0.4205613737355693\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  79 loss :  3.5101375174015126 acc:  0.42067302324542794\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  80 loss :  3.5809309279665036 acc:  0.4205613737355693\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  81 loss :  3.529639791935048 acc:  0.4212759305986647\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  82 loss :  3.494745178425566 acc:  0.42067302324542794\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  83 loss :  3.5252219971190106 acc:  0.4212312707947212\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'Softsign', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 72, 'dropout': 0.2840762822543078, 'dropout_transformers': 0.48711105250123177, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.9136538182522591, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 0.002467571712683242, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 45, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.726153429599967e-08}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.842765169877272 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.565421496904813 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.418100320375883 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.337991013893714 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.302647476929884 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.285308368389423 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.275170649014987 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Hardswish', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.12895258299652265, 'dropout_transformers': 0.21396271804655256, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.829393717522946, 'scheduler': 'StepLR', 'step_size': 10, 'lr': 1.9250669730059944e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'CELU', 'dropout_gcn': 0.2556219013502099, 'hidden_channels': 16, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 6, 'use_gcn': True, 'weight_decay': 6.38067356188693e-07}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  8.0035143221839 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.725587068978003 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.545352612511587 acc:  0.006297032356027957\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.415475400827699 acc:  0.008396043141370609\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.336751622668768 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.285481048842608 acc:  0.010740682848402296\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  7.234890299328303 acc:  0.011410579907554206\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  7.208396725735422 acc:  0.01297367304557533\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  7.176212351200944 acc:  0.015831900497956814\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  7.15605740628 acc:  0.016501797557108726\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  7.134627713995465 acc:  0.01933769510751848\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  7.110411603572005 acc:  0.02005225197061385\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  7.089846829236564 acc:  0.021235736775115557\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  7.065530162746623 acc:  0.02190563383426747\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  7.055861723625053 acc:  0.024227943639327423\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  7.019800032599497 acc:  0.026215304914811423\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  6.99897973012116 acc:  0.026259964718754886\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  6.996735936504299 acc:  0.028671594131701762\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  6.9658544265617754 acc:  0.030882254426903066\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  6.974803884150618 acc:  0.032378357859009\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  6.942546925302279 acc:  0.031976419623517854\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  6.933588407807431 acc:  0.03447736864435165\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  6.932553646928173 acc:  0.03780452403813947\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  6.901853221957967 acc:  0.03909965835249983\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  6.884577686503782 acc:  0.04039479266686019\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  6.877150769961083 acc:  0.04184623629502267\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  6.8815862687967595 acc:  0.04320836031529822\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  6.837372933403921 acc:  0.044414175021771654\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  6.852816969661389 acc:  0.04573163923810374\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  6.824746333946616 acc:  0.05115780541723422\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  6.801114534927627 acc:  0.05368108434003975\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  6.796160116034039 acc:  0.056249023066788736\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  6.775148723085048 acc:  0.0577674564008664\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  6.780391919410835 acc:  0.059218900029028874\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  6.782173698231325 acc:  0.0595315186566331\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  6.730208332255735 acc:  0.06223343679521247\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  6.733369803024551 acc:  0.06473438581604626\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  6.715533903089621 acc:  0.06705669562110622\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  6.7169366852711825 acc:  0.0702722015050354\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  6.69445469419835 acc:  0.07254985150615188\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  6.669257406461036 acc:  0.07364401670276667\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  6.6581999164516645 acc:  0.07567603778219413\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  6.654054544739804 acc:  0.07766339905767813\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  6.647546372171176 acc:  0.07893620347006676\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  6.647248647980771 acc:  0.07927115199964273\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  6.625805773977506 acc:  0.08224102896188286\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  6.645574278750662 acc:  0.08349150347229976\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  6.60572961225348 acc:  0.08527789563003818\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  6.549701488624184 acc:  0.08614876180693566\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  6.582182997364109 acc:  0.08806913337650447\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'LogSigmoid', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 336, 'dropout': 0.2282939727655005, 'dropout_transformers': 0.24099138042248647, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7143158597851634, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 0.0005750208659445011, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 48, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00988765355228221}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.787570103355076 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  7.38652691633805 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  7.369242191314697 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  7.36847852623981 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  7.350230859673542 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  7.306078475454579 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'ELU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.06552292882556396, 'dropout_transformers': 0.14281917135765446, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7793968123173062, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.00038042698579153597, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.0573953078353946e-06}\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  0 loss :  7.371892472388039 acc:  0.0370899671750441\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  1 loss :  6.986764954849028 acc:  0.07467119219346627\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  2 loss :  6.830272963349248 acc:  0.09798360985195274\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  3 loss :  6.639534036878129 acc:  0.11225241721188844\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  4 loss :  6.444648937440254 acc:  0.12759305986646718\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  5 loss :  6.264569490728244 acc:  0.15456758144831745\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  6 loss :  6.073321812589404 acc:  0.17508876136033763\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  7 loss :  5.813112997672927 acc:  0.18355179420762344\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  8 loss :  5.60767954839787 acc:  0.200812808431771\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  9 loss :  5.370509154360059 acc:  0.209588459906661\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  10 loss :  5.075217663402289 acc:  0.22504075207109842\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  11 loss :  4.847572555004711 acc:  0.23881830158765602\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  12 loss :  4.648838043212891 acc:  0.24882209767099123\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  13 loss :  4.419515589593162 acc:  0.26088024473572563\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  14 loss :  4.260620859307303 acc:  0.2763548668021347\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  15 loss :  4.0867906792063105 acc:  0.28682759082687626\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  16 loss :  3.9510731999303252 acc:  0.2939508295558583\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  17 loss :  3.7971010812571353 acc:  0.3062322756403099\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  18 loss :  3.657459007182591 acc:  0.3142263805461894\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  19 loss :  3.5685878202948773 acc:  0.3221981555500971\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  20 loss :  3.528792206670197 acc:  0.3252573521202242\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  21 loss :  3.433930175405153 acc:  0.3348368800660965\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  22 loss :  3.38948440215957 acc:  0.34026304624522696\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  23 loss :  3.328083505093212 acc:  0.3440367996784494\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  24 loss :  3.2636753874765314 acc:  0.3513163477212335\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  25 loss :  3.2033852825702076 acc:  0.3560056271352969\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  26 loss :  3.1223353298617083 acc:  0.36013665900006697\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  27 loss :  3.0915985308902365 acc:  0.36422303106089365\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  28 loss :  3.0296936941818453 acc:  0.36752785655270975\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  29 loss :  2.984363569340236 acc:  0.3747180849876069\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  30 loss :  2.945554041526687 acc:  0.3807471585199741\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  31 loss :  2.9410659696014836 acc:  0.3839180045999598\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  32 loss :  2.907327799729898 acc:  0.383650045776299\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  33 loss :  2.8529761811377297 acc:  0.3885626242100797\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  34 loss :  2.8121061157172833 acc:  0.3936091820556908\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  35 loss :  2.8054572562096824 acc:  0.3938101511734364\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  36 loss :  2.7836066568401496 acc:  0.39521693499765537\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  37 loss :  2.7370870449173617 acc:  0.3998168948038318\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  38 loss :  2.746573206404565 acc:  0.40153629725565504\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  39 loss :  2.7037575177743403 acc:  0.4019605653931179\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  40 loss :  2.7157872932057985 acc:  0.40265279235424156\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  41 loss :  2.682084046619039 acc:  0.40633722617957707\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  42 loss :  2.6490795679495367 acc:  0.40935176294576064\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  43 loss :  2.6446452778829657 acc:  0.4088381752004109\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  44 loss :  2.6264019751212966 acc:  0.4110041756916687\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  45 loss :  2.6147559797260125 acc:  0.41169640265279234\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  46 loss :  2.603031249113486 acc:  0.4122993100060291\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  47 loss :  2.5990306928124225 acc:  0.4122993100060291\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  48 loss :  2.567543046575197 acc:  0.4148225889288346\n",
            "\u001b[36m(eval_config pid=166899)\u001b[0m epoch:  49 loss :  2.552239649732348 acc:  0.41772547618515954\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 03:51:38,802\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 03:51:52,564\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 03:51:52,567\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_11       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_11\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_11`\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.0825693134742821, 'dropout_transformers': 0.17217142730319243, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.48052186073079006, 'patience': 2, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.011894470422078788, 'lr': 3.045095474960247e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 40, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softmin', 'dropout_gcn': 0.4154254363534686, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'PairNorm', 'num_layers_gcn': 3, 'use_gcn': True, 'weight_decay': 8.272689531465357e-05}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183132)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.037662029266357 acc:  0.002099010785342652\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  7.875250007795251 acc:  0.006274702454056227\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.730203835860543 acc:  0.013018332849518791\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.590285384136697 acc:  0.02320076814862783\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.521693001622739 acc:  0.03059196570127057\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.450060844421387 acc:  0.038407431391376194\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.410533158675484 acc:  0.04515106178683875\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.354178242061449 acc:  0.052207310809905545\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.312455591948136 acc:  0.05707522943974276\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.266076544056768 acc:  0.06127325101042806\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  7.243950968203337 acc:  0.06620815934618048\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.22455122159875 acc:  0.06949065493602483\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.1779505273570186 acc:  0.0713886966036219\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  7.155650325443434 acc:  0.07424692405600339\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  7.1378895925438925 acc:  0.07583234709599625\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  7.09395578633184 acc:  0.07857892503851908\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  7.097448473391325 acc:  0.07998570886273809\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  7.049453839011814 acc:  0.08148181229484402\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  7.031063556671143 acc:  0.082642967197374\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  7.046495831531027 acc:  0.0841167407275082\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  7.042469957600469 acc:  0.08480896768863184\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  7.047497687132462 acc:  0.08552352455172722\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  7.043664724930473 acc:  0.08590313288524663\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  7.0842093799425205 acc:  0.08632740102270951\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  7.013227359108303 acc:  0.08708661768974835\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  7.02184011625207 acc:  0.08789049416073064\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  26 loss :  6.995574038961659 acc:  0.08885067994551504\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  27 loss :  7.004201080488122 acc:  0.08893999955340195\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  28 loss :  6.982699332029923 acc:  0.089185628475091\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  29 loss :  7.0105278180993125 acc:  0.08969921622044079\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  30 loss :  6.975024679432744 acc:  0.08987785543621464\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  31 loss :  6.985873222351074 acc:  0.09016814416184712\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  32 loss :  7.026927491892939 acc:  0.0903691132795927\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  33 loss :  6.966023590253747 acc:  0.09072639171114039\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  34 loss :  6.968511768009352 acc:  0.09083804122099903\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  35 loss :  6.993140013321586 acc:  0.0908827010249425\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  36 loss :  6.988046832706617 acc:  0.09101668043677288\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  37 loss :  6.984381634256114 acc:  0.09110600004465981\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  38 loss :  6.957675415536632 acc:  0.091172989750575\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  39 loss :  6.979371029397716 acc:  0.09137395886832057\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  40 loss :  6.979806837828263 acc:  0.09146327847620749\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  41 loss :  6.970950230308201 acc:  0.09155259808409441\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  42 loss :  6.988438585530156 acc:  0.09157492798606615\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  43 loss :  6.966547883075217 acc:  0.0916195877900096\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  44 loss :  6.946747199348781 acc:  0.09166424759395306\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  45 loss :  7.003774767336638 acc:  0.09175356720183998\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  46 loss :  6.950084541154944 acc:  0.09173123729986825\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  47 loss :  6.9786254219386885 acc:  0.09168657749592479\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  48 loss :  6.966765424479609 acc:  0.09184288680972691\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  49 loss :  6.944605537082838 acc:  0.09188754661367037\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  50 loss :  8.137582675270412 acc:  0.09193220641761382\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  51 loss :  8.104379612466563 acc:  0.09202152602550075\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  52 loss :  8.139982949132504 acc:  0.09195453631958556\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  53 loss :  8.059505607770836 acc:  0.0920661858294442\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  54 loss :  8.148052796073582 acc:  0.09204385592747248\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  55 loss :  8.111463733341383 acc:  0.09197686622155729\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  56 loss :  8.123270553091299 acc:  0.09208851573141594\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  57 loss :  8.114837833072828 acc:  0.09208851573141594\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  58 loss :  8.071716267129649 acc:  0.0921331755353594\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  59 loss :  8.117590572523033 acc:  0.09226715494718978\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  60 loss :  8.113204748734184 acc:  0.09231181475113324\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  61 loss :  8.130150504734205 acc:  0.09226715494718978\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  62 loss :  8.064637992693031 acc:  0.09228948484916151\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  63 loss :  8.055522006490957 acc:  0.09231181475113324\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  64 loss :  8.104859103327213 acc:  0.0923564745550767\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  65 loss :  8.084512067877728 acc:  0.09237880445704844\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  66 loss :  8.023954204891039 acc:  0.09233414465310498\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  67 loss :  8.056539348934008 acc:  0.09233414465310498\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  68 loss :  8.008636557537576 acc:  0.09231181475113324\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  69 loss :  8.138320508210555 acc:  0.0923564745550767\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  70 loss :  8.060586556144383 acc:  0.09237880445704844\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  71 loss :  8.034547183824623 acc:  0.09242346426099189\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  72 loss :  8.102033552916154 acc:  0.09240113435902017\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  73 loss :  8.085307162740957 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  74 loss :  8.091753731603207 acc:  0.09240113435902017\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  75 loss :  8.086973750072977 acc:  0.09237880445704844\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  76 loss :  8.07447982871014 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  77 loss :  8.069768719051195 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  78 loss :  8.055764882460885 acc:  0.09246812406493536\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  79 loss :  8.056770656419838 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  80 loss :  8.094971967780072 acc:  0.09240113435902017\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  81 loss :  8.051023296687914 acc:  0.09242346426099189\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  82 loss :  8.04179743061895 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  83 loss :  8.090499007183572 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Softplus', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 360, 'dropout': 0.10597304071251731, 'dropout_transformers': 0.40747628620151766, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.465212147706223, 'scheduler': 'StepLR', 'step_size': 12, 'lr': 0.0012322025147537099, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 24, 'num_layers_transformer': 5, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00303872676983818}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  7.633594254084996 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  7.377994224003383 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.332768208639962 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.289701584407261 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.247939899989537 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.2893833024161205 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.273889010293143 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.259427901676723 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.26031653540475 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.29047624043056 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  7.290735857827323 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Tanhshrink', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 216, 'dropout': 0.21215822198870593, 'dropout_transformers': 0.3521890697144995, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 4, 'factor': 0.5906450707993585, 'patience': 6, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0001825987950553416, 'lr': 0.009186170768630219, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardsigmoid', 'dropout_gcn': 0.0698170686840229, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'LayerNorm', 'num_layers_gcn': 2, 'use_gcn': True, 'weight_decay': 2.145844923754989e-05}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  7.681587675784496 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  7.416097296045182 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.313909510348705 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.293830638236188 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.299347644156598 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.306840602387774 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.276675599686643 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.267844758135207 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.263919028830021 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.26007157183708 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.16894595113767458, 'dropout_transformers': 0.29697533481948746, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6273456483999726, 'scheduler': 'StepLR', 'step_size': 23, 'lr': 8.004379926363858e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0006658497740456014}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  7.496357081486629 acc:  0.02074447893173749\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  6.898501025713407 acc:  0.11310095348681419\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  6.272951848690326 acc:  0.16504030547305898\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  5.726749794299786 acc:  0.19391286872250632\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  5.262299849436833 acc:  0.21932429716633545\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  4.8839708364926855 acc:  0.24603085992452492\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  4.570892702616178 acc:  0.265234575620213\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  4.3170681494932905 acc:  0.28305383739365386\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  4.11642293379857 acc:  0.294553736909095\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  3.943231441424443 acc:  0.30888953397494584\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  3.800011313878573 acc:  0.31918361878391355\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  3.676897094799922 acc:  0.33066118839738295\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  3.5739094697512113 acc:  0.34242904673648483\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  3.4836416482925414 acc:  0.3513163477212335\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  3.4100455027360184 acc:  0.3619900408637206\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  3.342322012094351 acc:  0.36944822812227857\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  3.2812369144879856 acc:  0.37480740459549383\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  3.224510543163006 acc:  0.380345220284483\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  3.175870137948256 acc:  0.3854587678360092\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  3.1359292433812067 acc:  0.3907509546033093\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  3.091401061644921 acc:  0.3942120894089275\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  3.057473864922157 acc:  0.3977402139204609\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  3.024135422706604 acc:  0.4010003796083335\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  2.9861325905873226 acc:  0.40515374137507537\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  2.96808011165032 acc:  0.40638188598352054\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  2.95079152400677 acc:  0.4087711854944957\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  26 loss :  2.9339367389678954 acc:  0.40935176294576064\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  27 loss :  2.912305738375737 acc:  0.41183038206462275\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  28 loss :  2.8995941125429594 acc:  0.41381774334010674\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  29 loss :  2.8849761486053467 acc:  0.41513520755643885\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  30 loss :  2.8708255107586202 acc:  0.4156264653998169\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  31 loss :  2.8554092297187217 acc:  0.4173235379496684\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  32 loss :  2.8426659492345956 acc:  0.4179264453029051\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  33 loss :  2.8318362896259015 acc:  0.4199584663823326\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  34 loss :  2.8195317084972675 acc:  0.42080700265725834\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  35 loss :  2.8041856362269475 acc:  0.42199048746176004\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  36 loss :  2.794082898360032 acc:  0.4241788178549896\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  37 loss :  2.7850643781515267 acc:  0.4236652301096398\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  38 loss :  2.7721660724053017 acc:  0.4248040551101981\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  39 loss :  2.7663188695907595 acc:  0.42516133354174573\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  40 loss :  2.75504365334144 acc:  0.42625549873836055\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  41 loss :  2.7443906197181116 acc:  0.4274836433468057\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  42 loss :  2.736330063526447 acc:  0.4271710247192015\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  43 loss :  2.727372783880967 acc:  0.42837683942567495\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  44 loss :  2.7205148256742038 acc:  0.4285108188375053\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  45 loss :  2.705268848859347 acc:  0.43014090168144165\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  46 loss :  2.690271914922274 acc:  0.43056516981890447\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  47 loss :  2.691294838831975 acc:  0.43036420070115894\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  48 loss :  2.6820557594299315 acc:  0.43023022128932853\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  49 loss :  2.6796294047282294 acc:  0.4306321595248197\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  50 loss :  3.6956151448763332 acc:  0.43090011834848047\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  51 loss :  3.6826366534599893 acc:  0.4313690462898868\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  52 loss :  3.671341188137348 acc:  0.4319719536431235\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  53 loss :  3.6724699974060058 acc:  0.4320612732510104\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  54 loss :  3.657907227369455 acc:  0.4327758301141058\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  55 loss :  3.651265443288363 acc:  0.4325748609963602\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  56 loss :  3.6430469017762404 acc:  0.4334457271732577\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  57 loss :  3.6410377374062173 acc:  0.43324475805551216\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  58 loss :  3.6363509746698233 acc:  0.4334457271732577\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  59 loss :  3.625952480389522 acc:  0.4337583458008619\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  60 loss :  3.6229970620228693 acc:  0.43407096442846616\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  61 loss :  3.623480428182162 acc:  0.4341826139383248\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  62 loss :  3.6162796350625843 acc:  0.43384766540874886\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  63 loss :  3.6074276777414176 acc:  0.43404863452649445\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  64 loss :  3.603674323742206 acc:  0.4349418306053636\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  65 loss :  3.6053002889339743 acc:  0.43422727374226827\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  66 loss :  3.5945491460653454 acc:  0.43563405756648726\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  67 loss :  3.5927609168566192 acc:  0.4353660987428265\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  68 loss :  3.5821727422567515 acc:  0.43523211933099615\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  69 loss :  3.575807993228619 acc:  0.4360136659000067\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  70 loss :  3.574965079014118 acc:  0.43643793403746955\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  71 loss :  3.572670734845675 acc:  0.436482593841413\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  72 loss :  3.5683666779444767 acc:  0.43657191344929996\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  73 loss :  3.5638205454899716 acc:  0.43643793403746955\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  74 loss :  3.5633347749710085 acc:  0.43701851148873455\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  75 loss :  3.5585613305752095 acc:  0.4369738516847911\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  76 loss :  3.5572201417042657 acc:  0.4367505526650738\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  77 loss :  3.5555173635482786 acc:  0.4374651095281692\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  78 loss :  3.5532468208899863 acc:  0.43659424335127167\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  79 loss :  3.5467863064545853 acc:  0.43721948060648014\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  80 loss :  3.5479272769047663 acc:  0.43724181050845184\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  81 loss :  3.5481017571229203 acc:  0.4370408413907063\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  82 loss :  3.53833599457374 acc:  0.4382913159011232\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  83 loss :  3.5375791201224693 acc:  0.4371301609985932\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  84 loss :  3.5357605640704817 acc:  0.43735346001831055\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  85 loss :  3.5329230785369874 acc:  0.4376214188419713\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 648, 'dropout': 0.03099235009519055, 'dropout_transformers': 0.2908312840067566, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6195086451589237, 'scheduler': 'StepLR', 'step_size': 23, 'lr': 3.2632930856956466e-07, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 37, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0007214010551173657}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.17715385877169 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  8.159417071709266 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  8.141706686753492 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  8.123445180746225 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  8.106349416879507 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  8.089029202094444 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  8.072375458937424 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  8.056506479703463 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  8.040856860234188 acc:  0.0017417323537949668\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  8.023671238238995 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  8.007445603150588 acc:  0.002099010785342652\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.991686945695143 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.975118149243868 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  7.959586664346548 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  7.94437204507681 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  7.929779052734375 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  7.914537609540499 acc:  0.003103856374070518\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  7.899513659110436 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  7.885082090817965 acc:  0.0033941450997030122\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  7.870951861601609 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  7.857280302047729 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  7.842648638211764 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  7.829241110728337 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  7.817640249545757 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  7.809633889565101 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  7.801866949521578 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  26 loss :  7.793846273422242 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  27 loss :  7.78592020548307 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  28 loss :  7.77768795306866 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  29 loss :  7.769780859580407 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  30 loss :  7.762783387991099 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  31 loss :  7.754789242377648 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  32 loss :  7.747664726697481 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  33 loss :  7.740327332570002 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  34 loss :  7.733011531829834 acc:  0.0037290936292789676\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  35 loss :  7.725749866779034 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  36 loss :  7.71907083437993 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  37 loss :  7.712470934941218 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  38 loss :  7.704822760361892 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  39 loss :  7.698682425572322 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.13949337475007165, 'dropout_transformers': 0.466528286277739, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5430273316290184, 'scheduler': 'StepLR', 'step_size': 25, 'lr': 8.359825998554421e-07, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 31, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.031351158887499245}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.07942618590135 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  8.073408288222092 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  8.068000228588398 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  8.06182861328125 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  8.055106185032772 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  8.047771835327149 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  8.040297339512751 acc:  0.0006698970591519103\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  8.033639064201942 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  8.025377031473013 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  8.014745881007268 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  8.004907362277692 acc:  0.001496103432105933\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.993573742646437 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.979988310887263 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  7.96536963902987 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  7.950302072671744 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  7.934561028847328 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  7.91562559054448 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  7.897875961890588 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  7.878529229530922 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  7.860608317301824 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  7.843729859132033 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  7.826301651734572 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  7.811024376062247 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  7.79464529477633 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  7.7798151383033165 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  7.769873017531175 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 744, 'dropout': 0.1718706980136645, 'dropout_transformers': 0.3096451997669447, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6192804818045659, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 5.875556444842254e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.13293161242110085}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.02219165288485 acc:  0.0031708460799857088\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  7.821647592691275 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.60719228891226 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.472741380104652 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.386706829071045 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.329726255857027 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.2905325119311994 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'ReLU6', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 672, 'dropout': 0.12439317028194227, 'dropout_transformers': 0.33143525931371387, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.938594073109544, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 1.1297843027980222e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.010751232942208543}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  7.953679961424608 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  7.633211198219886 acc:  0.006364022061943148\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.430788586689876 acc:  0.005448496081102204\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.336551501200749 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.290296052052424 acc:  0.004823258825893754\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.263649243574876 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.245628180870643 acc:  0.005694125002791238\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.224587502846351 acc:  0.007659156376303508\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.200200961186336 acc:  0.013487260790925128\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.169768032660851 acc:  0.021838644128352278\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  7.1302317912761985 acc:  0.03141817207422459\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.084001159667968 acc:  0.04698211374852065\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.028441766592173 acc:  0.06209945738338209\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  6.966147815264188 acc:  0.07547506866444856\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  6.895609419162457 acc:  0.08666234955228547\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  6.824557168667133 acc:  0.09695643436125316\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  6.7465395707350515 acc:  0.10488354956121743\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  6.670735538922823 acc:  0.11153786034879307\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  6.5925758691934435 acc:  0.11741062456735815\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  6.514827328461867 acc:  0.12250184221691267\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  6.442265206116897 acc:  0.1281289775137887\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  6.369251045813927 acc:  0.13426970055601456\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  6.295823416343102 acc:  0.13927159859768215\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  6.227347539021419 acc:  0.14576960007145567\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  6.155909791359535 acc:  0.15162003438804902\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  6.086949033003587 acc:  0.15503650938972377\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  26 loss :  6.019422300045306 acc:  0.15927919076435254\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  27 loss :  5.9491409008319565 acc:  0.16495098586517204\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  28 loss :  5.885726624268752 acc:  0.1677198937096666\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  29 loss :  5.818060724551861 acc:  0.1719179152803519\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  30 loss :  5.757578893808218 acc:  0.17591496773329166\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  31 loss :  5.694065713882447 acc:  0.1802916285197508\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  32 loss :  5.627789167257456 acc:  0.18531585646339013\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  33 loss :  5.570811546765841 acc:  0.19025076479914252\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  34 loss :  5.511640409322886 acc:  0.19505169372306455\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  35 loss :  5.462203873120822 acc:  0.19991961235290176\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  36 loss :  5.396226523472713 acc:  0.20445258245316303\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  37 loss :  5.347937903037438 acc:  0.20786905745483777\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  38 loss :  5.300177559485802 acc:  0.21229037804524037\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  39 loss :  5.2472785619588995 acc:  0.21595248196860417\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  40 loss :  5.199525704750648 acc:  0.2192126476564768\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  41 loss :  5.150620559545664 acc:  0.22142330795167808\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  42 loss :  5.108911088796762 acc:  0.2240135765803988\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  43 loss :  5.062804908018846 acc:  0.22736306187615837\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  44 loss :  5.019234679295466 acc:  0.23019895942656812\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  45 loss :  4.974975905051598 acc:  0.2329008775651475\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  46 loss :  4.943055989192082 acc:  0.23535716678203783\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  47 loss :  4.897466325759888 acc:  0.23913092021526025\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  48 loss :  4.856376956059383 acc:  0.2414532300203202\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  49 loss :  4.814751107876117 acc:  0.24520465355157092\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  50 loss :  5.8066761713761545 acc:  0.24801822120000894\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  51 loss :  5.761299456082858 acc:  0.2508541187504187\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  52 loss :  5.7235350388747 acc:  0.25324341826139385\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  53 loss :  5.691812093441303 acc:  0.25603465600786013\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  54 loss :  5.644795230718759 acc:  0.25833463591094835\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  55 loss :  5.612473737276518 acc:  0.26092490453966904\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  56 loss :  5.5762894373673655 acc:  0.2639617712078244\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  57 loss :  5.5484504589667685 acc:  0.2652569055221848\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  58 loss :  5.522169619340163 acc:  0.2673782462094991\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  59 loss :  5.491697868934044 acc:  0.26920929817118106\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  60 loss :  5.459452614417443 acc:  0.2711296697407498\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  61 loss :  5.431446075439453 acc:  0.27258111336891233\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  62 loss :  5.398052520018357 acc:  0.2742781859187638\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  63 loss :  5.3824834236731895 acc:  0.2756626398410111\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  64 loss :  5.351498695520254 acc:  0.2779179599401559\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  65 loss :  5.323384277637189 acc:  0.27979367170578123\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  66 loss :  5.305761744425847 acc:  0.2805305584708483\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  67 loss :  5.277342576246995 acc:  0.28231695062858675\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  68 loss :  5.250261757924006 acc:  0.2832324766094277\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  69 loss :  5.225736599702102 acc:  0.28484022955139227\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  70 loss :  5.204296409166776 acc:  0.2866936114150459\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  71 loss :  5.18140131510221 acc:  0.2881003952392649\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  72 loss :  5.156616889513456 acc:  0.28917223053390795\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  73 loss :  5.141585779190064 acc:  0.29169550945671346\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  74 loss :  5.115265230032114 acc:  0.29241006631980887\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  75 loss :  5.095623243772066 acc:  0.29444208739923633\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  76 loss :  5.076279339423547 acc:  0.2953352834781055\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  77 loss :  5.054750405825102 acc:  0.2973003148516178\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  78 loss :  5.036751871842604 acc:  0.2983944800482326\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  79 loss :  5.017114833685068 acc:  0.2997789339704799\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  80 loss :  4.999887840564434 acc:  0.30100707857892506\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  81 loss :  4.981508867557232 acc:  0.3026818212268048\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  82 loss :  4.964840382796067 acc:  0.30513811044369515\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  83 loss :  4.945200799061702 acc:  0.30667887367974456\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  84 loss :  4.932948310558612 acc:  0.3079963378960766\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  85 loss :  4.908307629365187 acc:  0.3098050599557868\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Tanh', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': False, 'd_model': 264, 'dropout': 0.05048726866203275, 'dropout_transformers': 0.30262892090935056, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7653806061783281, 'scheduler': 'StepLR', 'step_size': 23, 'lr': 3.6626949432982137e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 50, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0001538036888233049}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.0931515620305 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  8.045275416741005 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  7.994153418907753 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  7.941102567085853 acc:  0.0025679387267489896\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.887117385864258 acc:  0.0031485161780139786\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.839468578191904 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.796313289495615 acc:  0.0033271553937878214\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.758915406007033 acc:  0.0037960833351941585\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.723967676896315 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.692609530228835 acc:  0.004711609316035103\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  7.663550996780396 acc:  0.005738784806734698\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.635148492226234 acc:  0.007056249023066789\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.608160525101882 acc:  0.007971775003907732\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  7.581472701292771 acc:  0.008664001965031374\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  7.55747301028325 acc:  0.009199919612352902\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  7.534039438687838 acc:  0.010584373534600183\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  7.510448840948252 acc:  0.011187280887836902\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  7.488976786686824 acc:  0.011879507848960543\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  7.46773036810068 acc:  0.01239309559431034\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  7.4467923934643085 acc:  0.012772703927829757\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  7.425588409717267 acc:  0.01362124020275551\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  21 loss :  7.405874677804801 acc:  0.014492106379652992\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  22 loss :  7.386522542513334 acc:  0.015117343634861443\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  23 loss :  7.3697388648986815 acc:  0.016032869615702387\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  24 loss :  7.355125595973088 acc:  0.016635776968939107\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  25 loss :  7.33957975094135 acc:  0.017238684322175825\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  26 loss :  7.325593585234422 acc:  0.01815421030301677\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  27 loss :  7.312282268817608 acc:  0.019025076479914253\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  28 loss :  7.296063434160673 acc:  0.019895942656811737\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  29 loss :  7.284074181776781 acc:  0.020900788245539603\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  30 loss :  7.270529101445125 acc:  0.021749324520465355\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  31 loss :  7.255558259670551 acc:  0.02255320099144765\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  32 loss :  7.2423592530764065 acc:  0.0239153250117232\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  33 loss :  7.22916756776663 acc:  0.024897840698479334\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  34 loss :  7.215806388854981 acc:  0.025925016189178928\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  35 loss :  7.202904077676626 acc:  0.027644418641002165\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  36 loss :  7.189595956068772 acc:  0.029408480896768865\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  37 loss :  7.177562794318566 acc:  0.030949244132818257\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  38 loss :  7.16607005412762 acc:  0.03202107942746131\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  39 loss :  7.153715471120981 acc:  0.034231739722662614\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  40 loss :  7.141760991169856 acc:  0.036085121586316236\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  41 loss :  7.128570464941172 acc:  0.037759864234196014\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  42 loss :  7.11642956000108 acc:  0.039121988254471565\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  43 loss :  7.104366196118868 acc:  0.04182390639305093\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  44 loss :  7.093456994570219 acc:  0.043163700511354756\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  45 loss :  7.082695594200721 acc:  0.045486010316414714\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  46 loss :  7.071083050507766 acc:  0.04695978384654891\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  47 loss :  7.061855778327355 acc:  0.04814326865105062\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  48 loss :  7.053036194581252 acc:  0.04943840296541098\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  49 loss :  7.044800387896024 acc:  0.05015295982850635\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  50 loss :  8.069101568368765 acc:  0.05444030100707858\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  51 loss :  8.055435360394991 acc:  0.05607038385101489\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  52 loss :  8.043180517049937 acc:  0.057253868655516606\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  53 loss :  8.031273445716272 acc:  0.05843735346001831\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  54 loss :  8.026883143645067 acc:  0.06011209610789808\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  55 loss :  8.014870067743155 acc:  0.06185382846169305\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  56 loss :  8.005701167766864 acc:  0.06317129267802514\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  57 loss :  7.999223041534424 acc:  0.06428778777661166\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  58 loss :  7.9894847246316765 acc:  0.06560525199294374\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  59 loss :  7.9830705385941725 acc:  0.0669673760132193\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  60 loss :  7.971761120282687 acc:  0.06768193287631467\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  61 loss :  7.96703162926894 acc:  0.06908871670053368\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  62 loss :  7.955256641828097 acc:  0.07047317062278097\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  63 loss :  7.94962402857267 acc:  0.07121005738784807\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  64 loss :  7.941931852927575 acc:  0.07259451131009535\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  65 loss :  7.931840496796828 acc:  0.07413527454614474\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  66 loss :  7.926317438712487 acc:  0.07525176964473126\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  67 loss :  7.919669782198392 acc:  0.07692651229261104\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  68 loss :  7.908247261780959 acc:  0.07759640935176294\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  69 loss :  7.903955023105328 acc:  0.07857892503851908\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  70 loss :  7.896555845554058 acc:  0.07965076033316214\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  71 loss :  7.8901842924264765 acc:  0.08027599758837059\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  72 loss :  7.887885137704703 acc:  0.08105754415738115\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  73 loss :  7.881698659750131 acc:  0.08188375053033517\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  74 loss :  7.871232032775879 acc:  0.08257597749145881\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  75 loss :  7.8675110816955565 acc:  0.08358082308018668\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  76 loss :  7.857927318719717 acc:  0.08447401915905589\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  77 loss :  7.858378153580886 acc:  0.08492061719849049\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  78 loss :  7.851034307479859 acc:  0.08538954513989684\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  79 loss :  7.8425636328183685 acc:  0.08650604023848335\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  80 loss :  7.8375141657315766 acc:  0.08704195788580488\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  81 loss :  7.835746816488412 acc:  0.08771185494495679\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  82 loss :  7.827075965587909 acc:  0.08842641180805216\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  83 loss :  7.8229082400982195 acc:  0.08907397896523234\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  84 loss :  7.814367628097534 acc:  0.09023513386776232\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  85 loss :  7.8118776027972885 acc:  0.09039144318156443\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  86 loss :  7.804928533847516 acc:  0.09155259808409441\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  87 loss :  7.797778364328238 acc:  0.09244579416296363\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  88 loss :  7.7927753998683045 acc:  0.09289239220239823\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  89 loss :  7.786168036094079 acc:  0.09318268092803073\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  90 loss :  7.780476093292236 acc:  0.0941205368108434\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  91 loss :  7.774881535310012 acc:  0.09456713485027801\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  92 loss :  7.770372658509475 acc:  0.09523703190942992\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  93 loss :  7.763156736814059 acc:  0.09530402161534511\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  94 loss :  7.765189970456637 acc:  0.09599624857646875\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  95 loss :  7.757259288200966 acc:  0.0963981868119599\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  96 loss :  7.753815203446608 acc:  0.09729138289082911\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  97 loss :  7.7445461493272045 acc:  0.09755934171448988\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  98 loss :  7.742939369495098 acc:  0.09825156867561352\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  99 loss :  7.73949635212238 acc:  0.09863117700913293\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'RReLU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.19900528053084462, 'dropout_transformers': 0.37293020932243187, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6475160476478035, 'scheduler': 'StepLR', 'step_size': 26, 'lr': 1.4042546570644202e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 33, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0004784745766630705}\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  0 loss :  8.073142777956448 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  1 loss :  8.05230541229248 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  2 loss :  8.027721610436073 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  3 loss :  8.003576733515812 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  4 loss :  7.973754706749549 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  5 loss :  7.943668332466713 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  6 loss :  7.910300948069646 acc:  0.0032378357859009\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  7 loss :  7.877442400272076 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  8 loss :  7.845206378056453 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  9 loss :  7.814087185492882 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  10 loss :  7.783712346737201 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  11 loss :  7.756586936803965 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  12 loss :  7.7300572138566235 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  13 loss :  7.705682083276602 acc:  0.004711609316035103\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  14 loss :  7.683419733781081 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  15 loss :  7.662242614305937 acc:  0.005046557845611058\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  16 loss :  7.641284165015588 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  17 loss :  7.62205958366394 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  18 loss :  7.604546231489915 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  19 loss :  7.587314638724694 acc:  0.004823258825893754\n",
            "\u001b[36m(eval_config pid=183132)\u001b[0m epoch:  20 loss :  7.570135644766 acc:  0.004823258825893754\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 05:24:03,397\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 05:24:17,220\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 05:24:17,222\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_12       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_12\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_12`\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=206162)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'SiLU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.2566481705378929, 'dropout_transformers': 0.3561738931081586, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.8520830540904167, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.00012598081526979583, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 39, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.001928504065077123}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.639690303269711 acc:  0.0056717951008195076\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.230072746063744 acc:  0.030859924524931335\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.024249849372736 acc:  0.07610030591965701\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  6.730345371715184 acc:  0.10606703436571914\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  6.422866813297378 acc:  0.1256056985909832\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  6.01624202461882 acc:  0.14472009467878436\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  5.74937508226107 acc:  0.1673402853761472\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  5.4914207684927145 acc:  0.18366344371748208\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  5.237151376361953 acc:  0.19400218833039323\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  4.99577096454258 acc:  0.2029564790210571\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  4.9489967290249615 acc:  0.22515240158095706\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  4.72296361283883 acc:  0.23721054864569144\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  4.585468715795591 acc:  0.24801822120000894\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  4.465719959589356 acc:  0.25916084228390235\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  4.339959160575654 acc:  0.2714646182703258\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  4.2204785040636965 acc:  0.2761092378804457\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  4.1341407378958595 acc:  0.29026639573052276\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  4.099205230201423 acc:  0.28901592122010583\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  3.9626439736542087 acc:  0.3005604805394904\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  3.910011095707643 acc:  0.3075943996605855\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  3.869453163786307 acc:  0.31270794721211176\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  3.9011303552702152 acc:  0.3174642163320903\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  3.7851713103289044 acc:  0.3227564030993904\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  3.7227801317609224 acc:  0.3284728580041534\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  3.680889057713514 acc:  0.3321126320255454\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  3.64531206951461 acc:  0.33610968447848516\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  3.5964888141141924 acc:  0.3434785521291562\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  3.6186272325462467 acc:  0.34656007860125493\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  3.5216114707499244 acc:  0.3461804702677355\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  3.4689504420957085 acc:  0.35171828595672466\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  3.4481255262257666 acc:  0.3520309045843289\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  3.445585987421387 acc:  0.35319205948685883\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  3.412704499074201 acc:  0.36129781390259696\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  3.4331221820255897 acc:  0.36362012370765695\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  3.376112623587667 acc:  0.36737154723890764\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  3.3140606520562197 acc:  0.37422682714422884\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  3.314561569490912 acc:  0.3719045173391689\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  3.2437705693964185 acc:  0.3754326418507023\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  3.3216353621562766 acc:  0.3777326217537905\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  3.2409451780372494 acc:  0.38003260165687874\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  3.2282865700109045 acc:  0.3803675501864547\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  3.259622854893434 acc:  0.3807694884219458\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  3.2022324653977123 acc:  0.3807248286180024\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  3.2120240520498604 acc:  0.38219860214813656\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  3.2098381759068153 acc:  0.38219860214813656\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  3.2043585477594556 acc:  0.38845097470022105\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  3.1713526748412146 acc:  0.39043833597570504\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  3.113468182153542 acc:  0.38800437666078647\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  3.1436714413445754 acc:  0.39226938793738697\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  3.179809971228658 acc:  0.39372083156554943\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  4.117079316570772 acc:  0.3949489761739946\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  4.165361492327472 acc:  0.3967800281356765\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  4.138846381416534 acc:  0.39675769823370477\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  4.19972297466001 acc:  0.39740526539088494\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  4.168321066062544 acc:  0.3980528325480651\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  4.161283937912414 acc:  0.3984994305874997\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  4.167216023919303 acc:  0.3988343791170757\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  4.105272414298031 acc:  0.4000401938235491\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  4.162082923857193 acc:  0.40071009088270104\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  4.118116250917232 acc:  0.40227318402072215\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  4.16672005333714 acc:  0.40359064823705426\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  4.038963882616779 acc:  0.40189357568720274\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  4.096314462203553 acc:  0.40189357568720274\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  4.053604490930142 acc:  0.4042828751981779\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  4.044489491585247 acc:  0.40673916441506824\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  4.130533217051842 acc:  0.40832458745506106\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  4.002096331985303 acc:  0.40854788647477835\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  3.9705196971999865 acc:  0.4101109796127995\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  4.01569212615157 acc:  0.40928477323984547\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  4.107369307033177 acc:  0.4097983609851953\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  4.026820706255609 acc:  0.41207601098631175\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  4.049495874170485 acc:  0.4103566085344885\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  3.989583460312316 acc:  0.40984302078913876\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  73 loss :  4.017548699618718 acc:  0.41145077373110334\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  74 loss :  3.8966253070191965 acc:  0.4117187325547641\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  75 loss :  3.979181669277852 acc:  0.41279056784940715\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  76 loss :  4.006949227615442 acc:  0.41299153696715274\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  77 loss :  3.9403616995784825 acc:  0.41317017618292656\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  78 loss :  4.048390235314822 acc:  0.4156264653998169\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  79 loss :  3.979539692734873 acc:  0.41399638255588056\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  80 loss :  4.032153731617847 acc:  0.4132818256927852\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  81 loss :  3.978607163082954 acc:  0.4140187124578523\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  82 loss :  3.9261055325662624 acc:  0.4140187124578523\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  83 loss :  3.933427297869208 acc:  0.41448764039925867\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.16411163560527028, 'dropout_transformers': 0.2805638030185365, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.35107413074384675, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 7.333177102644663e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 47, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00020022839259841243}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.575482999361478 acc:  0.022597860795391108\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.141158474408663 acc:  0.06506933434562222\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  6.955588311415452 acc:  0.08398276131567782\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  6.829997326777532 acc:  0.09896612553870889\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  6.724678883185754 acc:  0.10660295201304067\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  6.622821514423077 acc:  0.1182591608422839\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  6.51960082420936 acc:  0.1266552039836545\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  6.412853134595431 acc:  0.13270660741799342\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  6.309664462162898 acc:  0.13536386575262935\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  6.198155102363 acc:  0.14440747605118012\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  6.087185922035804 acc:  0.15146372507424694\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  5.9727643416478085 acc:  0.1568229015474622\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  5.855376192239615 acc:  0.16128888194180827\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  5.745265546211829 acc:  0.16419176919813322\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  5.631271872153649 acc:  0.17127034812317174\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  5.538035102990958 acc:  0.17323537949668402\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  5.4954755709721494 acc:  0.17542370988991357\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  5.457862498210027 acc:  0.17595962753723512\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  5.419017131511982 acc:  0.1768974834200478\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  5.381112447151771 acc:  0.17908581381327737\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  5.347673914982722 acc:  0.17986736038228793\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  5.302475059949435 acc:  0.1808945358729875\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  5.264753561753493 acc:  0.18212268048143268\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  5.2335705023545485 acc:  0.18455663979635129\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  5.1921046807215765 acc:  0.1858741040126834\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  5.155046540040236 acc:  0.1868342897974678\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  5.122426872987013 acc:  0.1889109706808387\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  5.083587309030386 acc:  0.19004979568139696\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  5.046382027405959 acc:  0.19181385793716366\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  5.014523154038649 acc:  0.19389053882053459\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  4.986121038290171 acc:  0.19491771431123417\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  4.973421727693998 acc:  0.1959002299979903\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  4.963449408457829 acc:  0.1969274054886899\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  4.953066396713257 acc:  0.1977982716655874\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  4.936181361858662 acc:  0.19844583882276756\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  4.925477721140935 acc:  0.1985351584306545\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  4.914986716783964 acc:  0.19967398343121273\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  4.903589461399958 acc:  0.20007592166670388\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  4.890202757028433 acc:  0.20003126186276043\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  4.879020573542668 acc:  0.20112542705937522\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  4.870369474704449 acc:  0.20079047852979925\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  4.856285971861619 acc:  0.20159435500078154\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  4.847674113053542 acc:  0.20268852019739633\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  4.836558818817139 acc:  0.20288948931514192\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  4.823628047796396 acc:  0.20344773686443515\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  4.813376155266395 acc:  0.20380501529598286\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  4.808933881612925 acc:  0.20405064421767188\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  4.80394466473506 acc:  0.20431860304133265\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  4.80405851144057 acc:  0.20427394323738918\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  4.795009389290443 acc:  0.2045865618649934\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  5.804117877666767 acc:  0.2047205412768238\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  5.799945365465605 acc:  0.20512247951231494\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  5.790551941211407 acc:  0.20518946921823014\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  5.796450046392588 acc:  0.20556907755174955\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  5.789507113970243 acc:  0.20565839715963646\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  5.783649228169367 acc:  0.20585936627738205\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  5.785284566879272 acc:  0.20599334568921243\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  5.77977028626662 acc:  0.20594868588526896\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  5.766364339681772 acc:  0.2062613045128732\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  5.7696793299454905 acc:  0.20661858294442087\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  5.765228190788856 acc:  0.20652926333653396\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  5.765140493099506 acc:  0.2065515932385057\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  5.76343264579773 acc:  0.2065739231404774\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  5.758882192464975 acc:  0.20668557265033607\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  5.756714846537664 acc:  0.20668557265033607\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  5.760755421565129 acc:  0.2068418819641382\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  5.7604607398693375 acc:  0.20697586137596857\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  5.7598237734574536 acc:  0.20699819127794028\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  5.755254422701322 acc:  0.20708751088582722\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  5.75883333499615 acc:  0.20717683049371413\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  5.755981625043429 acc:  0.20728848000357278\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  5.754449877372155 acc:  0.2071545005917424\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  5.74689657504742 acc:  0.20735546970948798\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  73 loss :  5.748747697243323 acc:  0.2073108099055445\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  74 loss :  5.746792591535128 acc:  0.20733313980751625\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  75 loss :  5.743859804593599 acc:  0.20719916039568587\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  76 loss :  5.748551291685838 acc:  0.20728848000357278\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  77 loss :  5.746576874072735 acc:  0.2074447893173749\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  78 loss :  5.743421587577233 acc:  0.20742245941540316\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  79 loss :  5.7425178197713995 acc:  0.20740012951343142\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  80 loss :  5.747659884966337 acc:  0.2075117790232901\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  81 loss :  5.741231184739333 acc:  0.2075341089252618\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  82 loss :  5.741952356925378 acc:  0.207601098631177\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  83 loss :  5.745384487738976 acc:  0.20769041823906392\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  84 loss :  5.737492201878474 acc:  0.2077350780430074\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  85 loss :  5.7457552763131945 acc:  0.20757876872920528\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  86 loss :  5.741748424676748 acc:  0.20755643882723354\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  87 loss :  5.742865525759184 acc:  0.207601098631177\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  88 loss :  5.739100584617028 acc:  0.2076680883370922\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  89 loss :  5.73309628046476 acc:  0.20775740794497913\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  90 loss :  5.736180672278771 acc:  0.20769041823906392\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  91 loss :  5.736226136867817 acc:  0.20769041823906392\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  92 loss :  5.739344310760498 acc:  0.20780206774892257\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  93 loss :  5.738895163169274 acc:  0.20771274814103566\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  94 loss :  5.738774505028358 acc:  0.2077350780430074\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  95 loss :  5.736929203913762 acc:  0.20777973784695086\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  96 loss :  5.7353580804971545 acc:  0.2078243976508943\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Hardtanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.18689687766203095, 'dropout_transformers': 0.41716998724083276, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5094999343807358, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 0.00015809038680401975, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 44, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.7714716238127446e-05}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.459395581025344 acc:  0.04405689659022397\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  6.752834364084097 acc:  0.1267221936895697\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  5.896414811794575 acc:  0.20016524127459082\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  5.2073768762441786 acc:  0.2479065716901503\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  4.71762527685899 acc:  0.27704709376325837\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  4.365859099534842 acc:  0.3038653060313065\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  4.103512441194974 acc:  0.32094768103968024\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  3.9074503531822793 acc:  0.3394591697742447\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  3.7572355875602135 acc:  0.35238818301587654\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  3.6441449330403253 acc:  0.3625706183149856\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  3.5391947966355546 acc:  0.3719268472411406\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  3.460605766223027 acc:  0.37864814773463146\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  3.3899419417748082 acc:  0.38595002567938724\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  3.3346013619349555 acc:  0.39137619185851774\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  3.2834971134479227 acc:  0.39622178058638324\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  3.2348928158099834 acc:  0.40115668892213563\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  3.191725890453045 acc:  0.40597994774802937\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  3.159251675238976 acc:  0.409240113435902\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  3.1285052171120276 acc:  0.4097313712792801\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  3.09063497873453 acc:  0.412723578143492\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  3.0557243328828076 acc:  0.4162740325569971\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  3.032594264470614 acc:  0.4177478060871313\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  3.018818580187284 acc:  0.4193778889310676\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  3.003504230425908 acc:  0.4199138065783891\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  2.987179785508376 acc:  0.42103030167697564\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  2.971629051061777 acc:  0.4209409820690887\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  2.966136431694031 acc:  0.4225487350110533\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  2.9485903923328105 acc:  0.4239555188352723\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  2.9441204401162953 acc:  0.4236652301096398\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  2.9243525725144606 acc:  0.4248263850121698\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  2.9195772372759308 acc:  0.425139003639774\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  2.912896855060871 acc:  0.4259428801107563\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  2.8986043159778303 acc:  0.42641180805216267\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  2.892927492581881 acc:  0.4279972310921555\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  2.8773884864953847 acc:  0.42964964383806353\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  2.873072257408729 acc:  0.42877877766116607\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  2.858627961232112 acc:  0.4318826340352366\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  2.852049646010766 acc:  0.43038653060313065\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  2.843059288538419 acc:  0.43083312864256523\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  2.8311432600021362 acc:  0.4313913761918585\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  2.8184942593941322 acc:  0.4324855413884733\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  2.814076491502615 acc:  0.4328204899180493\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  2.81015291764186 acc:  0.4328204899180493\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  2.801101229741023 acc:  0.43369135609494674\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  2.7978825844251194 acc:  0.4332894178594556\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  2.7912060957688554 acc:  0.4336466962910033\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  2.7921107824032125 acc:  0.4333787374673425\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  2.7853723764419556 acc:  0.43391465511466404\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  2.785607787278982 acc:  0.4343612531540987\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  2.7778622113741362 acc:  0.4347855212915615\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  3.80727420770205 acc:  0.43567871737043073\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  3.785101023087135 acc:  0.43532143893888303\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  3.7827486735123856 acc:  0.43541075854676997\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  3.77916936140794 acc:  0.43467387178170286\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  3.7672296505707963 acc:  0.43462921197775944\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  3.766626519423265 acc:  0.4346068820757877\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'LeakyReLU', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.23340638809373143, 'dropout_transformers': 0.22846037629217858, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 5.1417272499254924e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 35, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.004410752549760504}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.76941238968066 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.404859873169627 acc:  0.005738784806734698\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.297564338705393 acc:  0.008976620592635598\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  7.212658679685113 acc:  0.036531719625750844\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  7.10423774825794 acc:  0.07346537748699283\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  6.932950259586952 acc:  0.08163812160864614\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  6.782106322283186 acc:  0.10660295201304067\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  6.618791902531458 acc:  0.12636491525802201\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  6.435979616708596 acc:  0.13411339124221244\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  6.189109157583567 acc:  0.1429783623249894\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  6.058302615607917 acc:  0.1470424044838443\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  5.839990852931359 acc:  0.15427729272268495\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  5.664462714221891 acc:  0.17033249224035907\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  5.5547819324045875 acc:  0.17761204028314315\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  5.459481525687532 acc:  0.18741486724873277\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  5.315500966663467 acc:  0.19639148784136837\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  5.200412638360562 acc:  0.20599334568921243\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  5.0964190919972 acc:  0.21108456333876693\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  4.9504482799402165 acc:  0.2223165040305473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  4.8385556490061665 acc:  0.22910479422995333\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  4.7805586140915 acc:  0.23993479668624254\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  4.701169461511367 acc:  0.24319496237411517\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  4.58711275175297 acc:  0.25076479914253175\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  4.429803830951286 acc:  0.2560123261058884\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  4.319617182182866 acc:  0.2595627805193935\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  4.344727902439054 acc:  0.26420740012951344\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  4.311742851854037 acc:  0.2715539378782127\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  4.224394581171388 acc:  0.2775606815086082\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  4.065497859230255 acc:  0.28173637317732175\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  4.1447705569879965 acc:  0.28754214768997166\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  3.978551326517286 acc:  0.29267802514346963\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  4.009022885860677 acc:  0.29756827367527855\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  3.932920282779459 acc:  0.30158765603019005\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  3.8733221312474937 acc:  0.30949244132818254\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  3.87308159753597 acc:  0.3117031016233839\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  3.7756837439936635 acc:  0.3168836388808253\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  3.679555918251336 acc:  0.32117098005939754\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  3.7009684946283947 acc:  0.3242301766295246\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  3.5828438258037885 acc:  0.329991291338231\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  3.6379945864224568 acc:  0.3329165084965277\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  3.583312923015829 acc:  0.33284951879061253\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  3.5213717961444537 acc:  0.33963780899001855\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  3.535154868770578 acc:  0.34338923252126924\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  3.4778455955356193 acc:  0.34510863497309247\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  3.3953151662922436 acc:  0.3489270482102584\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  3.3948395931520943 acc:  0.35310273987897195\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  3.3622868986769094 acc:  0.3560949467431838\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  3.3389897406434215 acc:  0.3573454212536007\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  3.3130583030551506 acc:  0.36047160752964297\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  3.3275343213001443 acc:  0.3622133398834379\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  4.416955132724187 acc:  0.36672398008172746\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  4.392723917295147 acc:  0.37029676439720427\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  4.310478516797113 acc:  0.3749190541053525\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  4.281791964056771 acc:  0.3761918585177411\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  4.152020583605633 acc:  0.3767054462630909\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  4.225922504616849 acc:  0.3789384364602639\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  4.266025234201101 acc:  0.3805461894022285\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  4.31921226751871 acc:  0.3831811178348927\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  4.136008558326593 acc:  0.3845879016591117\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  4.28659940831488 acc:  0.38630730411093495\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  4.10577119662109 acc:  0.3895004800928924\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  4.105716934417213 acc:  0.3911975526427439\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  4.125250954867742 acc:  0.39389947078132326\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  4.1147537897419 acc:  0.3937654913694929\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  4.235926172586793 acc:  0.395328584507514\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  4.066647942505735 acc:  0.39680235803764824\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  4.0069011656265685 acc:  0.40073242078467275\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  4.093248128890991 acc:  0.4019382354911462\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  3.991408871538812 acc:  0.4045285041198669\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  4.0061879837313175 acc:  0.40479646294352767\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  4.015559943694642 acc:  0.40537704039479266\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  4.00003523400376 acc:  0.40807895853337206\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  3.9402782117854285 acc:  0.40830225755308935\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  73 loss :  3.9417251701461535 acc:  0.4095304021615345\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  74 loss :  3.9984237694873492 acc:  0.40984302078913876\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  75 loss :  3.891086822115509 acc:  0.41145077373110334\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  76 loss :  3.899100929665166 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  77 loss :  3.901799677470543 acc:  0.4138847330460219\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  78 loss :  3.848392386676213 acc:  0.4154254962820713\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  79 loss :  3.904298891568317 acc:  0.4158274345175625\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  80 loss :  3.8174606581639976 acc:  0.4154254962820713\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  81 loss :  3.8030670288554784 acc:  0.41830605363642454\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  82 loss :  3.9553417879775914 acc:  0.4171672286358663\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  83 loss :  3.9053975923101327 acc:  0.4185740124600853\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  84 loss :  3.8338636086639744 acc:  0.4210749614809191\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Hardshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 792, 'dropout': 0.10284065240920769, 'dropout_transformers': 0.32419200257356773, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5992406081255082, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 7.69859484585515e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 41, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.017396536372065976}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  8.04941469472605 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.922136923649928 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.735359768767457 acc:  0.005381506375187013\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  7.577627935609617 acc:  0.0052921867673000915\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  7.486139974394045 acc:  0.005582475492932586\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  7.4243676178938856 acc:  0.00649800147377353\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  7.372737944542945 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  7.350627222261228 acc:  0.005872764218565081\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  7.318840473681897 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  7.28349426242855 acc:  0.004733939218006833\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  7.272520352076818 acc:  0.009132929906437711\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  7.253072808672498 acc:  0.0071678985329254406\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  7.239548533112853 acc:  0.012460085300225531\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  7.191525726051597 acc:  0.01371055981064243\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  7.199245612938087 acc:  0.014536766183596454\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  7.198710574970379 acc:  0.014603755889511644\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  7.164306847365586 acc:  0.017707612263582164\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  7.173410499012554 acc:  0.019248375499631556\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  7.154406810973907 acc:  0.020923118147511334\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  7.140008953067806 acc:  0.022910479422995334\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  7.110113534060392 acc:  0.02474153138467722\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  7.091093240084348 acc:  0.02661724315030257\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  7.116693196596799 acc:  0.030703615211129222\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  7.084672907849292 acc:  0.033271553937878215\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  7.064762885753925 acc:  0.03597347207645758\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  7.0559571606295926 acc:  0.03923363776433021\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  7.042509799237018 acc:  0.04381126766853494\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  7.032513318361936 acc:  0.045776299042047205\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  7.01784754132891 acc:  0.046937453944577184\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  7.019753749553974 acc:  0.04885782551414599\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  7.000351278931944 acc:  0.051403434338923255\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  6.997228855853314 acc:  0.052832548065114\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  6.971963162188763 acc:  0.05671795100819507\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  6.9869354654858995 acc:  0.0585043431659335\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  6.9552416234583285 acc:  0.061384900520286716\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  6.953879849894063 acc:  0.06252372552084497\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  6.964360563905089 acc:  0.06553826228702855\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  6.909396078203108 acc:  0.06692271620927584\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  6.906462966145336 acc:  0.07054016032869616\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  6.920704538171941 acc:  0.07161199562333921\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  6.911893271066092 acc:  0.07386731572248398\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  6.869929667119379 acc:  0.07522943974275953\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  6.883897377894475 acc:  0.07855659513654735\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  6.901699482977807 acc:  0.08000803876470983\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  6.889201124231298 acc:  0.08061094611794654\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  6.872874183254642 acc:  0.08112453386329634\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  6.857675115545313 acc:  0.0834468436683563\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  6.87650997655375 acc:  0.08581381327735971\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  6.860737573850405 acc:  0.08679632896411585\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  6.860243010354209 acc:  0.08693030837594623\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  7.909052261939416 acc:  0.08460799857088627\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  7.929691491427121 acc:  0.08496527700243396\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  7.945395126209393 acc:  0.08592546278721837\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  8.021149291858807 acc:  0.08686331867003104\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  7.953607085701469 acc:  0.08664001965031373\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  7.902397362502305 acc:  0.0875778755331264\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  7.9329182718183615 acc:  0.08795748386664583\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  7.927286911677648 acc:  0.08900698925931715\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  7.919532882583725 acc:  0.08885067994551504\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  7.8827362927523525 acc:  0.08925261818100619\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  7.865299344896437 acc:  0.08987785543621464\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  7.854186388162466 acc:  0.0901458142598754\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  7.859621628181084 acc:  0.09168657749592479\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  7.8399609452361 acc:  0.09208851573141594\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  7.897898717360063 acc:  0.09313802112408727\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  7.864085170772526 acc:  0.09333899024183284\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  7.8729265253027005 acc:  0.0936739387714088\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  7.864135985607867 acc:  0.09376325837929571\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  7.9166971253348395 acc:  0.09429917602661725\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  7.8710838031101895 acc:  0.09474577406605185\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  7.89536900953813 acc:  0.09530402161534511\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  7.904955237061827 acc:  0.09552732063506242\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  7.886110049027663 acc:  0.09590692896858183\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  73 loss :  7.916193288523001 acc:  0.09637585690998816\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  74 loss :  7.838085844800188 acc:  0.09680012504745104\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  75 loss :  7.844064702520837 acc:  0.09659915592970547\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  76 loss :  7.829408688978716 acc:  0.09693410445928143\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  77 loss :  7.848443921629365 acc:  0.09715740347899873\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  78 loss :  7.901288682764227 acc:  0.09747002210660295\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  79 loss :  7.9058017263879306 acc:  0.09773798093026372\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  80 loss :  7.812633721144883 acc:  0.09776031083223545\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  81 loss :  7.854154513432429 acc:  0.09813991916575486\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  82 loss :  7.81592519133241 acc:  0.09887680593082196\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  83 loss :  7.905569423328746 acc:  0.09865350691110467\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  84 loss :  7.8323852965881775 acc:  0.09901078534265234\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  85 loss :  7.780531806545658 acc:  0.09936806377420003\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  86 loss :  7.807067627673383 acc:  0.09936806377420003\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  87 loss :  7.827703302556818 acc:  0.09983699171560637\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  88 loss :  7.857321815890866 acc:  0.10019427014715405\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  89 loss :  7.813351274370314 acc:  0.10035057946095617\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  90 loss :  7.854380367519139 acc:  0.1003059196570127\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.0817023140697439, 'dropout_transformers': 0.38333853206484925, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5372189019885185, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 0.00026273347649426345, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00037107674799099187}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.223069499089168 acc:  0.10823303485697698\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  5.878022703757653 acc:  0.18607507313042895\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  4.825290540548472 acc:  0.23689793001808723\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  4.18891934798314 acc:  0.28350043543308845\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  3.7954746301357565 acc:  0.31514190652703034\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  3.549005574446458 acc:  0.33519415849764417\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  3.366348064862765 acc:  0.3593327825290847\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  3.2310006875258224 acc:  0.37415983743831366\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  3.1259590313984797 acc:  0.3867762320523413\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  3.042052857692425 acc:  0.3983207913717259\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  2.973350066405076 acc:  0.4045285041198669\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  2.9075556388268105 acc:  0.40537704039479266\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  2.8595782683445856 acc:  0.41258959873166157\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  2.810210998241718 acc:  0.4199361364803609\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  2.768803941286527 acc:  0.4205167139316258\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  2.7359751591315637 acc:  0.4252729830516044\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  2.6997807631125816 acc:  0.42589822030681285\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  2.6685952498362613 acc:  0.4284438291315901\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  2.6171387103887707 acc:  0.4318826340352366\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  2.5913248924108654 acc:  0.4331331085456535\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  2.575853883303129 acc:  0.4336466962910033\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  2.5604213091043326 acc:  0.43467387178170286\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  2.5402655106324414 acc:  0.434830181095505\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  2.530915959064777 acc:  0.43462921197775944\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  2.5168606281280517 acc:  0.43545541835071344\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  2.502669325241676 acc:  0.4347855212915615\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  2.486223006248474 acc:  0.4371301609985932\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  2.4787555034344013 acc:  0.4366835629591586\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  2.4634403008681076 acc:  0.4369515217828194\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  2.4543477626947254 acc:  0.4381350065873211\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  2.4415911271021917 acc:  0.43775539825380166\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  2.4318367627950814 acc:  0.4394078109997097\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  2.421931452017564 acc:  0.4386485943326709\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  2.412060136061448 acc:  0.44032333698055065\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  2.4017291362469013 acc:  0.43878257374450125\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  2.3915236216325026 acc:  0.43858160462675566\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  2.3667151249372043 acc:  0.44088158452984394\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  2.361078847371615 acc:  0.440792264921957\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  2.3565244674682617 acc:  0.4421767188442043\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  2.3509244753764227 acc:  0.44135051247125023\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  2.3441172590622537 acc:  0.44202040953040217\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  2.3389408881847675 acc:  0.4414621619811089\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  2.333541041154128 acc:  0.4414398320791372\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  2.328678741821876 acc:  0.44222137864814776\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  2.3227139454621537 acc:  0.4417747806087131\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  2.3163420016948995 acc:  0.4421543889422325\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  2.311733992283161 acc:  0.44231069825603464\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  2.3079988397084747 acc:  0.44224370855011946\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  2.3059919018011827 acc:  0.442779626197441\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  2.2995351057786206 acc:  0.442779626197441\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  3.3475423115950362 acc:  0.441372842373222\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  3.306086459526649 acc:  0.4424893374718085\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  3.2982387891182534 acc:  0.44302525511913005\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  3.2952283492455114 acc:  0.4423330281580064\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  3.286945414543152 acc:  0.4431592345309604\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  3.276151756139902 acc:  0.44318156443293216\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  3.272943564561697 acc:  0.4433378737467343\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  3.2685416533396796 acc:  0.4427126364915258\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  3.2628243739788347 acc:  0.4436728222763102\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  3.262575995005094 acc:  0.4429582654132148\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  3.2580069615290714 acc:  0.44320389433490387\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  3.2580615832255435 acc:  0.4431369046289887\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  3.258054381150466 acc:  0.44360583257039504\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  3.2540810713401207 acc:  0.44349418306053634\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.0034694431333168047, 'dropout_transformers': 0.3956767916199589, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.4513684866663251, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 2.099067893845441e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00036075678435595036}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.934204544559602 acc:  0.004443650492374339\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.585803450307538 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.396334386640979 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  7.298954326875748 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  7.221879673004151 acc:  0.011477569613469397\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  7.156104075524115 acc:  0.021682334814550164\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  7.053361031316942 acc:  0.04191322600093786\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  6.941221818616313 acc:  0.06134024071634325\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  6.814392025240006 acc:  0.08371480249201706\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  6.676850512719923 acc:  0.09664381573364893\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  6.540043701664094 acc:  0.10584373534600183\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  6.407816440828385 acc:  0.11426210838934417\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  6.294331713645689 acc:  0.12600763682647434\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  6.15361551777009 acc:  0.13322019516334324\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  6.0380354942814 acc:  0.14204050644217672\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  5.962333439242455 acc:  0.1528481789964942\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  5.804556234421269 acc:  0.16296362458968805\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  5.728097989482264 acc:  0.1672509657682603\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  5.601091834037534 acc:  0.174396534399214\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  5.49856250209193 acc:  0.18239063930509344\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  5.444792362951463 acc:  0.1858964339146551\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  5.334608591756513 acc:  0.1894022285242168\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  5.257341800197478 acc:  0.19210414666279615\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  5.246364455069265 acc:  0.19453810597771476\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  5.190072161151517 acc:  0.19558761137038608\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  5.140677642822266 acc:  0.19813322019516336\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  5.160416652310279 acc:  0.1998079628430431\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  5.089661435158022 acc:  0.20226425205993345\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  5.067705339001071 acc:  0.20507781970837147\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  5.039608955383301 acc:  0.20592635598329723\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  4.988277678335867 acc:  0.20853895451398968\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  4.955613465462961 acc:  0.2105486456914454\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  4.93461077444015 acc:  0.21166514079003193\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  4.856134267007151 acc:  0.21392046088917668\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  4.906631312831756 acc:  0.21655538932184087\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  4.843884766486383 acc:  0.21872138981309872\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  4.80154527233493 acc:  0.22140097804970635\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  4.784994965214883 acc:  0.22247281334434943\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  4.7489827771340645 acc:  0.224661143737579\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  4.728077756204913 acc:  0.2252640510908157\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  4.6746278839726605 acc:  0.22711743295446932\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  4.663246099410519 acc:  0.23082419668177656\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  4.657167263953917 acc:  0.23039992854431368\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  4.652071891292449 acc:  0.2326775785454302\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  4.596188577528923 acc:  0.23316883638880825\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  4.593085630478398 acc:  0.2332804858986669\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  4.589178017647035 acc:  0.23410669227162093\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  4.548860920629194 acc:  0.23544648638992474\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  4.548792354522213 acc:  0.23609405354710492\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  4.546611672063028 acc:  0.23721054864569144\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  5.786748270834646 acc:  0.2363843422727374\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  5.721112195907101 acc:  0.23642900207668088\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  5.6418226426647555 acc:  0.23721054864569144\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  5.604494180986958 acc:  0.23759015697921085\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  5.618927229604413 acc:  0.2389299510975147\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  5.570864852782218 acc:  0.23913092021526025\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  5.554278349107312 acc:  0.2399124667842708\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  5.554627538496448 acc:  0.24035906482370542\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  5.571505254314792 acc:  0.2408726525690552\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  5.569952143392255 acc:  0.2418774981577831\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  5.512824569209929 acc:  0.2422571064913025\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  5.497162280544158 acc:  0.24315030257017173\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  5.496900786122968 acc:  0.24397650894312575\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  5.507620359236194 acc:  0.2444677667865038\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  5.468377217938823 acc:  0.24538329276734475\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  5.4806821761592746 acc:  0.24522698345354263\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  5.465213483379733 acc:  0.24542795257128822\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  5.409472225558373 acc:  0.245941540316638\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  5.439678084465765 acc:  0.2460085300225532\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  5.404983945046702 acc:  0.24609784963044012\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  5.4470275509742 acc:  0.24679007659156377\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  5.411437459145823 acc:  0.2468124064935355\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  5.43646973640688 acc:  0.24734832414085703\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.07480001693013202, 'dropout_transformers': 0.49702779405783615, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00020796054891357834, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 25, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0012676978323037484}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.571792890097349 acc:  0.005381506375187013\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.252199449611984 acc:  0.029564790210570974\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  6.935992262745631 acc:  0.08099055445146595\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  6.5765217933945985 acc:  0.09802826965589621\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  6.186480070798452 acc:  0.13007167898532926\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  5.7661862591750745 acc:  0.15747046870464237\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  5.393786932675893 acc:  0.17129267802514347\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  5.150437777278987 acc:  0.18598575352254204\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  8 loss :  4.914367044245013 acc:  0.2064176138266753\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  9 loss :  4.711204437809136 acc:  0.2203961324609785\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  10 loss :  4.514860497176192 acc:  0.23187370207444788\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  11 loss :  4.399642492978628 acc:  0.2389299510975147\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  12 loss :  4.243263958064654 acc:  0.2456512515910055\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  13 loss :  4.159017004129541 acc:  0.25435991335998037\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  14 loss :  4.100052101921489 acc:  0.26333653395261597\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  15 loss :  3.9974785306071507 acc:  0.2690306589554072\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  16 loss :  3.854325487413479 acc:  0.2688073599356899\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  17 loss :  3.8502436193801066 acc:  0.2713083089565237\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  18 loss :  3.787929152714387 acc:  0.2910032824955898\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  19 loss :  3.7673099022785217 acc:  0.2927896746533283\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  20 loss :  3.732974278107854 acc:  0.2954692628899359\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  21 loss :  3.6117482986158995 acc:  0.30339637808990016\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  22 loss :  3.5894641075425477 acc:  0.31094388495634506\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  23 loss :  3.586377890055416 acc:  0.3142263805461894\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  24 loss :  3.5444011124035786 acc:  0.31942924770560255\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  25 loss :  3.486085454926236 acc:  0.3329834982024429\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  26 loss :  3.5015172048379446 acc:  0.33155438447625213\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  27 loss :  3.4740430052953823 acc:  0.33729316928298686\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  28 loss :  3.4607911073524535 acc:  0.3399727575195945\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  29 loss :  3.3778059191376197 acc:  0.3395261594801599\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  30 loss :  3.39242827801304 acc:  0.34470669673760135\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  31 loss :  3.4172726496485355 acc:  0.3475872540919545\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  32 loss :  3.297356887628104 acc:  0.35855123596007415\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  33 loss :  3.304940869789997 acc:  0.3576580398812049\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  34 loss :  3.3098608228086515 acc:  0.36035995801978427\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  35 loss :  3.30496913422155 acc:  0.36348614429582654\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  36 loss :  3.2067326498395614 acc:  0.36739387714087934\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  37 loss :  3.2561856935952456 acc:  0.3716142286135364\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  38 loss :  3.243124068238353 acc:  0.3733336310653596\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  39 loss :  3.1817156886326448 acc:  0.37482973449746554\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  40 loss :  3.1745567503776257 acc:  0.37710738449858205\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  41 loss :  3.145655520999705 acc:  0.3836723756782708\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  42 loss :  3.1404723939094836 acc:  0.3820646227363062\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  43 loss :  3.1463587247688354 acc:  0.3838956746979881\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  44 loss :  3.162173684316737 acc:  0.3857937163655852\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  45 loss :  3.1247318737379466 acc:  0.3907062947993658\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  46 loss :  3.096523010093747 acc:  0.389947078132327\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  47 loss :  3.122077226638794 acc:  0.3928722952906237\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  48 loss :  3.0999237617463558 acc:  0.3908849340151397\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  49 loss :  3.0619921884463945 acc:  0.39329656342808655\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  50 loss :  4.163973260471839 acc:  0.39718196637116765\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  51 loss :  4.050631006255404 acc:  0.3994372864703124\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  52 loss :  4.078369177024783 acc:  0.4009780497063618\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  53 loss :  4.053613786478989 acc:  0.39818681195989547\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  54 loss :  3.9841206055561096 acc:  0.4041712256883192\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  55 loss :  3.988669120628415 acc:  0.4039479266686019\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  56 loss :  4.018895496848885 acc:  0.40108969921622045\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  57 loss :  3.9944373378316866 acc:  0.4053323805908492\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  58 loss :  3.921449202617616 acc:  0.40653819529732266\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  59 loss :  4.0251865332363215 acc:  0.4079673090235134\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  60 loss :  4.011379575001374 acc:  0.404684813433669\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  61 loss :  3.9685433802713876 acc:  0.40912846392604335\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  62 loss :  3.9746281591080526 acc:  0.40932943304378894\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  63 loss :  3.9641204153308434 acc:  0.41102650559364046\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  64 loss :  3.924772113334132 acc:  0.4079896389254851\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  65 loss :  3.905272349146486 acc:  0.4111604850054708\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  66 loss :  3.9805383664051086 acc:  0.4097983609851953\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  67 loss :  3.885347515572118 acc:  0.41162941294687716\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  68 loss :  3.8652669346059554 acc:  0.41352745461447427\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  69 loss :  3.902313933117699 acc:  0.4126119286336333\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  70 loss :  3.8490665450350927 acc:  0.41384007324207844\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  71 loss :  3.911534069148639 acc:  0.4142196815755979\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  72 loss :  3.8877495772965993 acc:  0.41567112520376037\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  73 loss :  3.8965398901291475 acc:  0.41747984726347054\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  74 loss :  3.855373022210507 acc:  0.41823906393050936\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': True, 'd_model': 600, 'dropout': 0.022817448732280914, 'dropout_transformers': 0.4558520793147647, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.24914906269364756, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 0.0007284315161590414, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.10385976559207999}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.591661666656708 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.384004816308722 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.334475453916963 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  7.286947887260597 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  7.281761969719733 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  7.281405365550435 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  7.279938190967053 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 720, 'dropout': 0.05561403616077981, 'dropout_transformers': 0.3866628501089536, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5405402890777122, 'scheduler': 'StepLR', 'step_size': 27, 'lr': 0.004458793317863841, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 30, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00815785948496254}\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  0 loss :  7.700524844095378 acc:  0.00013397941183038205\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  1 loss :  7.368492049371411 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  2 loss :  7.311666834140253 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  3 loss :  7.306599140167236 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  4 loss :  7.29696362318393 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  5 loss :  7.281959476585159 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  6 loss :  7.267452425585535 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=206162)\u001b[0m epoch:  7 loss :  7.28029996906212 acc:  0.003438804903646473\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 06:59:20,057\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 06:59:33,890\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 06:59:33,891\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_13       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_13\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_13`\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 552, 'dropout': 0.1155659148805338, 'dropout_transformers': 0.38243086285753525, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.37595760571399034, 'scheduler': 'StepLR', 'step_size': 24, 'lr': 0.001004108348410396, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 16, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.3641134563118605}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  6.51509057191702 acc:  0.16626845008150415\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  4.458736612246587 acc:  0.25502981041913225\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  3.705442577141982 acc:  0.31837974231293126\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  3.3542887651003324 acc:  0.3471629859544917\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  3.117536271535433 acc:  0.38293548891320367\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  2.9657866386266853 acc:  0.38762476832726706\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  2.8365775731893685 acc:  0.4031217202956479\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  2.7475126908375667 acc:  0.4051090815711319\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  2.6749435883301955 acc:  0.4107138869660362\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  2.616729453893808 acc:  0.4131031864770114\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  2.5678883992708648 acc:  0.42221378648147734\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  2.5237891582342296 acc:  0.4173235379496684\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  2.488647770881653 acc:  0.42458075609048074\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  2.457553339004517 acc:  0.4168322801062903\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  2.434566851762625 acc:  0.41928856932318065\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  2.4092802818004904 acc:  0.42234776589330775\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  2.384315037727356 acc:  0.41848469285219836\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  2.3613714163119974 acc:  0.4189536207936047\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 624, 'dropout': 0.09182294952725781, 'dropout_transformers': 0.4497198335830217, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.4702862800873809, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 4.449589428108805e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.001732776515013005}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  8.01670408864175 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.897093766735446 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.804483266030588 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.718918231225783 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.6454292020490096 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.584770433364376 acc:  0.005135877453497979\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  7.529577104506954 acc:  0.0051805372574414395\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  7.488907644825597 acc:  0.007056249023066789\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  7.453888542421402 acc:  0.00777080588616216\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  7.421647868617889 acc:  0.007569836768416586\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  7.388530832721341 acc:  0.006832950003349486\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  7.36368169476909 acc:  0.006765960297434294\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  7.347097772167575 acc:  0.007592166670388317\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  7.318555499661353 acc:  0.008016434807851193\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  7.303810015032369 acc:  0.008172744121653306\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  7.285476752250426 acc:  0.00906594020052252\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  7.274490171863187 acc:  0.010093115691222116\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  7.250772288537795 acc:  0.011298930397695554\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  18 loss :  7.2377740398530035 acc:  0.01299600294754706\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  19 loss :  7.2150084895472375 acc:  0.015563941674296049\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  20 loss :  7.203800804384293 acc:  0.018355179420762344\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  21 loss :  7.205580093014625 acc:  0.019940602460755196\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  22 loss :  7.199405876282722 acc:  0.021235736775115557\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  23 loss :  7.193353003840293 acc:  0.022396891677645536\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  24 loss :  7.177246146048269 acc:  0.0239153250117232\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  25 loss :  7.180662508933775 acc:  0.024875510796507603\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  26 loss :  7.173667000186059 acc:  0.026349284326641804\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  27 loss :  7.167277680673907 acc:  0.028158006386351964\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  28 loss :  7.1535583157693186 acc:  0.028850233347475603\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  29 loss :  7.15475151923395 acc:  0.0298774088381752\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  30 loss :  7.143336656016688 acc:  0.03128419266239421\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  31 loss :  7.137180306834559 acc:  0.03228903825112208\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  32 loss :  7.128033721062445 acc:  0.034298729428577805\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  33 loss :  7.128914848450692 acc:  0.03525891521336221\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  34 loss :  7.127372061821722 acc:  0.03646472991983565\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  35 loss :  7.1228998891768915 acc:  0.03771520443025255\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  36 loss :  7.115748651566044 acc:  0.03827345197954581\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  37 loss :  7.109596477016326 acc:  0.04023848335305808\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  38 loss :  7.108748454432334 acc:  0.042315164236429004\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  39 loss :  7.091780296448738 acc:  0.04287341178572226\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  40 loss :  7.0814305582354145 acc:  0.04347631913895898\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  41 loss :  7.093599085653982 acc:  0.04369961815867628\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  42 loss :  7.088429512516145 acc:  0.04392291717839358\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  43 loss :  7.0854721161627 acc:  0.044190876002054354\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  44 loss :  7.088850522810413 acc:  0.044637474041488955\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  45 loss :  7.091820633795954 acc:  0.045061742178951834\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  46 loss :  7.092757375778691 acc:  0.04537436080655606\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  47 loss :  7.079675425252606 acc:  0.04557532992430163\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  48 loss :  7.0725825432808165 acc:  0.045843288747962396\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  49 loss :  7.0829187946934855 acc:  0.04615590737556662\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  50 loss :  8.361313204611502 acc:  0.04812093874907889\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  51 loss :  8.259590081245669 acc:  0.046937453944577184\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  52 loss :  8.25290507347353 acc:  0.045218051492753944\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  53 loss :  8.187369931128718 acc:  0.043677288256704555\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  54 loss :  8.206431198120118 acc:  0.04287341178572226\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  55 loss :  8.191168283647107 acc:  0.041868566196994396\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Hardsigmoid', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 312, 'dropout': 0.17765502293209556, 'dropout_transformers': 0.4691076542727643, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 9.48983803475854e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 12, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.04267408540433159}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.782447209725013 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.449489879608154 acc:  0.005068887747582788\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.332188356839693 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.294764239971454 acc:  0.006319362257999687\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.28066059259268 acc:  0.006431011767858339\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.264738633082463 acc:  0.007949445101936002\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  7.233960452446571 acc:  0.02208427305004131\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  7.15069353397076 acc:  0.03762588482236563\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  6.99906812447768 acc:  0.05761114708706429\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  6.789417945421659 acc:  0.07105374807404595\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  6.550118094224196 acc:  0.0863943907286247\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  6.314718085068923 acc:  0.10745148828796641\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  6.099983699505145 acc:  0.12221155349128017\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  5.895000149653508 acc:  0.13326485496728668\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  5.714436479715201 acc:  0.14829287899426122\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  5.5537633125598616 acc:  0.15755978831252931\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  5.403148911549494 acc:  0.169015028024027\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  5.2660474960620585 acc:  0.18031395842172254\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  18 loss :  5.147037869233351 acc:  0.18611973293437242\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  19 loss :  5.02870991046612 acc:  0.19315365205546747\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  20 loss :  4.932252150315505 acc:  0.2014157157850077\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  21 loss :  4.833410798586332 acc:  0.2092758412790568\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  22 loss :  4.747081180719229 acc:  0.2156845231449434\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  23 loss :  4.669168989474957 acc:  0.22376794765870978\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  24 loss :  4.594387026933523 acc:  0.2285018868767166\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  25 loss :  4.524378523459801 acc:  0.2350445481544336\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  26 loss :  4.457950522349431 acc:  0.24042605452962063\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  27 loss :  4.3952657259427586 acc:  0.24721434472902665\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  28 loss :  4.339149009264433 acc:  0.25156867561351404\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  29 loss :  4.283607116112342 acc:  0.25695018198870107\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  30 loss :  4.237330057070806 acc:  0.2651452560123261\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  31 loss :  4.186241865158081 acc:  0.26599379228725184\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  32 loss :  4.137992389385516 acc:  0.27416653640890515\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  33 loss :  4.0912158874365 acc:  0.27704709376325837\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  34 loss :  4.0531118007806635 acc:  0.2828082084719648\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  35 loss :  4.020458397498498 acc:  0.2884576736708126\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  36 loss :  3.9850545681439913 acc:  0.29245472612375234\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  37 loss :  3.9449902534484864 acc:  0.2952459638702186\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  38 loss :  3.907709169387817 acc:  0.2982158408324587\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  39 loss :  3.8788228786908663 acc:  0.3020789138735681\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  40 loss :  3.8428687755878155 acc:  0.30667887367974456\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  41 loss :  3.8143630449588484 acc:  0.31063126632874083\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  42 loss :  3.7970058936339157 acc:  0.3134001741732354\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  43 loss :  3.7610372965152448 acc:  0.3179331442734966\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  44 loss :  3.736441500370319 acc:  0.32331465064868364\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  45 loss :  3.7100726751180795 acc:  0.32579326976754575\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  46 loss :  3.685517619206355 acc:  0.32840586829823815\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  47 loss :  3.6626642814049353 acc:  0.3315767143782239\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  48 loss :  3.637422257203322 acc:  0.3358640555567961\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  49 loss :  3.6187983457858746 acc:  0.3395261594801599\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  50 loss :  4.708423552146325 acc:  0.3380747158519974\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  51 loss :  4.641635627012986 acc:  0.3431212736976085\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  52 loss :  4.596497128559993 acc:  0.34685036732688745\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  53 loss :  4.566792664161095 acc:  0.3493289864457495\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  54 loss :  4.538375579393827 acc:  0.3512940178192618\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  55 loss :  4.519248790007371 acc:  0.35464350311502135\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  56 loss :  4.506302844561064 acc:  0.35781434919500704\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  57 loss :  4.4828875009830185 acc:  0.3596230712547172\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  58 loss :  4.465528545012841 acc:  0.3633744947859679\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  59 loss :  4.4383096841665415 acc:  0.36518321684567806\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  60 loss :  4.430854111451369 acc:  0.36621039233637764\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  61 loss :  4.412443377421453 acc:  0.3700064756715718\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 24, 'dropout': 0.1512935045843845, 'dropout_transformers': 0.42933963262193814, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.4264049933109602, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 6.498356485789421e-07, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0006318938901837176}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  8.09546654707902 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  8.090877496279203 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  8.094925120160296 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  8.093722103358981 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  8.093605298262377 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  8.089904084905879 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  8.089162746509471 acc:  0.0002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  8.088640913263067 acc:  0.00022329901971730344\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  8.096173559869086 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  8.086805270268368 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  8.090724184796526 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  8.09112566167658 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  8.087939529152184 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  8.089568378208401 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  8.088686656284999 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  8.088976459903316 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  8.088120160402951 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  8.086776046486168 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  18 loss :  8.085844093269401 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'GELU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 360, 'dropout': 0.07554783665265008, 'dropout_transformers': 0.40524569605083305, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6837805412783197, 'scheduler': 'StepLR', 'step_size': 29, 'lr': 4.043223095167945e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00010970541926191146}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.918905843205812 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.607863338053727 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.41976544035583 acc:  0.0051805372574414395\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.325107674638764 acc:  0.006698970591519103\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.25891989619792 acc:  0.0061183931402541145\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.221883673627837 acc:  0.008686331867003103\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  7.177859089955562 acc:  0.01636781814527834\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  7.125173753049193 acc:  0.03217738874126343\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  7.055893080575125 acc:  0.0451064019828953\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  7.0036762261591035 acc:  0.061742178951834405\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  6.926477784870052 acc:  0.07134403679967845\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  6.843389859720438 acc:  0.0821963691579394\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  6.760309151240757 acc:  0.08974387602438426\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  6.662621562220469 acc:  0.09550499073309068\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  6.603055657458906 acc:  0.1008864971082777\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  6.510920660836356 acc:  0.10586606524797357\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  6.406816582719819 acc:  0.11526695397807203\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  6.3336458807232 acc:  0.12069312015720252\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  18 loss :  6.229389463152204 acc:  0.126119286336333\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  19 loss :  6.131209433579645 acc:  0.13170176182926557\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  20 loss :  6.0547682177118896 acc:  0.13639104124332893\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  21 loss :  5.962261536542107 acc:  0.14161623830471384\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  22 loss :  5.882119250898602 acc:  0.14860549762186545\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  23 loss :  5.7963203301950665 acc:  0.15450059174240224\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  24 loss :  5.76117922678715 acc:  0.15921220105843736\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  25 loss :  5.64802638622893 acc:  0.16316459370743364\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  26 loss :  5.567772580795929 acc:  0.17151597704486077\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  27 loss :  5.503372581065202 acc:  0.17459750351695957\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  28 loss :  5.435402733939035 acc:  0.1808945358729875\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  29 loss :  5.394077361130915 acc:  0.18531585646339013\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  30 loss :  5.32390725111761 acc:  0.18638769175803319\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  31 loss :  5.286826927120946 acc:  0.18935756872027332\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  32 loss :  5.275912316907354 acc:  0.1931759819574392\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  33 loss :  5.193440501429453 acc:  0.1958332402920751\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  34 loss :  5.208370132606571 acc:  0.19960699372529755\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  35 loss :  5.152521866710246 acc:  0.20239823147176383\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  36 loss :  5.122280176948099 acc:  0.20393899470781324\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  37 loss :  5.013853946653735 acc:  0.2053011187280888\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  38 loss :  5.024261073905881 acc:  0.20793604716075295\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  39 loss :  5.0110394293520635 acc:  0.21159815108411675\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  40 loss :  4.943803045929981 acc:  0.21282629569256192\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  41 loss :  4.916725056512015 acc:  0.2151039456936784\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  42 loss :  4.854889140409582 acc:  0.2158408324587455\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  43 loss :  4.852887790744044 acc:  0.21876604961704219\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  44 loss :  4.820287440003467 acc:  0.21979322510774177\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  45 loss :  4.81149815310951 acc:  0.22204854520688655\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  46 loss :  4.759263403275433 acc:  0.2238572672665967\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  47 loss :  4.734658337440811 acc:  0.22801062903333855\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  48 loss :  4.708704151025339 acc:  0.23118147511332426\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  49 loss :  4.690406865432482 acc:  0.23263291874148673\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  50 loss :  5.845869008232565 acc:  0.2288591653082643\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  51 loss :  5.691476918068252 acc:  0.23196302168233482\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  52 loss :  5.668425756342271 acc:  0.23573677511555724\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  53 loss :  5.640211441937615 acc:  0.23810374472456067\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  54 loss :  5.622814250593426 acc:  0.24163186923609406\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  55 loss :  5.6156916538206465 acc:  0.24326195208003037\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  56 loss :  5.55133444120904 acc:  0.24580756090480763\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  57 loss :  5.51708703882554 acc:  0.24783958198423509\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  58 loss :  5.433009600438991 acc:  0.24980461335774737\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  59 loss :  5.427331243242536 acc:  0.2521939128687225\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  60 loss :  5.482010280384737 acc:  0.2521939128687225\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  61 loss :  5.376804468010654 acc:  0.25563271777236896\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  62 loss :  5.390406580532298 acc:  0.2580666770872876\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  63 loss :  5.370304688686082 acc:  0.2592055020878458\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  64 loss :  5.377976433569644 acc:  0.26032199718643234\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  65 loss :  5.341967053774025 acc:  0.2617287810106514\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  66 loss :  5.400860321621935 acc:  0.2634928432664181\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  67 loss :  5.314065151855726 acc:  0.26472098787486326\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  68 loss :  5.31542307989938 acc:  0.26679766875823413\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'CELU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 648, 'dropout': 0.03883519553988618, 'dropout_transformers': 0.3484781646627848, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7259681827630232, 'scheduler': 'StepLR', 'step_size': 25, 'lr': 1.595838551585142e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.02340891024800786}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  8.019123252111537 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  8.016653861708313 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  8.012079173371992 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  8.009751854962065 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  8.006767451308155 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  8.005190649105392 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Mish', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 696, 'dropout': 0.0607619171604327, 'dropout_transformers': 0.4384552899543174, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5909885644599762, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 0.020482977135993095, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 33, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 8.05404221290723e-06}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.779887709250817 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.473009648689857 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.359932536345262 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.339877378023588 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.3411651794727035 acc:  0.0010941651966147868\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.335087174635667 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  7.346633720397949 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  7.343389951265776 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  7.345045929688673 acc:  0.0012058147064734385\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Hardswish', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 240, 'dropout': 0.04506879474904886, 'dropout_transformers': 0.2922661979415089, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00026898013291267364, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 21, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.003824228180326681}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.579492787409095 acc:  0.014804725007257219\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.202250922858382 acc:  0.045709309336132015\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  6.987793546815158 acc:  0.05966549806846348\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  6.7567390649678325 acc:  0.07956144072527521\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  6.640022688071821 acc:  0.10057387848067346\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  6.470484682967543 acc:  0.10812138534711832\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  6.171944551627729 acc:  0.12151932653015653\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  7 loss :  6.081861456013258 acc:  0.13440367996784494\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  8 loss :  5.898425781527045 acc:  0.15061518879932118\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  9 loss :  5.731691688132686 acc:  0.16048500547082598\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  10 loss :  5.517134804965398 acc:  0.17642855547864145\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  11 loss :  5.357562382127986 acc:  0.1870575888171851\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  12 loss :  5.146588686458226 acc:  0.1940691780363084\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  13 loss :  5.011423410650072 acc:  0.20815934618047027\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  14 loss :  4.83425333513228 acc:  0.2134738628497421\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  15 loss :  4.6896637591569785 acc:  0.22852421677868834\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  16 loss :  4.512204118281104 acc:  0.2315164236429002\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  17 loss :  4.4617171434050835 acc:  0.24612017953241186\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  18 loss :  4.262920233124461 acc:  0.25773172855771165\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  19 loss :  4.314199209213257 acc:  0.2643190496393721\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  20 loss :  4.134732724568031 acc:  0.2701694839559654\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  21 loss :  4.069669851377689 acc:  0.2778956300381841\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  22 loss :  4.028214061726405 acc:  0.2828082084719648\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  23 loss :  3.9803818657411543 acc:  0.28897126141616236\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  24 loss :  3.9082627629434596 acc:  0.29680905700823973\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  25 loss :  3.782509052553656 acc:  0.30051582073554695\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  26 loss :  3.7608306301372676 acc:  0.3037089967175044\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  27 loss :  3.704533935259174 acc:  0.3138021124087265\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  28 loss :  3.645172767798994 acc:  0.322376794765871\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  29 loss :  3.6203008603783293 acc:  0.32561463055177187\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  30 loss :  3.5867561481518453 acc:  0.3273340330035951\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  31 loss :  3.562074197737198 acc:  0.3337427148694817\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  32 loss :  3.5450255804221724 acc:  0.33561842663510705\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  33 loss :  3.4487166897544648 acc:  0.341669830069446\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  34 loss :  3.406516578610383 acc:  0.34573387222830093\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  35 loss :  3.374600040180057 acc:  0.3485474398767389\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  36 loss :  3.358462919736042 acc:  0.35410758546769977\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  37 loss :  3.375681861152862 acc:  0.35680950360627917\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  38 loss :  3.3018724079238635 acc:  0.3614541232163991\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  39 loss :  3.3004411438989907 acc:  0.36134247370654043\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  40 loss :  3.2589098141846042 acc:  0.36679096978764264\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  41 loss :  3.2298194749395273 acc:  0.3682647433177768\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  42 loss :  3.253758483758852 acc:  0.37445012616394613\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  43 loss :  3.240161819830953 acc:  0.37201616684902755\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  44 loss :  3.1929168021878715 acc:  0.3756559408704196\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  45 loss :  3.16583257014525 acc:  0.37929571489181163\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  46 loss :  3.183903188012832 acc:  0.38532478842417883\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  47 loss :  3.166053056716919 acc:  0.3806801688140589\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  48 loss :  3.166506860509265 acc:  0.38291315901123196\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  49 loss :  3.1202182583302758 acc:  0.38237724136391044\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  50 loss :  4.17986033748648 acc:  0.38686555166022824\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  51 loss :  4.217904555730979 acc:  0.39095192372105486\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  52 loss :  4.22937569138724 acc:  0.39057231538753545\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  53 loss :  4.047013635741932 acc:  0.39336355313400173\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  54 loss :  4.125916142703435 acc:  0.3922470580354152\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  55 loss :  4.058805192649031 acc:  0.39573052274300513\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  56 loss :  4.113279353306946 acc:  0.3968916776455351\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  57 loss :  4.020868719623076 acc:  0.399883884509747\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  58 loss :  3.9859984174121026 acc:  0.39896835852890605\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  59 loss :  4.148859496889168 acc:  0.4000401938235491\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  60 loss :  4.067515616976349 acc:  0.39780720362637606\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  61 loss :  3.961815445116778 acc:  0.40499743206127325\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  62 loss :  4.025270560600238 acc:  0.39970524529397317\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  63 loss :  4.001524287229143 acc:  0.40213920460889174\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  64 loss :  3.9109504023077766 acc:  0.4028091016680437\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  65 loss :  4.075460892149856 acc:  0.40330035951142174\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  66 loss :  3.9738136763013276 acc:  0.40537704039479266\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  67 loss :  3.9805732492628043 acc:  0.40662751490520954\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  68 loss :  3.9535995142419913 acc:  0.40774401000379606\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  69 loss :  3.9194206725285707 acc:  0.40573431882634037\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  70 loss :  3.992008611476621 acc:  0.4056896590223969\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Softsign', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 504, 'dropout': 0.20658837703425684, 'dropout_transformers': 0.36710314041212155, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5258641286215395, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.0022431503702151387, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 31, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.007187906382530217}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.503902512330275 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.386573083584125 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.340217311565692 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.319203989322369 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.306978207368117 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.299592194190392 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  6 loss :  7.298255784694965 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 576, 'dropout': 0.13498131975978112, 'dropout_transformers': 0.3150465248871853, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6492361240491794, 'scheduler': 'StepLR', 'step_size': 24, 'lr': 0.0016497552110348234, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.013427152252701531}\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  0 loss :  7.612653246549803 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  1 loss :  7.362868941832926 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  2 loss :  7.313614328330923 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  3 loss :  7.336592112746194 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  4 loss :  7.288929654059009 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=229885)\u001b[0m epoch:  5 loss :  7.290249267471171 acc:  0.003438804903646473\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 07:42:07,539\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 07:42:21,427\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 07:42:21,429\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_14       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_14\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_14`\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=240819)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.08364036537484446, 'dropout_transformers': 0.27240122602325756, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.49112342767287376, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 2.850370433533623e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 15, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0008624478954328188}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.870938159127272 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  7.6025981502678555 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  7.456777507112227 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  7.366343676588918 acc:  0.006832950003349486\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  7.305408048265763 acc:  0.007927115199964273\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  7.260437954473131 acc:  0.009534868141928858\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  7.207876835160583 acc:  0.014514436281624724\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  7.18591110942928 acc:  0.021682334814550164\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  7.138119046014684 acc:  0.021682334814550164\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  7.10400568983937 acc:  0.02599200589509412\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  7.077600348086757 acc:  0.029475470602684056\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  7.057561714230603 acc:  0.032690976486613225\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  7.052158053594691 acc:  0.03222204854520689\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  7.019145492378992 acc:  0.03858607060715003\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  6.994568606369368 acc:  0.04347631913895898\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  6.9990136204785065 acc:  0.046446196101199114\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  6.969744005276047 acc:  0.04624522698345354\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  6.955353496638873 acc:  0.051626733358640556\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  6.949613967924628 acc:  0.056695621106223344\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  6.926304726200249 acc:  0.057633476989036016\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  6.911565649600429 acc:  0.06004510640198289\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  6.89952325456925 acc:  0.06113927159859768\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  6.904755261108165 acc:  0.06292566375633611\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  6.8740667750817215 acc:  0.06230042650112766\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  6.884904424652799 acc:  0.06364022061943148\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  6.859444592745249 acc:  0.06339459169774245\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  6.878848155946222 acc:  0.06556059218900029\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  6.839965747512934 acc:  0.06763727307237122\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  6.854830971200958 acc:  0.06844114954335351\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  6.833542201355214 acc:  0.07067413974052654\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  6.840209029103053 acc:  0.07091976866221557\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  6.835824260274872 acc:  0.07333139807516245\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  6.8246248296198955 acc:  0.07297411964361476\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  6.820572649249594 acc:  0.07505080052698569\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  6.813589565626538 acc:  0.07685952258669584\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  6.806279335313171 acc:  0.07598865640979836\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  6.804600762956925 acc:  0.07764106915570641\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  6.76743290078549 acc:  0.07938280150950137\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  6.769844990650206 acc:  0.07710515150838487\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  6.785856701945531 acc:  0.07746242993993256\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  6.774384331157189 acc:  0.07944979121541657\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  6.759382786641594 acc:  0.07942746131344483\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  42 loss :  6.758038360653943 acc:  0.08038764709822924\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  43 loss :  6.750476738878789 acc:  0.08047696670611616\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  44 loss :  6.75571249459536 acc:  0.08045463680414443\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  45 loss :  6.73912742119709 acc:  0.08078958533372038\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  46 loss :  6.743456713115896 acc:  0.0813924926869571\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  47 loss :  6.742825526317567 acc:  0.08248665788357189\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  48 loss :  6.735607573094259 acc:  0.08302257553089341\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  49 loss :  6.733470800268741 acc:  0.08239733827568498\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  50 loss :  7.769441575494431 acc:  0.08248665788357189\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  51 loss :  7.752205681254845 acc:  0.08300024562892169\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  52 loss :  7.766535573333274 acc:  0.08295558582497822\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  53 loss :  7.726868953413636 acc:  0.08382645200187572\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  54 loss :  7.737480982569338 acc:  0.08436236964919724\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  55 loss :  7.740650653839111 acc:  0.08521090592412299\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  56 loss :  7.739336658070106 acc:  0.08592546278721837\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  57 loss :  7.714482416633431 acc:  0.08748855592523949\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  58 loss :  7.744124634575297 acc:  0.08755554563115468\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  59 loss :  7.721766282583921 acc:  0.08670700935622892\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  60 loss :  7.7288231631271715 acc:  0.08715360739566354\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  61 loss :  7.68873089506426 acc:  0.08730991670946564\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  62 loss :  7.676337216646616 acc:  0.08813612308241967\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  63 loss :  7.704709952114192 acc:  0.08802447357256102\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  64 loss :  7.686098371753256 acc:  0.0881584529843914\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'ELU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 168, 'dropout': 0.02504365596054669, 'dropout_transformers': 0.26181736187976634, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 7.215081116117335e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 38, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.002595751650467914}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.9616015707696235 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  7.677520185083776 acc:  0.005046557845611058\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  7.495456822268613 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  7.413525104522705 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  7.343462887343827 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  7.281830824338472 acc:  0.006096063238282384\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  7.217269377274946 acc:  0.007234888238840631\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  7.216156446016752 acc:  0.011388250005582476\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  7.177195242234877 acc:  0.018489158832592726\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  7.127986181032408 acc:  0.027555099033115246\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  7.086785940023569 acc:  0.029698769622401356\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  7.021836187456038 acc:  0.03845209119531965\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  6.982787145601286 acc:  0.044324855413884735\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  6.942876268933703 acc:  0.052207310809905545\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  6.883914417320198 acc:  0.05895094120536811\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  6.8722146274326565 acc:  0.06913337650447715\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  6.787867952893664 acc:  0.07201393385883036\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  6.771666626830201 acc:  0.08159346180470267\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  6.705512290234332 acc:  0.08210704955005248\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  6.6937945605991604 acc:  0.08634973092468123\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  6.642948937582803 acc:  0.09425451622267378\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  6.662771595107926 acc:  0.09347296965366322\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  6.598099475140338 acc:  0.10242726034432709\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  6.516996427015825 acc:  0.10459326083558493\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  6.476290462733982 acc:  0.10845633387669427\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  6.450929188228153 acc:  0.11140388093696268\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  6.398294795643199 acc:  0.10859031328852467\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  6.394436949616545 acc:  0.11218542750597325\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  6.318063005700812 acc:  0.11417278878145724\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  6.292610251820171 acc:  0.11343590201639014\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  6.207032273699354 acc:  0.1180358618225666\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  6.14761647978029 acc:  0.12136301721635442\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  6.167126785625111 acc:  0.12136301721635442\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  6.115020615237576 acc:  0.12386396623718822\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  6.024943421770643 acc:  0.1308532255543398\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  6.000275188392693 acc:  0.13308621575151286\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  5.989407849478555 acc:  0.13447066967376015\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  5.933958513753398 acc:  0.13911528928388003\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  5.822721741416237 acc:  0.13757452604783066\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  5.815849004091916 acc:  0.1433579706585088\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  5.813546344116851 acc:  0.14250943438358304\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  5.775201140583812 acc:  0.14742201281736372\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  42 loss :  5.749940612099388 acc:  0.15164236429002076\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  43 loss :  5.728026440093568 acc:  0.14853850791595025\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  44 loss :  5.657255442826064 acc:  0.15657727262577317\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  45 loss :  5.689730374129502 acc:  0.15959180939195677\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  46 loss :  5.561374427555324 acc:  0.16300828439363152\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  47 loss :  5.566448251684229 acc:  0.16597816135587165\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  48 loss :  5.516267022886477 acc:  0.16597816135587165\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  49 loss :  5.480733621370542 acc:  0.16669271821896703\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  50 loss :  6.582702446650792 acc:  0.17189558537838018\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  51 loss :  6.418197084973742 acc:  0.17026550253444386\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  52 loss :  6.461329483485722 acc:  0.17479847263470513\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  53 loss :  6.404786299992274 acc:  0.17703146283187818\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  54 loss :  6.359431370154961 acc:  0.18100618538284616\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  55 loss :  6.2347148781889805 acc:  0.1785945559698993\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  56 loss :  6.324944786258511 acc:  0.18547216577719225\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  57 loss :  6.2706464387320136 acc:  0.18788379519013912\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  58 loss :  6.2616732270567566 acc:  0.1934662706830717\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  59 loss :  6.184577401701387 acc:  0.19295268293772191\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  60 loss :  6.117320764314878 acc:  0.19496237411517764\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  61 loss :  6.0222471877411525 acc:  0.19793225107741777\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  62 loss :  6.116059800128003 acc:  0.19983029274501485\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  63 loss :  5.91297693852778 acc:  0.20492151039456938\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  64 loss :  5.950724346654399 acc:  0.20572538686555167\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  65 loss :  6.015726012783451 acc:  0.20829332559230065\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  66 loss :  5.89037489724326 acc:  0.2097894290244066\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  67 loss :  5.972636312871546 acc:  0.21394279079114842\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  68 loss :  5.864218885248357 acc:  0.2158185025567738\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  69 loss :  5.839619349766444 acc:  0.22070875108858273\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  70 loss :  5.868404745221971 acc:  0.22142330795167808\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  71 loss :  5.894015532273513 acc:  0.22124466873590426\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  72 loss :  5.735963161175068 acc:  0.22419221579617266\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  73 loss :  5.839197263851032 acc:  0.22671549471897817\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  74 loss :  5.781477339617856 acc:  0.22941741285755757\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  75 loss :  5.680272452481143 acc:  0.2336600942321863\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  76 loss :  5.6855821142663485 acc:  0.23575910501752897\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  77 loss :  5.790925632823598 acc:  0.23640667217470915\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  78 loss :  5.74313179763047 acc:  0.2358484246254159\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  79 loss :  5.625610821730607 acc:  0.2404930442355358\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  80 loss :  5.583791704444619 acc:  0.24236875600116115\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  81 loss :  5.683037457766233 acc:  0.24375320992340843\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  82 loss :  5.511012575843117 acc:  0.2429270035504544\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  83 loss :  5.468061135365413 acc:  0.2474153138467722\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  84 loss :  5.552356693294499 acc:  0.2450483442377688\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  85 loss :  5.5962961953836725 acc:  0.2498269432597191\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  86 loss :  5.545264400802292 acc:  0.24826385012169797\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  87 loss :  5.477132515473799 acc:  0.2544938927718107\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Tanhshrink', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 672, 'dropout': 0.30102806432040374, 'dropout_transformers': 0.24643424474434394, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.19161314623344733, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 1.8263993018861268e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'relu', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.3344057849583721e-05}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  8.083354228684883 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  8.057233317559506 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  8.023734709795784 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  7.98778419735051 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  7.954229318795084 acc:  0.0012058147064734385\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  7.931315762656076 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  7.905801572719542 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  7.875699680392482 acc:  0.0028135676484380232\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  7.843251576944559 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  7.823455445906696 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  7.792730090998802 acc:  0.0037514235312506978\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  7.773580338774609 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  7.750331289627972 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  7.716716449801662 acc:  0.004153361766741844\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  7.70854344488192 acc:  0.004175691668713575\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  7.708277890662186 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  7.686952158182609 acc:  0.004398990688430878\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  7.694391026216395 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  7.687230899554341 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  7.679854096484785 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  7.673195602513161 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  7.6763712698672 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  7.667617200803356 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  7.662946885373412 acc:  0.004689279414063372\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  7.663297524973124 acc:  0.004733939218006833\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  7.654449871608189 acc:  0.004800928923922024\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  7.651477757622214 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  7.6462030130274155 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  7.647515725688774 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  7.658543282196302 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  7.6454614711408855 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  7.644273537547648 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  7.642788943122415 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  7.6391763246359945 acc:  0.004934908335752406\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  7.634351249502487 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  7.647199169928286 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  7.652522367589614 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  7.648782153089507 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  7.637447641677215 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  7.64461155498729 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  7.64447442223044 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  7.652067789510519 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  42 loss :  7.644730367580382 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.26042469883496683, 'dropout_transformers': 0.4225050899172923, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3128582433632491, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 0.0004572543787476834, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 27, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00015952403552773123}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=240819)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.076406872657038 acc:  0.14221914565795057\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  5.199409915554908 acc:  0.2717102471920148\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  4.06711625899038 acc:  0.34149119085367213\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  3.549341933957992 acc:  0.375454971752674\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  3.2974767884900493 acc:  0.3937654913694929\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  3.13532693770624 acc:  0.3994596163722841\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  3.067410429062382 acc:  0.4081236183373155\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  2.951849543663763 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  2.888833245923442 acc:  0.4168322801062903\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  2.8384008038428523 acc:  0.42022642520599335\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  2.7821824889029227 acc:  0.4222361163834491\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  2.7510782118766537 acc:  0.42100797177500393\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  2.6737521848370953 acc:  0.4236429002076681\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  2.6455338016633063 acc:  0.42605452962061496\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  2.6208030500719626 acc:  0.4273719938369471\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  2.5317510958640805 acc:  0.43701851148873455\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  2.494758015294229 acc:  0.43679521246901726\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  2.48053070499051 acc:  0.43759908893999955\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  2.464678092156687 acc:  0.44010003796083336\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  2.4736729098904515 acc:  0.43958645021548354\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  2.45986654989181 acc:  0.4394748007056249\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  2.433358525460766 acc:  0.438804903646473\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  2.417841362184094 acc:  0.4402340173726637\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  2.397788897637398 acc:  0.43936315119576624\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  2.3869287083225865 acc:  0.4402563472746355\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  2.3814923032637565 acc:  0.43916218207802066\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  2.3677310659039406 acc:  0.439631110019427\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  2.367541620039171 acc:  0.43934082129379454\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  2.3540533650305964 acc:  0.4389612129602751\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  2.336488042339202 acc:  0.43838063550901013\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 96, 'dropout': 0.3886695144311953, 'dropout_transformers': 0.4755895379373196, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3126510451544423, 'scheduler': 'StepLR', 'step_size': 11, 'lr': 0.003115395695820038, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 9, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.5916097802499936e-06}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.436282697125016 acc:  0.0063416921599714175\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  7.212115127349568 acc:  0.03878703972489561\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  6.576958393382135 acc:  0.14061139271598597\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  5.600444762506218 acc:  0.22399124667842707\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  4.999883455650829 acc:  0.2534220574771677\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  4.631175257335199 acc:  0.27081705111314563\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  4.353915896371146 acc:  0.28747515798405643\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  4.251229085654856 acc:  0.29167317955474176\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  4.141754584891774 acc:  0.2940624790657169\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  3.9904350008919973 acc:  0.3032847285800415\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  3.931753942899615 acc:  0.30373132661947616\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  3.8573486270191513 acc:  0.32985731192640066\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  3.8112847894151636 acc:  0.3314204050644218\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  3.7403656589650662 acc:  0.3342563026148315\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  3.7465137922875233 acc:  0.3368465712435522\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  3.6957033148435787 acc:  0.3388785923229797\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  3.668903243875949 acc:  0.3432775830114106\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  3.6443839674798126 acc:  0.3420940982069089\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  3.6698633577222024 acc:  0.3391912109505839\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  3.591868699154007 acc:  0.34341156242324095\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  3.59623679490847 acc:  0.34515329477703593\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  3.602328755031122 acc:  0.34245137663845654\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  3.5521914491029545 acc:  0.3493289864457495\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  3.6191870854279706 acc:  0.35113770850545967\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  3.590094138528699 acc:  0.35176294576066813\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  3.5516304992069707 acc:  0.35290177076122636\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  3.5363712377637344 acc:  0.3528794408592546\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  3.537924534806581 acc:  0.3530804099770002\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  3.51825519365685 acc:  0.3510930487015162\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  3.5177116928813614 acc:  0.3534376884085479\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  3.529599408122981 acc:  0.35531340017417323\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  3.5108211820370685 acc:  0.3553803898800884\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  3.51006129523304 acc:  0.35562601880177747\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  3.530871785689737 acc:  0.3555366991938905\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  3.488640994669121 acc:  0.3567201839983922\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  3.5246629091066737 acc:  0.3571444521358551\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  3.47338480370067 acc:  0.35721144184177034\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  3.4965252742589077 acc:  0.3560056271352969\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  3.514104303912582 acc:  0.3575463903713463\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  3.4654578382723797 acc:  0.35716678203782687\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  3.4830474697540854 acc:  0.3565862045865619\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  3.5282277726681435 acc:  0.356988142822053\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  42 loss :  3.499465552445884 acc:  0.3564745550767032\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  43 loss :  3.4910053159588967 acc:  0.35678717370430746\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.26176244882353994, 'dropout_transformers': 0.35960546228510337, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.09391636365674572, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 0.0004980287702724313, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 29, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.178349314405947e-05}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  6.642477376644428 acc:  0.22144563785364982\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  4.307800107735854 acc:  0.33229127124131924\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  3.404343102528499 acc:  0.3904829957796485\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  3.066374941972586 acc:  0.40343433892325214\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  2.882018562463614 acc:  0.41616238304713843\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  2.759709693835332 acc:  0.4228613536386575\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  2.6717337773396417 acc:  0.4246030859924525\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  2.600776622845576 acc:  0.4275283031507492\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  2.5403851674153253 acc:  0.4247817252082263\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  2.4937294226426343 acc:  0.43074380903467835\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  2.4474410625604484 acc:  0.42786325168032513\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  2.405096910550044 acc:  0.4298729428577809\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  2.379670923489791 acc:  0.43331174776142733\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  2.3493228527215813 acc:  0.42554094187526514\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  2.3176697666828447 acc:  0.4281535404059576\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  2.21936611028818 acc:  0.4369068619788759\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  2.1865505704512964 acc:  0.43891655315633166\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  2.1729658044301545 acc:  0.439631110019427\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  2.1631432799192574 acc:  0.43974275952928565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  2.159134797866528 acc:  0.4400553781568899\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  2.1481594865138716 acc:  0.44047964629435277\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  2.1424754014381997 acc:  0.43893888305830336\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  2.1395754016362702 acc:  0.4400330482549182\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  2.1308839715444123 acc:  0.4396980997253422\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  2.1281670707922715 acc:  0.43987673894111606\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  2.1216525930624743 acc:  0.4396087801174553\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.3255327624021237, 'dropout_transformers': 0.4261089778147534, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.044275480365008085, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 0.0004603167346985069, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 7.900880626782388e-05}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.125234882648175 acc:  0.16850144027867717\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  5.499251292302058 acc:  0.2952682937721903\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  4.194097502414997 acc:  0.35709979233191164\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  3.555223488807678 acc:  0.3926043364669629\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  3.251786252168509 acc:  0.40850322667083494\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  3.070808487672072 acc:  0.419757497264587\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  2.956885440532978 acc:  0.42612151932653014\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  2.8637396353941695 acc:  0.4283321796217315\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  2.7955385428208572 acc:  0.43074380903467835\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  2.742249452150785 acc:  0.430855458544537\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  2.6895980449823234 acc:  0.43324475805551216\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  2.6515621148622954 acc:  0.43119040707411294\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  2.614175451718844 acc:  0.43273117031016234\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  2.5828039609468902 acc:  0.4320612732510104\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  2.5531350685999943 acc:  0.4346962016836746\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  2.4764549383750327 acc:  0.4382466560971797\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  2.460761891878568 acc:  0.44030100707857894\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  2.459047420208271 acc:  0.44032333698055065\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  2.450570986821101 acc:  0.4400107183529464\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  2.448845259959881 acc:  0.43974275952928565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  2.450185276911809 acc:  0.4400553781568899\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  2.441068034905654 acc:  0.4405019761963245\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  2.4412200395877544 acc:  0.4404126565884376\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  2.4367277255425086 acc:  0.4400107183529464\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  2.430050545472365 acc:  0.4400107183529464\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  2.425056635416471 acc:  0.44012236786280506\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  2.426526247538053 acc:  0.44054663600026794\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  2.4226103947712825 acc:  0.44068061541209835\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  2.418950686087975 acc:  0.44110488354956123\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  2.419740390777588 acc:  0.44090391443181565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  2.416048238827632 acc:  0.4409932340397026\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  2.416730026098398 acc:  0.44090391443181565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  2.4128282638696525 acc:  0.4409932340397026\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  2.413807773590088 acc:  0.44112721345153294\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  2.4129675186597384 acc:  0.4411495433535047\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  2.413176032213064 acc:  0.4411718732554764\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  2.4161118525725143 acc:  0.44126119286336335\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  2.415702348489028 acc:  0.4411495433535047\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  2.4136825928321253 acc:  0.44092624433378735\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  2.4113872252977813 acc:  0.44108255364758947\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  2.415359775836651 acc:  0.44110488354956123\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  2.4114996653336744 acc:  0.44112721345153294\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.3620644576278445, 'dropout_transformers': 0.36335352686063094, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.005605225573789778, 'scheduler': 'StepLR', 'step_size': 12, 'lr': 0.00532913197852938, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 22, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.513141383436628e-05}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.473565908578726 acc:  0.00649800147377353\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  7.1138074288001425 acc:  0.007994104905879464\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  6.773706806623019 acc:  0.02652792354241565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  6.473188216869648 acc:  0.03753656521447871\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  6.1917194623213545 acc:  0.053502445124265906\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  5.96159636424138 acc:  0.06752562356251256\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  5.764617021267231 acc:  0.0777080588616216\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  5.586753482085008 acc:  0.08822544269030659\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  5.428747078088613 acc:  0.10073018779447558\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  5.271665518100445 acc:  0.11272134515329478\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  5.138976042087261 acc:  0.12629792555210684\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  5.0136873758756195 acc:  0.13540852555657282\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  4.884782391328078 acc:  0.13795413438135007\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  4.857928199034471 acc:  0.14087935153964673\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  4.857141381043654 acc:  0.14360359958019783\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  4.834500712614793 acc:  0.14612687850300338\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  4.837990764471201 acc:  0.14780162115088316\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  4.832561518595769 acc:  0.14925306477904562\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  4.822179009364201 acc:  0.14994529174016927\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  4.815295336796687 acc:  0.149967621642141\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  4.809739222893348 acc:  0.15130741576044482\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  4.806949366056002 acc:  0.1517316838979077\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  4.800373407510611 acc:  0.15287050889846593\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  4.7973411450019245 acc:  0.1535850657615613\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  4.798976432360136 acc:  0.15356273585958957\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  4.801255248143122 acc:  0.1535180760556461\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  4.795159581991342 acc:  0.1537190451733917\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  4.800302479817317 acc:  0.15360739566353304\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  4.798648221676166 acc:  0.1536520554674765\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  4.797609325555655 acc:  0.15369671527141995\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  4.796883370326116 acc:  0.1537190451733917\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  4.7996687779059775 acc:  0.15374137507536342\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  4.7903618445763225 acc:  0.15367438536944822\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  4.790240529867319 acc:  0.1535850657615613\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  4.787132442914523 acc:  0.15360739566353304\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  4.795494637122521 acc:  0.1536520554674765\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  4.789212072812594 acc:  0.1536520554674765\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 744, 'dropout': 0.35244470312079823, 'dropout_transformers': 0.4137718898777406, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.09741381846649833, 'scheduler': 'StepLR', 'step_size': 8, 'lr': 0.0011796440650127984, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 18, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.8001586956766223e-05}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  6.731825414070716 acc:  0.23506687805640533\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  4.584040794005761 acc:  0.33691356094946745\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  3.7995109283007107 acc:  0.37849183842082934\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  3.503187636228708 acc:  0.39403345019315367\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  3.329693361429068 acc:  0.3992363173525668\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  3.212804684272179 acc:  0.4062702364736619\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  3.1241427403229935 acc:  0.4086372060826653\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  3.0536528037144586 acc:  0.4107808766719514\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  2.8900827939693743 acc:  0.4249603644240002\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  2.8243002799841075 acc:  0.4273719938369471\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  2.8014980921378503 acc:  0.4287117879552509\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  2.7750952812341545 acc:  0.4291583859946855\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  2.7578238964080812 acc:  0.4304758502110176\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  2.738800514661349 acc:  0.4312573967800281\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  2.7157548354222225 acc:  0.43148069579974546\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  2.7050813784966103 acc:  0.43290980952593616\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  2.682970831944392 acc:  0.432842819820021\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  2.6793151525350716 acc:  0.4327981600160775\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  2.675640716919532 acc:  0.43268651050621887\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  2.6727850877321684 acc:  0.43288747962396446\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  2.6697280700390156 acc:  0.4331554384476252\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  2.6666898507338304 acc:  0.4329321394279079\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  2.6652987003326416 acc:  0.43308844874171004\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  2.6688252210617067 acc:  0.43349038697720116\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  2.6622274453823382 acc:  0.43346805707522945\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  2.665920396951529 acc:  0.4335797065850881\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  2.663863724928636 acc:  0.43366902619297504\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  2.659606698843149 acc:  0.4335127168791729\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  2.663222492658175 acc:  0.4335797065850881\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  2.663309731850257 acc:  0.43362436638903157\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  2.660713507578923 acc:  0.4336020364870598\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  2.6623629643366886 acc:  0.4335127168791729\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 720, 'dropout': 0.3161850809518158, 'dropout_transformers': 0.4977608435941159, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.044307897769411346, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 0.000823517444793287, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.395697650129215e-06}\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  0 loss :  7.034973698395949 acc:  0.19496237411517764\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  1 loss :  5.174713376852182 acc:  0.3212602996672845\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  2 loss :  4.030081306971036 acc:  0.3688899805729853\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  3 loss :  3.5583061163242045 acc:  0.39159949087823503\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  4 loss :  3.329571480017442 acc:  0.41026728892660164\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  5 loss :  3.173399908726032 acc:  0.41553714579192996\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  6 loss :  3.051147781885587 acc:  0.41897595069557647\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  7 loss :  2.9712436290887685 acc:  0.41844003304825494\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  8 loss :  2.9116252147234403 acc:  0.4230846526583748\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  9 loss :  2.8547522434821495 acc:  0.4229953330504879\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  10 loss :  2.8102477898964513 acc:  0.4242234776589331\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  11 loss :  2.7712042129956758 acc:  0.42634481834624743\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  12 loss :  2.738183667109563 acc:  0.42531764285554785\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  13 loss :  2.7064092617768507 acc:  0.4238661992273854\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  14 loss :  2.6900225455944353 acc:  0.42317397226626174\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  15 loss :  2.6657873502144445 acc:  0.4289350869749682\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  16 loss :  2.647303480368394 acc:  0.4258089006989259\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  17 loss :  2.6303537313754743 acc:  0.42819820020990107\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  18 loss :  2.608024736551138 acc:  0.4297612933479222\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  19 loss :  2.5246185045975906 acc:  0.43603599580197844\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  20 loss :  2.496126649929927 acc:  0.4377107384498582\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  21 loss :  2.4884966611862183 acc:  0.4378670477636603\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  22 loss :  2.4820722084779008 acc:  0.4380010271754907\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  23 loss :  2.4742755027917713 acc:  0.43833597570506666\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  24 loss :  2.4702898355630727 acc:  0.4384476252149253\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  25 loss :  2.4630445938843946 acc:  0.4388495634504165\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  26 loss :  2.4600335964789757 acc:  0.4392291717839359\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  27 loss :  2.4570164350362926 acc:  0.43891655315633166\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  28 loss :  2.4529523831147415 acc:  0.43862626443069913\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  29 loss :  2.4487942365499644 acc:  0.4394524708036532\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  30 loss :  2.4423351269501907 acc:  0.438804903646473\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  31 loss :  2.4432027651713444 acc:  0.43871558403858607\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  32 loss :  2.441640833707956 acc:  0.43913985217604895\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  33 loss :  2.4358594490931584 acc:  0.439385481097738\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  34 loss :  2.4363471012849076 acc:  0.43980974923520083\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  35 loss :  2.431652538592999 acc:  0.43916218207802066\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  36 loss :  2.432398555828975 acc:  0.4398320791371726\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  37 loss :  2.4289839836267326 acc:  0.43951946050956836\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  38 loss :  2.422591757774353 acc:  0.4396087801174553\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  39 loss :  2.4226562573359565 acc:  0.43965343992139877\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  40 loss :  2.421311527949113 acc:  0.43989906884308777\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  41 loss :  2.4182157498139603 acc:  0.43980974923520083\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  42 loss :  2.421404587305509 acc:  0.43989906884308777\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  43 loss :  2.420576632939852 acc:  0.43974275952928565\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  44 loss :  2.4150060176849366 acc:  0.43987673894111606\n",
            "\u001b[36m(eval_config pid=240819)\u001b[0m epoch:  45 loss :  2.4193115381094126 acc:  0.4398320791371726\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 08:39:05,507\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 08:39:19,406\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 08:39:19,408\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_15       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_15\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_15`\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=255211)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 744, 'dropout': 0.37517339098161123, 'dropout_transformers': 0.3787838205825871, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.12352744640110168, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.0002488219778548973, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 13, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00035970202196859084}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=255211)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.364086484909057 acc:  0.039702565705736555\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  6.592517592356756 acc:  0.1906750329366054\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  5.503632329060481 acc:  0.26849474130808565\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  4.617004062579229 acc:  0.31757586584194897\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  4.0278824751193705 acc:  0.353013420271085\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  3.6452543863883387 acc:  0.37887144675434875\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  3.394614835885855 acc:  0.3995935957841145\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  3.2220194321412308 acc:  0.4099993301029409\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  3.0970316079946665 acc:  0.41803809481276377\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  3.003039921247042 acc:  0.42120894089274946\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  2.9291308403015135 acc:  0.42746131344483396\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  2.86278539620913 acc:  0.427126364915258\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  2.814720403231107 acc:  0.42960498403412006\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  2.766693960703336 acc:  0.43230690217269946\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  2.727980457819425 acc:  0.4321952526628408\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  2.695144950426542 acc:  0.4344729026639573\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  2.6621405087984527 acc:  0.4352991090369113\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  2.6131706384512094 acc:  0.4375097693321126\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  2.603094192651602 acc:  0.4379340374695755\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  2.598882897083576 acc:  0.43811267668534937\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  2.588654013780447 acc:  0.4379340374695755\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  2.586219360278203 acc:  0.4381350065873211\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  2.580234956741333 acc:  0.43782238795971684\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  2.579531088242164 acc:  0.4379117075676038\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  2.5716856424625103 acc:  0.43838063550901013\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  2.5689253036792463 acc:  0.4378670477636603\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  2.5625997965152445 acc:  0.43934082129379454\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  2.554937388346745 acc:  0.4380903467833776\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  2.556182789802551 acc:  0.4388942232543599\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  2.5478170303198007 acc:  0.4386709242346426\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  2.5495133840120756 acc:  0.43797869727351896\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  2.542304539680481 acc:  0.43820199629323625\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softmin', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.4303446189538846, 'dropout_transformers': 0.39618334798544874, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.1929208090728584, 'scheduler': 'StepLR', 'step_size': 10, 'lr': 0.00016074456435110759, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 29, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.303567355813741e-06}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.441639041900634 acc:  0.008128084317709845\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.000974864226121 acc:  0.12431056427662282\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  6.367049587689913 acc:  0.19851282852868277\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  5.6174758544335 acc:  0.249670633945917\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  4.983229061273428 acc:  0.28843534376884084\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  4.484345089472257 acc:  0.3184244021168747\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  4.112707600226769 acc:  0.34399213987450594\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  3.828932096407964 acc:  0.3632405153741375\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  3.614911196782039 acc:  0.37844717861688587\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  3.4563663537685687 acc:  0.3911305629368287\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  3.3398073728267965 acc:  0.3937654913694929\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  3.3105190588877753 acc:  0.3965567291159592\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  3.287736415863037 acc:  0.39818681195989547\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  3.2677705012834988 acc:  0.39903534823482123\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  3.2474657994050244 acc:  0.4012236786280508\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  3.2223600240854116 acc:  0.4031887100015631\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  3.2037129182081956 acc:  0.4054663600026796\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  3.1861876506071822 acc:  0.4070294531407007\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  3.17025773525238 acc:  0.4088158452984391\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  3.1478517825786883 acc:  0.40964205167139317\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  3.137030027462886 acc:  0.41031194873054505\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  3.1253644998256975 acc:  0.4106022374561776\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  3.1256683331269484 acc:  0.4105352477502624\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  3.121291580566993 acc:  0.4106245673581493\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  3.1200186307613667 acc:  0.4110041756916687\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  3.1142440960957454 acc:  0.41147310363307504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  3.11111175096952 acc:  0.411808052162651\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  3.1046254781576303 acc:  0.4122546502020856\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  3.106553525191087 acc:  0.41241095951588774\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  3.103359413146973 acc:  0.41265658843757674\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  3.0988961348166835 acc:  0.4125449389277181\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  3.097200628427359 acc:  0.4126119286336333\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  32 loss :  3.0984989166259767 acc:  0.412723578143492\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  33 loss :  3.0985287391222442 acc:  0.412723578143492\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  34 loss :  3.0971006888609667 acc:  0.4126119286336333\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  35 loss :  3.1010829265301045 acc:  0.41265658843757674\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  36 loss :  3.0928860077491174 acc:  0.4127682379474354\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  37 loss :  3.096259726010836 acc:  0.4128352276533506\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  38 loss :  3.0961100339889525 acc:  0.41299153696715274\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  39 loss :  3.0957784194212694 acc:  0.4129245472612375\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  40 loss :  3.0926290347025946 acc:  0.4129245472612375\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  41 loss :  3.0884380689034097 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  42 loss :  3.100589084625244 acc:  0.4129245472612375\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  43 loss :  3.0936452040305507 acc:  0.41301386686912445\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  44 loss :  3.0908809386766873 acc:  0.41301386686912445\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  45 loss :  3.095403520877545 acc:  0.41294687716320927\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  46 loss :  3.0938848202045146 acc:  0.4129245472612375\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  47 loss :  3.0937667791660015 acc:  0.41303619677109615\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  48 loss :  3.0951032345111553 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  49 loss :  3.0895692018362193 acc:  0.41301386686912445\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  50 loss :  4.382076131380521 acc:  0.4130585266730679\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  51 loss :  4.374174145551828 acc:  0.41287988745729404\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  52 loss :  4.380227083426256 acc:  0.4129022173592658\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  53 loss :  4.3752876740235545 acc:  0.412969207065181\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  54 loss :  4.368814373016358 acc:  0.41303619677109615\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  55 loss :  4.367030398662274 acc:  0.41299153696715274\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.4636847034200783, 'dropout_transformers': 0.3394752457859019, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.06949860075030925, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.0005134136056054586, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 22, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.7219412122018558e-05}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.35659881738516 acc:  0.06801688140589063\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  5.99318311397846 acc:  0.23870665207779737\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  4.563186429097102 acc:  0.31427104035013287\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  3.857261081842276 acc:  0.3631735256682223\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  3.4862702388029834 acc:  0.3904606658776768\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  3.252641567817101 acc:  0.4072974119643615\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  3.099556282850412 acc:  0.4191099301074068\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  2.9899440306883593 acc:  0.4232632918741487\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  2.9050068360108594 acc:  0.4261661791304736\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  2.835556178826552 acc:  0.42998459236763953\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  2.776030711027292 acc:  0.4293146953084876\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  2.728287328206576 acc:  0.43235156197664293\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  2.689123439788818 acc:  0.43266418060424716\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  2.6451038525654718 acc:  0.4379117075676038\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  2.6091116244976336 acc:  0.4357010472724025\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  2.578657399691068 acc:  0.4377107384498582\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  2.4919525146484376 acc:  0.4438961212960275\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  2.4685374553386983 acc:  0.4450572761985575\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  2.4600477805504433 acc:  0.4452805752182748\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  2.4516368884306687 acc:  0.4446330080610946\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  2.4531843423843385 acc:  0.4454592144340486\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  2.4440622916588417 acc:  0.44539222472813345\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  2.43885715007782 acc:  0.44619610119911574\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  2.436246391443106 acc:  0.4455262041399638\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  2.4329759469399086 acc:  0.4457048433557377\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  2.430708283644456 acc:  0.4448339771788402\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  2.4204380897375253 acc:  0.44621843110108744\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  2.4173593191000133 acc:  0.4454815443360204\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  2.4137624098704413 acc:  0.4454368845320769\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  2.4138325122686535 acc:  0.44559319384587903\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  2.406637664941641 acc:  0.4459504722774267\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  2.4050195565590493 acc:  0.44619610119911574\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.4545311325786798, 'dropout_transformers': 0.3427038180519678, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.03546656447170152, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 0.00011604020649369613, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 17, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.826875105333904e-05}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.483869789027366 acc:  0.004465980394346068\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.2350059677572816 acc:  0.03572784315476855\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  6.991468970515147 acc:  0.11209610789808633\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  6.487117142236533 acc:  0.16303061429560325\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  5.93793005101821 acc:  0.1996293236272693\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  5.450928696063387 acc:  0.22711743295446932\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  5.0451805491407375 acc:  0.24891141727887814\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  4.721128059034588 acc:  0.26849474130808565\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  4.4580812113625665 acc:  0.2913828908291093\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  4.2191287529568715 acc:  0.3058303374048188\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  4.035539601029468 acc:  0.32347095996248576\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  3.8780763570000145 acc:  0.3409552732063506\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  3.7488254779527166 acc:  0.354174575173615\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  3.63374857341542 acc:  0.3645579795904696\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  3.5488884829673446 acc:  0.37496371390929595\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  3.4585966402743042 acc:  0.3826452001875712\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  3.3743782143632903 acc:  0.3916441506821785\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  3.2963167238636175 acc:  0.3973606055869415\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  3.246015640867858 acc:  0.3978295335283478\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  3.242683108113393 acc:  0.3980974923520086\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  3.2412728682285596 acc:  0.3980305026460934\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  3.229393910960991 acc:  0.3984994305874997\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  3.22901128320133 acc:  0.39845477078355623\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  3.2403197889568425 acc:  0.3989236987249626\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  3.220263392985368 acc:  0.3988567090190474\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  3.217246159785936 acc:  0.39952660607819934\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  3.2301114687398704 acc:  0.3992363173525668\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  3.2169914265640642 acc:  0.3995935957841145\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  3.2209353687382545 acc:  0.40006252372552087\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  3.215014607966447 acc:  0.4000848536274926\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  3.2198893062206877 acc:  0.4008217403925597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  3.2128276764845647 acc:  0.401045039412277\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  32 loss :  3.2092066913091837 acc:  0.4010227095103053\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  33 loss :  3.2079190366408405 acc:  0.40115668892213563\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  34 loss :  3.1994878744878688 acc:  0.4011343590201639\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  35 loss :  3.214148369156012 acc:  0.4015809570595985\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  36 loss :  3.205137996112599 acc:  0.4015586271576268\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  37 loss :  3.19173054534848 acc:  0.40153629725565504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  38 loss :  3.2067739081983806 acc:  0.4015586271576268\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  39 loss :  3.206540690750635 acc:  0.40153629725565504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  40 loss :  3.211435378098688 acc:  0.40167027666748545\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  41 loss :  3.2003089880742945 acc:  0.4017819261773441\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  42 loss :  3.2047542704253638 acc:  0.40175959627537233\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  43 loss :  3.200833875592015 acc:  0.401625616863542\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  44 loss :  3.206295139649335 acc:  0.40169260656945716\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  45 loss :  3.2049727540056243 acc:  0.40169260656945716\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  46 loss :  3.2046046777933586 acc:  0.40171493647142886\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.48031658926679976, 'dropout_transformers': 0.44336394664525064, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.2254594401436717, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.0015946074962007331, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 14, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.496979231147604e-06}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.43849295102633 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.331872767668504 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  7.30846272615286 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  7.290719553140494 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  7.281753316292396 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  7.276916933059693 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  7.276260038522573 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  7.2755462719843935 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  7.246010215465839 acc:  0.008150414219681575\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  7.203468399781447 acc:  0.006810620101377755\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  7.180755259440495 acc:  0.0056271352968760464\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  7.2174516201019285 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  7.160607139880841 acc:  0.007480517160529665\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  7.098979788560134 acc:  0.006230042650112766\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.42441304222493625, 'dropout_transformers': 0.4259212174192606, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.15803599980018546, 'scheduler': 'StepLR', 'step_size': 11, 'lr': 0.0006021822927933536, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 22, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.7152918538288324e-07}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.418464985214362 acc:  0.008664001965031374\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.129851361282733 acc:  0.07583234709599625\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  6.634840516483083 acc:  0.11187280887836902\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  6.057517837075626 acc:  0.13625706183149855\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  5.521352816028755 acc:  0.15731415939084029\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  5.067310040738402 acc:  0.17582564812540474\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  4.70787099629891 acc:  0.19078668244646407\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  4.433390004294259 acc:  0.21070495500524752\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  4.233048056354042 acc:  0.23147176383895673\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  4.061688324984382 acc:  0.24661143737578992\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  3.9118486873242033 acc:  0.2570618314985597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  3.74733726517493 acc:  0.27260344327088404\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  3.7032155810284015 acc:  0.277158743273117\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  3.6762041725030468 acc:  0.28158006386351964\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  3.6471307097362873 acc:  0.2820713217068977\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  3.6274339912318383 acc:  0.28448295111984456\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  3.6069081150183155 acc:  0.2890605810240493\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  3.58021424397701 acc:  0.29404014916374516\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  3.558764293414204 acc:  0.2964294486747203\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  3.556316556048994 acc:  0.2993993256369605\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  3.520778099028002 acc:  0.3015429962262466\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  3.5032766927190186 acc:  0.30283813054060693\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  3.473849470875844 acc:  0.30395462563919345\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  3.4703173757601187 acc:  0.3052274300515821\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  3.465002330411382 acc:  0.30591965701270574\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  3.4603884440510213 acc:  0.30667887367974456\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  3.4590503929042016 acc:  0.30741576044481167\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  3.4500176065108357 acc:  0.30786235848424626\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  3.446538983272905 acc:  0.3087332246611437\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  3.4516309409582315 acc:  0.30882254426903066\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  3.453819811845026 acc:  0.3086215751512851\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  3.4361360433722745 acc:  0.3087332246611437\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  32 loss :  3.43774536076714 acc:  0.3101400084853628\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  33 loss :  3.4372881981505063 acc:  0.31005068887747583\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  34 loss :  3.4441407387997924 acc:  0.31007301877944754\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  35 loss :  3.429999351501465 acc:  0.3100953486814193\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  36 loss :  3.426184171388129 acc:  0.3102516579952214\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  37 loss :  3.429005154040681 acc:  0.3101846682893062\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  38 loss :  3.424764412791789 acc:  0.3101623383873345\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  39 loss :  3.4353284475182284 acc:  0.31036330750508007\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  40 loss :  3.4313852045716358 acc:  0.3102963177991649\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  41 loss :  3.432461564280406 acc:  0.31063126632874083\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  42 loss :  3.4294757522454784 acc:  0.31058660652479736\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  43 loss :  3.426022353292513 acc:  0.3107429158385995\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  44 loss :  3.4258334396266137 acc:  0.3107652457405712\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  45 loss :  3.4210117123708 acc:  0.310698256034656\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  46 loss :  3.436088537969509 acc:  0.3107652457405712\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  47 loss :  3.425366872498969 acc:  0.3107429158385995\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  48 loss :  3.4258542842223862 acc:  0.3107652457405712\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  49 loss :  3.4259343187348184 acc:  0.310698256034656\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 720, 'dropout': 0.3994778479445833, 'dropout_transformers': 0.333963922376929, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.26762419502860635, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 0.007140964480689178, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 9.741466573591825e-06}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.6562733148273665 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.357694886860094 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  7.317912714104903 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  7.303370119396009 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  7.290774516055459 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  7.291951315026534 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  7.29407458054392 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  7.288999140890021 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  7.2883075663917944 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'ReLU6', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 696, 'dropout': 0.3416170158224381, 'dropout_transformers': 0.4784946756057745, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.06547841819081573, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 0.0003003563513613697, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00025119682840431517}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.3918655248788685 acc:  0.0445928142375455\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  6.775804141851572 acc:  0.15606368488042338\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  5.780081884677593 acc:  0.22763102069981914\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  4.939724603066078 acc:  0.27767233101846683\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  4.385150825060331 acc:  0.3146059888797088\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  4.001710792688223 acc:  0.3440367996784494\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  3.736539684809171 acc:  0.3642676908648371\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  3.5504012382947483 acc:  0.3784695085188576\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  3.404320260194632 acc:  0.3909072639171114\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  3.2958680189572847 acc:  0.4000401938235491\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  3.204644304055434 acc:  0.40455083402183867\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  11 loss :  3.1413328152436475 acc:  0.4138624031440502\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  12 loss :  3.0740136495003334 acc:  0.41529151687024096\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  13 loss :  3.0180254312661976 acc:  0.4175914967733292\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  14 loss :  2.951251372924218 acc:  0.42100797177500393\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  15 loss :  2.9429791964017427 acc:  0.42134292030457987\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  16 loss :  2.935555514922509 acc:  0.42196815755978834\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  17 loss :  2.93034644310291 acc:  0.4228613536386575\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  18 loss :  2.9240573736337514 acc:  0.4228613536386575\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  19 loss :  2.9190922718781693 acc:  0.42297300314851616\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  20 loss :  2.915770965356093 acc:  0.42355358059978115\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  21 loss :  2.9107329295231748 acc:  0.42274970412879886\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  22 loss :  2.9107365406476533 acc:  0.4230846526583748\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  23 loss :  2.9049675941467283 acc:  0.42397784873724403\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  24 loss :  2.9033566639973567 acc:  0.4240001786392158\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  25 loss :  2.8992105575708242 acc:  0.4240225085411875\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  26 loss :  2.8952840915093057 acc:  0.4241564879530179\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  27 loss :  2.8899431760494525 acc:  0.4243797869727352\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  28 loss :  2.881476847942059 acc:  0.4243797869727352\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  29 loss :  2.888065919509301 acc:  0.4244467766786504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  30 loss :  2.883646477185763 acc:  0.42449143648259385\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  31 loss :  2.886629605293274 acc:  0.42458075609048074\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  32 loss :  2.882687962972201 acc:  0.4246030859924525\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  33 loss :  2.878677219610948 acc:  0.4245360962865373\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  34 loss :  2.883635113789485 acc:  0.4244467766786504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  35 loss :  2.883813579265888 acc:  0.42451376638456556\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  36 loss :  2.8821768082105197 acc:  0.4244467766786504\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  37 loss :  2.8845566822932316 acc:  0.4246254158944242\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  38 loss :  2.8814760098090537 acc:  0.4245360962865373\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  39 loss :  2.8798777268483087 acc:  0.4246030859924525\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  40 loss :  2.8803088958446796 acc:  0.42469240560033944\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  41 loss :  2.883746176499587 acc:  0.4248040551101981\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  42 loss :  2.8853392472633947 acc:  0.4247817252082263\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  43 loss :  2.8790029947574323 acc:  0.4248263850121698\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  44 loss :  2.883055569575383 acc:  0.4247817252082263\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  45 loss :  2.883786806693444 acc:  0.42471473550231115\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  46 loss :  2.8767956293546235 acc:  0.4247593953062546\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  47 loss :  2.879601605121906 acc:  0.4248263850121698\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  48 loss :  2.8793491785342877 acc:  0.4248487149141415\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  49 loss :  2.883670981113727 acc:  0.4247817252082263\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  50 loss :  4.155346013949468 acc:  0.42464774579639597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  51 loss :  4.142054409247178 acc:  0.42471473550231115\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  52 loss :  4.142481244527376 acc:  0.42471473550231115\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  53 loss :  4.141133115841792 acc:  0.42464774579639597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'LogSigmoid', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 648, 'dropout': 0.47144715714542196, 'dropout_transformers': 0.41178046485953895, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3634603364811308, 'scheduler': 'StepLR', 'step_size': 9, 'lr': 0.0021574897520968434, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 9.498817582174396e-05}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  7.440602559309739 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.327760421312773 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  7.305390295615563 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  7.288651649768536 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  7.281494379043579 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  7.266512335263766 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  7.25312799673814 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  7.255630889305702 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  8 loss :  7.263565518305852 acc:  0.0033271553937878214\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  9 loss :  7.24487519631019 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  10 loss :  7.237284014775203 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'RReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 192, 'dropout': 0.44918973877350016, 'dropout_transformers': 0.45668898709570793, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.016541478043279535, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.54755002835045e-05}\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  0 loss :  8.025845986660396 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  1 loss :  7.408452279099794 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  2 loss :  7.345656617779598 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  3 loss :  7.329409487893648 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  4 loss :  7.316667200248932 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  5 loss :  7.314442768275181 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  6 loss :  7.3075570302588915 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=255211)\u001b[0m epoch:  7 loss :  7.316179498333797 acc:  0.005001898041667597\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 09:26:58,593\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 09:27:13,156\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 09:27:13,158\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_16       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_16\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_16`\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'SiLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.28226871881079674, 'dropout_transformers': 0.3238904480542086, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.4153605845223523, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.004061100598483793, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 3, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.0959718815457053e-06}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.39358906012315 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  7.315770516028771 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  7.301066028154813 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  7.293103643564078 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  7.2912207310016335 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  7.287496038583609 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  7.28570473744319 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  7.285790513111995 acc:  0.003438804903646473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45934053481490406 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 288, 'dropout': 0.41701128346134164, 'dropout_transformers': 0.3880139179194972, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.13766905538402274, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 0.0009901827069737036, 'dropout_lstm': 0.45934053481490406, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 17, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00012395458461874993}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.275299929771103 acc:  0.06573923140477414\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  5.810169139830005 acc:  0.19639148784136837\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  4.391798011395109 acc:  0.26590447267936496\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  3.753120598672819 acc:  0.3066342138758011\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  3.420137844165834 acc:  0.33867762320523415\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  3.216909332435672 acc:  0.35716678203782687\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  3.06173828469605 acc:  0.3698501663577697\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  2.9469618116106306 acc:  0.380345220284483\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  2.858783475491179 acc:  0.39231404774133044\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  2.799208861439168 acc:  0.3969363374494786\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  2.731194057384459 acc:  0.40673916441506824\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  2.6827229331521427 acc:  0.4079896389254851\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  2.641664701349595 acc:  0.411562423240962\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  2.592190862703724 acc:  0.4159837438313646\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  2.557985622341893 acc:  0.41964584775472835\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  2.52853376524789 acc:  0.41906527030346336\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  2.495578483373177 acc:  0.4228390237366858\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  2.467377027543653 acc:  0.42239242569725116\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  2.437514501459458 acc:  0.4223031060893643\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  2.418542477263122 acc:  0.4259205502087846\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  2.389588333979374 acc:  0.4273943237389188\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  2.315055685884812 acc:  0.43657191344929996\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  22 loss :  2.2833688158948884 acc:  0.4389612129602751\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  23 loss :  2.275635501917671 acc:  0.43876024384252954\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  24 loss :  2.2566181801948226 acc:  0.4375544291360561\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  25 loss :  2.2579859525215724 acc:  0.4388942232543599\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  26 loss :  2.250298942838396 acc:  0.4400330482549182\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  27 loss :  2.2457542950365723 acc:  0.44032333698055065\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  28 loss :  2.2335349852297486 acc:  0.44074760511801353\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  29 loss :  2.2265073271358715 acc:  0.4403679967844941\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  30 loss :  2.2329505161077035 acc:  0.4412388629613916\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  31 loss :  2.220011805285927 acc:  0.4415291516870241\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  32 loss :  2.2119848617986473 acc:  0.4413951722751937\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  33 loss :  2.2182115526760326 acc:  0.44282428600138446\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  34 loss :  2.2061079359855973 acc:  0.44170779090279794\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  35 loss :  2.1983667231407487 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  36 loss :  2.2072692107753595 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  37 loss :  2.1882791729534374 acc:  0.44108255364758947\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  38 loss :  2.188527349664384 acc:  0.4419087600205435\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48091713613422116 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 288, 'dropout': 0.4838967722896893, 'dropout_transformers': 0.3084625562688811, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7479402536073985, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 0.0010529466865984967, 'dropout_lstm': 0.48091713613422116, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardsigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 6, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.5092695758329243e-05}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.304498311852207 acc:  0.12185427505973248\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  5.497456037697672 acc:  0.25384632561463055\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  4.218636037922707 acc:  0.3159457829980126\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  3.663745653729479 acc:  0.3537949668400956\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  3.385526044028146 acc:  0.3692695889065047\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  3.199942111968994 acc:  0.38572672665966995\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  3.072255489205112 acc:  0.39063930509345063\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  2.9808872307048127 acc:  0.3961324609784963\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  2.905599760408161 acc:  0.4021838644128352\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  2.8358013690018855 acc:  0.40814594823928724\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  2.7727281105618515 acc:  0.40711877274858765\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  2.7342090827076375 acc:  0.4144429805953152\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  2.69934415616909 acc:  0.4145992899091173\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  2.6520662568196527 acc:  0.41692159971417725\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  2.633176140424584 acc:  0.42007011589219123\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  2.5968406200408936 acc:  0.41906527030346336\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  2.555864516426535 acc:  0.4236652301096398\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  2.5356934731747924 acc:  0.42038273451979546\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  2.5230057259567644 acc:  0.42281669383471404\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  2.499838496456627 acc:  0.42199048746176004\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  2.479473845297549 acc:  0.42370988991358327\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  2.432208279601666 acc:  0.4280865507000424\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  22 loss :  2.40703066857923 acc:  0.42980595315186565\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  23 loss :  2.3972789059166146 acc:  0.43172632472143446\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  24 loss :  2.3832557962722136 acc:  0.42647879775807784\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  25 loss :  2.376055184532614 acc:  0.43076613893665006\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  26 loss :  2.3560934006666936 acc:  0.42826518991581625\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  27 loss :  2.3546819887241397 acc:  0.4310564276622826\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  28 loss :  2.344302353738737 acc:  0.42938168501440277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45349153484569504 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 120, 'dropout': 0.41253970608099116, 'dropout_transformers': 0.3847227124045911, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3395385990561092, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 0.07180824122993944, 'dropout_lstm': 0.45349153484569504, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 9, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0012407641312109853}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m loss is undifined\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41967075950939603 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 216, 'dropout': 0.4964415671229234, 'dropout_transformers': 0.36944152413605036, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.20360100207657367, 'scheduler': 'ExponentialLR', 'lr': 0.003136543825653575, 'dropout_lstm': 0.41967075950939603, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'PReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 16, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00018494768994650862}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.42687169286131 acc:  0.03809481276377197\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  6.833475859110592 acc:  0.09278074269253958\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  6.6162634514670335 acc:  0.10512917848290645\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  6.545888190961066 acc:  0.10879128240627024\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  6.51633624448121 acc:  0.10934952995556349\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  6.513674157266398 acc:  0.10948350936739387\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  6.567182883051515 acc:  0.10952816917133734\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  6.479216408183556 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  6.537539558556244 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  6.505505936746379 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  6.508301451006009 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  6.5096400057086505 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  6.520968382595149 acc:  0.10955049907330906\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 216, 'dropout': 0.46026017974225514, 'dropout_transformers': 0.3989962272993866, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.2159580107754916, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 0.03774050149663838, 'dropout_lstm': 0.3932575395352555, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 11, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 8.659732505484108e-07}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3932575395352555 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 264, 'dropout': 0.4359533882589522, 'dropout_transformers': 0.2846257038729461, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.010725306748563717, 'dropout_lstm': 0.428987788959831, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'LeakyReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 14, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.144356978971987e-05}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.428987788959831 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.074214132208573 acc:  0.15543844762521491\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  5.570118442334627 acc:  0.20150503539289463\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  4.7062074661254885 acc:  0.2214902976575933\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  4.274358699196263 acc:  0.22209320501083\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  4.027489300778037 acc:  0.23441931089922516\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  3.841892285096018 acc:  0.24779492218029162\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  3.6856026122444554 acc:  0.25482884130138667\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  3.5779713254225882 acc:  0.26813746287653795\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  3.4978087952262475 acc:  0.2768461246455128\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  3.470077487042076 acc:  0.2839916932764665\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  3.3133850022366174 acc:  0.29714400553781567\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  3.3300417674215215 acc:  0.29812652122457184\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  3.2640940214458265 acc:  0.29852845946006296\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  3.2097099605359527 acc:  0.30513811044369515\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  3.218051102286891 acc:  0.3124623182904227\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  3.1337372930426346 acc:  0.3235602795703727\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  3.146563708154779 acc:  0.3300582810441462\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  3.103832887348376 acc:  0.32405153741375076\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  3.0934070863221823 acc:  0.3290534354554184\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  3.1007292847884327 acc:  0.341915458991135\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  3.0443998989306 acc:  0.33443494183060535\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  3.042930959400378 acc:  0.33523881830158764\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  22 loss :  3.0171468082227206 acc:  0.34781055311167186\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  23 loss :  3.048434571215981 acc:  0.34396980997253424\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  24 loss :  3.0602097360711347 acc:  0.3402853761471987\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  25 loss :  3.001659318020469 acc:  0.3456222227184423\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  26 loss :  2.973738183473286 acc:  0.34767657369984145\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  27 loss :  2.9801946865884883 acc:  0.3480785119353326\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  28 loss :  2.947976114875392 acc:  0.3551570908603711\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  29 loss :  2.959069407613654 acc:  0.35589397762543823\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  30 loss :  2.959202816611842 acc:  0.3489717080142018\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  31 loss :  2.9218523903896934 acc:  0.35194158497644196\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  32 loss :  2.991666854055304 acc:  0.34848045017082374\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  33 loss :  2.92514782955772 acc:  0.3510707187995445\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  34 loss :  2.9598670783795806 acc:  0.3571444521358551\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  35 loss :  2.942332619114926 acc:  0.3539512761538977\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  36 loss :  2.927883215954429 acc:  0.345644552620414\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  37 loss :  2.9210925378297503 acc:  0.36232498939329655\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  38 loss :  2.964657221342388 acc:  0.3502668423285622\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  39 loss :  2.9425987820876274 acc:  0.34325525310943883\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  40 loss :  2.955415600224545 acc:  0.3536163276243217\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  41 loss :  2.9305635878914282 acc:  0.35857356586204586\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  42 loss :  2.875923171796297 acc:  0.36402206194314807\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  43 loss :  2.885964258093583 acc:  0.3563182457629011\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  44 loss :  2.876371185403121 acc:  0.37210548645691444\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  45 loss :  2.9000147443068656 acc:  0.3572784315476855\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  46 loss :  2.8750129749900415 acc:  0.3623473192952683\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  47 loss :  2.9333729969827753 acc:  0.36033762811781256\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  48 loss :  2.935565850609227 acc:  0.36306187615836366\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  49 loss :  2.9253847122192385 acc:  0.3573454212536007\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardsigmoid', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 168, 'dropout': 0.3836030430672184, 'dropout_transformers': 0.3165540760618967, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.569252714753683, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 0.0007364463175801398, 'dropout_lstm': 0.45944734034269746, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 21, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.692382291581718e-06}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45944734034269746 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.555942486379748 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  7.2744783954085595 acc:  0.006029073532367193\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  7.179983112299554 acc:  0.01958332402920751\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  6.968090725836353 acc:  0.03563852354688163\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  6.577022592598032 acc:  0.07656923386106335\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  6.129046725335522 acc:  0.09918942455842619\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  5.788537546853039 acc:  0.11812518143045352\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  5.4551335539773245 acc:  0.1443181564432932\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  5.206766935152428 acc:  0.16399080008038766\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  4.967996497020543 acc:  0.18247995891298038\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  4.765461086112762 acc:  0.1959002299979903\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  4.553716046787868 acc:  0.21731460598887972\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  4.351231534904409 acc:  0.2287028559944622\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  4.277055722530757 acc:  0.23752316727329567\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  4.110382597023081 acc:  0.24676774668959203\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  4.083211996844995 acc:  0.2546055422816694\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  3.9941082290399854 acc:  0.2582229864010897\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  3.7883741098029593 acc:  0.2734743094477815\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  3.695145154667792 acc:  0.284862559453364\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  3.6681848463611066 acc:  0.2867159413170176\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  3.6676021468973605 acc:  0.29147221043699617\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  3.6408797892454627 acc:  0.3001585423039993\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  22 loss :  3.58888255101498 acc:  0.2995779648527343\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  23 loss :  3.5350927704962616 acc:  0.3038653060313065\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  24 loss :  3.5285237882738913 acc:  0.30949244132818254\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  25 loss :  3.4274229223483075 acc:  0.3120827099569033\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  26 loss :  3.5340069253868034 acc:  0.31815644329321396\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  27 loss :  3.502655728955135 acc:  0.3204340932943304\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  28 loss :  3.373406751133571 acc:  0.323203001138825\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  29 loss :  3.390023291668045 acc:  0.3220195163343233\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  30 loss :  3.383418051995964 acc:  0.3257039501596588\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  31 loss :  3.3319189481646103 acc:  0.32760199182725586\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  32 loss :  3.3035740763227515 acc:  0.33088448741710025\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  33 loss :  3.300139153115103 acc:  0.3303932295737222\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  34 loss :  3.294556992076268 acc:  0.3332961168300471\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  35 loss :  3.2388816392310313 acc:  0.33907956144072526\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  36 loss :  3.1899378188302583 acc:  0.3435232119330996\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  37 loss :  3.1845729685275352 acc:  0.3440367996784494\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  38 loss :  3.2221931141113567 acc:  0.34553290311055535\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  39 loss :  3.1824077044691994 acc:  0.349864904093071\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  40 loss :  3.201082127116551 acc:  0.34982024428912756\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  41 loss :  3.1492163399669613 acc:  0.3507357702699685\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  42 loss :  3.106356580680776 acc:  0.34966393497532544\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  43 loss :  3.181068970778278 acc:  0.3539512761538977\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  44 loss :  3.122477157093654 acc:  0.35665319429247705\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  45 loss :  3.12581884972403 acc:  0.3566978540964205\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  46 loss :  3.0810735849576574 acc:  0.3590424938034522\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  47 loss :  3.093094932698758 acc:  0.3610075251769645\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  48 loss :  3.0473559571203785 acc:  0.3622133398834379\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  49 loss :  3.107101014841383 acc:  0.3620347006676641\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  50 loss :  4.255811332542206 acc:  0.3577696893910636\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  51 loss :  4.213731095055554 acc:  0.35998034968626486\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  52 loss :  4.13496101236789 acc:  0.3639550722372329\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  53 loss :  4.18375399848011 acc:  0.36623272223834935\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  54 loss :  4.1399325589153255 acc:  0.3680191143960878\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  55 loss :  4.135110763745887 acc:  0.37056472322086503\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  56 loss :  4.1644352685625305 acc:  0.37087734184846927\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  57 loss :  4.130722141711511 acc:  0.3711899604760735\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  58 loss :  4.030518217621562 acc:  0.37241810508451867\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  59 loss :  4.097957713581692 acc:  0.3741151776343702\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  60 loss :  4.041688718528391 acc:  0.37346761047719\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  61 loss :  4.0803726432479435 acc:  0.37505303351718283\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  62 loss :  4.093005400951777 acc:  0.37576759038027824\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  63 loss :  4.060666732698958 acc:  0.3758345800861934\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  64 loss :  4.000438881811695 acc:  0.37360158988902037\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  65 loss :  4.020993959123843 acc:  0.3766384565571757\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  66 loss :  3.9733174872175554 acc:  0.3777326217537905\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  67 loss :  4.067474220400658 acc:  0.3783355291070272\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  68 loss :  4.032799591527921 acc:  0.37784427126364917\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  69 loss :  4.015614618764859 acc:  0.37884911685237704\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  70 loss :  4.037151869212355 acc:  0.37985396244110486\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4892240851759689 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'LeakyReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 384, 'dropout': 0.399367972565674, 'dropout_transformers': 0.3455632035651406, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.28846233721517756, 'scheduler': 'StepLR', 'step_size': 16, 'lr': 0.001439786491238468, 'dropout_lstm': 0.4892240851759689, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 18, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.092193693300096e-05}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  6.729663104277391 acc:  0.177790679498917\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  4.2171943114354065 acc:  0.30511578054172345\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  3.3262828936943643 acc:  0.35252216242770695\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  2.9943937374995304 acc:  0.376281178125628\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  2.8072195823375994 acc:  0.38807136636670164\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  2.6754906360919657 acc:  0.4014246477457964\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  2.583676336361812 acc:  0.3992139874505951\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  2.5060353976029615 acc:  0.41124980461335775\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  2.43633443575639 acc:  0.4135721144184177\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  2.3846177862240716 acc:  0.4154478261840431\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  2.3396031232980583 acc:  0.4163856820668557\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  2.2909904580849867 acc:  0.4175468369693857\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  2.253965297112098 acc:  0.4172118884398098\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  2.216079744008871 acc:  0.4164303418707992\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  2.1906809128247775 acc:  0.4177924658910747\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  2.1557552997882548 acc:  0.4181497443226224\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  2.014460791074313 acc:  0.43545541835071344\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  1.9458558330169091 acc:  0.4349418306053636\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  1.9176864477304312 acc:  0.4346068820757877\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  1.894322146819188 acc:  0.43543308844874173\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  1.869515493282905 acc:  0.43391465511466404\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  1.8536589723366959 acc:  0.4329321394279079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4401446401729308 and num_layers=1\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Hardshrink', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 240, 'dropout': 0.4893371274412556, 'dropout_transformers': 0.33090480903514535, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.3936936124230907, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 0.008129832820973137, 'dropout_lstm': 0.4401446401729308, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 16, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00010874018698185569}\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  0 loss :  7.553864505803474 acc:  0.015273652948663556\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  1 loss :  7.03443547721221 acc:  0.043766607864591474\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  2 loss :  6.479757505042531 acc:  0.10631266328740817\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  3 loss :  5.910037174403111 acc:  0.1337784427126365\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  4 loss :  5.442730457983284 acc:  0.16448205792376572\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  5 loss :  5.16895228457228 acc:  0.18181006185382848\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  6 loss :  4.83658758056498 acc:  0.18480226871804034\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  7 loss :  4.684228498244954 acc:  0.18536051626733357\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  8 loss :  4.510932565849518 acc:  0.19998660205881696\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  9 loss :  4.331111012218154 acc:  0.20679722216019472\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  10 loss :  4.193470337680567 acc:  0.20367103588415247\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  11 loss :  4.09233688194061 acc:  0.21387580108523324\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  12 loss :  4.041385657319399 acc:  0.2153272447133957\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  13 loss :  3.963963811642656 acc:  0.2243708550119465\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  14 loss :  3.8962770800724207 acc:  0.22258446285420808\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  15 loss :  3.897717326600975 acc:  0.224080566286314\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  16 loss :  3.806242087177027 acc:  0.22441551481588995\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  17 loss :  3.795447378515083 acc:  0.23406203246767746\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  18 loss :  3.7554265115862693 acc:  0.23066788736797444\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  19 loss :  3.692736186713816 acc:  0.22571064913025032\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  20 loss :  3.5301626508481037 acc:  0.24627648884621398\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  21 loss :  3.47903100352421 acc:  0.2522162427706942\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  22 loss :  3.485206332162162 acc:  0.2505638300247862\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  23 loss :  3.4837195895542608 acc:  0.25581135698814284\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  24 loss :  3.4905990306462082 acc:  0.2590045329701003\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  25 loss :  3.4151262523971986 acc:  0.2556773775763124\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  26 loss :  3.400100095249782 acc:  0.2599200589509412\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  27 loss :  3.396962653810733 acc:  0.25558805796842554\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  28 loss :  3.3411590139442513 acc:  0.26326954424670074\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  29 loss :  3.2800441902374553 acc:  0.2637161422861354\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  30 loss :  3.301470063557135 acc:  0.2632918741486725\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  31 loss :  3.2751265374299523 acc:  0.26494428689458055\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  32 loss :  3.224419228384428 acc:  0.2713083089565237\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  33 loss :  3.317098035990635 acc:  0.2775383516066364\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  34 loss :  3.1728120251236676 acc:  0.2736529486635554\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  35 loss :  3.294182055464415 acc:  0.27273742268271445\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  36 loss :  3.2315796758526956 acc:  0.2777839805283255\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  37 loss :  3.206261850963129 acc:  0.2775383516066364\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  38 loss :  3.2006670849345555 acc:  0.28035191925507447\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  39 loss :  3.2244526626907777 acc:  0.2839916932764665\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  40 loss :  3.1917843439868676 acc:  0.29149454033896793\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  41 loss :  3.0836709013609127 acc:  0.290824643279816\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  42 loss :  3.043661696888576 acc:  0.2943081079874059\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  43 loss :  3.085175362702842 acc:  0.29477703592881227\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  44 loss :  3.0888824552019067 acc:  0.29477703592881227\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  45 loss :  3.07430233687998 acc:  0.29837215014626084\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  46 loss :  3.0799787735270563 acc:  0.29618381975303126\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  47 loss :  3.00918012021858 acc:  0.2980148717147132\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  48 loss :  3.0088694585817994 acc:  0.29966728446062124\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  49 loss :  3.012919256620318 acc:  0.2994439854409039\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  50 loss :  4.202155356095216 acc:  0.3018779447558225\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  51 loss :  4.143361909367214 acc:  0.2989750574994976\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  52 loss :  4.088114110108848 acc:  0.3002478619118862\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  53 loss :  4.068911485582869 acc:  0.3042449143648259\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  54 loss :  4.150391202106654 acc:  0.30286046044257864\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  55 loss :  4.024013207337567 acc:  0.3069914923073488\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  56 loss :  4.0652774160153395 acc:  0.30763905946452896\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  57 loss :  4.047253089530446 acc:  0.30690217269946185\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  58 loss :  4.014981539449959 acc:  0.3075943996605855\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  59 loss :  4.076035595385828 acc:  0.3087778844650872\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  60 loss :  4.0118680757896925 acc:  0.30830895652368084\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  61 loss :  3.9748776092707554 acc:  0.308956523680861\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  62 loss :  4.008706551845942 acc:  0.30949244132818254\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  63 loss :  3.976586201480616 acc:  0.3097380702498716\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  64 loss :  3.9364909613243886 acc:  0.3105196168188822\n",
            "\u001b[36m(eval_config pid=267397)\u001b[0m epoch:  65 loss :  3.9345168109252073 acc:  0.3120380501529598\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 10:10:36,348\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 10:10:51,078\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 10:10:51,080\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_17       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_17\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_17`\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36652763344461714 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'SELU', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 312, 'dropout': 0.47356564755638175, 'dropout_transformers': 0.23565132304611372, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.32670935294270237, 'scheduler': 'ExponentialLR', 'lr': 0.00018244539836324145, 'dropout_lstm': 0.36652763344461714, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Tanhshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 8, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00035865863756313123}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.570150178807382 acc:  0.02400464461961012\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.003720960544266 acc:  0.05988879708818078\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  6.758088752513624 acc:  0.07915950248978407\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  6.6785156817836615 acc:  0.08581381327735971\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  6.625853953470711 acc:  0.087198267199607\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  6.600495764317404 acc:  0.08780117455284371\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  6.6131971847010025 acc:  0.08791282406270237\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  6.622673111107513 acc:  0.08811379318044794\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  6.656497594964414 acc:  0.08811379318044794\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  6.626912925079579 acc:  0.08811379318044794\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  6.603197206977669 acc:  0.08806913337650447\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  6.619272293935295 acc:  0.08809146327847621\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  6.617052161966571 acc:  0.08809146327847621\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softshrink', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 24, 'dropout': 0.4651438564481439, 'dropout_transformers': 0.35420745747162125, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 1, 'factor': 0.1299982566803774, 'patience': 2, 'scheduler': 'ReduceLROnPlateau', 'threshold': 1.1728515579649546e-05, 'lr': 0.005489659324026275, 'dropout_lstm': 0.38220631784534786, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'GELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 5, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.1639115017052855e-07}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.38220631784534786 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.402355971456576 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.057596487157485 acc:  0.014626085791483376\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  6.659712715309207 acc:  0.02730947011142621\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  6.279435362134661 acc:  0.04110934952995556\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  6.057931118652601 acc:  0.041890896098966124\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  5.989184111106296 acc:  0.0433423397271286\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  5.944240694286442 acc:  0.046356876493312195\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  5.888580791088713 acc:  0.05073353727977134\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  5.858397575987487 acc:  0.051046155907375566\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  5.8523978505815775 acc:  0.05245293973159458\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  5.855835722274139 acc:  0.0532791461045486\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  5.843701446757597 acc:  0.05377040394792667\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  5.834407161263859 acc:  0.05390438335975705\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  5.830239520353429 acc:  0.05390438335975705\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  5.838441964958896 acc:  0.05385972355581359\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  5.823649478559735 acc:  0.05397137306567224\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  5.83081580811188 acc:  0.05399370296764397\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  5.841793424942914 acc:  0.05399370296764397\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  5.826863136612067 acc:  0.05403836277158743\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  5.830226325187363 acc:  0.05399370296764397\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  5.832522865103073 acc:  0.054016032869615704\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  5.835686928083916 acc:  0.054016032869615704\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  5.835895670562231 acc:  0.05397137306567224\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  5.830881467386454 acc:  0.05397137306567224\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'PReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 144, 'dropout': 0.44179996429273377, 'dropout_transformers': 0.38844350810617606, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.48939246460426955, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 0.00033046509105822026, 'dropout_lstm': 0.4122688912611493, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'CELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 25, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.005676351616739094}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4122688912611493 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.699511150213389 acc:  0.00777080588616216\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.160051173430222 acc:  0.04682580443471853\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  6.677337052271916 acc:  0.08753321572918295\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  6.000873352931096 acc:  0.16017238684322177\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  5.397197099832388 acc:  0.20438559274724785\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  4.978876682428213 acc:  0.23566978540964206\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  4.671181099231426 acc:  0.2615278118929058\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  4.435013090647184 acc:  0.2814460844516893\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  4.258253081028278 acc:  0.29555858249782285\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  4.112780195016128 acc:  0.3075720697586138\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  3.9997609890424286 acc:  0.31867003103856373\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  3.8948439836502073 acc:  0.3234932898644575\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  3.8099629237101627 acc:  0.3370922001652413\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  3.734073259280278 acc:  0.3422950673246544\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  3.6654769292244542 acc:  0.3454212536006967\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  3.603370528954726 acc:  0.351852265368555\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  3.543750390639672 acc:  0.355000781546569\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  3.4973346655185407 acc:  0.35855123596007415\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  3.4512146381231457 acc:  0.36344148449188307\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  3.4085453308545626 acc:  0.3694035683183351\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  3.3679869193297165 acc:  0.37127928008396044\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  3.3321625214356643 acc:  0.37460643547774825\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  3.268436938065749 acc:  0.3821092825402497\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  3.243296480178833 acc:  0.3810597771475783\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  24 loss :  3.2254968771567714 acc:  0.3832927673447514\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  25 loss :  3.2073357765491193 acc:  0.3846325614630552\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  26 loss :  3.196224256662222 acc:  0.3872898197976911\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  27 loss :  3.187797845326937 acc:  0.38610633499318936\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  28 loss :  3.1702307517711934 acc:  0.38825000558247547\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  29 loss :  3.1588633445593026 acc:  0.3896791193086662\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  30 loss :  3.1441356420516966 acc:  0.390282026661903\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  31 loss :  3.128332596558791 acc:  0.39139852176048945\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  32 loss :  3.1163246613282425 acc:  0.3920237590156979\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  33 loss :  3.1006985059151284 acc:  0.39448004823258825\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  34 loss :  3.0884765001443717 acc:  0.3922247281334435\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  35 loss :  3.072418447641226 acc:  0.3956858629390617\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  36 loss :  3.0665485272040733 acc:  0.39675769823370477\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  37 loss :  3.0564654680398795 acc:  0.3957751825469486\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  38 loss :  3.046357409770672 acc:  0.3980528325480651\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  39 loss :  3.0397425651550294 acc:  0.40057611147087063\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  40 loss :  3.022156082666837 acc:  0.4001741732353795\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  41 loss :  3.015448440038241 acc:  0.4012236786280508\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  42 loss :  3.006356474069449 acc:  0.40088873009847487\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  43 loss :  2.9889050905521097 acc:  0.39916932764665164\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  44 loss :  2.9705677344248844 acc:  0.4039255967666302\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  45 loss :  2.9644549516531136 acc:  0.4051314114731036\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  46 loss :  2.9600298606432403 acc:  0.40519840117901884\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  47 loss :  2.946601341320918 acc:  0.4049304423553581\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  48 loss :  2.9471483927506665 acc:  0.40638188598352054\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  49 loss :  2.940132194298964 acc:  0.40519840117901884\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'CELU', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 288, 'dropout': 0.40795089233998405, 'dropout_transformers': 0.26095956950477817, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.12735982825741812, 'scheduler': 'StepLR', 'step_size': 26, 'lr': 6.296086035079849e-05, 'dropout_lstm': 0.48326871615766065, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ReLU6', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 12, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0020704279488374887}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48326871615766065 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  8.049807071685791 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.626627635955811 acc:  0.005738784806734698\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  7.441541069432309 acc:  0.00783779559207735\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  7.318670834993061 acc:  0.015742580890069892\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  7.236667602940609 acc:  0.02652792354241565\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  7.119360878593043 acc:  0.035459884331107784\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  6.989996528625488 acc:  0.051470424044838446\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  6.92373709427683 acc:  0.06585088091463279\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  6.686829712516383 acc:  0.07967309023513387\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  6.597689548291658 acc:  0.08902931916128888\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  6.394356873160914 acc:  0.11419511868342898\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  6.166916671552156 acc:  0.13268427751602171\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  6.044281703547427 acc:  0.13806578389120872\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  5.935896140650699 acc:  0.15889958243083313\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  5.71558286265323 acc:  0.1715383069468325\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  5.6074846819827435 acc:  0.1933992809771565\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  5.425071565728438 acc:  0.20259920058950942\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  5.318343599219071 acc:  0.20588169617935378\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  5.21471313677336 acc:  0.21941361677422236\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  5.088273768675955 acc:  0.22082040059844138\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  4.980497257333052 acc:  0.23477658933077283\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  4.857841305983694 acc:  0.24346292119777593\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  4.834042237934313 acc:  0.2483754996315566\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  4.729713550366854 acc:  0.2515910055154858\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  24 loss :  4.767798107548764 acc:  0.2606569457160083\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  25 loss :  4.566046491422151 acc:  0.2643413795413438\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  26 loss :  4.557399461143895 acc:  0.27001317464216334\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  27 loss :  4.597841732125533 acc:  0.27164325748609963\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  28 loss :  4.403255051060727 acc:  0.2747694437621419\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  29 loss :  4.449589510967857 acc:  0.2754170109193221\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  30 loss :  4.460977667256405 acc:  0.27702476386128666\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  31 loss :  4.48176333276849 acc:  0.27767233101846683\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  32 loss :  4.395083575499685 acc:  0.27983833150972465\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  33 loss :  4.426199195259496 acc:  0.28061987807873523\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  34 loss :  4.489453087354962 acc:  0.2810664761181698\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  35 loss :  4.421038996545892 acc:  0.28307616729562557\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  36 loss :  4.493457442835758 acc:  0.28254024964830404\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  37 loss :  4.416108312104877 acc:  0.2839023736685796\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  38 loss :  4.478475231873362 acc:  0.28425965210012727\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  39 loss :  4.454959465328016 acc:  0.2859790545519505\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  40 loss :  4.405069765291716 acc:  0.2861800236696961\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  41 loss :  4.429769912518953 acc:  0.2875198177879999\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  42 loss :  4.361882518467151 acc:  0.28783243641560413\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  43 loss :  4.347439597782336 acc:  0.28738583837616954\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  44 loss :  4.342569318570589 acc:  0.2882790344550387\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  45 loss :  4.3632520650562485 acc:  0.28952950896545565\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  46 loss :  4.354185756884124 acc:  0.28995377710291853\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  47 loss :  4.329833284177278 acc:  0.2901547462206641\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  48 loss :  4.355469987266942 acc:  0.2912489114172789\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  49 loss :  4.334662271800794 acc:  0.29115959180939194\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  50 loss :  5.5031720763758605 acc:  0.2886586427885582\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  51 loss :  5.424636328847785 acc:  0.289417859455597\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  52 loss :  5.37552342163889 acc:  0.28955183886742736\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  53 loss :  5.404220377771478 acc:  0.2897974677891164\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30299781744469606 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'GELU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 192, 'dropout': 0.4238829795442378, 'dropout_transformers': 0.2729915989790161, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00013374349154575196, 'dropout_lstm': 0.30299781744469606, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'SiLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 17, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0006048267474072481}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.849862230926001 acc:  0.004644619610119911\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.294428592970391 acc:  0.03633075050800527\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  6.948189691335213 acc:  0.0816827814125896\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  6.488795697188177 acc:  0.13904829957796486\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  5.989470129253483 acc:  0.1810955049907331\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  5.542427295396308 acc:  0.21043699618158676\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  5.205028910596831 acc:  0.23089118638769177\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  4.956149694298496 acc:  0.2539803050264609\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  4.736589423748625 acc:  0.26556952414978896\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  4.567270633553257 acc:  0.28153540405957617\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  4.430827803972389 acc:  0.28968581827925777\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  4.32109608369715 acc:  0.300180872205971\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  4.206060016856474 acc:  0.31005068887747583\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  4.12265156096771 acc:  0.3153205457428042\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  4.038734387950737 acc:  0.3228010629033339\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  3.973788842433641 acc:  0.3264854967286694\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  3.9013516922958758 acc:  0.33258155996695177\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  3.8414634396048153 acc:  0.3413572114418418\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  3.7881245452816747 acc:  0.3405310050688877\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  3.7242641208552514 acc:  0.3443047585021102\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  3.6866466578315285 acc:  0.3506911104660251\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  3.635676848788221 acc:  0.35312506978094366\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  3.5893677222628555 acc:  0.3600250094902083\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  3.563482665214218 acc:  0.3604269477256995\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  24 loss :  3.5224192623330763 acc:  0.3617667418440033\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  25 loss :  3.478678362710135 acc:  0.3664560212580667\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  26 loss :  3.4587246389950024 acc:  0.36504923743384765\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  27 loss :  3.4222944383861638 acc:  0.36799678449411605\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  28 loss :  3.401009551617278 acc:  0.36880066096509834\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  29 loss :  3.366923554604795 acc:  0.3755889511645044\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  30 loss :  3.340744785901879 acc:  0.37608020900788247\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  31 loss :  3.322615613456534 acc:  0.3793403746957551\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  32 loss :  3.2912947590611563 acc:  0.37777728155773393\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  33 loss :  3.2611868341429893 acc:  0.38255588057968426\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  34 loss :  3.2457590884521226 acc:  0.38101511734363486\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  35 loss :  3.216773051173747 acc:  0.38315878793292096\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  36 loss :  3.202867724314457 acc:  0.38675390215036953\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  37 loss :  3.1798672455699504 acc:  0.3850791595024898\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  38 loss :  3.1669512135641917 acc:  0.38825000558247547\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  39 loss :  3.1559731800015234 acc:  0.3879820467588147\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  40 loss :  3.1329277202862653 acc:  0.3928946251925954\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  41 loss :  3.1164966130457006 acc:  0.39316258401625614\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  42 loss :  3.0982490487459327 acc:  0.3936315119576625\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  43 loss :  3.080677355037016 acc:  0.3937654913694929\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  44 loss :  3.065612899155176 acc:  0.39700332715539377\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  45 loss :  3.044199574895266 acc:  0.396735368331733\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  46 loss :  3.0369636050793303 acc:  0.3992363173525668\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  47 loss :  3.0166758389032187 acc:  0.401045039412277\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  48 loss :  3.0043422454545476 acc:  0.3989013688229909\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  49 loss :  2.985748805919615 acc:  0.4009110600004466\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  50 loss :  4.000773946778113 acc:  0.40269745215818503\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  51 loss :  3.9743186966711734 acc:  0.4033450193153652\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  52 loss :  3.974269159701692 acc:  0.40544403010070784\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  53 loss :  3.967952998746343 acc:  0.4073867315722484\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  54 loss :  3.9395555748659024 acc:  0.4048857825514146\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  55 loss :  3.930649116259663 acc:  0.4085702163767501\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  56 loss :  3.916853407851788 acc:  0.4081236183373155\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  57 loss :  3.917590746358663 acc:  0.4079896389254851\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  58 loss :  3.892721949505205 acc:  0.40832458745506106\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  59 loss :  3.882069317232661 acc:  0.41026728892660164\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  60 loss :  3.8794849259512767 acc:  0.410401268338432\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  61 loss :  3.8659464251093505 acc:  0.4099546702989974\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  62 loss :  3.8475175344643473 acc:  0.41207601098631175\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  63 loss :  3.833438148017691 acc:  0.40935176294576064\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  64 loss :  3.8277141346650967 acc:  0.4139293928499654\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  65 loss :  3.8165042760993253 acc:  0.4138847330460219\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  66 loss :  3.809124774291736 acc:  0.41395172275193715\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3986106592081212 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 360, 'dropout': 0.372783434715439, 'dropout_transformers': 0.21646544352332928, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.7084135651818453, 'scheduler': 'StepLR', 'step_size': 19, 'lr': 0.030604381156659942, 'dropout_lstm': 0.3986106592081212, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softmin', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 32, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.5438366099111661e-06}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  6.649804639452286 acc:  0.18658866087577874\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  5.829691410064697 acc:  0.18444499028649264\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  5.68197258738161 acc:  0.1895808677399906\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43113457779595576 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'Softsign', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 456, 'dropout': 0.49472151109376195, 'dropout_transformers': 0.30398234014288233, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6729743005963787, 'scheduler': 'StepLR', 'step_size': 17, 'lr': 0.0026865137236515876, 'dropout_lstm': 0.43113457779595576, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'SELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00021107398439389134}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.8695514018719015 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.627708458400273 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  7.487490820717978 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  7.407362534449651 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  7.344403303586519 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  7.312266316447225 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  7.287351531582279 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  7.279765415858556 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  7.243943617894099 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  7.250665221180949 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  7.256997868731306 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Sigmoid', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': True, 'd_model': 120, 'dropout': 0.44572920698705765, 'dropout_transformers': 0.3771307545443429, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.8823452794251451, 'scheduler': 'StepLR', 'step_size': 23, 'lr': 0.001953597368102606, 'dropout_lstm': 0.3185403571630809, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardtanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 27, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 9.229894737223489e-06}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3185403571630809 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.716067037662538 acc:  0.005716454904762968\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  7.33573759704077 acc:  0.00520286715941317\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  7.227383092671883 acc:  0.013174642163320902\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  7.040570792029886 acc:  0.032333698055065536\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  6.82808463713702 acc:  0.04957238237724136\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  6.555294489660183 acc:  0.08416140053145167\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  6.178232180972059 acc:  0.11147087064287788\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  5.670135241596639 acc:  0.12361833731549919\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  5.578030530144186 acc:  0.1551928187035259\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  5.216079485516588 acc:  0.17254315253556038\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  5.067051799357438 acc:  0.18451197999240784\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  4.994941184500687 acc:  0.1984681687247393\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  4.705206784881463 acc:  0.20371569568809592\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  4.584386579128874 acc:  0.2134068731438269\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  4.4098829501817205 acc:  0.2215796172654802\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  4.3359072408756285 acc:  0.23243194962374114\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  4.322254934230773 acc:  0.23676395060625685\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  4.348890102210165 acc:  0.23024361923051156\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  4.141913928905455 acc:  0.24006877609807292\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  4.0830627088787175 acc:  0.25369001630082844\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  4.076548295862534 acc:  0.25619096532166225\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  4.026933820307756 acc:  0.2556773775763124\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  3.945470182835555 acc:  0.2709063707210325\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  3.817965860126399 acc:  0.2613715025791037\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  24 loss :  3.799658152235656 acc:  0.2845722707277315\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  25 loss :  3.7676635990623666 acc:  0.2802402697452158\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  26 loss :  3.759343584044641 acc:  0.2836120849429471\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  27 loss :  3.7997789523180794 acc:  0.28754214768997166\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  28 loss :  3.721831676338901 acc:  0.29790322220485455\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  29 loss :  3.703962794872893 acc:  0.29325860259473463\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  30 loss :  3.648469967000625 acc:  0.29732264475358955\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  31 loss :  3.729812722246186 acc:  0.3033070584820133\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  32 loss :  3.6240664229673496 acc:  0.3012080476966706\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  33 loss :  3.4869577984849944 acc:  0.29660808789049414\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  34 loss :  3.504466335312659 acc:  0.30404394524708034\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  35 loss :  3.5222270628985237 acc:  0.31058660652479736\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  36 loss :  3.446458950763991 acc:  0.3075943996605855\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  37 loss :  3.4932503099201107 acc:  0.31096621485831677\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  38 loss :  3.3720006662256576 acc:  0.31511957662505863\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  39 loss :  3.4776025359370126 acc:  0.3207020521179912\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  40 loss :  3.315616060705746 acc:  0.3125293079963379\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  41 loss :  3.339791792781413 acc:  0.31699528839068397\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  42 loss :  3.4244746681021043 acc:  0.31998749525489584\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  43 loss :  3.305842123111757 acc:  0.32831654869035126\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  44 loss :  3.371299386024475 acc:  0.33155438447625213\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  45 loss :  3.32072781314369 acc:  0.32934372418105085\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  46 loss :  3.2999886284355355 acc:  0.33405533349708594\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  47 loss :  3.3069760929636596 acc:  0.3366679320277784\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  48 loss :  3.314525081329987 acc:  0.3392358707545274\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  49 loss :  3.2449973931833473 acc:  0.3355067771252484\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  50 loss :  4.3168145448219875 acc:  0.33829801487171474\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  51 loss :  4.420792281126776 acc:  0.34062032467677467\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  52 loss :  4.240421168944415 acc:  0.3432999129133823\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  53 loss :  4.291655672698462 acc:  0.3409552732063506\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  54 loss :  4.291294554702374 acc:  0.3443047585021102\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  55 loss :  4.274401191903763 acc:  0.3411115825201527\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  56 loss :  4.30211701112635 acc:  0.3489047183082866\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  57 loss :  4.1198365748429495 acc:  0.3493289864457495\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  58 loss :  4.120275978280716 acc:  0.3471629859544917\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  59 loss :  4.087165465875834 acc:  0.34752026438603933\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  60 loss :  4.245273127275355 acc:  0.3471853158564634\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  61 loss :  4.227706817017884 acc:  0.3506687805640533\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  62 loss :  4.143052393648805 acc:  0.3489493781122301\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  63 loss :  4.233260040523625 acc:  0.3537503070361521\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  64 loss :  4.2198810857885025 acc:  0.3545765134091061\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  65 loss :  4.171628687562061 acc:  0.35801531831275263\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  66 loss :  4.25493264398655 acc:  0.36033762811781256\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  67 loss :  4.172611593198376 acc:  0.35835026684232857\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  68 loss :  4.1740617451547575 acc:  0.35982404037246274\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  69 loss :  4.1747561703209115 acc:  0.36583078400285823\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  70 loss :  4.228697462242191 acc:  0.3655851550811692\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  71 loss :  4.076727254050119 acc:  0.36556282517919747\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  72 loss :  4.140842341575302 acc:  0.3719938369470558\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  73 loss :  4.063532626929403 acc:  0.3689793001808722\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  74 loss :  4.133179951114815 acc:  0.37340062077127484\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  75 loss :  4.1310889580670525 acc:  0.3723734452805752\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  76 loss :  4.085477360156404 acc:  0.3784025188129424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4697974851634549 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Mish', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.41463105538163153, 'dropout_transformers': 0.20246596977219092, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.448390260843404, 'scheduler': 'ExponentialLR', 'lr': 0.0008100456727013664, 'dropout_lstm': 0.4697974851634549, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softplus', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 14, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.3036052052776295e-07}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.325672261068754 acc:  0.06334993189379899\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  5.9361276582022695 acc:  0.21905633834267468\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  4.667956385657052 acc:  0.28448295111984456\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  4.2215827113000035 acc:  0.3031060893642677\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  4.029089390674484 acc:  0.3115691222115535\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  3.9886489092746626 acc:  0.3171292678025143\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  3.959212746575614 acc:  0.3173748967242034\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  3.94630383553906 acc:  0.3183127526070161\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  3.937366926781485 acc:  0.31824576290110085\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  3.930722622113807 acc:  0.31837974231293126\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  3.951776789727612 acc:  0.31837974231293126\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  3.922784988011155 acc:  0.31837974231293126\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  3.924513146141979 acc:  0.3183127526070161\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  3.930226593374092 acc:  0.3183127526070161\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  3.94500640619581 acc:  0.3183127526070161\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3426584497123991 and num_layers=1\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=278540)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Tanhshrink', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 408, 'dropout': 0.3492998418880478, 'dropout_transformers': 0.4417864251563269, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 9, 'factor': 0.07336042631402362, 'patience': 3, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0032489148617814946, 'lr': 0.0004044735745729699, 'dropout_lstm': 0.3426584497123991, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 11, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.4935469409271925e-05}\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  0 loss :  7.235180938160503 acc:  0.10995243730880021\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  1 loss :  5.299121061405102 acc:  0.24364156041354978\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  2 loss :  4.148717946939535 acc:  0.3101623383873345\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  3 loss :  3.618564165555514 acc:  0.3505794609561664\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  4 loss :  3.3048251158707624 acc:  0.36913560949467433\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  5 loss :  3.0603384871582886 acc:  0.3948149967621642\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  6 loss :  2.977987176054841 acc:  0.4011343590201639\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  7 loss :  2.9138618582612152 acc:  0.4035459884331108\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  8 loss :  2.8868795875069146 acc:  0.40620324676774666\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  9 loss :  2.8629121546978715 acc:  0.40631489627760536\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  10 loss :  2.85144995809435 acc:  0.40852555657280665\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  11 loss :  2.837533639027522 acc:  0.4088381752004109\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  12 loss :  2.8184911304420526 acc:  0.4107585467699797\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  13 loss :  2.8004568306716173 acc:  0.41279056784940715\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  14 loss :  2.787755666079221 acc:  0.41529151687024096\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  15 loss :  2.782497009197315 acc:  0.4139293928499654\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  16 loss :  2.7544213508392548 acc:  0.4149119085367215\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  17 loss :  2.7368693201691956 acc:  0.4142196815755979\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  18 loss :  2.7325488453978424 acc:  0.4154924859879865\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  19 loss :  2.7201776087700904 acc:  0.41593908402742114\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  20 loss :  2.731351822406262 acc:  0.4163856820668557\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  21 loss :  2.718876305159989 acc:  0.4168769399102338\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  22 loss :  2.7218248477348914 acc:  0.41707790902797937\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  23 loss :  2.735465203131829 acc:  0.4171672286358663\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  24 loss :  2.7218830502116598 acc:  0.4171672286358663\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  25 loss :  2.731010395330149 acc:  0.41727887814572495\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  26 loss :  2.69696142290022 acc:  0.416943929616149\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  27 loss :  2.7160497778779145 acc:  0.4173235379496684\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  28 loss :  2.7170196079707645 acc:  0.4174128575575553\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  29 loss :  2.725757512179288 acc:  0.41747984726347054\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  30 loss :  2.725975288377775 acc:  0.41707790902797937\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  31 loss :  2.7027236414956044 acc:  0.41712256883192284\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  32 loss :  2.722239305923035 acc:  0.41707790902797937\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  33 loss :  2.705655859900521 acc:  0.4169885894200924\n",
            "\u001b[36m(eval_config pid=278540)\u001b[0m epoch:  34 loss :  2.6994647112759678 acc:  0.4171002389299511\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 11:19:00,681\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 11:19:14,894\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 11:19:14,895\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_18       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_18\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_18`\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36099695838797724 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'ELU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 240, 'dropout': 0.49914038621041334, 'dropout_transformers': 0.2502821712317257, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5900053207023038, 'scheduler': 'StepLR', 'step_size': 22, 'lr': 0.0002316383897140383, 'dropout_lstm': 0.36099695838797724, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'PReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0009528949209821547}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.4663807062002325 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  7.175534673837515 acc:  0.022374561775673804\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  6.93991087766794 acc:  0.042382153942344195\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  6.673391675949096 acc:  0.0615188799321171\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  6.406817175791814 acc:  0.07911484268584061\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  6.151322306119479 acc:  0.09193220641761382\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  5.898030016972468 acc:  0.10939418975950696\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  5.6645215621361364 acc:  0.12379697653127303\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  5.443446969985962 acc:  0.13855704173458677\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  5.256123010928814 acc:  0.14974432262242368\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  5.072807256992046 acc:  0.16475001674742648\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  4.913225067578829 acc:  0.1786838755777862\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  4.763075003257165 acc:  0.1841100417569167\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  4.633036727171678 acc:  0.19165754862336154\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  4.509641559307392 acc:  0.20291181921711363\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  4.3983827737661505 acc:  0.2098787486322935\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  4.292409761135395 acc:  0.21762722461648393\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  4.20012242610638 acc:  0.227229082464328\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  4.113417546565716 acc:  0.232610588839515\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  4.028228139877319 acc:  0.2402697452158185\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  3.9526984838339 acc:  0.24797356139606547\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  3.8817778018804696 acc:  0.25435991335998037\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  3.811087412100572 acc:  0.26121519326530157\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  3.774994521874648 acc:  0.2633588638545877\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  3.7361328418438253 acc:  0.2688966795435768\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  3.702460736494798 acc:  0.2738985775852444\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  3.6665150605715238 acc:  0.27979367170578123\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  3.63607457784506 acc:  0.2839023736685796\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  3.606573148874136 acc:  0.28872563249447336\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  3.5752906029041 acc:  0.2929459839671304\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  3.5471701328571026 acc:  0.2968537168121832\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  3.5163178022091204 acc:  0.30042650112766006\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  3.4898732313743004 acc:  0.3050264609338365\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  3.461507170016949 acc:  0.3081526472098787\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  3.435822448363671 acc:  0.31043029721099524\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  3.4154658757723295 acc:  0.3147399682915392\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  3.3889650088090164 acc:  0.3170846079985709\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  3.364558086028466 acc:  0.31762052564589244\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  3.3424018786503717 acc:  0.3233816403545988\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  3.3246928655184234 acc:  0.32530201192416763\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  40 loss :  3.2985485296982984 acc:  0.32561463055177187\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  41 loss :  3.277530697675852 acc:  0.33090681731907196\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  42 loss :  3.26046004478748 acc:  0.331733023692026\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  43 loss :  3.2436097933695867 acc:  0.33706987026326957\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  44 loss :  3.219001423395597 acc:  0.34044168546100084\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  45 loss :  3.2035281052956215 acc:  0.3416028403635308\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  46 loss :  3.1971020258389986 acc:  0.3430989437956367\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  47 loss :  3.1862847474905163 acc:  0.34341156242324095\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  48 loss :  3.1714094858903152 acc:  0.3438581604626756\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  49 loss :  3.1594549032358024 acc:  0.34752026438603933\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  50 loss :  4.562117772835951 acc:  0.3340776633990577\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  51 loss :  4.325338862492488 acc:  0.33767277761650627\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  52 loss :  4.2515668832338775 acc:  0.3424960364424\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  53 loss :  4.196490447337811 acc:  0.3461804702677355\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  54 loss :  4.1714821246954115 acc:  0.34928432664180603\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  55 loss :  4.146561371363126 acc:  0.3522542036040462\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  56 loss :  4.126143532532912 acc:  0.3524105129178483\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  57 loss :  4.109095061742343 acc:  0.35475515262488\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  58 loss :  4.10068367261153 acc:  0.35663086439050534\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  59 loss :  4.0875397737209616 acc:  0.3561172766451555\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  60 loss :  4.07534445982713 acc:  0.35723377174374205\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  61 loss :  4.075545778641334 acc:  0.3600026795882366\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  62 loss :  4.057168766168448 acc:  0.35989103007837797\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  63 loss :  4.050438380241394 acc:  0.3606055869414733\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  64 loss :  4.043629492246188 acc:  0.3640443918451198\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  65 loss :  4.03209759088663 acc:  0.36422303106089365\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  66 loss :  4.015902722798861 acc:  0.3667016501797557\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  67 loss :  4.017177943082956 acc:  0.3665453408659536\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  68 loss :  4.016168033159696 acc:  0.3677064957684836\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  69 loss :  4.003743243217468 acc:  0.36761717616059664\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  70 loss :  3.9994472943819486 acc:  0.3673045575329924\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  71 loss :  4.001839214104873 acc:  0.36909094969073086\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  72 loss :  3.994150255276607 acc:  0.36971618694593933\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  73 loss :  3.987306262896611 acc:  0.36987249625974145\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  74 loss :  3.9820880082937387 acc:  0.3706093830248085\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  75 loss :  3.9812848164485053 acc:  0.3719938369470558\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  76 loss :  3.9692473649978637 acc:  0.3719268472411406\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  77 loss :  3.9680438885321982 acc:  0.3721501462608579\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4519105057384538 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'LogSigmoid', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 384, 'dropout': 0.33444080886129024, 'dropout_transformers': 0.3418084126891912, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.015073765226183589, 'dropout_lstm': 0.4519105057384538, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softsign', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 21, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.854126529900434e-06}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.808883651934172 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  7.46582219475194 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  7.341999601062976 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  7.291928502133018 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  7.259744368101421 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  7.27054779655055 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  7.258608270946302 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  7.212700442263954 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  7.253210690146998 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  7.251948728059467 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  7.232101912247507 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  7.247445648594907 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49760611033727187 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Softshrink', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 312, 'dropout': 0.3899359329276796, 'dropout_transformers': 0.4532240363117542, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5468480973470571, 'scheduler': 'StepLR', 'step_size': 24, 'lr': 0.001147928926972868, 'dropout_lstm': 0.49760611033727187, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Tanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.431122872269132e-05}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  6.734819600562088 acc:  0.17491012214456378\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  4.396004847117832 acc:  0.29520130406627515\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  3.5287201885415724 acc:  0.3426300158542304\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  3.187941597289398 acc:  0.3694258982203068\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  2.9743019873354615 acc:  0.3860393452872742\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  2.8396363078045246 acc:  0.397896523234263\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  2.743414051392499 acc:  0.4006431011767858\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  2.657938853031447 acc:  0.40464015362972555\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  2.6064337682323298 acc:  0.41220999039814216\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  2.544112766490263 acc:  0.41384007324207844\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  2.4984010407904615 acc:  0.4159167541254494\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  2.454335817769796 acc:  0.4134381350065873\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  2.419700746776677 acc:  0.4145992899091173\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  2.380221957919978 acc:  0.4145992899091173\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  2.3483679635184154 acc:  0.41596141392939284\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  2.3259466515869653 acc:  0.41707790902797937\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  2.299784798582061 acc:  0.4203157448138803\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  2.2725116024498178 acc:  0.4200477859902195\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  2.256724450768543 acc:  0.41321483598687003\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  2.23607980103052 acc:  0.41631869236094055\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  2.210976982317051 acc:  0.41788178549896166\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  2.189828672328917 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3764144674438583 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 528, 'dropout': 0.3643058290084673, 'dropout_transformers': 0.49086229734025066, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6436057561775197, 'scheduler': 'StepLR', 'step_size': 25, 'lr': 5.1285625665280206e-05, 'dropout_lstm': 0.3764144674438583, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'LogSigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 22, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0004831347750571131}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.931970286082072 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  7.4895902656647095 acc:  0.009624187749815778\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  7.324164781225733 acc:  0.014894044615144139\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  7.19082423865077 acc:  0.019181385793716366\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  7.07852897873844 acc:  0.02782305785677601\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  6.871109284550311 acc:  0.06364022061943148\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  6.681679156889398 acc:  0.091172989750575\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  6.399562318641019 acc:  0.11915235692115311\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  6.1246304052421845 acc:  0.14981131232833889\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  5.896705012723624 acc:  0.16818882165107296\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  5.666059361882956 acc:  0.19275171381997633\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  5.395955677492073 acc:  0.20793604716075295\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  5.270598147288863 acc:  0.21601947167451935\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  5.061341153569968 acc:  0.23524551727217918\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  4.936360968164651 acc:  0.25208226335886386\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  4.753256786300476 acc:  0.25913851238193064\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  4.564397981367915 acc:  0.26503360650246743\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  4.497345369982432 acc:  0.27202286581961904\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  4.403328039559973 acc:  0.2794140633722618\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  4.341630852366069 acc:  0.2888819418082755\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  4.210375553154083 acc:  0.2953129535761338\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  4.1677694205778195 acc:  0.30498180112989304\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  4.033207373446729 acc:  0.3112118437800058\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  3.9750076431825936 acc:  0.31427104035013287\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  3.9444493500583144 acc:  0.3196525467253199\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  3.8038880825042725 acc:  0.32751267221936897\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  3.8216445733265703 acc:  0.3296340129066833\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  3.751281387834664 acc:  0.3308621575151285\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  3.745048841798162 acc:  0.3415358506576156\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  3.6907962517565993 acc:  0.3366679320277784\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  3.6587607314787713 acc:  0.34300962418774983\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  3.6325948468173843 acc:  0.3457785320322444\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  3.595930108104844 acc:  0.34669405801308534\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  3.5544867975166046 acc:  0.35127168791729\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  3.560614712267037 acc:  0.3501328629167318\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  3.5241474588233306 acc:  0.3542638947815019\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  3.5682973861694336 acc:  0.3522542036040462\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  3.450218318456627 acc:  0.35799298841078087\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  3.5009347186031112 acc:  0.3565415447826184\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  3.4408488876848335 acc:  0.3577026996851484\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  40 loss :  3.456620790872229 acc:  0.36069490654936026\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  41 loss :  3.4155942503228247 acc:  0.3573454212536007\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  42 loss :  3.378915740782956 acc:  0.36502690753187594\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  43 loss :  3.402271236281797 acc:  0.36638903155215147\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  44 loss :  3.3407272373337342 acc:  0.36696960900341646\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  45 loss :  3.3421988602144173 acc:  0.3657191344929996\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  46 loss :  3.3025975715683167 acc:  0.3680191143960878\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  47 loss :  3.3408104712704576 acc:  0.3701627849853739\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  48 loss :  3.3030200148203286 acc:  0.3707880222405824\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  49 loss :  3.27559794575335 acc:  0.3731549918495858\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  50 loss :  4.276744107165968 acc:  0.37578992028224995\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  51 loss :  4.21403786935002 acc:  0.3767724359690061\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  52 loss :  4.248205808271845 acc:  0.37692874528280823\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  53 loss :  4.246151369738292 acc:  0.3793627045977268\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  54 loss :  4.181990112166807 acc:  0.37931804479378334\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  55 loss :  4.237314988331622 acc:  0.37576759038027824\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  56 loss :  4.156534892966948 acc:  0.37835785900899893\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  57 loss :  4.20159972432148 acc:  0.38219860214813656\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  58 loss :  4.18275624585439 acc:  0.3770627246946386\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  59 loss :  4.109752790037408 acc:  0.38476654087488554\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  60 loss :  4.187151107443384 acc:  0.3855927472478396\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  61 loss :  4.14030431839357 acc:  0.3840073242078467\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  62 loss :  4.087111567876425 acc:  0.3846102315610834\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  63 loss :  4.194641216691718 acc:  0.3838956746979881\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  64 loss :  4.096366856471602 acc:  0.38570439675769824\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  65 loss :  4.1662323417433775 acc:  0.38762476832726706\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  66 loss :  4.130461758877858 acc:  0.38771408793515394\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  67 loss :  4.113421075315361 acc:  0.389120871759373\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  68 loss :  4.10043474277818 acc:  0.38827233548444723\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  69 loss :  4.17731330193669 acc:  0.38941116048500546\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  70 loss :  4.10193739167179 acc:  0.3887635933278253\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  71 loss :  4.066105118717056 acc:  0.38842864479824935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29199178526549857 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ReLU6', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 48, 'dropout': 0.43167051808142787, 'dropout_transformers': 0.4085320132395845, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.43656647830530976, 'scheduler': 'StepLR', 'step_size': 20, 'lr': 3.779822907191557e-05, 'dropout_lstm': 0.29199178526549857, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 30, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00010604876310854615}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  8.29727775133573 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  8.066540226569543 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  7.985101923575768 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  7.926893362632165 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  7.856037675417387 acc:  0.0017417323537949668\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  7.768233038828924 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  7.675277328491211 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  7.592488879423875 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  7.521330749071561 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  7.462781330255361 acc:  0.002992206864211866\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  7.416766130007231 acc:  0.003952392648996271\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  7.377839077436007 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  7.349735890902005 acc:  0.004733939218006833\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  7.323091943447406 acc:  0.005068887747582788\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  7.300394696455736 acc:  0.005381506375187013\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  7.282409873375526 acc:  0.005716454904762968\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  7.266806639157808 acc:  0.00582810441462162\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  7.248793579981878 acc:  0.007033919121095058\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  7.233948949667123 acc:  0.006743630395462564\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  7.221617973767794 acc:  0.008128084317709845\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  7.210172865940974 acc:  0.008150414219681575\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  7.204661512374878 acc:  0.008820311278833487\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  7.1966283688178425 acc:  0.008619342161087912\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  7.190689699466412 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  7.185948716677152 acc:  0.01031641471093942\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  7.178411410405086 acc:  0.011276600495723824\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  7.173423664386456 acc:  0.011276600495723824\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  7.168934657023503 acc:  0.011991157358819195\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  7.163076873926016 acc:  0.01228144608445169\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  7.158128991493812 acc:  0.013330951477123015\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  7.15061851648184 acc:  0.0136882299086707\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  7.146012478608352 acc:  0.014693075497398567\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  7.1426175410930925 acc:  0.015340642654578747\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  7.13711771598229 acc:  0.017372663734006207\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  7.129277878541213 acc:  0.01676975638076949\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  7.122954361255353 acc:  0.017060045106401984\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  7.121618292881892 acc:  0.017886251479356005\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  7.114467437450703 acc:  0.018087220597101578\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  7.107130292745737 acc:  0.019047406381885984\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  7.09994395329402 acc:  0.020208561284415963\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  40 loss :  7.096253926937397 acc:  0.0196503137351227\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  41 loss :  7.09440060028663 acc:  0.0196503137351227\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  42 loss :  7.088252441699688 acc:  0.019739633343009624\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  43 loss :  7.086375331878662 acc:  0.02009691177455731\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  44 loss :  7.084071225386399 acc:  0.0201639014804725\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  45 loss :  7.082333913216224 acc:  0.020588169617935376\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  46 loss :  7.080888124612661 acc:  0.02069981912779403\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  47 loss :  7.077956995597252 acc:  0.02078913873568095\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  48 loss :  7.072513187848605 acc:  0.020588169617935376\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  49 loss :  7.070294416867769 acc:  0.021302726481030747\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  50 loss :  8.250200950182402 acc:  0.019851282852868277\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  51 loss :  8.195034936758189 acc:  0.02074447893173749\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  52 loss :  8.178327366021962 acc:  0.021816314226380546\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  53 loss :  8.165360949589656 acc:  0.022240582363843422\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  54 loss :  8.157139444351197 acc:  0.02268718040327803\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  55 loss :  8.149450019689708 acc:  0.02286581961905187\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  56 loss :  8.136647492188674 acc:  0.023223098050599557\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  57 loss :  8.134692276441134 acc:  0.022910479422995334\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  58 loss :  8.124678131250235 acc:  0.022888149521023603\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  59 loss :  8.115166939221895 acc:  0.023803675501864546\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  60 loss :  8.112743245638335 acc:  0.02384833530580801\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  61 loss :  8.106867661842934 acc:  0.02398231471763839\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  62 loss :  8.105495540912335 acc:  0.023870665207779737\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  63 loss :  8.105081404172457 acc:  0.023714355893977624\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  64 loss :  8.100522155028123 acc:  0.02400464461961012\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  65 loss :  8.097714068339421 acc:  0.02389299510975147\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  66 loss :  8.095147965504573 acc:  0.023468726972288592\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  67 loss :  8.095433374551627 acc:  0.023937654913694928\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  68 loss :  8.092447244204008 acc:  0.023781345599892815\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  69 loss :  8.08432997923631 acc:  0.023736685795949355\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m GAT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25661274634629566 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'LeakyReLU', 'amsgrad': False, 'batch_size': 16, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.30800021614726614, 'dropout_transformers': 0.36273808433775845, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 2, 'factor': 0.3233130592800654, 'patience': 10, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.3211198729005216, 'lr': 9.003547349055623e-05, 'dropout_lstm': 0.25661274634629566, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'RReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'LeakyReLU', 'dropout_gcn': 0.001199406154753696, 'hidden_channels': 512, 'layer_type': 'GAT', 'norm': 'BatchNorm', 'num_layers_gcn': 1, 'use_gcn': True, 'weight_decay': 0.00015248169710939716}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.899178357881921 acc:  0.005314516669271822\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  7.513519135591026 acc:  0.007971775003907732\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  7.364673774933147 acc:  0.014670745595426835\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  7.222215665835086 acc:  0.01900274657794252\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  7.106142173303622 acc:  0.01947167451934886\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  7.013447792730599 acc:  0.03170846079985709\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  6.871502853999628 acc:  0.03628609070406181\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  6.817516803741455 acc:  0.04858986669048523\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  6.677881739963995 acc:  0.05874997208762254\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  6.506716001813657 acc:  0.05968782797043521\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  6.461866962575467 acc:  0.08474197798271665\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  6.195866072289298 acc:  0.09954670298997387\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  6.038506886669409 acc:  0.12038050152959828\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  5.95181105070025 acc:  0.1344483397717884\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  5.797734122409999 acc:  0.14706473438581605\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  5.7950764950190745 acc:  0.14934238438693254\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  5.770444509024932 acc:  0.16242770694236652\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  5.6205780417005595 acc:  0.16798785253332738\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  5.737670838275802 acc:  0.17258781233950382\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  5.523698066996637 acc:  0.18585177411071166\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  5.378092868305813 acc:  0.18819641381774335\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  5.216742406381625 acc:  0.20163901480472501\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  5.26921442513154 acc:  0.21396512069312015\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  5.197514892738556 acc:  0.21682334814550164\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  5.180929397868219 acc:  0.2194359466761941\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  5.2187715000081285 acc:  0.22787664962150816\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  5.027150512855743 acc:  0.22941741285755757\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  4.988506141110001 acc:  0.23240961972176943\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  5.039669219578538 acc:  0.23774646629301296\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  5.069594258459929 acc:  0.23694258982203067\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  4.927430774563941 acc:  0.2414532300203202\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  5.115901904685475 acc:  0.24743764374874394\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  5.061480357268146 acc:  0.24833083982761317\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  4.890204656903989 acc:  0.24902306678873679\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  4.840400684659726 acc:  0.24973762365183216\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  4.9534071628178395 acc:  0.2534220574771677\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  4.905909295394042 acc:  0.2568831922827859\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  4.930946570690547 acc:  0.2585132751267222\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  4.81896867707511 acc:  0.2600093785588281\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  4.773433034665117 acc:  0.26105888395149945\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  40 loss :  4.810793816486251 acc:  0.2613268427751602\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  41 loss :  4.770425228314979 acc:  0.2625549873836054\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  42 loss :  4.799474941235837 acc:  0.2628676060112096\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  43 loss :  4.8616678803880635 acc:  0.2621977089520577\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  44 loss :  4.876836362286149 acc:  0.26224236875600115\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  45 loss :  4.815016949288199 acc:  0.2633142040506442\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  46 loss :  4.766549319864433 acc:  0.2651452560123261\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  47 loss :  4.901563499575463 acc:  0.264988946698524\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  48 loss :  4.726300150434548 acc:  0.264653998168948\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  49 loss :  4.952528109060269 acc:  0.26541321483598684\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4766541425719399 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'RReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 432, 'dropout': 0.4567714069620133, 'dropout_transformers': 0.43434786507788126, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.09430711391420205, 'scheduler': 'ExponentialLR', 'lr': 0.0009468108039063848, 'dropout_lstm': 0.4766541425719399, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 25, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.9940926909694348e-06}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.614694278658801 acc:  0.1438492285018869\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  6.185582230109294 acc:  0.1829488868543867\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  5.974812059912063 acc:  0.18752651675859142\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  5.895465646991293 acc:  0.18844204273943238\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  5.890926947120492 acc:  0.18837505303351718\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  5.988072202405856 acc:  0.18846437264140412\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  5.918033971131303 acc:  0.18844204273943238\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  5.821111595357648 acc:  0.18841971283746065\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  5.875773488110259 acc:  0.18841971283746065\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  5.97145833677918 acc:  0.18841971283746065\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  5.872124824815124 acc:  0.18841971283746065\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3261206651696913 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'SiLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.40263773452452967, 'dropout_transformers': 0.4660203616355475, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.15754890999079812, 'scheduler': 'StepLR', 'step_size': 12, 'lr': 0.00018330178869909358, 'dropout_lstm': 0.3261206651696913, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Hardshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 17, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.3813857066955279e-05}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  7.611456240140475 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  7.309188215549176 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  7.295457608883197 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  7.285025688318106 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  7.238918330119207 acc:  0.010963981868119598\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  6.939029051707341 acc:  0.04957238237724136\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  6.412488453204816 acc:  0.07873523435232119\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  5.914730471831102 acc:  0.11051068485809347\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  5.507334133294912 acc:  0.1403434338923252\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  5.191365476754996 acc:  0.1549695196838086\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  4.941291856765747 acc:  0.1733693589085144\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  4.740170236734244 acc:  0.1864770113659201\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  4.580726304421058 acc:  0.19281870352589153\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  4.549864248129038 acc:  0.19565460107630128\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  4.5197292694678675 acc:  0.19916039568586294\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  4.498322140253507 acc:  0.19989728245093005\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  4.477625060081482 acc:  0.20275550990331154\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  4.447214431029099 acc:  0.20521179912020185\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  4.426743984222412 acc:  0.2059710157872407\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  4.401871604185838 acc:  0.20800303686666816\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  4.387776963527386 acc:  0.20932050108300024\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  4.362950225976797 acc:  0.21048165598553023\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  4.343898657652048 acc:  0.213563182457629\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  4.322690433722276 acc:  0.21383114128128977\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  4.3005962280126715 acc:  0.2147466672621307\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  4.300977774766776 acc:  0.21456802804635688\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  4.294692906966576 acc:  0.21499229618381976\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  4.295428173358624 acc:  0.2148806466739611\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  4.284901345693148 acc:  0.21550588392916956\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  4.289141449561486 acc:  0.2161981108902932\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  4.285179152855506 acc:  0.2156175334390282\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  4.279919613324679 acc:  0.21593015206663244\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  4.274204008395856 acc:  0.21637675010606702\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  4.274112736261808 acc:  0.216131121184378\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  4.271361167614277 acc:  0.21695732755733202\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  4.270726343301626 acc:  0.216711698635643\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  4.2678873263872585 acc:  0.21655538932184087\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  4.264542449437655 acc:  0.21689033785141684\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  4.264985398145822 acc:  0.21691266775338855\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  4.259381538171034 acc:  0.21668936873367126\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.39835295062948795 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.011854644777911427, 'dropout_transformers': 0.2901432719501403, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.789797312978834, 'scheduler': 'StepLR', 'step_size': 18, 'lr': 0.0006435251285857135, 'dropout_lstm': 0.39835295062948795, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.007209207292907e-07}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  6.722567229927657 acc:  0.20384967509992633\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  4.32532404568381 acc:  0.31418172074224593\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  3.3741332228312237 acc:  0.3585289060581024\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  2.944519765362768 acc:  0.37771029185181876\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  2.7376946960380693 acc:  0.3911305629368287\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  2.5394967430366013 acc:  0.39878971931313223\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  2.439687738875429 acc:  0.40446151441395173\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  2.321445010379403 acc:  0.4097313712792801\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  2.2085529365939296 acc:  0.41089252618181005\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  2.145592678092911 acc:  0.4102449590246299\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  2.0747427711943667 acc:  0.41352745461447427\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  1.995236670899534 acc:  0.41464394971306073\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  1.945397796745072 acc:  0.4193332291271241\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  1.8714615078029517 acc:  0.41656432128262955\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  1.7984257822265168 acc:  0.41640801196882743\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  1.7490842677875906 acc:  0.4166313109885448\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  1.6868035964623183 acc:  0.41654199138065784\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  1.6322844492461153 acc:  0.41397405265390885\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'SELU', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.2490298908435148, 'dropout_transformers': 0.33308059874343243, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.015693223833386137, 'scheduler': 'StepLR', 'step_size': 14, 'lr': 0.00389877002654694, 'dropout_lstm': 0.008721348759390624, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Sigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 15, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0014172444089564753}\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.008721348759390624 and num_layers=1\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  0 loss :  6.3390464746035065 acc:  0.22854654668066007\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  1 loss :  3.7726616896115814 acc:  0.3058526673067905\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  2 loss :  3.099001688223619 acc:  0.3439474800705625\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  3 loss :  2.828851787860577 acc:  0.36618806243440594\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  4 loss :  2.6688114367998566 acc:  0.37969765312730275\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  5 loss :  2.5528691328488864 acc:  0.39425674921287096\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  6 loss :  2.463381218910217 acc:  0.399883884509747\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  7 loss :  2.3776013612747193 acc:  0.4037916173547998\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  8 loss :  2.322897533270029 acc:  0.4056226693164817\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  9 loss :  2.272776493659386 acc:  0.41044592814237546\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  10 loss :  2.224219710093278 acc:  0.4057119889243686\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  11 loss :  2.178108547284053 acc:  0.40682848402295513\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  12 loss :  2.143923053374657 acc:  0.4111381551034991\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  13 loss :  2.11380312534479 acc:  0.40633722617957707\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  14 loss :  1.9912134647369384 acc:  0.412143000692227\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  15 loss :  1.9660302116320683 acc:  0.4154924859879865\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  16 loss :  1.954953956604004 acc:  0.41770314628318783\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  17 loss :  1.941453719139099 acc:  0.419757497264587\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  18 loss :  1.9355148067841164 acc:  0.42082933255923005\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  19 loss :  1.9291605234146119 acc:  0.421744858540071\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  20 loss :  1.9275338475520793 acc:  0.4222584462854208\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  21 loss :  1.9216372792537395 acc:  0.42272737422682716\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  22 loss :  1.9177568325629601 acc:  0.42315164236429004\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  23 loss :  1.912377024613894 acc:  0.4239555188352723\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  24 loss :  1.9109894349024845 acc:  0.42397784873724403\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  25 loss :  1.9065773111123305 acc:  0.4247593953062546\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  26 loss :  1.9035286930891184 acc:  0.4248263850121698\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  27 loss :  1.9020461064118606 acc:  0.42507201393385885\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  28 loss :  1.8998852647267854 acc:  0.42511667373780226\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  29 loss :  1.8993376355904799 acc:  0.42522832324766097\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  30 loss :  1.9005724631823027 acc:  0.42522832324766097\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  31 loss :  1.8985450093562786 acc:  0.42522832324766097\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  32 loss :  1.9009590754142174 acc:  0.4252506531496327\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  33 loss :  1.8994050594476553 acc:  0.425384632561463\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  34 loss :  1.8974122762680055 acc:  0.4253623026594913\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  35 loss :  1.899637853182279 acc:  0.4252729830516044\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  36 loss :  1.8998200095616855 acc:  0.42529531295357614\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  37 loss :  1.8990919562486501 acc:  0.425384632561463\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  38 loss :  1.898807656764984 acc:  0.42545162226737826\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  39 loss :  1.8989547344354483 acc:  0.425384632561463\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  40 loss :  1.8964044213294984 acc:  0.4254069624634348\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  41 loss :  1.897835795695965 acc:  0.42551861197329344\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  42 loss :  1.8966700434684753 acc:  0.42549628207132173\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  43 loss :  1.8977903246879577 acc:  0.42545162226737826\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  44 loss :  1.8971760960725637 acc:  0.42551861197329344\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  45 loss :  1.8987569469671983 acc:  0.42549628207132173\n",
            "\u001b[36m(eval_config pid=295713)\u001b[0m epoch:  46 loss :  1.8986746962253864 acc:  0.42549628207132173\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 13:12:01,499\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 13:12:15,911\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 13:12:15,913\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_19       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_19\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_19`\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m GCNConv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4212373473574615 and num_layers=1\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Hardshrink', 'amsgrad': False, 'batch_size': 32, 'concatenate_features': True, 'd_model': 264, 'dropout': 0.2713825276869094, 'dropout_transformers': 0.39674897693108957, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.001428428264605978, 'dropout_lstm': 0.4212373473574615, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'PReLU', 'dropout_gcn': 0.04455764197113807, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'PairNorm', 'num_layers_gcn': 10, 'use_gcn': True, 'weight_decay': 0.000263245820961097}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.500547092277687 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.274046954575119 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.202538963798043 acc:  0.03286961570238707\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  6.928416488887547 acc:  0.09941272357814349\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  6.34959556339504 acc:  0.14429582654132148\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  5.615624787924173 acc:  0.1937565594087042\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  5.038737332070624 acc:  0.22521939128687224\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  4.639090209574133 acc:  0.24904539669070852\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  4.378796810870404 acc:  0.27193354621173216\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  4.26179283815664 acc:  0.28584507514012014\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  4.043942358110335 acc:  0.29924301632315836\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  3.9103514314531447 acc:  0.3035303575017306\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  3.8074361844496294 acc:  0.30712547171917914\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  3.740137497028271 acc:  0.32152825849094524\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  3.6825187889846056 acc:  0.32979032222048543\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  3.535481186179848 acc:  0.33441261192863364\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  3.5693882778807953 acc:  0.3353504678114463\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  3.541435710200063 acc:  0.34207176830493713\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  3.4964607695599534 acc:  0.34819016144519127\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  3.4319328328112624 acc:  0.34481834624746\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  3.431920895209679 acc:  0.3552910702722015\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  3.4127921674635027 acc:  0.3524775026237635\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  3.383422531448044 acc:  0.35062412076010985\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  3.38916706205248 acc:  0.3577026996851484\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  3.3345007529625525 acc:  0.36525020655159324\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  3.325493527459098 acc:  0.36527253645356494\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  3.2731093876845354 acc:  0.36855503204340934\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  3.273322742302101 acc:  0.36877833106312663\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  3.238557383730695 acc:  0.3665230109639819\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  3.2307092109760203 acc:  0.3702297746912891\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  3.2213573789263106 acc:  0.37929571489181163\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  3.1657903294463257 acc:  0.37512002322309806\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  3.2139387280790954 acc:  0.37395886832056807\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  33 loss :  3.1427185652139302 acc:  0.37576759038027824\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  34 loss :  3.155590207426698 acc:  0.38063550901011545\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  35 loss :  3.1833264477603085 acc:  0.3832927673447514\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  36 loss :  3.1661848921875855 acc:  0.37983163253913316\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  37 loss :  3.1079499438092424 acc:  0.3799209521470201\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  38 loss :  3.178836135597496 acc:  0.382823839403345\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  39 loss :  3.164182274491637 acc:  0.3823549114619387\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  40 loss :  3.1089459499279104 acc:  0.38711118058191724\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  41 loss :  3.1186384804598934 acc:  0.38298014871714714\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  42 loss :  3.11011601828195 acc:  0.39014804725007257\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  43 loss :  3.1014507350388105 acc:  0.38452091195319654\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  44 loss :  3.1268030046583055 acc:  0.3867092423464261\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  45 loss :  3.0975186341292376 acc:  0.39005872764218563\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  46 loss :  3.0803451404704916 acc:  0.3908402742111962\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  47 loss :  3.102796804654848 acc:  0.39124221244668733\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  48 loss :  3.0744495942042422 acc:  0.3879820467588147\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  49 loss :  3.043707312403859 acc:  0.39334122323203\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Softshrink', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 96, 'dropout': 0.19342491645813628, 'dropout_transformers': 0.31932322903528376, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.956584722264092, 'scheduler': 'StepLR', 'step_size': 13, 'lr': 0.0001110224379529757, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.0030829169373873407}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.966885566711426 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.711490831877056 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.5285619635331 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.393947792053223 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  7.30714750289917 acc:  0.010026125985306925\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  7.2430929987054125 acc:  0.014648415693455106\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  7.177117523394133 acc:  0.02009691177455731\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  7.118290519714355 acc:  0.02710850099368064\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  7.067378049147757 acc:  0.034075430408860505\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  7.004233997746518 acc:  0.03751423531250698\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  6.946017405861302 acc:  0.04381126766853494\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  6.882480837169447 acc:  0.04865685639640042\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  6.8099948029769095 acc:  0.051403434338923255\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  6.742855092098838 acc:  0.056807270616082\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  6.6831784348738825 acc:  0.05941986914677445\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  6.61191675286544 acc:  0.0630596431681665\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  6.54426928570396 acc:  0.06971395395574213\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  6.476331078378778 acc:  0.07054016032869616\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  6.423467570856998 acc:  0.07583234709599625\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  6.349699170965898 acc:  0.08070026572583347\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  6.284653583325838 acc:  0.08333519415849765\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  6.206351305309095 acc:  0.08784583435678717\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  6.167443149968197 acc:  0.09333899024183284\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  6.089349530872545 acc:  0.0961078980863274\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  6.01639004255596 acc:  0.09977000200969117\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  5.9660944788079515 acc:  0.10401268338431995\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  5.901682683041221 acc:  0.10716119956233393\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  5.839598103573448 acc:  0.11042136525020656\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  5.784916802456505 acc:  0.11305629368287073\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  5.71763831690738 acc:  0.11875041868566197\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  5.661834370462518 acc:  0.12096107898086328\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  5.601963866384406 acc:  0.1262755956501351\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  5.557015820553429 acc:  0.12544938927718108\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  33 loss :  5.495767508055034 acc:  0.13181341133912422\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  34 loss :  5.423430427752043 acc:  0.13612308241966817\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  35 loss :  5.387209194584897 acc:  0.14405019761963245\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  36 loss :  5.323590961255525 acc:  0.14907442556327177\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  37 loss :  5.287212371826172 acc:  0.15193265301565326\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  38 loss :  5.2412168201647304 acc:  0.15550543733113012\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  39 loss :  5.182013687334563 acc:  0.15965879909787195\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  40 loss :  5.154288005828858 acc:  0.15914521135252216\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  41 loss :  5.101783722325375 acc:  0.16477234664939822\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  42 loss :  5.073477463973196 acc:  0.16952861576937678\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  43 loss :  5.042693489476254 acc:  0.17068977067190674\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  44 loss :  4.986374714500026 acc:  0.17198490498626712\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  45 loss :  4.950513272536428 acc:  0.17723243194962374\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  46 loss :  4.9303208652295565 acc:  0.17662952459638703\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  47 loss :  4.8816704549287495 acc:  0.18306053636424535\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  48 loss :  4.846647754468416 acc:  0.18326150548199094\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  49 loss :  4.79751773633455 acc:  0.1852935265614184\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  50 loss :  5.971495026036313 acc:  0.19047406381885984\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  51 loss :  5.835799603713186 acc:  0.19150123930955942\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  52 loss :  5.785117079082288 acc:  0.19554295156644264\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  53 loss :  5.719105334030955 acc:  0.1972176942143224\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  54 loss :  5.746127013156289 acc:  0.1964808074492553\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  55 loss :  5.665659116443835 acc:  0.19797691088136124\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  56 loss :  5.643028394799483 acc:  0.2009021280396579\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  57 loss :  5.607920199946354 acc:  0.20087979813768617\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  58 loss :  5.524099500555741 acc:  0.20422928343344574\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  59 loss :  5.543281264054148 acc:  0.2083156554942724\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  60 loss :  5.49081294913041 acc:  0.20652926333653396\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  61 loss :  5.4614035104450425 acc:  0.2092981711810285\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  62 loss :  5.439111840097528 acc:  0.21188843980974922\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  63 loss :  5.454909399936073 acc:  0.21282629569256192\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  64 loss :  5.397096463253623 acc:  0.21630976040015185\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  65 loss :  5.411486173930921 acc:  0.21637675010606702\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  66 loss :  5.36180160924008 acc:  0.21883303932295736\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  67 loss :  5.333008811348363 acc:  0.2219592255989996\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  68 loss :  5.322397954840409 acc:  0.22461648393363554\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  69 loss :  5.312762641906739 acc:  0.22332134961927516\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  70 loss :  5.284418713419061 acc:  0.22600093785588282\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  71 loss :  5.276292248776085 acc:  0.2285018868767166\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  72 loss :  5.21291278537951 acc:  0.2268718040327803\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  73 loss :  5.238785929428904 acc:  0.2289931447200947\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  74 loss :  5.212205776415373 acc:  0.23086885648572003\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  75 loss :  5.215251219900031 acc:  0.23392805305584707\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Softplus', 'amsgrad': False, 'batch_size': 64, 'concatenate_features': True, 'd_model': 360, 'dropout': 0.4632829677185178, 'dropout_transformers': 0.4196628430206137, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.8307854128929457, 'scheduler': 'StepLR', 'step_size': 21, 'lr': 1.383836032077874e-05, 'dropout_lstm': 0.4610202594693588, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 2, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.1796740137853448e-06}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4610202594693588 and num_layers=1\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  8.012241082019116 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.905013469328363 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.820194617811456 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.737622559788716 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  7.6707618092916094 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  7.602218202797763 acc:  0.002210660295201304\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  7.5508525342826385 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  7.492411693894719 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  7.450441504099283 acc:  0.002992206864211866\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  7.402127202734889 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  7.365784214203616 acc:  0.0031485161780139786\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  7.348294505153794 acc:  0.0033494852957595515\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  7.311483446373997 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  7.309001687061356 acc:  0.0033494852957595515\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  7.278768625604101 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  7.283885197467114 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  7.275361038116087 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  7.2560915085206545 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  7.253035051276885 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  7.25523059913911 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  7.234887490789574 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  7.233511350241052 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  7.24520292626806 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  7.2300613874412445 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  7.236832641693483 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  7.220420682286641 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  7.240891180842755 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  7.218551181885133 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  7.226333853710129 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  7.223607327564653 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  7.212518623076289 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  7.214857911489096 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  7.212289574634598 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  33 loss :  7.2131870625967 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  34 loss :  7.215512482516737 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  35 loss :  7.211133043450046 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  36 loss :  7.204611835709537 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  37 loss :  7.2033004818192445 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  38 loss :  7.197589730641928 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  39 loss :  7.1987495307462765 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  40 loss :  7.191037821482463 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  41 loss :  7.179597688008504 acc:  0.004309671080543956\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  42 loss :  7.195533878831978 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  43 loss :  7.196162798318518 acc:  0.004890248531808946\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  44 loss :  7.193332488278308 acc:  0.005403836277158743\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  45 loss :  7.190723534089973 acc:  0.004934908335752406\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  46 loss :  7.1674514563686875 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  47 loss :  7.185458838221538 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  48 loss :  7.189849422638675 acc:  0.006297032356027957\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  49 loss :  7.194941342595112 acc:  0.00585043431659335\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  50 loss :  8.197391251483596 acc:  0.005403836277158743\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  51 loss :  8.193275026528232 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'CELU', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': False, 'd_model': 168, 'dropout': 0.21786694238434431, 'dropout_transformers': 0.27997982761435086, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 7, 'factor': 0.7099089087507221, 'patience': 5, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.04390510071214791, 'lr': 0.0005108267598408587, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 32, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.8873644432597555e-05}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.720979726615072 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.406243568708916 acc:  0.010093115691222116\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.300338805222712 acc:  0.012080476966706116\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.259986372555003 acc:  0.015050353928946252\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  7.130102866837959 acc:  0.020543509813991917\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  7.013447008213075 acc:  0.019962932362726928\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  6.933698786406958 acc:  0.026818212268048144\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  6.828146233278162 acc:  0.03322689413393475\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  6.680234568459647 acc:  0.03974722550968001\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  6.628586228154287 acc:  0.039992854431369046\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  6.511989589498825 acc:  0.042382153942344195\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  6.441527110187947 acc:  0.05593640443918451\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  6.3336424306661145 acc:  0.06091597257888038\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  6.276595303992264 acc:  0.06464506620815935\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  6.1371531807074025 acc:  0.07143335640756537\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  6.123168532587901 acc:  0.07752941964584775\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  6.091011147539155 acc:  0.0729294598396713\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  5.854791468932849 acc:  0.07931581180358618\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  5.846780444393639 acc:  0.08840408190608043\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  5.7602927624678415 acc:  0.09146327847620749\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  5.673863783603957 acc:  0.10595538485586048\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  5.703727077035343 acc:  0.10666994171895586\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  5.623642717088972 acc:  0.11419511868342898\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  5.5628690799745195 acc:  0.11106893240738673\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  5.574616035493482 acc:  0.11843780005805775\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  5.481780833556872 acc:  0.12009021280396578\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  5.469559545276546 acc:  0.1299600294754706\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  5.421633311680385 acc:  0.12868722506308197\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  5.38437241065402 acc:  0.13196972065292634\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  5.300148723506126 acc:  0.14009780497063617\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  5.371180253870347 acc:  0.14273273340330037\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  5.17762824667602 acc:  0.1398298461469754\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  5.177980390917353 acc:  0.14056673291204252\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  33 loss :  5.259422081859172 acc:  0.14771230154299622\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  34 loss :  5.160265728205192 acc:  0.1546122412522609\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  35 loss :  5.195160975977152 acc:  0.15427729272268495\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  36 loss :  5.068047771934702 acc:  0.1549695196838086\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  37 loss :  5.198300269471497 acc:  0.15432195252662842\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  38 loss :  5.145559781739692 acc:  0.15635397360605588\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  39 loss :  5.0561904506523065 acc:  0.15684523144943394\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  40 loss :  5.048605031326037 acc:  0.15773842752830314\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  41 loss :  5.044504890922739 acc:  0.16135587164772347\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  42 loss :  5.02011899587487 acc:  0.15662193242971664\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  43 loss :  4.996638584537666 acc:  0.15988209811758927\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  44 loss :  4.896892194988347 acc:  0.16086461380434539\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  45 loss :  4.928877938695314 acc:  0.16327624321729228\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  46 loss :  4.8586788838651 acc:  0.16334323292320746\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  47 loss :  4.91479614201714 acc:  0.16305294419757496\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  48 loss :  4.908401781771364 acc:  0.16856842998459237\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  49 loss :  4.87727438501951 acc:  0.16995288390683966\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  50 loss :  6.4669515104854804 acc:  0.16517428488488936\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  51 loss :  6.1360489540741225 acc:  0.1635888618448965\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  52 loss :  6.043675106112697 acc:  0.16497331576714377\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  53 loss :  6.089036612951455 acc:  0.1697072549851506\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  54 loss :  5.964905911133069 acc:  0.16443739811982225\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  55 loss :  6.05259405665037 acc:  0.17158296675077597\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  56 loss :  5.9265434080813115 acc:  0.16988589420092445\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  57 loss :  5.986510012330127 acc:  0.1716052966527477\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  58 loss :  5.963951820085029 acc:  0.17444119420315746\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  59 loss :  5.83032159244313 acc:  0.17718777214568027\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  60 loss :  5.767787091872272 acc:  0.17604894714512204\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  61 loss :  5.870774838102966 acc:  0.17461983341893128\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  62 loss :  5.882658241175804 acc:  0.17633923587075453\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  63 loss :  5.808472252693496 acc:  0.178371256950182\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  64 loss :  5.8861509351169365 acc:  0.17662952459638703\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  65 loss :  5.88308922182612 acc:  0.17805863832257776\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  66 loss :  5.798814681397767 acc:  0.18120715450059174\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  67 loss :  5.797781591655827 acc:  0.17973338097045755\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  68 loss :  5.7235002457594675 acc:  0.18178773195185674\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  69 loss :  5.764075888305151 acc:  0.1808052162651006\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  70 loss :  5.88615994894204 acc:  0.18156443293213942\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  71 loss :  5.905490662871289 acc:  0.18053725744143984\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  72 loss :  5.673203532435313 acc:  0.1820556907755175\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  73 loss :  5.687778444851146 acc:  0.18111783489270483\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  74 loss :  5.76656398853334 acc:  0.1852265368555032\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  75 loss :  5.833404597114114 acc:  0.1842663510707188\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  76 loss :  5.7638245911157435 acc:  0.1830158765603019\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  77 loss :  5.7296454325443555 acc:  0.18377509322734073\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  78 loss :  5.586316721779959 acc:  0.18397606234508632\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  79 loss :  5.775127258621344 acc:  0.1852265368555032\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'ReLU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.2986619795509168, 'dropout_transformers': 0.3725707191288807, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6912571913858578, 'scheduler': 'StepLR', 'step_size': 27, 'lr': 0.006153166601226652, 'dropout_lstm': 0.2225255166922815, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardswish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 12, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.7524072082896956e-05}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2225255166922815 and num_layers=1\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  6.966867589504919 acc:  0.20418462362950227\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  4.530090784358087 acc:  0.2278989795234799\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  3.8210463568428965 acc:  0.25348904718308285\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  3.4369778343450244 acc:  0.2850188687671661\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  3.16768317579109 acc:  0.31299823593774423\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  2.9666324686781267 acc:  0.3422727374226827\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  2.7727502729291116 acc:  0.3586852153719045\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  2.6087869283194856 acc:  0.38123841636335215\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  2.495952702014246 acc:  0.39291695509456714\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  2.419101088960594 acc:  0.3971373065672242\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  2.3475985371063803 acc:  0.40035281245115334\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  2.27702983294692 acc:  0.4009110600004466\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  2.2300981717689017 acc:  0.406672174709153\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  2.2026542391732473 acc:  0.40307706049170444\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  2.1599900655657334 acc:  0.40807895853337206\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  2.1081757946549176 acc:  0.4046624835316973\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  2.0709839736189797 acc:  0.4055556796105665\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  2.0501611177052292 acc:  0.4101333095147712\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  2.030592534029595 acc:  0.4102449590246299\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  2.0069830651595213 acc:  0.4095973918674497\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  1.964753197732373 acc:  0.40743139137619183\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  1.9479559470559948 acc:  0.41044592814237546\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  2.0057727009336523 acc:  0.40115668892213563\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  2.770670977708335 acc:  0.3965790590179309\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  2.315530119655288 acc:  0.4053323805908492\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  2.197426145321855 acc:  0.4127459080454637\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  2.223924176715245 acc:  0.4101333095147712\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  2.0862517902784257 acc:  0.421744858540071\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  2.0294091211301146 acc:  0.42100797177500393\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  2.009496915006192 acc:  0.42074001295134317\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  2.14098696062498 acc:  0.4148672487327781\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  2.0430332522525965 acc:  0.4169662595181207\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  2.008820546007602 acc:  0.41881964138177435\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardsigmoid', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.28738031242909173, 'dropout_transformers': 0.3092490600265414, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.30171509976712185, 'scheduler': 'ExponentialLR', 'lr': 2.3643877242507104e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.00045319677749843136}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.888018513453826 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.613952720438251 acc:  0.004689279414063372\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.576332274284072 acc:  0.004309671080543956\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.559763828306708 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  7.561918764623977 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  7.547752100092764 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  7.551852022418539 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'GELU', 'amsgrad': False, 'batch_size': 128, 'concatenate_features': True, 'd_model': 552, 'dropout': 0.486752578693352, 'dropout_transformers': 0.34881289437946, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.24736480923689938, 'scheduler': 'StepLR', 'step_size': 28, 'lr': 0.02543724034031982, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 3, 'num_layers_transformer': 1, 'optimizer': 'AdamW', 'positive_function': 'exp', 'epochs_complete_problem': 24, 'reg': True, 'transformers_model': True, 'activation_gcn': 'RReLU', 'dropout_gcn': 0.13550226747096092, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 9, 'use_gcn': True, 'weight_decay': 0.0590462897751758}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.6871050174419695 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.307740292182335 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.302916163664598 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.296135297188392 acc:  0.0071232387289819794\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.347154448756278 and num_layers=1\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'PReLU', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 504, 'dropout': 0.3797765193911646, 'dropout_transformers': 0.2955623689790295, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5201233688471268, 'scheduler': 'StepLR', 'step_size': 15, 'lr': 0.0018499170739355057, 'dropout_lstm': 0.347154448756278, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 3, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'sig', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 6.362921474895234e-06}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.900983302823959 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  7.646710032801474 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  7.491064588485226 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  7.392443278528029 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  7.346342345206968 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  7.307998841808688 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 600, 'dropout': 0.23699218246435155, 'dropout_transformers': 0.25499097742103005, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.0002899579045394837, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.1769324063849738}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.25921250123244 acc:  0.09981466181363464\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  6.1018646166874815 acc:  0.18652167116986357\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  5.025120625129113 acc:  0.24620949914029877\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  4.318410185667185 acc:  0.29149454033896793\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  3.872628635626573 acc:  0.3282942187883795\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  3.5722392889169545 acc:  0.3566978540964205\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  3.3684218351657575 acc:  0.3721948060648014\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  3.220011461698092 acc:  0.3872228300917759\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  3.105362899486835 acc:  0.3990800080387647\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  3.014948980624859 acc:  0.4068061541209834\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  2.9449217246128963 acc:  0.4111381551034991\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  2.8831358212691085 acc:  0.4187973114798026\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  2.834573503640982 acc:  0.4202934149119085\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  2.790204334259033 acc:  0.4238661992273854\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  2.7523452300291793 acc:  0.42781859187638166\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  2.716800412764916 acc:  0.4292923654065159\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  2.6883457092138436 acc:  0.4320612732510104\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  2.6607621504710273 acc:  0.4330661188397383\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  2.6362633851858286 acc:  0.43355737668311634\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  2.6161411120341374 acc:  0.4388718933523882\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  2.5901851947490986 acc:  0.4360136659000067\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  2.576699297244732 acc:  0.4386485943326709\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  2.5569019170907827 acc:  0.43817966639126454\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  2.5412463169831496 acc:  0.4388718933523882\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  2.5234610777634843 acc:  0.439050532568162\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  2.508478859754709 acc:  0.43996605854900295\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  2.497414761323195 acc:  0.4372864703123953\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  2.4784407138824465 acc:  0.44398544090391445\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  2.4688068279853232 acc:  0.44253399727575193\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  2.460050493020278 acc:  0.44164080119688276\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  2.44608533015618 acc:  0.44286894580532793\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  2.43369929423699 acc:  0.4424000178639216\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  2.4247807025909425 acc:  0.4421767188442043\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': False, 'd_model': 624, 'dropout': 0.12188887895377962, 'dropout_transformers': 0.2259671172251792, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00025928872473061785, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 31, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.2005904394121396}\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  0 loss :  7.054591155552364 acc:  0.1379094745774066\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  1 loss :  5.94907882997206 acc:  0.21121854275059732\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  2 loss :  5.227670052668431 acc:  0.25170265502534445\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  3 loss :  4.643281143028419 acc:  0.2837683942567492\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  4 loss :  4.207592750762726 acc:  0.3134448339771788\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  5 loss :  3.901508126225505 acc:  0.33675725163566533\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  6 loss :  3.6059515076083737 acc:  0.35267847174150907\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  7 loss :  3.4227140283251143 acc:  0.37040841390706297\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  8 loss :  3.276982770933138 acc:  0.3774200031261863\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  9 loss :  3.171601528887982 acc:  0.386798561954313\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  10 loss :  3.0724020787885973 acc:  0.3963111001942701\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  11 loss :  3.0225565383484314 acc:  0.39939262666636893\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  12 loss :  2.9112026908180932 acc:  0.4095973918674497\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  13 loss :  2.8579704861540893 acc:  0.4078779894156265\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  14 loss :  2.831817930394953 acc:  0.41924390951923723\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  15 loss :  2.772498832715975 acc:  0.41480025902686285\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  16 loss :  2.7500011437422747 acc:  0.4182167340285376\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  17 loss :  2.68828036234929 acc:  0.4186410021660005\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  18 loss :  2.684186973771849 acc:  0.42330795167809215\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  19 loss :  2.6478637331849213 acc:  0.42609918942455843\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  20 loss :  2.6439180657580184 acc:  0.4247593953062546\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  21 loss :  2.613974918018688 acc:  0.42708170511131455\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  22 loss :  2.60359453988242 acc:  0.42569725118906726\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  23 loss :  2.557360549073119 acc:  0.42940401491637453\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  24 loss :  2.526262518409249 acc:  0.42551861197329344\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  25 loss :  2.5225454377127696 acc:  0.4313020565839716\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  26 loss :  2.5088030058187205 acc:  0.42942634481834624\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  27 loss :  2.5018371985508847 acc:  0.43096710805439564\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  28 loss :  2.4805570849171885 acc:  0.4313913761918585\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  29 loss :  2.4693007802629805 acc:  0.43273117031016234\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  30 loss :  2.4498311939773028 acc:  0.43232923207467117\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  31 loss :  2.4366229280725227 acc:  0.4318379742312931\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  32 loss :  2.4355545627487287 acc:  0.4312573967800281\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  33 loss :  2.428374985714892 acc:  0.4329767992318514\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  34 loss :  2.409835671211456 acc:  0.43208360315298217\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  35 loss :  2.3960408097380523 acc:  0.4355893977625438\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  36 loss :  2.382286546947239 acc:  0.4341602840363531\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  37 loss :  2.3585506035731387 acc:  0.434584552173816\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  38 loss :  2.3950483698944947 acc:  0.431101087466226\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  39 loss :  2.3684450854788293 acc:  0.43273117031016234\n",
            "\u001b[36m(eval_config pid=323753)\u001b[0m epoch:  40 loss :  2.371703089533986 acc:  0.43096710805439564\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 14:09:26,914\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 14:09:41,015\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 14:09:41,017\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_20       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_20\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_20`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=338248)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Mish', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.23088325133538307, 'dropout_transformers': 0.19201447830589397, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.0003940817058048093, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 38, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 5.2857004951775224e-08}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  6.578302790568425 acc:  0.232610588839515\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  4.273491369760953 acc:  0.34120090212803966\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  3.3945573073167066 acc:  0.38293548891320367\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  3.0396016084230864 acc:  0.4050420918652167\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  2.848206222974337 acc:  0.4144429805953152\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  2.716562190422645 acc:  0.42007011589219123\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  2.6221540817847617 acc:  0.4255856016792086\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  2.546076242740338 acc:  0.42882343746510954\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  2.472055746958806 acc:  0.4335797065850881\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  2.4126951896227324 acc:  0.433423397271286\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  2.359285435309777 acc:  0.4359466761940915\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  2.314789153979375 acc:  0.4351204698211375\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  2.2669403626368596 acc:  0.436482593841413\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  2.2193495475328886 acc:  0.43911752227407724\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  2.176864526822017 acc:  0.4373311301163388\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  2.1377223482498757 acc:  0.4371078310966215\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  2.0979835491914014 acc:  0.4361029855078936\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  2.060838514107924 acc:  0.4351874595270527\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  2.0219734522012565 acc:  0.4349418306053636\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': True, 'd_model': 672, 'dropout': 0.097137219051831, 'dropout_transformers': 0.23803196121127565, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 3.120289238923346e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.07457961731638527}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.851861365541013 acc:  0.004398990688430878\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.45785218370175 acc:  0.004175691668713575\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  7.319658128087392 acc:  0.0063416921599714175\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  7.225289681714452 acc:  0.012035817162762655\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  7.16630109912621 acc:  0.03141817207422459\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  7.0982793219789055 acc:  0.04166759707924882\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  6.975934776717318 acc:  0.0674809637585691\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  6.850100680025752 acc:  0.10182435299109037\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  6.656350675457252 acc:  0.10968447848513944\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  6.510024878793134 acc:  0.1225911618247996\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  6.421326140443722 acc:  0.13527454614474244\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  6.235421240686656 acc:  0.14753366232722237\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  6.10203971405943 acc:  0.153361766741844\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  6.004481232808735 acc:  0.1699975437107831\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  5.844558812900932 acc:  0.18214501038340442\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  5.739036051813 acc:  0.19203715695688095\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  5.6178208339714 acc:  0.2011030971574035\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  5.452624452328253 acc:  0.20668557265033607\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  5.459477204762533 acc:  0.2146573476542438\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  5.2580449481210305 acc:  0.21986021481365697\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  5.26314978970739 acc:  0.2238572672665967\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  5.152052575242734 acc:  0.23010963981868118\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  5.036892830968617 acc:  0.23723287854766317\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  5.008704727995181 acc:  0.24433378737467343\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  4.797257456236971 acc:  0.24891141727887814\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  4.832431597623996 acc:  0.25429292365406514\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  4.700434374952031 acc:  0.2588258937543264\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  4.670317113042592 acc:  0.2603443270884041\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  4.635415962356293 acc:  0.2697452158185026\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  4.502765646951641 acc:  0.27490342317397226\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  4.55226359681455 acc:  0.27769466092043854\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  4.417616797064593 acc:  0.28153540405957617\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  4.388795070305556 acc:  0.2837683942567492\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  4.246273708914568 acc:  0.2883013643570105\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  4.25849104784206 acc:  0.2925440457316392\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  4.170302101238045 acc:  0.3004041712256883\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  4.160293509146411 acc:  0.3056740280910167\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  4.102662806025522 acc:  0.3078176986803028\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  4.068290256454559 acc:  0.30978273005381507\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  4.002635853019303 acc:  0.3125069780943662\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  3.904963908795111 acc:  0.3149632673112565\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  3.991989701094028 acc:  0.31867003103856373\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  3.913161524755512 acc:  0.32360493937431617\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  3.8380838868146885 acc:  0.3240068776098073\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  3.810061717461683 acc:  0.32914275506330526\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  3.7742919336535974 acc:  0.3305495388875243\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  3.790154815433982 acc:  0.3368912310474957\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  3.7368243640054484 acc:  0.33852131389143203\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  3.739796695595016 acc:  0.3426970055601456\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  3.621703249251771 acc:  0.3458455217381596\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.1459475105056787, 'dropout_transformers': 0.2551532922444997, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00014227301485477144, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 29, 'reg': True, 'transformers_model': True, 'activation_gcn': 'swish', 'dropout_gcn': 0.028405453137809206, 'hidden_channels': 16, 'layer_type': 'GCNConv', 'norm': 'LayerNorm', 'num_layers_gcn': 8, 'use_gcn': True, 'weight_decay': 0.03803583561683999}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.468671417236328 acc:  0.03173079070182882\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.067751462997928 acc:  0.041890896098966124\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  6.926936555677845 acc:  0.07710515150838487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  6.860087056313792 acc:  0.09621954759618605\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  6.7256674951122655 acc:  0.10533014760065203\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  6.612302490972703 acc:  0.13677064957684837\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  6.533190031974546 acc:  0.14181720742245943\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  6.439455792211717 acc:  0.13708326820445257\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  6.281109474551293 acc:  0.14626085791483376\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  6.177227610926474 acc:  0.17276645155527767\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  6.075664877122448 acc:  0.16885871871022487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  5.985419544096916 acc:  0.17044414175021771\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  5.818609409947549 acc:  0.18020230891186387\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  5.7107955901853495 acc:  0.1869236094053547\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  5.584661166898666 acc:  0.18725855793493065\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  5.437832576997819 acc:  0.20034388049036464\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  5.334683984325778 acc:  0.20380501529598286\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  5.181966489361178 acc:  0.20793604716075295\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  5.093247518231792 acc:  0.20793604716075295\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  4.966798917708858 acc:  0.22314271040350134\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  4.875822039573423 acc:  0.2222495143246321\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  4.7767444349104355 acc:  0.22403590648237054\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  4.654260593844998 acc:  0.2340843623696492\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  4.545066139774938 acc:  0.23580376482147244\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  4.486815704837922 acc:  0.24656677757184645\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  4.366864410523445 acc:  0.2509434383583056\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  4.300906136728102 acc:  0.254471562869839\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  4.242243492987848 acc:  0.2581559966951745\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  4.204905960636754 acc:  0.2619520800303687\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  4.03999643787261 acc:  0.2701694839559654\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  4.038854638991817 acc:  0.27392090748721615\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  3.9834952431340374 acc:  0.27512672219368955\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  3.9323778244756884 acc:  0.2841926623942121\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  3.84459488314967 acc:  0.28352276533506016\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  3.7922140059932588 acc:  0.2847285800415336\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  3.7339578136321037 acc:  0.29506732465444474\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  3.7201843123282154 acc:  0.29651876828260726\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  3.669512619510774 acc:  0.3015206663242748\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  3.5988083562543314 acc:  0.30638858495411203\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  3.6186426762611634 acc:  0.30766138936650067\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  3.5160786198031517 acc:  0.311278833485921\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  3.4939814875202795 acc:  0.3215059285889735\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  3.4883720659440565 acc:  0.3205010830002456\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  3.4552261091047716 acc:  0.32831654869035126\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  3.4240802503401233 acc:  0.3284505281021816\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  3.3818133846406013 acc:  0.3318000133979412\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  3.355200961328322 acc:  0.33287184869258424\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  3.3174023797435144 acc:  0.3378290869303084\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  3.2778321296938002 acc:  0.339101891342697\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  3.2979508492254443 acc:  0.3409552732063506\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  50 loss :  4.38650080004046 acc:  0.3467833776209722\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  51 loss :  4.25674693199896 acc:  0.34629211977759417\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  52 loss :  4.273689486903529 acc:  0.3450193153652055\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  53 loss :  4.237143688817178 acc:  0.3491503472299757\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  54 loss :  4.230600898496566 acc:  0.35296876046714154\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  55 loss :  4.221159021316036 acc:  0.35685416341022264\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  56 loss :  4.156838693926411 acc:  0.3600696692941518\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  57 loss :  4.115573581572502 acc:  0.36038228792175603\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  58 loss :  4.14968219572498 acc:  0.36216868007949443\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  59 loss :  4.12395613885695 acc:  0.36929191880847645\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  60 loss :  4.173492571615403 acc:  0.36777348547439875\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  61 loss :  4.136963285938386 acc:  0.3690239599848157\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  62 loss :  4.073508564118416 acc:  0.36810843400397475\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  63 loss :  4.058035152189193 acc:  0.3725297545943773\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  64 loss :  3.9845025339434224 acc:  0.37512002322309806\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  65 loss :  3.9935029352864913 acc:  0.37578992028224995\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  66 loss :  4.0528815823216595 acc:  0.3778219413616774\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  67 loss :  3.9660748020295173 acc:  0.37654913694928877\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  68 loss :  4.059161440018685 acc:  0.3824665609717973\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  69 loss :  3.9876580561361004 acc:  0.38114909675546527\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  70 loss :  3.959330607998756 acc:  0.38217627224616485\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  71 loss :  3.924062298190209 acc:  0.38356072616841214\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  72 loss :  3.975560635905112 acc:  0.38648594332670877\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  73 loss :  3.970125235280683 acc:  0.38896456244557087\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  74 loss :  3.945903911898213 acc:  0.3876024384252953\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  75 loss :  3.9866811029372675 acc:  0.39099658352499833\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  76 loss :  3.8896596770132743 acc:  0.39097425362302657\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  77 loss :  3.8466907793475738 acc:  0.39307326440836926\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  78 loss :  3.9638505043522003 acc:  0.3957751825469486\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 576, 'dropout': 0.0656846861423468, 'dropout_transformers': 0.20657698851009756, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 4.500491747337928e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 40, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.16460029699077308}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.680032613623233 acc:  0.007301877944755822\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.245516180082132 acc:  0.019739633343009624\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  7.034234345414256 acc:  0.05955384855860483\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  6.745419447658626 acc:  0.1222338833932519\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  6.385938881007769 acc:  0.15930152066632428\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  6.016428903768991 acc:  0.18317218587410403\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  5.7179597898294 acc:  0.2026661902954246\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  5.418853330248185 acc:  0.22173592657928232\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  5.190947070376564 acc:  0.23685327021414376\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  4.964696385478246 acc:  0.2531764285554786\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  4.757772028901194 acc:  0.26865105062188777\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  4.5937705403975855 acc:  0.2773373824888909\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  4.408017917443778 acc:  0.28872563249447336\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  4.255421667608596 acc:  0.29886340798963895\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  4.167025202103243 acc:  0.30917982270057837\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  4.03190182183535 acc:  0.31703994819462744\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  3.9145384089637347 acc:  0.32632918741486727\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  3.818242417037032 acc:  0.3327378692807539\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  3.7690174070023397 acc:  0.34126789183395484\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  3.69043600832233 acc:  0.34743094477815245\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  3.6313815135082215 acc:  0.35437554429136053\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  3.541292598229328 acc:  0.36089587566710585\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  3.50107820889422 acc:  0.3649152580220173\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  3.4383365034147073 acc:  0.36938123841636333\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  3.3900799441883582 acc:  0.3752316727329567\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  3.3189616803904527 acc:  0.3792063952839247\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  3.2634188473679635 acc:  0.38402965410981843\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  3.251815719458893 acc:  0.38590536587544383\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  3.1895314973729256 acc:  0.39021503695598775\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  3.15730507683208 acc:  0.3955295536252596\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  3.142635187119928 acc:  0.39584217225286383\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  3.0923904863022664 acc:  0.3992809771565103\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  3.080720666710657 acc:  0.4021615345108635\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  3.0410412486272915 acc:  0.40397025657057367\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  3.042198412290966 acc:  0.40544403010070784\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  3.0029520824665332 acc:  0.4088381752004109\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  2.9912061054287977 acc:  0.4092177835339303\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  2.9488323317229295 acc:  0.4131478462809548\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  2.9553644948333275 acc:  0.41375075363419156\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  2.9187421598507246 acc:  0.41500122814460844\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  2.9190932521383273 acc:  0.4151798673603823\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  2.8667527373510464 acc:  0.41823906393050936\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  2.863964952585351 acc:  0.4186410021660005\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  2.8477970389009433 acc:  0.4201147756961347\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  2.846448654436883 acc:  0.42074001295134317\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  2.84338628244764 acc:  0.42192349775584487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  2.795407098668222 acc:  0.42239242569725116\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  2.7654391882073788 acc:  0.42250407520710986\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  2.771078440979237 acc:  0.4250050242279436\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  2.7743146255726123 acc:  0.4243797869727352\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  50 loss :  3.8375133758282844 acc:  0.42469240560033944\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  51 loss :  3.8251534982491995 acc:  0.42587589040484114\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  52 loss :  3.7594429864228225 acc:  0.42763995266060784\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  53 loss :  3.7803319446913157 acc:  0.42743898354286225\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  54 loss :  3.7710182466579756 acc:  0.4297389634459505\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  55 loss :  3.727415377857121 acc:  0.4288011075631378\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  56 loss :  3.735958474283 acc:  0.42998459236763953\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  57 loss :  3.7318098199276526 acc:  0.4296719737400353\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  58 loss :  3.7127222523434473 acc:  0.4293370252104593\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  59 loss :  3.688638623434169 acc:  0.42993993256369606\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  60 loss :  3.641539935847275 acc:  0.4304311904070741\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  61 loss :  3.7005976775220333 acc:  0.43192729383918005\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  62 loss :  3.691552455188664 acc:  0.432262242368756\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  63 loss :  3.681654646196438 acc:  0.43331174776142733\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  64 loss :  3.6523565135839333 acc:  0.43288747962396446\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  65 loss :  3.646419142948762 acc:  0.4339369850166358\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  66 loss :  3.6464967909660047 acc:  0.4338253355067771\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  67 loss :  3.6618298101061173 acc:  0.4327758301141058\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  68 loss :  3.6069532296129765 acc:  0.4357457070763459\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  69 loss :  3.6095676149120766 acc:  0.4339369850166358\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  70 loss :  3.606033984031386 acc:  0.4348971708014202\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  71 loss :  3.581975647511373 acc:  0.4358796864881763\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  72 loss :  3.5833286165281106 acc:  0.43465154187973115\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  73 loss :  3.5642162352117874 acc:  0.4365272536453565\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  74 loss :  3.5521484476919394 acc:  0.4353660987428265\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  75 loss :  3.564778499020875 acc:  0.4375544291360561\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  76 loss :  3.5713990207846837 acc:  0.4382689859991515\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  77 loss :  3.5532898302296645 acc:  0.4375544291360561\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  78 loss :  3.5607518803982336 acc:  0.43686220217493243\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  79 loss :  3.545597675192447 acc:  0.43715249090056496\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  80 loss :  3.5327672121179012 acc:  0.43739811982225396\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  81 loss :  3.5268000173204728 acc:  0.43679521246901726\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Softsign', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': False, 'd_model': 528, 'dropout': 0.08130915145844503, 'dropout_transformers': 0.26817407977524577, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 1.0191927624520731e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 6, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 33, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 0.2457965145089869}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  8.005774406286386 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.806958348934467 acc:  0.0057834446106781595\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  7.629161449579092 acc:  0.0066766406895473725\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  7.4993975455944355 acc:  0.00582810441462162\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  7.408709177604089 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  7.341382716252253 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  7.290829155995295 acc:  0.005716454904762968\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  7.2473565358382 acc:  0.008329053435455418\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  7.207036363161527 acc:  0.0167027666748543\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  7.164008679756751 acc:  0.024294933345242613\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  7.122137850981492 acc:  0.03467833776209722\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  7.072387625620915 acc:  0.044905432865149725\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  7.02194766998291 acc:  0.05758881718509256\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  6.966156497368446 acc:  0.0671906750329366\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  6.903679121457613 acc:  0.07614496572360048\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  6.843060148679293 acc:  0.08576915347341625\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  6.775757045012254 acc:  0.09458946475224973\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  6.70935214482821 acc:  0.10345443583502668\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  6.643521279555101 acc:  0.11131456132907576\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  6.575960482083834 acc:  0.11910769711720966\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  6.510615334144005 acc:  0.12509211084563338\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  6.446690199925349 acc:  0.1320367103588415\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  6.379068521352915 acc:  0.13699394859656566\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  6.315172485204843 acc:  0.1429783623249894\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  6.25512062219473 acc:  0.14818122948440257\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  6.191014190820547 acc:  0.15369671527141995\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  6.130155629378098 acc:  0.15704620056717952\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  6.075519033578726 acc:  0.1618247995891298\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  6.011611501987164 acc:  0.1654199138065784\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  5.956138669527494 acc:  0.16897036822008352\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  5.897766186640813 acc:  0.17325770939865573\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  5.846243322812594 acc:  0.17685282361610433\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  5.788189000349778 acc:  0.17948775204876852\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  5.73638444680434 acc:  0.18268092803072594\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  5.681949120301467 acc:  0.18638769175803319\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  5.636275892991286 acc:  0.18866534175914967\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  5.590197097338163 acc:  0.1928856932318067\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  5.538368280117329 acc:  0.19578858048813166\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  5.490073358095609 acc:  0.1993613648036085\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  5.440702874843891 acc:  0.20210794274613134\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  5.398026426021869 acc:  0.20503315990442803\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  5.351966898257916 acc:  0.20777973784695086\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  5.312942013373742 acc:  0.2102360270638412\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  5.265616292219896 acc:  0.21291561530044883\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  5.225387965715848 acc:  0.21570685304691511\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  5.1849973311791056 acc:  0.21814081236183372\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  5.141800014789288 acc:  0.220686421186611\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  5.099734115600586 acc:  0.22316504030547307\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  5.064252934089073 acc:  0.2254650202085613\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  5.030529238627508 acc:  0.2272514123662997\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  50 loss :  6.087184124726516 acc:  0.2287028559944622\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  51 loss :  6.024169048896202 acc:  0.23053390795614406\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  52 loss :  5.97810991360591 acc:  0.23178438246656097\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  53 loss :  5.949603091753446 acc:  0.23352611482035593\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  54 loss :  5.910825091141921 acc:  0.23593774423330283\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  55 loss :  5.875928409282977 acc:  0.23779112609695643\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  56 loss :  5.83904952269334 acc:  0.23971149766652525\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  57 loss :  5.803527721991906 acc:  0.24114061139271598\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  58 loss :  5.777488051928007 acc:  0.2434182613938325\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  59 loss :  5.743196612138014 acc:  0.2455619319831186\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  60 loss :  5.711334951107318 acc:  0.24743764374874394\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  61 loss :  5.674453555620634 acc:  0.24935801531831275\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  62 loss :  5.652532559174758 acc:  0.25114440747605116\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  63 loss :  5.629083934197059 acc:  0.25306477904561997\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  64 loss :  5.594409806911762 acc:  0.25500748051716055\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  65 loss :  5.56896647306589 acc:  0.25657057365518166\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  66 loss :  5.535475829931406 acc:  0.2585802648326374\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  67 loss :  5.5194638362297646 acc:  0.26047830650023446\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  68 loss :  5.491471620706411 acc:  0.2619744099323404\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  69 loss :  5.46008285008944 acc:  0.264073420717683\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  70 loss :  5.440137004852295 acc:  0.26574816336556284\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  71 loss :  5.408482962388259 acc:  0.26782484424893377\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  72 loss :  5.390299712694608 acc:  0.26943259719089835\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  73 loss :  5.368033753908597 acc:  0.27137529866243887\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  74 loss :  5.342252316841712 acc:  0.27311703101623386\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  75 loss :  5.3145717584169825 acc:  0.27503740258580267\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  76 loss :  5.293263948880709 acc:  0.27664515552776725\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  77 loss :  5.269726914625902 acc:  0.27843154768550565\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  78 loss :  5.247305367543147 acc:  0.279726681999866\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  79 loss :  5.231627339583177 acc:  0.2816470535694348\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  80 loss :  5.205642344401433 acc:  0.283210146707456\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  81 loss :  5.186767875231229 acc:  0.28481789964942056\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  82 loss :  5.162885383459238 acc:  0.28664895161110243\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.1820438967529205, 'dropout_transformers': 0.17218223419240686, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00019574478154976574, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.6141442148596727e-07}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.035861642544086 acc:  0.15345108634973093\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  5.4454494806436395 acc:  0.24783958198423509\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  4.372879727070148 acc:  0.30315074916821116\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  3.743149401591374 acc:  0.3485697697787107\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  3.370356376354511 acc:  0.3745617756738048\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  3.1316699138054482 acc:  0.3948149967621642\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  2.975345629912156 acc:  0.407833329611683\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  2.8551911739202644 acc:  0.4175691668713574\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  2.76643149302556 acc:  0.4238661992273854\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  2.6966251850128176 acc:  0.42759529285666437\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  2.638260162793673 acc:  0.4307214791327066\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  2.589937655742352 acc:  0.4349641605073354\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  2.5407112029882577 acc:  0.43744277962619743\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  2.502972645025987 acc:  0.4369515217828194\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  2.4680872091880213 acc:  0.4363262845276109\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  2.432810205679673 acc:  0.43677288256704555\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  2.404669550748972 acc:  0.44070294531407006\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  2.378176395709698 acc:  0.44128352276533506\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  2.3520061602959266 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  2.3325820776132438 acc:  0.4418194404126566\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  2.3047151941519517 acc:  0.4425786570796954\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  2.2804781831227814 acc:  0.4409709041377308\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  2.2618838136012736 acc:  0.44206506933434564\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  2.2409698761426484 acc:  0.4415514815889958\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  2.2243457491581258 acc:  0.44318156443293216\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  2.200896916939662 acc:  0.441618471294911\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  2.1870535116929273 acc:  0.4427572962954693\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  2.166097374145801 acc:  0.44304758502110175\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  2.150569300468151 acc:  0.44458834825715116\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  2.131082954773536 acc:  0.44289127570729964\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  2.1187722472044137 acc:  0.4424000178639216\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  2.102259646929227 acc:  0.44150682178505235\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  2.085718297958374 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  2.0720517222697916 acc:  0.4408592546278722\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': True, 'd_model': 672, 'dropout': 0.24186544031114676, 'dropout_transformers': 0.17276092248896802, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 8.634418928586347e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': True, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 3.7001543423485955e-09}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.5690701023224864 acc:  0.006297032356027957\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.1460053659254505 acc:  0.054373311301163386\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  6.7313382333324805 acc:  0.12192126476564769\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  6.2855868278011195 acc:  0.15963646919590024\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  5.73976906499555 acc:  0.19945068441149544\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  5.291652261057208 acc:  0.22524172118884397\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  4.984438283981816 acc:  0.23906393050934507\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  4.636886189060826 acc:  0.2596967599312239\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  4.383802495464202 acc:  0.2778956300381841\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  4.133149322386711 acc:  0.29261103543755446\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  4.039817311686854 acc:  0.3093138021124087\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  3.8377439821920087 acc:  0.32385056829600517\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  3.7175532125657607 acc:  0.33244758055512136\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  3.557155664505497 acc:  0.3477882232097001\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  3.470605897903442 acc:  0.3563182457629011\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  3.3789442816088275 acc:  0.3656521447870844\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  3.277840655849826 acc:  0.37248509479043385\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  3.286061394599176 acc:  0.38099278744166315\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  3.1742822570185507 acc:  0.3867762320523413\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  3.134237878553329 acc:  0.3887412634258536\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  3.0359088759268484 acc:  0.39412276980104055\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  3.033731995859454 acc:  0.399883884509747\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  2.9782742177286456 acc:  0.4007994104905879\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  2.9147945819362517 acc:  0.40388093696268673\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  2.953401276373094 acc:  0.41066922716209275\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  2.8927126223041166 acc:  0.4137060938302481\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  2.851704566709457 acc:  0.41471093941897597\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  2.8646012929178055 acc:  0.41803809481276377\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  2.8150601986915835 acc:  0.41844003304825494\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  2.7697312762660364 acc:  0.4207176830493714\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  2.78216097739435 acc:  0.422079807069647\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  2.7149971946593254 acc:  0.4220351472657035\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  2.7200455888625115 acc:  0.42433512716879174\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  2.7141575397983675 acc:  0.42723801442511666\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  2.67007354844001 acc:  0.4271040350132863\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  2.6432026909243675 acc:  0.4274836433468057\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  2.6480734240624213 acc:  0.4307884688386218\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  2.6295071517267536 acc:  0.4309224482504522\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  2.6226366896783153 acc:  0.4314583658977737\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  2.622027430226726 acc:  0.43286514972199275\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  2.5796423358301963 acc:  0.43270884040819063\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  2.560803012694082 acc:  0.4325748609963602\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  2.571740372719303 acc:  0.4326418507022754\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  2.5645180463790895 acc:  0.4352767791349396\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  2.5606000008121614 acc:  0.43424960364424\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  2.4911352442156884 acc:  0.4352767791349396\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  2.5132210746888193 acc:  0.43780005805774513\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  2.485045140789401 acc:  0.4351874595270527\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  2.499869660408266 acc:  0.4355224080566286\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  2.472604372424464 acc:  0.43628162472366744\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  50 loss :  3.588303782863002 acc:  0.43507581001719403\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  51 loss :  3.5768481454541607 acc:  0.4346962016836746\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  52 loss :  3.531684637069702 acc:  0.4384252953129536\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  53 loss :  3.5791641250733406 acc:  0.436482593841413\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  54 loss :  3.563506237153084 acc:  0.4392515016859076\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  55 loss :  3.511491007958689 acc:  0.4359243462921198\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  56 loss :  3.4838830132638257 acc:  0.43605832570395014\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  57 loss :  3.529058114943966 acc:  0.437643748743943\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  58 loss :  3.4428440155521516 acc:  0.43724181050845184\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  59 loss :  3.562250151172761 acc:  0.43949713060759665\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  60 loss :  3.5353825169224895 acc:  0.4389612129602751\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  61 loss :  3.42788874103177 acc:  0.43911752227407724\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  62 loss :  3.415444472528273 acc:  0.4372641404104236\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  63 loss :  3.397919451805853 acc:  0.4408145948239287\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  64 loss :  3.4325157119381813 acc:  0.4379340374695755\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  65 loss :  3.4174858370134906 acc:  0.4391845119799924\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  66 loss :  3.353404369661885 acc:  0.4398544090391443\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  67 loss :  3.4130012281479374 acc:  0.44068061541209835\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  68 loss :  3.349291593797745 acc:  0.43987673894111606\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  69 loss :  3.3624990724748183 acc:  0.441953419824487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  70 loss :  3.3748071947405416 acc:  0.4403903266864658\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  71 loss :  3.3228793436481108 acc:  0.4396087801174553\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  72 loss :  3.289768935788062 acc:  0.44032333698055065\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  73 loss :  3.364080366011589 acc:  0.4409485742357591\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  74 loss :  3.283127567845006 acc:  0.4427572962954693\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  75 loss :  3.3732432826872794 acc:  0.44289127570729964\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  76 loss :  3.31947619376644 acc:  0.4405019761963245\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  77 loss :  3.3489412015484223 acc:  0.4406359556081549\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  78 loss :  3.320443194912326 acc:  0.4405689659022397\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  79 loss :  3.353144141166441 acc:  0.44260098698166717\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  80 loss :  3.2700868652712916 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 696, 'dropout': 0.20928057907776443, 'dropout_transformers': 0.11402937317477521, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 6.107307571744248e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': True, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.0384899781509204e-08}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.519042015075684 acc:  0.04477145345331934\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  6.99467909519489 acc:  0.08726525690552218\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  6.764722743401161 acc:  0.10814371524909006\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  6.603622660270104 acc:  0.13788714467543486\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  6.45898709663978 acc:  0.15287050889846593\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  6.322610110502977 acc:  0.16517428488488936\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  6.188338639185979 acc:  0.17495478194850725\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  6.054320115309495 acc:  0.18766049617042183\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  5.923644410646879 acc:  0.19418082754616708\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  5.787937589792105 acc:  0.2017060045106402\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  5.656936432765081 acc:  0.21349619275171383\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  5.526179475050706 acc:  0.22037380255900677\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  5.401860941373385 acc:  0.2268048143268651\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  5.2740005529843845 acc:  0.23372708393810152\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  5.153741451410147 acc:  0.23866199227385393\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  5.033967315233671 acc:  0.2504298506129558\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  4.9182053382580095 acc:  0.2537793359087154\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  4.807709096028255 acc:  0.26027733738248887\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  4.700370927957388 acc:  0.26717727709175354\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  4.5965915056375355 acc:  0.2720451957215908\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  4.50554380783668 acc:  0.2793470736663466\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  4.407638613994305 acc:  0.2874528280820847\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  4.31798904125507 acc:  0.29261103543755446\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  4.230060544380775 acc:  0.29834982024428913\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  4.1509824679448055 acc:  0.3021459035794833\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  4.068659298236554 acc:  0.3077953687783311\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  3.9955411966030416 acc:  0.3122613491726771\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  3.927852487564087 acc:  0.3167719893709667\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  3.857829998089717 acc:  0.32097001094165195\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  3.795241484275231 acc:  0.3228010629033339\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  3.7344031774080717 acc:  0.32800393006274703\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  3.6767922731546254 acc:  0.3332067972221602\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  3.6193338357485256 acc:  0.33693589085143916\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  3.569405961036682 acc:  0.3395931491860751\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  3.5210468787413376 acc:  0.3433669026192975\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  3.4700287855588474 acc:  0.3471629859544917\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  3.423693741284884 acc:  0.3514503271330639\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  3.3826044669518103 acc:  0.35466583301699306\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  3.3406742132627048 acc:  0.35721144184177034\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  3.3035957978321955 acc:  0.36210169037357925\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  3.267148514894339 acc:  0.3640443918451198\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  3.2316450320757353 acc:  0.36810843400397475\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  3.194895551754878 acc:  0.3709666614563562\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  3.162921060048617 acc:  0.37418216734028537\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  3.1307653152025665 acc:  0.37688408547886476\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  3.101560135988089 acc:  0.3786928075385749\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  3.073356661429772 acc:  0.38085880802983274\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  3.0439999672082756 acc:  0.3839180045999598\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  3.0170607456794154 acc:  0.3871781702878324\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  2.99319253884829 acc:  0.3874461291114932\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Sigmoid', 'amsgrad': True, 'batch_size': 128, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.1974981872994371, 'dropout_transformers': 0.1366602684359503, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.0006439833451097718, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softsign', 'dropout_gcn': 0.090262296667379, 'hidden_channels': 32, 'layer_type': 'GAT', 'norm': 'BatchNorm', 'num_layers_gcn': 4, 'use_gcn': True, 'weight_decay': 2.017723618595775e-08}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.400372175069956 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.3105234256157505 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  7.302922670657818 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  7.297633284788866 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  7.293458105967595 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  7.290379109749427 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  7.289141871378972 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 16, 'concatenate_features': True, 'd_model': 648, 'dropout': 0.16123317454962627, 'dropout_transformers': 0.2183992164822446, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00017898534027005025, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 2, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 1.1934293956918332e-09}\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  0 loss :  7.633759321866336 acc:  0.025590067659602974\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  1 loss :  7.118744970201613 acc:  0.07659156376303508\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  2 loss :  6.531222016661317 acc:  0.12946877163209253\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  3 loss :  5.956003449179909 acc:  0.1626286760601121\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  4 loss :  5.538775635765982 acc:  0.1798450304803162\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  5 loss :  5.182132290793466 acc:  0.22356697854096422\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  6 loss :  4.952363642779264 acc:  0.23470959962485766\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  7 loss :  4.669382832267067 acc:  0.2518366344371748\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  8 loss :  4.298220522753843 acc:  0.28061987807873523\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  9 loss :  4.13585981955895 acc:  0.2939508295558583\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  10 loss :  3.9238361028524547 acc:  0.30705848201326397\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  11 loss :  3.7845313699095398 acc:  0.31978652613715025\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  12 loss :  3.6639029812979533 acc:  0.33072817810329813\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  13 loss :  3.6075429783000814 acc:  0.341915458991135\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  14 loss :  3.4844718512955244 acc:  0.3483688006609651\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  15 loss :  3.478414130377603 acc:  0.35783667909697875\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  16 loss :  3.389784886286809 acc:  0.3665006810620101\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  17 loss :  3.3017698251284084 acc:  0.370073465377487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  18 loss :  3.3287669561959645 acc:  0.37599088939999553\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  19 loss :  3.1583129275928843 acc:  0.3754326418507023\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  20 loss :  3.1793879912449765 acc:  0.3828015095013733\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  21 loss :  3.046074862246747 acc:  0.3829578188151754\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  22 loss :  3.1559971145816617 acc:  0.3859946854833307\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  23 loss :  3.0014092296987145 acc:  0.38771408793515394\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  24 loss :  2.9232601102415496 acc:  0.3942344193108992\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  25 loss :  2.977856216730771 acc:  0.3984324408815845\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  26 loss :  2.9681943379915676 acc:  0.39573052274300513\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  27 loss :  2.9066851014023896 acc:  0.3967130384297613\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  28 loss :  2.965855874381699 acc:  0.40352365853113903\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  29 loss :  2.916192795846846 acc:  0.4043052051001496\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  30 loss :  2.8864636654620406 acc:  0.40506442176718843\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  31 loss :  2.842072069228112 acc:  0.4079896389254851\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  32 loss :  2.8762085004286333 acc:  0.407252752160418\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  33 loss :  2.8864804139504066 acc:  0.4090614742201282\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  34 loss :  2.7605227707149265 acc:  0.4113614541232164\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  35 loss :  2.8119264974460734 acc:  0.41124980461335775\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  36 loss :  2.78308994369907 acc:  0.4167429604984034\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  37 loss :  2.814712272657381 acc:  0.41162941294687716\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  38 loss :  2.816033065735877 acc:  0.4160060737333363\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  39 loss :  2.780535215264434 acc:  0.411562423240962\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  40 loss :  2.701683666322615 acc:  0.41714489873389454\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  41 loss :  2.7083718301532986 acc:  0.418596342362057\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  42 loss :  2.674960674939456 acc:  0.416363352164884\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  43 loss :  2.732633706573006 acc:  0.4210972913828908\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  44 loss :  2.7864766054220134 acc:  0.41832838353839624\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  45 loss :  2.702771546957376 acc:  0.42192349775584487\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  46 loss :  2.641018348973948 acc:  0.41810508451867895\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  47 loss :  2.6910127017881487 acc:  0.42067302324542794\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  48 loss :  2.7149250699089955 acc:  0.4201817654020499\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  49 loss :  2.660213039471553 acc:  0.4205613737355693\n",
            "\u001b[36m(eval_config pid=338248)\u001b[0m epoch:  50 loss :  3.924301630967147 acc:  0.41852935265614183\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-27-a45cd2199ea0>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-11 15:37:59,816\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-11 15:38:14,483\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-11 15:38:14,485\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_21       |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 10              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_21\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_21`\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(eval_config pid=360327)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(eval_config pid=360327)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 64, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.180672988078028, 'dropout_transformers': 0.07792733151736303, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 0.00011369165460865716, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 3, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 39, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 4.1294739512530716e-08}\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  0 loss :  7.412035228489162 acc:  0.08958756671058214\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  1 loss :  6.380841902085951 acc:  0.16930531674965946\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  2 loss :  5.500373853670133 acc:  0.23075720697586138\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  3 loss :  4.859526184055355 acc:  0.2728937319965165\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  4 loss :  4.279371403314017 acc:  0.3030614295603242\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  5 loss :  3.872425279417238 acc:  0.33164370408413907\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  6 loss :  3.5996754086100973 acc:  0.35176294576066813\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  7 loss :  3.3814119692448967 acc:  0.3661657325324342\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  8 loss :  3.224690594039597 acc:  0.3797423129312462\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  9 loss :  3.095646141292332 acc:  0.39034901636781816\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  10 loss :  2.950100218499457 acc:  0.397070316861309\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  11 loss :  2.9253297569034817 acc:  0.4034120090212804\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  12 loss :  2.817364270870502 acc:  0.4087935153964674\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  13 loss :  2.7634105132176328 acc:  0.41535850657615614\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  14 loss :  2.7031722518947574 acc:  0.4207623428533149\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  15 loss :  2.663823127746582 acc:  0.4230623227564031\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  16 loss :  2.6015030103963572 acc:  0.42667976687582343\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  17 loss :  2.562900476522379 acc:  0.4269030658955407\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  18 loss :  2.5392717581528883 acc:  0.43074380903467835\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  19 loss :  2.5083716432531395 acc:  0.4330661188397383\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  20 loss :  2.457561212819773 acc:  0.43391465511466404\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  21 loss :  2.4472759328522047 acc:  0.4353437688408548\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  22 loss :  2.421799542186977 acc:  0.439050532568162\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  23 loss :  2.3820069861578776 acc:  0.4376884085478865\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  24 loss :  2.363553930829455 acc:  0.43775539825380166\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  25 loss :  2.3549766498845774 acc:  0.4373311301163388\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  26 loss :  2.3111639706404894 acc:  0.438469955116897\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  27 loss :  2.307998405469881 acc:  0.4401893575687203\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  28 loss :  2.2895647262359833 acc:  0.44128352276533506\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  29 loss :  2.269612353164833 acc:  0.441372842373222\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  30 loss :  2.2394383687239428 acc:  0.4423553580599781\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  31 loss :  2.237036844233533 acc:  0.44168546100082623\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  32 loss :  2.213573836780095 acc:  0.44327088404081905\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  33 loss :  2.1956274909573 acc:  0.4421767188442043\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  34 loss :  2.1820627817740808 acc:  0.44228836835406293\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  35 loss :  2.177938893124774 acc:  0.44126119286336335\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  36 loss :  2.144554013972516 acc:  0.4429359355112431\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  37 loss :  2.1277458175912605 acc:  0.43911752227407724\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Tanh', 'amsgrad': True, 'batch_size': 32, 'concatenate_features': True, 'd_model': 600, 'dropout': 0.21900951238716584, 'dropout_transformers': 0.16533033614951256, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lr': 7.860356569111925e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features_globally': False, 'normalize_features_independantly': False, 'num_heads': 12, 'num_layers_transformer': 4, 'optimizer': 'AdamW', 'positive_function': 'abs', 'epochs_complete_problem': 48, 'reg': True, 'transformers_model': True, 'use_gcn': False, 'weight_decay': 2.7814242331144896e-07}\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  0 loss :  7.998823694126335 acc:  0.0032824955898443607\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  1 loss :  7.7965339186662685 acc:  0.0037514235312506978\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  2 loss :  7.639612594764389 acc:  0.0051805372574414395\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  3 loss :  7.527121012796185 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  4 loss :  7.454050792191556 acc:  0.006297032356027957\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  5 loss :  7.403727374390928 acc:  0.005448496081102204\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  6 loss :  7.340766938146717 acc:  0.0075028470625013955\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  7 loss :  7.294688453217466 acc:  0.021704664716521896\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  8 loss :  7.237106825777157 acc:  0.024428912757072995\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  9 loss :  7.186609185384419 acc:  0.04148895786347498\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  10 loss :  7.142934145327813 acc:  0.04892481522006118\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  11 loss :  7.045439357529143 acc:  0.0629926534622513\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  12 loss :  6.998474001170632 acc:  0.0747605118013532\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  13 loss :  6.9288921241988675 acc:  0.08380412209990398\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  14 loss :  6.835002545111194 acc:  0.08409441082553648\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  15 loss :  6.794551666625246 acc:  0.0902128039657906\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  16 loss :  6.745449654356448 acc:  0.09820690887167005\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  17 loss :  6.667157067510182 acc:  0.10374472456065918\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  18 loss :  6.626785615247167 acc:  0.11131456132907576\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  19 loss :  6.589191739430684 acc:  0.11412812897751379\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  20 loss :  6.489425879038737 acc:  0.11312328338878593\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  21 loss :  6.496654935939583 acc:  0.11875041868566197\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  22 loss :  6.435984240320629 acc:  0.12741442065069333\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  23 loss :  6.404157921225725 acc:  0.13067458633856596\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  24 loss :  6.364143502926398 acc:  0.1345153294777036\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  25 loss :  6.3220387675805005 acc:  0.13927159859768215\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  26 loss :  6.261000698911929 acc:  0.14389388830583033\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  27 loss :  6.210717375406962 acc:  0.14815889958243084\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  28 loss :  6.200788069627956 acc:  0.15206663242748364\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  29 loss :  6.1269175535190605 acc:  0.1540093338990242\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  30 loss :  6.075366779715715 acc:  0.1564432932139428\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  31 loss :  6.043243905027469 acc:  0.1612218922358931\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  32 loss :  6.016794858578437 acc:  0.1649063260612286\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  33 loss :  6.006516031162468 acc:  0.16713931625840162\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  34 loss :  5.973660577557044 acc:  0.16865774959247928\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  35 loss :  5.91181567186367 acc:  0.1741732353794967\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  36 loss :  5.853667590432538 acc:  0.17473148292878996\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  37 loss :  5.8252137007113705 acc:  0.17526740057611148\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  38 loss :  5.829522287060401 acc:  0.1788848446955318\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  39 loss :  5.75513180430064 acc:  0.18024696871580734\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  40 loss :  5.6940288686466785 acc:  0.18247995891298038\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  41 loss :  5.724148693198929 acc:  0.1832391755800192\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  42 loss :  5.670875680660773 acc:  0.18643235156197666\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  43 loss :  5.608617953911513 acc:  0.18817408391577162\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  44 loss :  5.572125143633631 acc:  0.18989348636759484\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  45 loss :  5.5507230844326365 acc:  0.1950070339191211\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  46 loss :  5.554286471384014 acc:  0.19799924078333297\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  47 loss :  5.471146877654299 acc:  0.19969631333318447\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  48 loss :  5.494749751633512 acc:  0.20112542705937522\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  49 loss :  5.456985200950485 acc:  0.20293414911908536\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  50 loss :  6.511593053440848 acc:  0.20396132460978497\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  51 loss :  6.535636379333313 acc:  0.20378268539401112\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  52 loss :  6.4240620578834395 acc:  0.20581470647343858\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  53 loss :  6.3279654108835555 acc:  0.2066409128463926\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  54 loss :  6.4174427700613785 acc:  0.2077350780430074\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  55 loss :  6.309593560452947 acc:  0.20885157314159392\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  56 loss :  6.276847982121085 acc:  0.21101757363285176\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  57 loss :  6.253713410771535 acc:  0.21287095549650537\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  58 loss :  6.270591458874549 acc:  0.2164214099100105\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  59 loss :  6.253443132617517 acc:  0.2162874304981801\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  60 loss :  6.225733143126893 acc:  0.21881070942098566\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  61 loss :  6.130303008827621 acc:  0.21990487461760042\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  62 loss :  6.19055274003994 acc:  0.22082040059844138\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  63 loss :  6.07587679560313 acc:  0.22247281334434943\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  64 loss :  6.12736983213596 acc:  0.2240135765803988\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  65 loss :  6.05367253925986 acc:  0.225487350110533\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  66 loss :  6.01235741483951 acc:  0.22609025746376973\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  67 loss :  6.015399798661649 acc:  0.22660384520911953\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  68 loss :  5.981417473204836 acc:  0.2297523613871335\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  69 loss :  5.919635201642613 acc:  0.23044458834825715\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  70 loss :  5.962218453070361 acc:  0.23189603197641961\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  71 loss :  5.908001063112727 acc:  0.23323582609472343\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  72 loss :  5.843350718835157 acc:  0.23573677511555724\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  73 loss :  5.866073933904042 acc:  0.23580376482147244\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  74 loss :  5.8374146530014315 acc:  0.23841636335216487\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  75 loss :  5.762506784793145 acc:  0.24006877609807292\n",
            "\u001b[36m(eval_config pid=360327)\u001b[0m epoch:  76 loss :  5.831758093691158 acc:  0.24096197217694215\n"
          ]
        }
      ],
      "source": [
        "run_all_xp(xps_name=\"hyperparameter_tuning_projet_long_with_reduced_search_space_and_layer_normalization\", num_xp=0, algo=None, xp_size=10, xps_number=30, accuracy_target=0.98, max_num_epochs=None, storage_path='/content/tuning',drive_path=\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQlM5RK2VTjU",
        "outputId": "6bbb653e-9b12-42a9-807a-abd51980e98b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-06 18:25:57,062\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-06 18:26:10,677\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-06 18:26:10,679\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_0        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_0\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_0`\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7139129724354693 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Softplus', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1200, 'dropout': 0.25926108944253146, 'dropout_StationIdEmbedding': 0.6617067241662258, 'dropout_timeStampEmbedding': 0.703771911609112, 'dropout_transformers': 0.2106148532882447, 'early_stopping': 9, 'encoder_only': False, 'epochs_classifcation_only': 78, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6455072704467397, 'scheduler': 'StepLR', 'step_size': 12, 'dropout_lstm': 0.7139129724354693, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'CELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 6, 'alpha': 0.9048161384865954, 'centered': False, 'eps': 2.830262974672483e-07, 'lr': 0.0001538268984097869, 'momentum': 0.015507939593735698, 'optimizer': 'RMSprop', 'weight_decay': 5.006192140894922e-06, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.141670772007533 acc:  0.0025679387267489896\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.710882895333427 acc:  0.0014067838242190116\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.517875943865095 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.443558979034424 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.374841662815639 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.317255469730922 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.327423177446637 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.284202643803188 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  7.313279492514474 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.361218643188477 acc:  0.0024562892168903377\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  7.327044595990862 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  7.368080030168806 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  7.271814400809152 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  7.275568212781634 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  7.3209308215550015 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  7.23683124269758 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 504, 'dropout': 0.3291271414458241, 'dropout_StationIdEmbedding': 0.25297478241770976, 'dropout_timeStampEmbedding': 0.3974229173352428, 'dropout_transformers': 0.233546966213382, 'early_stopping': 6, 'encoder_only': False, 'epochs_classifcation_only': 62, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'alpha': 0.9820220267903932, 'centered': True, 'eps': 1.3704179718814581e-08, 'lr': 0.0035072715527129047, 'momentum': 0.49900480812856207, 'optimizer': 'RMSprop', 'weight_decay': 0.032580408773536185, 'positive_function': 'relu', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softmin', 'dropout_gcn': 0.19159830365229769, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'InstanceNorm', 'num_layers_gcn': 8, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.7753709857746705 acc:  0.0011834848045017081\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.473089096909862 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.421832731214621 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.4286474373381015 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.425255209712659 acc:  0.0024562892168903377\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.404662447460627 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.404230529979124 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.382139117030774 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'CELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1368, 'dropout': 0.09552411043273457, 'dropout_StationIdEmbedding': 0.14634456035876497, 'dropout_timeStampEmbedding': 0.6274796931061111, 'dropout_transformers': 0.24045343711296796, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 57, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.605982408994092, 'scheduler': 'ExponentialLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 4, 'alpha': 0.9628295861427273, 'centered': False, 'eps': 8.494756680333419e-08, 'lr': 0.0007819182523463567, 'momentum': 0.10461780143512661, 'optimizer': 'RMSprop', 'weight_decay': 1.1562009209415351e-07, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.512898442053026 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.307995479337631 acc:  0.0017417323537949668\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.2748148056768605 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.263883055410077 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.2590862797152615 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.238992377250425 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.237813512740597 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.243990756619361 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'PReLU', 'batch_size': 32, 'concatenate_features': False, 'd_model': 1104, 'dropout': 0.6614457120385521, 'dropout_StationIdEmbedding': 0.3826982164322794, 'dropout_timeStampEmbedding': 0.8425306180018143, 'dropout_transformers': 0.3124666466183116, 'early_stopping': 9, 'encoder_only': False, 'epochs_classifcation_only': 69, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.0649490436609362, 'scheduler': 'StepLR', 'step_size': 23, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.9795235166428282, 'beta_2': 0.9995885093712042, 'eps': 3.6340882196783776e-08, 'lr': 9.30356039741827e-05, 'optimizer': 'AdamW', 'weight_decay': 0.010810401620123476, 'positive_function': 'abs', 'epochs_complete_problem': 20, 'reg': True, 'transformers_model': True, 'activation_gcn': 'SiLU', 'dropout_gcn': 0.44155211776964376, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 1, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.684342008241465 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.348259449005127 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.314682329204721 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.351960645595067 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.2798167752548 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.276536290074738 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.254162801823146 acc:  0.011410579907554206\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.261039290629642 acc:  0.010539713730656722\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  7.252629904679849 acc:  0.008619342161087912\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.18986867850935 acc:  0.025813366679320278\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  7.039705807054546 acc:  0.039367617176160594\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  6.9229924846702895 acc:  0.05647232208650604\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  6.72789388978985 acc:  0.06502467454167876\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  6.6006833331685675 acc:  0.07509546033092915\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  6.376358408323476 acc:  0.08641672063059644\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  6.231044191709707 acc:  0.09211084563338767\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  6.081253743507493 acc:  0.1073621686800795\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  5.984289975233481 acc:  0.11841547015608601\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  5.87349005820046 acc:  0.11779023290087756\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  19 loss :  5.670591656590851 acc:  0.13516289663488376\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  20 loss :  5.532946049327582 acc:  0.14447446575709533\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  21 loss :  5.477495771058848 acc:  0.15354040595761784\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  22 loss :  5.416565801056338 acc:  0.16311993390349017\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  23 loss :  5.206013216099269 acc:  0.1654199138065784\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  24 loss :  5.174766694995719 acc:  0.16926065694571601\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  25 loss :  5.121310798215195 acc:  0.17147131724091733\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  26 loss :  5.131433748863112 acc:  0.17196257508429538\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  27 loss :  5.0524912317034225 acc:  0.1732130495947123\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  28 loss :  5.168368930548009 acc:  0.1741955652814684\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  29 loss :  5.047147703842378 acc:  0.17486546234062034\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  30 loss :  5.136017517304756 acc:  0.17533439028202666\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  31 loss :  5.100281688529001 acc:  0.17428488488935534\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  32 loss :  5.12947416305542 acc:  0.17587030792934819\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  33 loss :  5.134997173094414 acc:  0.17834892704821026\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  34 loss :  5.0846205328551815 acc:  0.17879552508764487\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  35 loss :  5.0609567870556464 acc:  0.18062657704932675\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  36 loss :  5.010678230876654 acc:  0.1816090927360829\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  37 loss :  5.11301377793433 acc:  0.18281490744255632\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  38 loss :  4.993942603259019 acc:  0.1830158765603019\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  39 loss :  5.058995364417492 acc:  0.18422169126677534\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  40 loss :  5.154976515702798 acc:  0.18395373244311458\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  41 loss :  4.978944160568882 acc:  0.18453430989437955\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  42 loss :  5.1074022407263096 acc:  0.18540517607127704\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  43 loss :  5.085286227750107 acc:  0.18607507313042895\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  44 loss :  4.953038185415133 acc:  0.1869905991112699\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  45 loss :  4.950248933174241 acc:  0.18678962999352433\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  46 loss :  4.990644219895484 acc:  0.187146908425072\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  47 loss :  5.001370873249752 acc:  0.18737020744478933\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  48 loss :  4.903319308455561 acc:  0.1874371971507045\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  49 loss :  4.885884721514205 acc:  0.18766049617042183\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  50 loss :  4.9730932846875255 acc:  0.18761583636647836\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  51 loss :  4.98325733399727 acc:  0.18759350646450662\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  52 loss :  4.913334231981089 acc:  0.18799544469999777\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  53 loss :  4.942698646599139 acc:  0.18815175401379988\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  54 loss :  4.991234564445388 acc:  0.18799544469999777\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  55 loss :  4.915015119901845 acc:  0.18812942411182815\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  56 loss :  4.954727313887905 acc:  0.188308063327602\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  57 loss :  4.988996818032064 acc:  0.18846437264140412\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  58 loss :  4.9519564803217495 acc:  0.1885313623473193\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  59 loss :  4.971609270068961 acc:  0.18837505303351718\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  60 loss :  5.000043912672661 acc:  0.18828573342563026\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  61 loss :  4.865597953259106 acc:  0.1879507848960543\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  62 loss :  5.049313787003638 acc:  0.18815175401379988\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  63 loss :  4.863285068055274 acc:  0.18837505303351718\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  64 loss :  4.876593502474503 acc:  0.18835272313154544\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  65 loss :  4.952342332248956 acc:  0.18835272313154544\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  66 loss :  4.8959399243475685 acc:  0.1883973829354889\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  67 loss :  4.933929456791407 acc:  0.1883973829354889\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.42443929217145804 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'SiLU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 576, 'dropout': 0.9606034360693589, 'dropout_StationIdEmbedding': 0.7021465025350949, 'dropout_timeStampEmbedding': 0.9768470093851694, 'dropout_transformers': 0.1405650029640072, 'early_stopping': 9, 'encoder_only': False, 'epochs_classifcation_only': 54, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 8, 'factor': 0.6666864900356849, 'patience': 5, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00018455992332687843, 'dropout_lstm': 0.42443929217145804, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 5, 'lr': 0.0006312750469574822, 'momentum': 0.2638135939945019, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 1.63967054716315e-08, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.280596562435752 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.256532337791041 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.224960668463456 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  8.196979803788034 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  8.18907984683388 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  8.158261329249331 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  8.13242059506868 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  8.109882224233527 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  8.099840891988654 acc:  0.0013844539222472813\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  8.091785054457816 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  8.073656242772152 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  8.06886716139944 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  8.067283655467786 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  8.039673604463276 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  8.03457391136571 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  8.025623582538806 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  8.006140553323846 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  7.978066665247867 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  7.978230787578382 acc:  0.002724248040551102\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  19 loss :  7.967106076290733 acc:  0.002992206864211866\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  20 loss :  7.954159867136102 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  21 loss :  7.949796882428621 acc:  0.003103856374070518\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  22 loss :  7.931167075508519 acc:  0.00326016568787263\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  23 loss :  7.917120296076725 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  24 loss :  7.925385746202971 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  25 loss :  7.911214065551758 acc:  0.0033271553937878214\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  26 loss :  7.922129375056216 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  27 loss :  7.901907855586002 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  28 loss :  7.89169518320184 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  29 loss :  7.892362203096089 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  30 loss :  7.887232665011758 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  31 loss :  7.884603696120413 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  32 loss :  7.880587939212197 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  33 loss :  7.846661166140907 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  34 loss :  7.853250147167005 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  35 loss :  7.861166537435431 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  36 loss :  7.85407028700176 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  37 loss :  7.824381682747289 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  38 loss :  7.847518293481124 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  39 loss :  7.811666669343647 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  40 loss :  7.8315651793228955 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  41 loss :  7.833738156368858 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  42 loss :  7.828666436044793 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  43 loss :  7.824642623098273 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  44 loss :  7.811587092750951 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  45 loss :  7.802470824592992 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  46 loss :  7.809590088693719 acc:  0.0037290936292789676\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  47 loss :  7.792563317951403 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  48 loss :  7.774012128930343 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  49 loss :  7.785027273077714 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  50 loss :  7.80104072470414 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  51 loss :  7.783702398601331 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  52 loss :  7.780288314819336 acc:  0.0037960833351941585\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  53 loss :  7.785500491292853 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Tanhshrink', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1368, 'dropout': 0.6238939123266131, 'dropout_StationIdEmbedding': 0.1292615821199019, 'dropout_timeStampEmbedding': 0.8781617151784016, 'dropout_transformers': 0.8811515134982568, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 35, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 14, 'eta_min': 0.0052881174150808735, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 4, 'lr': 2.9157911340962906e-06, 'momentum': 0.4682233132149382, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 1.0037748582491188e-08, 'positive_function': 'exp', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softplus', 'dropout_gcn': 0.9030576356970846, 'hidden_channels': 64, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 8, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Softsign', 'batch_size': 32, 'concatenate_features': False, 'd_model': 480, 'dropout': 0.6733854350253079, 'dropout_StationIdEmbedding': 0.9748155140913536, 'dropout_timeStampEmbedding': 0.12653239977988118, 'dropout_transformers': 0.3572181452939681, 'early_stopping': 8, 'encoder_only': False, 'epochs_classifcation_only': 48, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 6, 'factor': 0.4045063769233146, 'patience': 7, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0017478509844923245, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.8625488143127279, 'beta_2': 0.9983153990220303, 'eps': 1.0235009212261073e-08, 'lr': 0.0009705224723279593, 'optimizer': 'Adam', 'weight_decay': 0.06676877242895549, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.723357775125159 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.640044327241829 acc:  0.004890248531808946\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.653185735265892 acc:  0.003371815197731282\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.64516965452447 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.667519506201686 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.690660545624882 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.653785935367447 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  \n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m 7.654637141400073 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  7.679623379764787 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.620445423815624 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Tanh', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1368, 'dropout': 0.4280420135087235, 'dropout_StationIdEmbedding': 0.7887871836946115, 'dropout_timeStampEmbedding': 0.4772474533184021, 'dropout_transformers': 0.662459819786631, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 26, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 2.0653326999894176e-06, 'max_lr': 0.27236898166820467, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 14, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 4, 'lr': 5.827440793657726e-07, 'momentum': 0.21656257520048455, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 2.016587174016015e-07, 'positive_function': 'abs', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softsign', 'dropout_gcn': 0.7499520501904579, 'hidden_channels': 1024, 'layer_type': 'GCNConv', 'norm': 'GraphNorm', 'num_layers_gcn': 4, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.1156139592178 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.042719076607973 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.773064766221374 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.495565414428711 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.424582849022086 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.392427910375231 acc:  0.002099010785342652\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.391183995108568 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.364311738778617 acc:  0.0012058147064734385\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2747819132178011 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Softplus', 'batch_size': 64, 'concatenate_features': True, 'd_model': 504, 'dropout': 0.3957791952489571, 'dropout_StationIdEmbedding': 0.702372492734025, 'dropout_timeStampEmbedding': 0.09474334414227226, 'dropout_transformers': 0.0463891876881809, 'early_stopping': 6, 'encoder_only': False, 'epochs_classifcation_only': 58, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.016169922985659214, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.2747819132178011, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'SiLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 3, 'lr': 1.1078303311413616e-05, 'momentum': 0.26188080369782574, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.0004189190842914088, 'positive_function': 'relu', 'epochs_complete_problem': 47, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.145222040528026 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.14349975799049 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.142906924199792 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  8.14208585856347 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  8.141110201787683 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  8.139245571370898 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  8.143215696238938 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5503585263795484 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'ReLU6', 'batch_size': 32, 'concatenate_features': False, 'd_model': 696, 'dropout': 0.4321527117415681, 'dropout_StationIdEmbedding': 0.03868435467749587, 'dropout_timeStampEmbedding': 0.6928207271119554, 'dropout_transformers': 0.014403770793150472, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 39, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 12, 'eta_min': 0.07250020026056199, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.5503585263795484, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softsign', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 2, 'alpha': 0.9113688075049072, 'centered': True, 'eps': 2.808398740903699e-06, 'lr': 4.10486923010962e-07, 'momentum': 0.1742385654185275, 'optimizer': 'RMSprop', 'weight_decay': 1.187599422660745e-08, 'positive_function': 'abs', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.634506872144796 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  10.352408595004324 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'LogSigmoid', 'batch_size': 16, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.43404767392452515, 'dropout_StationIdEmbedding': 0.5115991835013279, 'dropout_timeStampEmbedding': 0.03669710922497316, 'dropout_transformers': 0.7793126564077055, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 64, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 28, 'eta_min': 0.02215536930446558, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 24, 'num_layers_transformer': 6, 'alpha': 0.9275788812049294, 'centered': False, 'eps': 5.783023301794646e-06, 'lr': 5.70888403847423e-07, 'momentum': 0.14234176774838492, 'optimizer': 'RMSprop', 'weight_decay': 0.00039246007806665494, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.17891469171526153, 'hidden_channels': 2048, 'layer_type': 'GAT', 'norm': 'LayerNorm', 'num_layers_gcn': 6, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.12246152629023 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.034792423248291 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.753981071969737 acc:  8.931960788692137e-05\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.604520383088485 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.603159697159477 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.612694615903108 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.497958805250085 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.606812186863111 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  7.631114026774531 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.655013374660326 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  7.61395730143008 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  7.627248017684273 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  7.6701069085494336 acc:  6.698970591519103e-05\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  7.777148889458698 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  7.710559140080991 acc:  6.698970591519103e-05\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  7.742739677429199 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  7.72588586807251 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  7.723996473395306 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  7.705101013183594 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6828398700211156 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'SELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1080, 'dropout': 0.43075567017964045, 'dropout_StationIdEmbedding': 0.3223490839324896, 'dropout_timeStampEmbedding': 0.11959456607335395, 'dropout_transformers': 0.32149231283350965, 'early_stopping': 9, 'encoder_only': False, 'epochs_classifcation_only': 31, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.5410076163403952, 'patience': 9, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00010877615201678248, 'dropout_lstm': 0.6828398700211156, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 4, 'alpha': 0.9667077810181143, 'centered': False, 'eps': 3.516832501133623e-08, 'lr': 8.615261318640419e-06, 'momentum': 0.30860464238821306, 'optimizer': 'RMSprop', 'weight_decay': 0.00027063099652533274, 'positive_function': 'abs', 'epochs_complete_problem': 18, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.019879081032492 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.020033923062412 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.020997741005637 acc:  0.0015184333340776633\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  8.020327307961203 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  8.020408977161754 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  8.020615230907094 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  8.019808075644754 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  8.020765044472434 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  8.019878994334828 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  8.020042766224254 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  8.019204053011807 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  8.020388516512783 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  8.019359588623047 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  8.01939955624667 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  8.018892461603338 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  8.01924688165838 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  8.019352045926182 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  8.019651586359197 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  8.018320430408824 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  19 loss :  8.019055886702104 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  20 loss :  8.019464492797852 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  21 loss :  8.019747127186168 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  22 loss :  8.019196683710272 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  23 loss :  8.019123857671564 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  24 loss :  8.019150733947754 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  25 loss :  8.01840790835294 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  26 loss :  8.019336873834783 acc:  0.0018533818636536185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9428669887968822 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'RReLU', 'batch_size': 32, 'concatenate_features': False, 'd_model': 144, 'dropout': 0.30505538233349916, 'dropout_StationIdEmbedding': 0.5032306905819148, 'dropout_timeStampEmbedding': 0.8559672395122064, 'dropout_transformers': 0.6058989839613876, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 52, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.9428669887968822, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Tanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 5, 'alpha': 0.9132665251491426, 'centered': True, 'eps': 1.0681541341594436e-06, 'lr': 0.00022473415354181788, 'momentum': 0.09082775790003822, 'optimizer': 'RMSprop', 'weight_decay': 5.510074339651595e-09, 'positive_function': 'sig', 'epochs_complete_problem': 28, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.838113997059484 acc:  0.003371815197731282\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.733797920561741, 'dropout_StationIdEmbedding': 0.22404208966807704, 'dropout_timeStampEmbedding': 0.6115560596108587, 'dropout_transformers': 0.7193928893078161, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 27, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 0.003563260646682764, 'max_lr': 0.05492730749376794, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 18, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 12, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9711031512281438, 'beta_2': 0.9692721421474142, 'eps': 8.869389620199954e-09, 'lr': 0.05800861176479262, 'optimizer': 'AdamW', 'weight_decay': 2.638729604280237e-08, 'positive_function': 'exp', 'epochs_complete_problem': 41, 'reg': True, 'transformers_model': True, 'activation_gcn': 'SELU', 'dropout_gcn': 0.2567966435972764, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'PairNorm', 'num_layers_gcn': 1, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.576977797916958 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.433067430768694 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.500073977879116 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.498208086831229 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.443463856833322 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.390187740325928 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.369619887215751 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': False, 'd_model': 408, 'dropout': 0.665146435790974, 'dropout_StationIdEmbedding': 0.42906771209417016, 'dropout_timeStampEmbedding': 0.4702705877777681, 'dropout_transformers': 0.4870487116399056, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 35, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 3.3306067818274087e-06, 'max_lr': 0.1467969648554335, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 27, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 4, 'lr': 0.0008003162560382942, 'momentum': 0.2965617635371624, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.001704207234665908, 'positive_function': 'sig', 'epochs_complete_problem': 36, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.087551096866004 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.076332323174727 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.044042692686382 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  7.99167245061774 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  7.905370180230392 acc:  0.00585043431659335\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  7.763498868440327 acc:  0.006564991179688721\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  7.5699186074106315 acc:  0.006073733336310653\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  7.446257962678608 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  7.378013269524825 acc:  0.0045106401982895295\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.354314633419639 acc:  0.0075028470625013955\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  7.321782092044228 acc:  0.007458187258557935\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  7.292111888684724 acc:  0.012058147064734386\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  7.272750357577675 acc:  0.020320210794274613\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  7.230117290898373 acc:  0.024272603443270886\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  7.17553441900956 acc:  0.031016233838733448\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  7.081731510162354 acc:  0.03872005001898041\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  6.968053165235017 acc:  0.050845186789629994\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  6.816717172923841 acc:  0.061608199540004016\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  6.666805613668341 acc:  0.07726146082218699\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  19 loss :  6.522519161826686 acc:  0.08945358729875176\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  20 loss :  6.346654199299059 acc:  0.09892146573476543\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  21 loss :  6.184644076698705 acc:  0.11046602505415001\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  22 loss :  6.035679280130487 acc:  0.12038050152959828\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  23 loss :  5.873156125921952 acc:  0.1345823191836188\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  24 loss :  5.812066956570274 acc:  0.13549784516445973\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  25 loss :  5.7340931189687625 acc:  0.14496572360047338\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  26 loss :  5.597234991977089 acc:  0.1495210236027064\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  27 loss :  5.492813235835025 acc:  0.16200343880490364\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  28 loss :  5.402165141858553 acc:  0.1648393363553134\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  29 loss :  5.326574636760511 acc:  0.17598195743920683\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  30 loss :  5.230512312838906 acc:  0.1898711564656231\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  31 loss :  5.149873874061986 acc:  0.19025076479914252\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  32 loss :  5.057874870300293 acc:  0.20175066431458366\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  33 loss :  5.030094006187038 acc:  0.20306812853091574\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  34 loss :  4.991101405495091 acc:  0.20483219078668244\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  35 loss :  5.8338344824941535 acc:  0.20474287117879553\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  36 loss :  5.802380205455579 acc:  0.21579617265480205\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  37 loss :  5.783175453386809 acc:  0.21849809079338142\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  38 loss :  5.794926317114579 acc:  0.21530491481142397\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  39 loss :  5.8369243119892325 acc:  0.21360784226157248\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  40 loss :  5.767747623042056 acc:  0.22801062903333855\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  41 loss :  5.697406367251747 acc:  0.23196302168233482\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  42 loss :  5.68411024495175 acc:  0.23450863050711207\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  43 loss :  5.704104644373843 acc:  0.23703190942991761\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  44 loss :  5.608707372765792 acc:  0.23185137217247617\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  45 loss :  5.570561574634753 acc:  0.24134158051046156\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  46 loss :  5.580515565370258 acc:  0.2434182613938325\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  47 loss :  5.572089712243331 acc:  0.24297166335439788\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  48 loss :  5.508589247653359 acc:  0.2514123662997119\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  49 loss :  5.462103336735775 acc:  0.24873277806310432\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  50 loss :  5.443658286646793 acc:  0.25791036777348547\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  51 loss :  5.441287632992393 acc:  0.25286380992787444\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  52 loss :  5.443859973706697 acc:  0.257039501596588\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  53 loss :  5.450860831612035 acc:  0.260433646696291\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  54 loss :  5.485501470063862 acc:  0.2605229663041779\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  55 loss :  5.482288902684262 acc:  0.2613938324810754\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  56 loss :  5.4881165906002645 acc:  0.25871424424446776\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  57 loss :  5.472454387263248 acc:  0.2582899761070049\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  58 loss :  5.48296927401894 acc:  0.257285130518277\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  59 loss :  5.489509984066612 acc:  0.2556773775763124\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  60 loss :  5.382304583097759 acc:  0.25069780943661657\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  61 loss :  5.4960581126965975 acc:  0.25384632561463055\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  62 loss :  5.436123888116134 acc:  0.25038519080901234\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  63 loss :  5.4390968021593595 acc:  0.2500725721814081\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18390114890082632 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'Softshrink', 'batch_size': 16, 'concatenate_features': False, 'd_model': 1056, 'dropout': 0.2450016010491265, 'dropout_StationIdEmbedding': 0.8751907044052445, 'dropout_timeStampEmbedding': 0.4980229201128875, 'dropout_transformers': 0.5459436867073139, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 25, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.04660905496478961, 'scheduler': 'StepLR', 'step_size': 17, 'dropout_lstm': 0.18390114890082632, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 12, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8753430804674709, 'beta_2': 0.9604872687745583, 'eps': 2.2476785782047834e-06, 'lr': 0.0005002538302103282, 'optimizer': 'AdamW', 'weight_decay': 1.570523768502373e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  7.7371301583840815 acc:  0.041890896098966124\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  7.334439875374378 acc:  0.051202465221177676\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.1236017992798715 acc:  0.06127325101042806\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  6.832228304634632 acc:  0.05709755934171449\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  6.618042401864495 acc:  0.06683339660138891\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  6.497593503602793 acc:  0.11305629368287073\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  5.992248924685196 acc:  0.11698635642989527\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  5.921653176697207 acc:  0.14507737311033206\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  5.5857977262685 acc:  0.15052586919143424\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  5.337933345579765 acc:  0.16611214076770203\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  5.335964797248303 acc:  0.17709845253779335\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  5.2822388125137545 acc:  0.19371189960476073\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  5.077045591784195 acc:  0.18944688832816023\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Softplus', 'batch_size': 64, 'concatenate_features': False, 'd_model': 720, 'dropout': 0.6713799315302484, 'dropout_StationIdEmbedding': 0.07807473167543788, 'dropout_timeStampEmbedding': 0.7194000255447135, 'dropout_transformers': 0.22017744352414936, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 67, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 1, 'factor': 0.7095096372468199, 'patience': 8, 'scheduler': 'ReduceLROnPlateau', 'threshold': 5.406942736701601e-05, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.917245234448603, 'beta_2': 0.9979760828897231, 'eps': 1.7949982882503993e-08, 'lr': 0.07180319954970667, 'optimizer': 'AdamW', 'weight_decay': 2.672399778915436e-06, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ELU', 'dropout_gcn': 0.009800963274890107, 'hidden_channels': 2048, 'layer_type': 'GCNConv', 'norm': 'InstanceNorm', 'num_layers_gcn': 9, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GAT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8077015242197328 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Softshrink', 'batch_size': 16, 'concatenate_features': True, 'd_model': 1440, 'dropout': 0.424930653895912, 'dropout_StationIdEmbedding': 0.8356749901292031, 'dropout_timeStampEmbedding': 0.7748568722037691, 'dropout_transformers': 0.8864292197781687, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 61, 'input_size': 2, 'learnable_pos_encoding': False, 'T_max': 5, 'eta_min': 0.000845888121512347, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.8077015242197328, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softmin', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.9854597264805187, 'beta_2': 0.9841297150729207, 'eps': 1.6678915826240303e-06, 'lr': 9.967385128087866e-06, 'optimizer': 'Adam', 'weight_decay': 0.0025454757870817793, 'positive_function': 'relu', 'epochs_complete_problem': 25, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LeakyReLU', 'dropout_gcn': 0.32495698355976477, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 8, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  9.890950782136768 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.34833169108286 acc:  0.015340642654578747\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  7.349357290417736 acc:  0.09351762945760668\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  6.372865814189012 acc:  0.1696179353772637\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  5.303770889162393 acc:  0.18504789763972937\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  4.966848503232627 acc:  0.174396534399214\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  4.8192630001387675 acc:  0.20342540696246345\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  4.472871115070363 acc:  0.23964450796061004\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  4.257264189695189 acc:  0.2664627202286582\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  3.951787107277915 acc:  0.30741576044481167\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  3.8924723208262657 acc:  0.3164370408413907\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  3.8465081859009427 acc:  0.3265748163365563\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  3.9320883900707306 acc:  0.278319898175647\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  4.101634069262999 acc:  0.2181854721657772\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  4.4001382370893865 acc:  0.20690887167005337\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  4.4298922391462074 acc:  0.20748944912131836\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  16 loss :  4.353121144609301 acc:  0.20407297411964362\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  17 loss :  4.206842972970134 acc:  0.24480271531607975\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  18 loss :  4.018880276155722 acc:  0.2941294687716321\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'ReLU6', 'batch_size': 32, 'concatenate_features': False, 'd_model': 888, 'dropout': 0.5965985814957975, 'dropout_StationIdEmbedding': 0.31853065290482796, 'dropout_timeStampEmbedding': 0.505034365973917, 'dropout_transformers': 0.13719489145214714, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 26, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 12, 'eta_min': 4.9775741633749974e-05, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 3, 'lr': 0.0023012085231793656, 'momentum': 0.20611453843350197, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 0.0028375541616436576, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardsigmoid', 'dropout_gcn': 0.33183221332300483, 'hidden_channels': 1024, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 10, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.020710471368606 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.020564602267358 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.020109539647256 acc:  0.0016524127459080454\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  8.019956428773941 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  8.019889296254805 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  8.019730057254915 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  8.01917774446549 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  8.019357133680774 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  8.01899232556743 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  8.019188277952132 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  8.019149903328188 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  8.019285964965821 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  8.018815446669056 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  13 loss :  8.018896662804389 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  14 loss :  8.018870144505655 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  15 loss :  8.01905328689083 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40693957329744346 and num_layers=1\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=60669)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'ReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 552, 'dropout': 0.31418065391016503, 'dropout_StationIdEmbedding': 0.9170122040932379, 'dropout_timeStampEmbedding': 0.7519874014575396, 'dropout_transformers': 0.24473354482957022, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 24, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.40693957329744346, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 12, 'num_layers_transformer': 1, 'alpha': 0.9877232284848576, 'centered': True, 'eps': 3.96938206445058e-07, 'lr': 0.0018253708553199364, 'momentum': 0.28568258748991526, 'optimizer': 'RMSprop', 'weight_decay': 0.1769820160131162, 'positive_function': 'abs', 'epochs_complete_problem': 31, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  0 loss :  8.009873847027759 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  1 loss :  8.016720731775244 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  2 loss :  8.017503758410474 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  3 loss :  8.017505218932678 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  4 loss :  8.017398093963836 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  5 loss :  8.017497709581068 acc:  0.002389299510975147\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  6 loss :  8.017508159984242 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  7 loss :  8.017457821986058 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  8 loss :  8.014653782744508 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  9 loss :  7.799489464793172 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  10 loss :  7.7032837734355795 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  11 loss :  7.6853931166908955 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=60669)\u001b[0m epoch:  12 loss :  7.6879384534342305 acc:  0.002925217158296675\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-06 20:07:13,292\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-06 20:07:28,015\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-06 20:07:28,016\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_1        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_1\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_1`\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Softshrink', 'batch_size': 128, 'concatenate_features': False, 'd_model': 120, 'dropout': 0.8301701469867244, 'dropout_StationIdEmbedding': 0.5655882640525879, 'dropout_timeStampEmbedding': 0.2939189411543632, 'dropout_transformers': 0.4648875006740148, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 11, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 9.368540868939229e-07, 'max_lr': 0.10821345862655626, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 28, 'dropout_lstm': 0.9508510389294802, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardsigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 24, 'num_layers_transformer': 5, 'lr': 0.08447637166331295, 'momentum': 0.008015512419474596, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.2627864584937101, 'positive_function': 'relu', 'epochs_complete_problem': 3, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LeakyReLU', 'dropout_gcn': 0.6613457094402753, 'hidden_channels': 64, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 4, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9508510389294802 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'LeakyReLU', 'batch_size': 128, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.8209879365270651, 'dropout_StationIdEmbedding': 0.44365202679620575, 'dropout_timeStampEmbedding': 0.27366779202346486, 'dropout_transformers': 0.9729843269123895, 'early_stopping': 10, 'encoder_only': True, 'epochs_classifcation_only': 15, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 5.4378989153586717e-05, 'max_lr': 0.3093565932930617, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 1, 'dropout_lstm': 0.8190940671037286, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softmin', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 24, 'num_layers_transformer': 5, 'amsgrad': True, 'beta_1': 0.8034842027718958, 'beta_2': 0.9824751586383071, 'eps': 5.956372855819424e-06, 'lr': 6.02971710119714e-07, 'optimizer': 'Adam', 'weight_decay': 0.00023837966392902175, 'positive_function': 'sig', 'epochs_complete_problem': 10, 'reg': True, 'transformers_model': True, 'activation_gcn': 'PReLU', 'dropout_gcn': 0.98470581307162, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 6, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8190940671037286 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Hardswish', 'batch_size': 16, 'concatenate_features': False, 'd_model': 312, 'dropout': 0.5396895566751263, 'dropout_StationIdEmbedding': 0.8075607913239145, 'dropout_timeStampEmbedding': 0.35021425948049095, 'dropout_transformers': 0.45738321584959396, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 45, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 0.014809498970484393, 'max_lr': 0.1296010430061614, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 29, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 24, 'num_layers_transformer': 2, 'lr': 0.05041525421689873, 'momentum': 0.4714499827178006, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.313315942268527, 'positive_function': 'sig', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LeakyReLU', 'dropout_gcn': 0.5838443304631716, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 3, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5892482624658961 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Hardshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.02871094933921825, 'dropout_StationIdEmbedding': 0.5973034841166309, 'dropout_timeStampEmbedding': 0.9761405416663385, 'dropout_transformers': 0.9935022305177372, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 76, 'input_size': 2, 'learnable_pos_encoding': False, 'T_max': 2, 'eta_min': 1.0163479384012925e-05, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.5892482624658961, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ReLU6', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 4, 'amsgrad': True, 'beta_1': 0.933261928544172, 'beta_2': 0.9825257647149878, 'eps': 5.267299521705942e-07, 'lr': 3.776445571903993e-07, 'optimizer': 'Adam', 'weight_decay': 1.5278438743409054e-05, 'positive_function': 'relu', 'epochs_complete_problem': 39, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Hardtanh', 'batch_size': 16, 'concatenate_features': True, 'd_model': 912, 'dropout': 0.19181154680743065, 'dropout_StationIdEmbedding': 0.9911896237026416, 'dropout_timeStampEmbedding': 0.5879748932864318, 'dropout_transformers': 0.8535716725540936, 'early_stopping': 10, 'encoder_only': True, 'epochs_classifcation_only': 5, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 2, 'eta_min': 0.0004051141569890603, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 24, 'num_layers_transformer': 3, 'amsgrad': True, 'beta_1': 0.9990764989068798, 'beta_2': 0.9530714655773819, 'eps': 1.7888012567440073e-07, 'lr': 1.0748967559938573e-05, 'optimizer': 'Adam', 'weight_decay': 0.001278147777854455, 'positive_function': 'relu', 'epochs_complete_problem': 26, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.07371009698435 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  7.685710229793517 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  7.443371820850532 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  7.400675549226649 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  7.383055041818058 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  8.433155604771205 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  8.507695506600772 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  8.489301949989896 acc:  0.0025679387267489896\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  8.47714658544845 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  8.507470303222913 acc:  0.0023669696090034163\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  8.44711613855442 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  8.475712744127803 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  8.474041990873193 acc:  0.0026349284326641804\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  8.46684570873485 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  8.40850657374919 acc:  0.0029028872563249446\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  8.362995600500026 acc:  0.0025902686287207198\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  8.44516944083847 acc:  0.0025679387267489896\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  8.429168080081459 acc:  0.0023669696090034163\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  8.402783770521149 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  8.329125596695587 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  8.370917095857507 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  8.420888696398054 acc:  0.002232990197173034\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  8.39024408324426 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  8.360802209677816 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  8.36158360553389 acc:  0.0033494852957595515\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  8.377133673980456 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  8.320778385931705 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  8.400482678613743 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  8.36517995545844 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  8.32918325392138 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  8.374940363298945 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Mish', 'batch_size': 128, 'concatenate_features': False, 'd_model': 48, 'dropout': 0.9599599377538068, 'dropout_StationIdEmbedding': 0.4207419624484802, 'dropout_timeStampEmbedding': 0.42032324427711865, 'dropout_transformers': 0.5391492972432135, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 43, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 6.692661919810062e-05, 'max_lr': 0.05016332037826411, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 20, 'dropout_lstm': 0.005930944669753857, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 6, 'lr': 6.980446531435832e-05, 'momentum': 0.012510845552782368, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 4.867302302555901e-06, 'positive_function': 'exp', 'epochs_complete_problem': 14, 'reg': True, 'transformers_model': True, 'activation_gcn': 'LogSigmoid', 'dropout_gcn': 0.026928764193590138, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 7, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.005930944669753857 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.686156132346705 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.60980284841437 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  8.49911426744963 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  8.424844149539345 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  8.371795523794074 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  8.333946499071622 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  8.28223560734799 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  8.218767999347888 acc:  0.002076680883370922\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  8.131423533590217 acc:  0.002925217158296675\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  8.020259084199605 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  7.901914867601897 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  7.786102495695415 acc:  0.0037960833351941585\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  7.6721999168396 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  7.593778073160272 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  7.51016933039615 acc:  0.004488310296317799\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  7.460464020779258 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  7.415165002722489 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  7.381454573179546 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  7.344120843786943 acc:  0.004398990688430878\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  7.327186760149504 acc:  0.004711609316035103\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  7.296949517099481 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  7.281625185514751 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  7.267205333709716 acc:  0.0048455887278654845\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  7.2612669693796255 acc:  0.005225197061384901\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  7.25607425790084 acc:  0.005872764218565081\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  7.243738345095986 acc:  0.0056717951008195076\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  7.2488248925460015 acc:  0.00515820735546971\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  7.2441333017851175 acc:  0.007368867650671014\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  7.227741196281031 acc:  0.005225197061384901\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  7.229402632462351 acc:  0.005917424022508541\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  7.222329460947138 acc:  0.005962083826452002\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  7.2208047666047745 acc:  0.005493155885045665\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  7.217106081310072 acc:  0.006408681865886608\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  7.222782375938014 acc:  0.005917424022508541\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  7.210481437883879 acc:  0.006185382846169305\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Hardsigmoid', 'batch_size': 16, 'concatenate_features': False, 'd_model': 864, 'dropout': 0.530864328646683, 'dropout_StationIdEmbedding': 0.5734420846694784, 'dropout_timeStampEmbedding': 0.2289745911000377, 'dropout_transformers': 0.4241367210174926, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 16, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.0012499298747719045, 'scheduler': 'ExponentialLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 5, 'amsgrad': False, 'beta_1': 0.8092649590697468, 'beta_2': 0.9861468063704495, 'eps': 2.096439470849257e-09, 'lr': 6.872976873201176e-06, 'optimizer': 'Adam', 'weight_decay': 1.0126490439148928e-06, 'positive_function': 'sig', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Softshrink', 'dropout_gcn': 0.45102094330981835, 'hidden_channels': 512, 'layer_type': 'GAT', 'norm': 'LayerNorm', 'num_layers_gcn': 10, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.983290035306043 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  7.883747945305045 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  7.8787633735714975 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  7.888237585548226 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  7.888084429820985 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  7.890391317032676 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  7.888014174599684 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Sigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 216, 'dropout': 0.8111906187891494, 'dropout_StationIdEmbedding': 0.790091380648746, 'dropout_timeStampEmbedding': 0.7973492994383862, 'dropout_transformers': 0.6442532769556406, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'T_max': 25, 'eta_min': 0.32652290090419206, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.08071215445972812, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'PReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 24, 'num_layers_transformer': 4, 'lr': 0.007683460016217922, 'momentum': 0.37050981359324386, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.006906876154550657, 'positive_function': 'relu', 'epochs_complete_problem': 29, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.08071215445972812 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.66463127869826 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.464838145329402 acc:  0.0046222897081481815\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  8.20645870062021 acc:  0.007994104905879464\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  7.853411436080933 acc:  0.009400888730098474\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  7.59308888728802 acc:  0.01103097157403479\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  7.4211236183459945 acc:  0.01299600294754706\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  7.30122703405527 acc:  0.01752897304780832\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  7.204567021590012 acc:  0.024920170600451062\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  7.129659498654879 acc:  0.02279882991313668\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  7.078083097017728 acc:  0.055824754929325864\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  7.028105882497934 acc:  0.02407163432552531\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  6.997994591639592 acc:  0.021235736775115557\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  6.9540163883796104 acc:  0.03706763727307237\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  6.935874836261456 acc:  0.020900788245539603\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  6.892827239403358 acc:  0.040997700020096915\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  6.950068983664879 acc:  0.01951633432329232\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  7.156177568435669 acc:  0.010874662260232678\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  7.268460673552293 acc:  0.010003796083335193\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9948722394784901 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Softmin', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1200, 'dropout': 0.8978344152517316, 'dropout_StationIdEmbedding': 0.6351256648989213, 'dropout_timeStampEmbedding': 0.5332537847067437, 'dropout_transformers': 0.7912071529729393, 'early_stopping': 9, 'encoder_only': True, 'epochs_classifcation_only': 71, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8894909941303533, 'scheduler': 'StepLR', 'step_size': 5, 'dropout_lstm': 0.9948722394784901, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.9527327445081933, 'beta_2': 0.9710864404063841, 'eps': 1.052996476375188e-06, 'lr': 0.005467900278907302, 'optimizer': 'Adam', 'weight_decay': 0.32635530412566527, 'positive_function': 'sig', 'epochs_complete_problem': 34, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'GELU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 360, 'dropout': 0.7362641889989356, 'dropout_StationIdEmbedding': 0.7086529012877063, 'dropout_timeStampEmbedding': 0.9316416923123648, 'dropout_transformers': 0.9257699731437827, 'early_stopping': 10, 'encoder_only': True, 'epochs_classifcation_only': 38, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 3.225760868408335e-07, 'max_lr': 0.19963975408846357, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 6, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 6, 'lr': 0.0001313744948603213, 'momentum': 0.1136222767379999, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 1.1208283884249933e-05, 'positive_function': 'relu', 'epochs_complete_problem': 2, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Hardtanh', 'dropout_gcn': 0.7992180228498926, 'hidden_channels': 64, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 3, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.106738986739193 acc:  0.00022329901971730344\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.096878063247864 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  8.0654021803155 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  8.014328485511871 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  7.945225715637207 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  7.84243594020246 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  7.703721948416836 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  7.563149578600044 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  7.4806469319814655 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  7.440552050808826 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  7.408374499125653 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  7.391842428460179 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  7.381083792950734 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  7.3808426971895145 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  7.370722977511854 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  7.352582041039525 acc:  0.005046557845611058\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  7.343863021896546 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  7.321549346648067 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  7.315216926207025 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  7.286428440048034 acc:  0.004309671080543956\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  7.293645404907594 acc:  0.00326016568787263\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  7.267058159931596 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  7.2859260662492495 acc:  0.0037960833351941585\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  7.2814811223960785 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  7.2534616252025925 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  7.27037342485175 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7881903375504518 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'ELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1224, 'dropout': 0.5671097847313655, 'dropout_StationIdEmbedding': 0.2431507577512859, 'dropout_timeStampEmbedding': 0.6683385154989354, 'dropout_transformers': 0.3828629598690466, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 80, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7881903375504518, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8477600838001569, 'beta_2': 0.990649735091279, 'eps': 1.4317116847659442e-07, 'lr': 1.0082885521871854e-05, 'optimizer': 'Adam', 'weight_decay': 2.891384205322503e-07, 'positive_function': 'relu', 'epochs_complete_problem': 11, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.393771321361601 acc:  0.0016524127459080454\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.158955826185137 acc:  0.008038764709822925\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  7.7365623469128035 acc:  0.017037715204430252\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  7.310345010607654 acc:  0.04090838041220999\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  6.94189758700226 acc:  0.08291092602103477\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  6.599139820218711 acc:  0.12292611035437555\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  6.336469393126003 acc:  0.15036955987763215\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  6.134011380959556 acc:  0.17714311234173682\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  5.914486735279024 acc:  0.1967041064689726\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  5.755203499219805 acc:  0.20865060402384833\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  5.568563391400882 acc:  0.22414755599222919\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  5.459024614064481 acc:  0.2346649398209142\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  5.3222728824116174 acc:  0.24424446776678652\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  5.212988401582728 acc:  0.2532210883594221\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  5.152501488231239 acc:  0.26128218297121675\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  4.991655893974904 acc:  0.26804814326865106\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  4.900922560567007 acc:  0.27664515552776725\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  4.828633091212567 acc:  0.2835897550409754\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  4.735040366337562 acc:  0.2904227050443249\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  4.658102432470671 acc:  0.29680905700823973\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  4.58191811601529 acc:  0.3023245427952571\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  4.468177138822865 acc:  0.3090905030926914\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  4.421309464889047 acc:  0.31433803005604805\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  4.378862665585823 acc:  0.3200991447647545\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  4.311449082109941 acc:  0.32447580555121364\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  4.249326461272714 acc:  0.3290757653573901\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  4.2136588471098095 acc:  0.3333631065359623\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  4.132749450144344 acc:  0.33677958153763704\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  4.085321212938319 acc:  0.3395931491860751\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  4.043153770306971 acc:  0.34374651095281694\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  4.020919062080184 acc:  0.3466717281111136\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  3.9477707041495758 acc:  0.35075810017194026\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  3.9166928610876592 acc:  0.3532367192908023\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  3.8945375774543325 acc:  0.35703280262599646\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  3.830124894985978 acc:  0.35877453497979145\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  3.800717498619519 acc:  0.36132014380456867\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  3.770339198137453 acc:  0.36399973204117636\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  3.7480004695073474 acc:  0.36480360851215865\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  3.7064090162047543 acc:  0.36755018645468146\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  3.6596119915627683 acc:  0.3688899805729853\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  3.654220479945238 acc:  0.3709666614563562\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  3.6135757843237273 acc:  0.37346761047719\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  3.5840767902853603 acc:  0.37556662126253265\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  3.5540845406617168 acc:  0.37688408547886476\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  3.527918197721711 acc:  0.380010271754907\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  3.503174197611384 acc:  0.38056851930420027\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  46 loss :  3.4774178996760186 acc:  0.3824665609717973\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  47 loss :  3.4711187322726422 acc:  0.3852131389143202\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  48 loss :  3.4440934757911723 acc:  0.3849451800906594\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  49 loss :  3.4162854062325043 acc:  0.38688788156219994\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  50 loss :  3.385612260608773 acc:  0.3889868923475426\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  51 loss :  3.37618759539739 acc:  0.3904606658776768\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  52 loss :  3.344518067324973 acc:  0.39159949087823503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  53 loss :  3.320195862135962 acc:  0.39255967666301944\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  54 loss :  3.2954250780075633 acc:  0.3949713060759663\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  55 loss :  3.276284478721818 acc:  0.3946586874483621\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  56 loss :  3.2758282404295436 acc:  0.3961324609784963\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  57 loss :  3.251275636762849 acc:  0.397896523234263\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  58 loss :  3.2507132722445182 acc:  0.39820914186186723\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  59 loss :  3.220857016079089 acc:  0.3982984614697542\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  60 loss :  3.1977214338891793 acc:  0.40033048254918163\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  61 loss :  3.1949254093369888 acc:  0.40057611147087063\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  62 loss :  3.1843892117445383 acc:  0.4010227095103053\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  63 loss :  3.1676931318812347 acc:  0.4023848335305808\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  64 loss :  3.1438020748617763 acc:  0.4029877408838175\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  65 loss :  3.1236706653814665 acc:  0.4029877408838175\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  66 loss :  3.096973784931043 acc:  0.40455083402183867\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  67 loss :  3.0922128991930897 acc:  0.40662751490520954\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  68 loss :  3.090031631329921 acc:  0.4062702364736619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  69 loss :  3.081799377321573 acc:  0.4068061541209834\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  70 loss :  3.0674431873241645 acc:  0.4085925462787218\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  71 loss :  3.0399494533139375 acc:  0.4070517830426724\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  72 loss :  3.048680650002045 acc:  0.40955273206350623\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  73 loss :  3.0284451240020274 acc:  0.41008864971082776\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  74 loss :  3.0224917434272967 acc:  0.41082553647589487\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  75 loss :  3.008364797262621 acc:  0.4120983408882835\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  76 loss :  2.99371709873539 acc:  0.4117857222606793\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  77 loss :  2.981871862061985 acc:  0.4132594957908135\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  78 loss :  2.975150576436707 acc:  0.41361677422236115\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  79 loss :  2.9733233651565634 acc:  0.4136391041243329\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  80 loss :  4.033896783259527 acc:  0.41413036196771097\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  81 loss :  3.9754851363716326 acc:  0.4143090011834848\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  82 loss :  3.958176800093726 acc:  0.4150682178505236\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  83 loss :  3.948692114565385 acc:  0.4148225889288346\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  84 loss :  3.962065900183473 acc:  0.4154478261840431\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  85 loss :  3.9462621424210633 acc:  0.4171672286358663\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  86 loss :  3.9173873319675785 acc:  0.4175468369693857\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  87 loss :  3.912364627678357 acc:  0.4191545899113503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  88 loss :  3.907600236812811 acc:  0.41884197128374606\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  89 loss :  3.8966268706696194 acc:  0.4191099301074068\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  90 loss :  3.88383840890455 acc:  0.41919924971529376\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GAT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8247204716264702 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Softshrink', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1272, 'dropout': 0.12854579791817278, 'dropout_StationIdEmbedding': 0.19238450021312126, 'dropout_timeStampEmbedding': 0.6538570582005737, 'dropout_transformers': 0.3992301696591553, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 80, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'dropout_lstm': 0.8247204716264702, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8386744976190655, 'beta_2': 0.9907557316370873, 'eps': 1.6619452567615624e-07, 'lr': 1.0323229721054282e-05, 'optimizer': 'Adam', 'weight_decay': 1.3631584396945346e-07, 'positive_function': 'relu', 'epochs_complete_problem': 7, 'reg': True, 'transformers_model': True, 'activation_gcn': 'Hardshrink', 'dropout_gcn': 0.07379743955334861, 'hidden_channels': 256, 'layer_type': 'GAT', 'norm': 'PairNorm', 'num_layers_gcn': 5, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.201357873458436 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.019099858886037 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  8.018220192893258 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  8.017428078464956 acc:  0.001563093138021124\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  8.016528720962269 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8303086957303105 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'ELU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1248, 'dropout': 0.49585900096956337, 'dropout_StationIdEmbedding': 0.2864036836777289, 'dropout_timeStampEmbedding': 0.7806548104755296, 'dropout_transformers': 0.13241337753429783, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 75, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8303086957303105, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8774676219672991, 'beta_2': 0.9907819147418413, 'eps': 4.9234655156455195e-06, 'lr': 1.770748858481716e-06, 'optimizer': 'Adam', 'weight_decay': 2.247764259217346e-09, 'positive_function': 'relu', 'epochs_complete_problem': 13, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  8.642015472132497 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  8.616681213778351 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  8.58664959013774 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  8.55744610531792 acc:  0.0006475671571801799\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  8.534793384412197 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  8.508793546267205 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  8.479249494862183 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  8.448816923570883 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  8.416285604706609 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  8.393054862297019 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  8.362920346684481 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  8.322897851155066 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  8.286978242284965 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  8.232911896331148 acc:  0.005895094120536811\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  8.182709798762936 acc:  0.0076144965723600475\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  8.127115399425566 acc:  0.009378558828126745\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  8.067036141899868 acc:  0.010696023044458835\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  7.993489599976864 acc:  0.011522229417412858\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  7.916103702565138 acc:  0.012460085300225531\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  7.856822625504738 acc:  0.012616394614027644\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  7.781373353528727 acc:  0.013152312261349173\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  7.733510381888345 acc:  0.013576580398812049\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  7.68392515432148 acc:  0.015072683830917982\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  7.638252470505799 acc:  0.017439653439921397\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  7.6036186642671755 acc:  0.019627983833150973\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  7.562254646061603 acc:  0.022285242167786882\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  7.502822062107905 acc:  0.024160953933412232\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  7.487838962315265 acc:  0.026505593640443918\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  7.46414274445379 acc:  0.028850233347475603\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  7.427580394045845 acc:  0.03313757452604783\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  7.3575204554652665 acc:  0.037313266194761406\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  7.367188920525356 acc:  0.04046178237277538\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  7.306950302024163 acc:  0.04515106178683875\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  7.265299020637392 acc:  0.049773351494986934\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  7.25853721758458 acc:  0.05636067257664739\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  7.211456803127109 acc:  0.05917424022508541\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  7.118647767611199 acc:  0.0637295402273184\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  7.107178383472703 acc:  0.0719692740548869\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  7.052242408872275 acc:  0.0778643681754237\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  6.993163553207957 acc:  0.08195074023625036\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  6.992847232918464 acc:  0.08809146327847621\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  6.925544207008722 acc:  0.0923564745550767\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  6.9040186168011575 acc:  0.09666614563562066\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  6.82516409839011 acc:  0.10195833240292075\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  6.786362912642394 acc:  0.10470491034544359\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  6.789507054533634 acc:  0.1085456534845812\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  46 loss :  6.758087335456728 acc:  0.11602617064511087\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  47 loss :  6.658436717787338 acc:  0.11834848045017082\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  48 loss :  6.65545282313961 acc:  0.1217202956479021\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  49 loss :  6.614573608518271 acc:  0.1265882142777393\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  50 loss :  6.572210094691571 acc:  0.12924547261237523\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  51 loss :  6.582849030719378 acc:  0.1340910613402407\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  52 loss :  6.560628404167934 acc:  0.13779782506754795\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  53 loss :  6.45596263296317 acc:  0.1398298461469754\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  54 loss :  6.500498759184833 acc:  0.14418417703146283\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  55 loss :  6.477260524689839 acc:  0.14619386820891855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  56 loss :  6.36313905266567 acc:  0.14936471428890427\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  57 loss :  6.363815117880936 acc:  0.15237925105508787\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  58 loss :  6.348732451493827 acc:  0.15559475693901703\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  59 loss :  6.353991216389921 acc:  0.15834133488153987\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  60 loss :  6.302003119004334 acc:  0.16057432507871292\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  61 loss :  6.240001576109083 acc:  0.1627849853739142\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  62 loss :  6.293212803246464 acc:  0.16651407900319318\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  63 loss :  6.1980265647328965 acc:  0.16812183194515776\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  64 loss :  6.180254791419544 acc:  0.17098005939753924\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  65 loss :  6.168719384058607 acc:  0.1735256682223165\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  66 loss :  6.112228698131301 acc:  0.17636156577272627\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  67 loss :  6.126704702826695 acc:  0.17680816381216086\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  68 loss :  6.0965251647989165 acc:  0.17901882410736217\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  69 loss :  6.065308982789205 acc:  0.18239063930509344\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  70 loss :  6.03707052150946 acc:  0.18292655695241497\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  71 loss :  6.064602477388232 acc:  0.18603041332648548\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  72 loss :  5.988251436443229 acc:  0.18815175401379988\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  73 loss :  6.039702035993805 acc:  0.18942455842618852\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  74 loss :  5.934584929680949 acc:  0.19121095058392693\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  75 loss :  7.1141421657582224 acc:  0.19056338342674675\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  76 loss :  6.958473532611787 acc:  0.19290802313377844\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  77 loss :  6.944847254228842 acc:  0.1956099412723578\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  78 loss :  6.927888770378073 acc:  0.19665944666502913\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  79 loss :  6.917497227953366 acc:  0.19735167362615277\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  80 loss :  6.896544161891438 acc:  0.20043320009825158\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  81 loss :  6.867457552105969 acc:  0.2020856128441596\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  82 loss :  6.874580617974566 acc:  0.20282249960922671\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  83 loss :  6.80569282002474 acc:  0.20322443784471786\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  84 loss :  6.8097245081557025 acc:  0.20387200500189803\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  85 loss :  6.757179405052624 acc:  0.20733313980751625\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  86 loss :  6.818542105989306 acc:  0.20748944912131836\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  87 loss :  6.743042608830317 acc:  0.20894089274948083\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6593645563236669 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'batch_size': 16, 'concatenate_features': True, 'd_model': 1008, 'dropout': 0.3605725842176154, 'dropout_StationIdEmbedding': 0.3609065767551209, 'dropout_timeStampEmbedding': 0.570607302955783, 'dropout_transformers': 0.5624993018383793, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 59, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'dropout_lstm': 0.6593645563236669, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8365637728609997, 'beta_2': 0.9770824657171174, 'eps': 5.985097869887318e-07, 'lr': 6.341197488531829e-05, 'optimizer': 'Adam', 'weight_decay': 0.00016958082404274464, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Hardswish', 'dropout_gcn': 0.36585932478972727, 'hidden_channels': 1024, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 9, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.714339630332535 acc:  0.013308621575151286\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  7.31909578860163 acc:  0.040082174039255965\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  6.959034114540694 acc:  0.06935667552419444\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  6.504909284100561 acc:  0.10629033338543643\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  6.186875821587568 acc:  0.1492307348770739\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  5.947606061033146 acc:  0.16885871871022487\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  5.774046111249638 acc:  0.18634303195408972\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  5.5414427711578185 acc:  0.20757876872920528\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  5.312444118682496 acc:  0.22358930844293592\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  5.112605036375765 acc:  0.23486590893865977\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  5.049270183026434 acc:  0.2456512515910055\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  4.979922875672758 acc:  0.25069780943661657\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  4.879403526911479 acc:  0.25695018198870107\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  4.754583066095135 acc:  0.2718888864077887\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  4.675475026319127 acc:  0.27356362905566844\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  4.548041298003968 acc:  0.2818256927852087\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  4.561986854690278 acc:  0.28834602416095395\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  4.402683879087071 acc:  0.29421878837951904\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  4.295075062506213 acc:  0.30196726436370946\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  4.1024178502088535 acc:  0.30763905946452896\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  4.1438078152205415 acc:  0.308710894759172\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  4.201592773734452 acc:  0.31308755554563117\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  4.008242084594544 acc:  0.3222204854520689\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  4.024054373095849 acc:  0.32054574280418907\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  3.9928016705427343 acc:  0.32742335261148203\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  3.9496671139837027 acc:  0.3294330437889378\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  3.877458306843649 acc:  0.3308398276131568\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  3.8759879066558653 acc:  0.3343902820266619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  3.7553777666149024 acc:  0.3378514168322801\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  3.8564592692666424 acc:  0.3448630060514034\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  3.768440403624209 acc:  0.3479445325235022\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  3.7425680645925556 acc:  0.34982024428912756\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  3.698189266427548 acc:  0.3494629658575799\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  3.716522719331844 acc:  0.3487484089944845\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  3.6823877531611275 acc:  0.3552017506643146\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  3.6037627522816913 acc:  0.35627358595895764\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  3.5717223304474426 acc:  0.3565862045865619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  3.583915499156107 acc:  0.35805997811669604\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  3.466619929153762 acc:  0.3602259786079539\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  3.5733525710191554 acc:  0.3667016501797557\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  3.493040508852747 acc:  0.36607641292454723\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  3.517112582029697 acc:  0.36909094969073086\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  3.4507786171165056 acc:  0.3695598776321372\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  3.5056251266045484 acc:  0.37201616684902755\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  3.389285313155123 acc:  0.37319965165352925\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  3.351668297173734 acc:  0.37297635263381196\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  46 loss :  3.351295409802191 acc:  0.3764374874394301\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  47 loss :  3.3146463489818 acc:  0.3778666011656209\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  48 loss :  3.3775926707033626 acc:  0.37554429136056094\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  49 loss :  3.355611386413346 acc:  0.3773976732242145\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  50 loss :  3.2707533886332714 acc:  0.3799209521470201\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  51 loss :  3.3357702001126226 acc:  0.37873746734251834\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  52 loss :  3.353751909233139 acc:  0.3768394256749213\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  53 loss :  3.261646851808011 acc:  0.38217627224616485\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  54 loss :  3.3315910836179814 acc:  0.379184065381953\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  55 loss :  3.296845140571366 acc:  0.3815510349909564\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  56 loss :  3.2486846789628445 acc:  0.38510148940446154\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  57 loss :  3.264022488793927 acc:  0.38320344773686443\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  58 loss :  3.2027750514938447 acc:  0.38702186097403035\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6820397738894634 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 984, 'dropout': 0.36137238237566216, 'dropout_StationIdEmbedding': 0.001895044032539983, 'dropout_timeStampEmbedding': 0.368372085802816, 'dropout_transformers': 0.5720927204261574, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 73, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.6820397738894634, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.8358288102519749, 'beta_2': 0.9748144032174882, 'eps': 6.165560646873057e-08, 'lr': 9.43401259328304e-05, 'optimizer': 'Adam', 'weight_decay': 5.366267094044646e-05, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.369270573119204 acc:  0.08353616327624322\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  6.16626712376486 acc:  0.1955206216644709\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  5.508271168805882 acc:  0.24364156041354978\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  5.01468244998041 acc:  0.27316169082017727\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  4.655061326341001 acc:  0.29564790210570974\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  4.3968677463645705 acc:  0.31645937074336244\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  4.149057578183934 acc:  0.33347475604582094\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  3.951834041915254 acc:  0.3432105933054954\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  3.8008824665389374 acc:  0.35410758546769977\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  3.7088656868049483 acc:  0.3633298349820244\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  3.5852513741590304 acc:  0.3684433825335507\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  3.474619397146259 acc:  0.3754996315566175\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  3.4287025314605164 acc:  0.3801665810687091\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  3.3255940839915934 acc:  0.38726748989571935\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  3.2692347715000905 acc:  0.3908179443092245\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  3.2087323223045487 acc:  0.39604314137060936\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  3.1564241811900797 acc:  0.3969586673514503\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  3.070671838200735 acc:  0.4000848536274926\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  3.068474004368582 acc:  0.4041265658843758\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  3.028635307700334 acc:  0.4050867516691602\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  2.9795239071646136 acc:  0.4082799276511176\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  2.93795249419298 acc:  0.41022262912265817\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  2.9462309554665387 acc:  0.41185271196659445\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  2.898481698807128 acc:  0.4135051247125025\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  2.874725049127362 acc:  0.41558180559587343\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  2.813196256489097 acc:  0.41803809481276377\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  2.788663448687799 acc:  0.41866333206797224\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  2.786900733045475 acc:  0.41946720853895453\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  2.743373646707592 acc:  0.41832838353839624\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  2.7433091666170224 acc:  0.421499229618382\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  2.7139087565644773 acc:  0.42221378648147734\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  2.690439873826718 acc:  0.420918652167117\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  2.688309710896658 acc:  0.42252640510908157\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  2.664599332980767 acc:  0.4240001786392158\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  2.635271516388762 acc:  0.42458075609048074\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  2.6376229503197584 acc:  0.4262331688363888\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  2.620314466739129 acc:  0.42627782864033226\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  2.6061099053856855 acc:  0.42804189089609895\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  2.60455999688474 acc:  0.4272603443270884\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  2.5723570692325066 acc:  0.4274836433468057\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  2.5500233344689103 acc:  0.42824286001384454\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  2.5440524580949795 acc:  0.43058749972087623\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  2.535510127415914 acc:  0.4301185717794699\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  2.529737835158845 acc:  0.42980595315186565\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.46012352861682093 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1176, 'dropout': 0.24085212538021228, 'dropout_StationIdEmbedding': 0.002762140268031453, 'dropout_timeStampEmbedding': 0.2054455380730971, 'dropout_transformers': 0.3616520701255228, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 71, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.46012352861682093, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.8303874274237837, 'beta_2': 0.9643748194109263, 'eps': 6.434880517763961e-08, 'lr': 5.506564773909709e-05, 'optimizer': 'Adam', 'weight_decay': 1.4197120191748532e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.422426777685474 acc:  0.04566464953218855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  6.6032871029334155 acc:  0.153361766741844\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  5.956253442935601 acc:  0.21086126431904964\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  5.4566089293200095 acc:  0.24471339570819284\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  5.122436195076583 acc:  0.26849474130808565\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  4.7683666823153015 acc:  0.2878101065136324\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  4.537703287101792 acc:  0.3050934506397517\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  4.355706286287593 acc:  0.32139427907911483\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  4.204001346748032 acc:  0.33066118839738295\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  4.047812950111435 acc:  0.3415135207556439\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  3.9102917502740184 acc:  0.3506911104660251\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  3.8006677784605656 acc:  0.35703280262599646\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  3.686207871237201 acc:  0.3659424335127169\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  3.6122037536369827 acc:  0.371480249201706\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  3.530211925506592 acc:  0.37726369381238417\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  3.4511989233736506 acc:  0.38121608646138044\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  3.3660451252303436 acc:  0.3864189536207936\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  3.316565038201338 acc:  0.3896567894066945\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  3.2726234033436117 acc:  0.3942120894089275\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  3.204552816059775 acc:  0.3971373065672242\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  3.1776026337446566 acc:  0.40030815264720987\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  3.1280816757750367 acc:  0.4045731639238104\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  3.0581911109878632 acc:  0.40638188598352054\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  3.041192478762415 acc:  0.40854788647477835\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  3.02957374464252 acc:  0.41145077373110334\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  2.993438306682838 acc:  0.4124779492218029\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  2.956670581223722 acc:  0.415782774713619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  2.950464499924711 acc:  0.41712256883192284\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  2.910261358329636 acc:  0.4195341982448697\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  2.8731744731971602 acc:  0.42082933255923005\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  2.8350227178927665 acc:  0.4229953330504879\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  2.82024120856188 acc:  0.424067168345131\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  2.8202491291982685 acc:  0.4249603644240002\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  2.7797145872058984 acc:  0.4259875399146998\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  2.765624812977043 acc:  0.426545787463993\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  2.7486962287011973 acc:  0.428287519817788\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  2.7159761483083944 acc:  0.4300515820735547\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  2.7103197103488945 acc:  0.429694303642007\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  2.7040610913031116 acc:  0.42940401491637453\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  2.677229661427572 acc:  0.43090011834848047\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  2.642909034997403 acc:  0.4298729428577809\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  2.6440740959373064 acc:  0.43170399481946276\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  2.624294876338479 acc:  0.4324632114865016\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  2.6247150369746954 acc:  0.4318826340352366\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  2.585557960464569 acc:  0.4355447379586004\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  2.6049719113789633 acc:  0.4345622222718442\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  46 loss :  2.5942177629756356 acc:  0.43422727374226827\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.43434834532781436 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ELU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1152, 'dropout': 0.011013474382048194, 'dropout_StationIdEmbedding': 0.00790098293560111, 'dropout_timeStampEmbedding': 0.2214004849006575, 'dropout_transformers': 0.2814219152974762, 'early_stopping': 2, 'encoder_only': False, 'epochs_classifcation_only': 72, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.43434834532781436, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8173809535101957, 'beta_2': 0.9629981549756063, 'eps': 5.535905596153284e-08, 'lr': 0.0019149273234474703, 'optimizer': 'Adam', 'weight_decay': 1.600197278886951e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  6.978514671325684 acc:  0.15755978831252931\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  5.578635058036217 acc:  0.19835651921488065\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  5.0047308628375715 acc:  0.21032534667172811\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  4.708114049984858 acc:  0.21282629569256192\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  4.514688315758338 acc:  0.2154612241252261\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  4.370883220892686 acc:  0.21860974030324007\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  4.243651584478525 acc:  0.2109059241229931\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  4.1533183611356295 acc:  0.20706518098385548\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30367792710605657 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'PReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1320, 'dropout': 0.13199651356910314, 'dropout_StationIdEmbedding': 0.1349210556895789, 'dropout_timeStampEmbedding': 0.19303613251472868, 'dropout_transformers': 0.6966804329161463, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 66, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.30367792710605657, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.8963213758870979, 'beta_2': 0.9540348522499347, 'eps': 2.338940433303009e-09, 'lr': 0.00011960294116477681, 'optimizer': 'Adam', 'weight_decay': 0.00010384410442619273, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.34616985854569 acc:  0.07335372797713419\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  6.368587720644224 acc:  0.16941696625951813\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  5.776766323543095 acc:  0.22696112364066723\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  5.301588812074461 acc:  0.2568162025768707\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  4.956083596169532 acc:  0.2793470736663466\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  4.665060363449417 acc:  0.29696536632204185\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  4.4769617344116 acc:  0.3136904628988679\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  4.2115654945373535 acc:  0.32226514525601235\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  3.9957482781443563 acc:  0.3318223432999129\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  3.9033298008925432 acc:  0.33773976732242145\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  3.773499390462062 acc:  0.34591251144407476\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  3.6840956244435343 acc:  0.35200857468235713\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  3.581098108024864 acc:  0.35995801978429315\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  3.455324037925347 acc:  0.36462496929638477\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  3.40096997214364 acc:  0.36987249625974145\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  3.3185966781802945 acc:  0.3730880021436706\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  3.2852154094856103 acc:  0.37632583792957147\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  3.197357502850619 acc:  0.38157336489292815\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  3.184345698856807 acc:  0.3843646026393944\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  3.1070162349647577 acc:  0.3892101913672599\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  3.0779482201262787 acc:  0.39133153205457427\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  3.0380302342501553 acc:  0.39059464528950716\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  3.0290401482081912 acc:  0.3961771207824398\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  2.9850152672587575 acc:  0.39718196637116765\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  2.9434636556185207 acc:  0.39992854431369046\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  2.934349920366194 acc:  0.40131299823593775\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  2.889656372003622 acc:  0.4017372663734006\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  2.8623149128226966 acc:  0.4047294732376125\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  2.8338813915119303 acc:  0.4064712055914075\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  2.837163553371296 acc:  0.4076323604939374\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  2.7955350725800843 acc:  0.4078779894156265\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  2.756877037195059 acc:  0.41031194873054505\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  2.739638168495018 acc:  0.41089252618181005\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  2.734822620045055 acc:  0.41207601098631175\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  2.744842204180631 acc:  0.415782774713619\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  2.7032341473586077 acc:  0.41560413549784514\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  2.6718943102376445 acc:  0.4167876203023469\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  2.6626516138757026 acc:  0.41618471294911014\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  2.656953771631201 acc:  0.41768081638121607\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  2.6298554310431848 acc:  0.41924390951923723\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  2.632571980669782 acc:  0.42062836344148447\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  2.63199015930816 acc:  0.42058370363754105\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  2.576614886730701 acc:  0.4214768997164102\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  2.5764983050473087 acc:  0.42062836344148447\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  2.6027497411607863 acc:  0.4219011678538731\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  2.578943861114395 acc:  0.42333028158006386\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  46 loss :  2.5758629161994775 acc:  0.42252640510908157\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  47 loss :  2.551611885324225 acc:  0.4241788178549896\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  48 loss :  2.525154079590644 acc:  0.4243797869727352\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  49 loss :  2.5335470271277263 acc:  0.4242234776589331\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  50 loss :  2.502127869979485 acc:  0.4238438693254137\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  51 loss :  2.525129443282014 acc:  0.4263224884442757\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  52 loss :  2.505235700340538 acc:  0.42842149922961836\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  53 loss :  2.4955733539341214 acc:  0.4271040350132863\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  54 loss :  2.49740799823841 acc:  0.42837683942567495\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5246383891759951 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'CELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 648, 'dropout': 0.20522205289613513, 'dropout_StationIdEmbedding': 0.07569626942763033, 'dropout_timeStampEmbedding': 0.3486033441766751, 'dropout_transformers': 0.18105456410747045, 'early_stopping': 2, 'encoder_only': False, 'epochs_classifcation_only': 55, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8085756537070063, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.5246383891759951, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.8208303674611096, 'beta_2': 0.9667559904178682, 'eps': 4.369601211192274e-08, 'lr': 0.010345308052864882, 'optimizer': 'Adam', 'weight_decay': 2.0125254769307256e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.066092830932069 acc:  0.1534287564477592\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  4.867574808840266 acc:  0.2136301721635442\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  4.216584839506777 acc:  0.21467967755621553\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  3.9125029412572254 acc:  0.2251747314829288\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  3.738116188677485 acc:  0.22950673246544448\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  3.6180911635210413 acc:  0.22705044324855414\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  3.532129360530191 acc:  0.23683094031217203\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  3.4657468410309202 acc:  0.23551347609583995\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  3.4183940501984007 acc:  0.24871044816113258\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  3.3584717390779963 acc:  0.2485764687493022\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  3.3219710866848153 acc:  0.24806288100395238\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  3.272610180392237 acc:  0.24906772659268026\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  3.2709639172354144 acc:  0.24839782953352835\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  3.2214627522908286 acc:  0.2522162427706942\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  3.1913144674129827 acc:  0.25348904718308285\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  3.2034283598026114 acc:  0.25243954179041156\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  3.160056435419414 acc:  0.25636960453743607\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  3.1317137572579754 acc:  0.25435991335998037\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  3.1362792960184063 acc:  0.25563271777236896\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  3.1255981693724673 acc:  0.2586025947346091\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  3.1278868164131026 acc:  0.2593841413036197\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  3.1398090159821654 acc:  0.2600093785588281\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  3.1057871587262182 acc:  0.259853069245026\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  3.0990372774843684 acc:  0.25987539914699775\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  3.101603512278574 acc:  0.26047830650023446\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  3.0853949706711457 acc:  0.2592278319898176\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  3.1078543834343644 acc:  0.26092490453966904\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  3.1180687721617923 acc:  0.2605229663041779\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  3.0992167795489647 acc:  0.261014224147556\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  3.0886938886014286 acc:  0.26108121385347116\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  3.0520576245770483 acc:  0.26108121385347116\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  3.0865353452945183 acc:  0.2613045128731885\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  3.0987127669557126 acc:  0.2617511109126231\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  3.08386659764958 acc:  0.26163946140276445\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  3.088144660709861 acc:  0.2617734408145948\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  3.0797910033585785 acc:  0.26166179130473616\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  3.0866797898343936 acc:  0.26179577071656657\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  3.075399284591218 acc:  0.2613268427751602\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  3.1009930250887385 acc:  0.2616171315007927\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3222794518038893 and num_layers=1\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=86188)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 984, 'dropout': 0.08480769825751716, 'dropout_StationIdEmbedding': 0.17963035583085768, 'dropout_timeStampEmbedding': 0.4170156959961103, 'dropout_transformers': 0.5926570139752845, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 74, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.3222794518038893, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': True, 'beta_1': 0.8604000400634382, 'beta_2': 0.9754826879665086, 'eps': 3.304684136482976e-07, 'lr': 4.720358505500233e-05, 'optimizer': 'Adam', 'weight_decay': 3.0391831322775776e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  0 loss :  7.934535154929528 acc:  0.017908581381327737\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  1 loss :  6.954682610585139 acc:  0.09650983632181855\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  2 loss :  6.280689041431134 acc:  0.1582073554697095\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  3 loss :  5.785936439954318 acc:  0.21048165598553023\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  4 loss :  5.394444190538847 acc:  0.2434405912958042\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  5 loss :  5.071703030512883 acc:  0.2697005560145591\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  6 loss :  4.795263972649208 acc:  0.2880334055333497\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  7 loss :  4.567933409030621 acc:  0.30734877073889644\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  8 loss :  4.371794588749225 acc:  0.32215349574615365\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  9 loss :  4.205422546313359 acc:  0.33499318937989864\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  10 loss :  4.056466152117802 acc:  0.3446843668356296\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  11 loss :  3.92988490324754 acc:  0.3524551727217918\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  12 loss :  3.8166494791324324 acc:  0.3608065560592189\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  13 loss :  3.7148909440407385 acc:  0.3664783511600384\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  14 loss :  3.629356862948491 acc:  0.37328897126141614\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  15 loss :  3.5526315615727353 acc:  0.37887144675434875\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  16 loss :  3.476452662394597 acc:  0.3844539222472813\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  17 loss :  3.413733926186195 acc:  0.3884733046021928\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  18 loss :  3.35710829771482 acc:  0.392760645780765\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  19 loss :  3.305520228239206 acc:  0.3952392648996271\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  20 loss :  3.2570285356961763 acc:  0.3997945649018601\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  21 loss :  3.2115160887057965 acc:  0.40167027666748545\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  22 loss :  3.171302160849938 acc:  0.40484112274747114\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  23 loss :  3.1372859092859122 acc:  0.40890516490632606\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  24 loss :  3.0994342418817373 acc:  0.4113837840251881\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  25 loss :  3.066802228414095 acc:  0.41203135118236833\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  26 loss :  3.040417374097384 acc:  0.41464394971306073\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  27 loss :  3.00600639123183 acc:  0.4181497443226224\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  28 loss :  2.981980558542105 acc:  0.41765848647924436\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  29 loss :  2.9565307507148155 acc:  0.4195565281468414\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  30 loss :  2.934003754762503 acc:  0.4212312707947212\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  31 loss :  2.9091742680622983 acc:  0.42185650804992963\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  32 loss :  2.8891341631229106 acc:  0.4218788379519014\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  33 loss :  2.871492229975187 acc:  0.4246254158944242\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  34 loss :  2.8442835037524885 acc:  0.4249826943259719\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  35 loss :  2.8312653596584614 acc:  0.4248487149141415\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  36 loss :  2.812590846648583 acc:  0.4256079315811804\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  37 loss :  2.7949418288010817 acc:  0.4253399727575196\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  38 loss :  2.7764650326508744 acc:  0.42607685952258667\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  39 loss :  2.765993668482854 acc:  0.42819820020990107\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  40 loss :  2.747255875514104 acc:  0.42904673648482683\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  41 loss :  2.7339707649671112 acc:  0.42906906638679854\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  42 loss :  2.7181765207877526 acc:  0.42964964383806353\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  43 loss :  2.7067901061131403 acc:  0.4309224482504522\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  44 loss :  2.6941738367080688 acc:  0.4319942835450952\n",
            "\u001b[36m(eval_config pid=86188)\u001b[0m epoch:  45 loss :  2.682091701947726 acc:  0.4303418707991872\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 00:16:49,221\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 00:17:03,791\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 00:17:03,793\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_2        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_2\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_2`\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3185351864747675 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1440, 'dropout': 0.06481227396936776, 'dropout_StationIdEmbedding': 0.1708766743744856, 'dropout_timeStampEmbedding': 0.07422947228325949, 'dropout_transformers': 0.0794317889686042, 'early_stopping': 1, 'encoder_only': False, 'epochs_classifcation_only': 63, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3770916843597625, 'scheduler': 'StepLR', 'step_size': 30, 'dropout_lstm': 0.3185351864747675, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'alpha': 0.938452613050594, 'centered': True, 'eps': 3.6555484290291812e-09, 'lr': 0.08737157533127207, 'momentum': 0.4793949095942875, 'optimizer': 'RMSprop', 'weight_decay': 2.535044971156741e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1763145348079828 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.26070687905349665, 'dropout_StationIdEmbedding': 0.08653789669073876, 'dropout_timeStampEmbedding': 0.16094489916002702, 'dropout_transformers': 0.3143248311414082, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 79, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.1763145348079828, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8964571198071845, 'beta_2': 0.9575675306205829, 'eps': 3.6159380704877956e-07, 'lr': 2.9024428536914103e-05, 'optimizer': 'AdamW', 'weight_decay': 7.080137709065855e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.992803896390475 acc:  0.007971775003907732\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  7.210398354897133 acc:  0.043610298550789364\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  6.659728593092698 acc:  0.11801353192059487\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  6.0411898282858045 acc:  0.17676350400821741\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  5.502544535123385 acc:  0.2237902775606815\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  5.041511205526499 acc:  0.2584239555188353\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  4.660384108470036 acc:  0.28638099278744167\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  4.350908769094027 acc:  0.30947011142621084\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  4.093732268993671 acc:  0.32860683741598373\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  3.8868792588894183 acc:  0.34492999575731864\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  3.7112732905607957 acc:  0.35739008105754416\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  3.5663635914142313 acc:  0.3676618359645401\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  3.4340036135453444 acc:  0.37768796194984705\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  13 loss :  3.3283984459363496 acc:  0.3852354688162919\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  14 loss :  3.2316810131072997 acc:  0.3920684188196414\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  15 loss :  3.1476197664554304 acc:  0.3991469977446799\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  16 loss :  3.0796898438380316 acc:  0.4028314315700154\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  17 loss :  3.0136470244481015 acc:  0.4068731438268986\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  18 loss :  2.957270288467407 acc:  0.4106245673581493\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  19 loss :  2.9041437515845665 acc:  0.4154254962820713\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  20 loss :  2.854418167701134 acc:  0.416608981086573\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  21 loss :  2.8135515433091385 acc:  0.4187749815778309\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  22 loss :  2.775945834013132 acc:  0.4205390438335976\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  23 loss :  2.7339409809846145 acc:  0.42373221981555503\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  24 loss :  2.697172190592839 acc:  0.4263894781501909\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  25 loss :  2.667392818744366 acc:  0.4263224884442757\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  26 loss :  2.6380578848031853 acc:  0.42779626197440995\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  27 loss :  2.6092634952985323 acc:  0.4297389634459505\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  28 loss :  2.5833501650736883 acc:  0.43036420070115894\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  29 loss :  2.557438111305237 acc:  0.43094477815242394\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  30 loss :  2.5339702331102814 acc:  0.43154768550566064\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  31 loss :  2.5079033081348125 acc:  0.43215059285889734\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  32 loss :  2.48730890750885 acc:  0.43362436638903157\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  33 loss :  2.465559346859272 acc:  0.43386999531072057\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  34 loss :  2.4450344470831062 acc:  0.434584552173816\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  35 loss :  2.4279422668310313 acc:  0.43465154187973115\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  36 loss :  2.405574607849121 acc:  0.4352991090369113\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  37 loss :  2.3889400738936204 acc:  0.43605832570395014\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  38 loss :  2.3716567873954775 acc:  0.4358796864881763\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  39 loss :  2.357432921116169 acc:  0.43757675903802784\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  40 loss :  2.3405820764028107 acc:  0.4369738516847911\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  41 loss :  2.3229784672076885 acc:  0.4372864703123953\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  42 loss :  2.306348563157595 acc:  0.4371078310966215\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  43 loss :  2.295723746373103 acc:  0.4392291717839359\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  44 loss :  2.278423621104314 acc:  0.4383136458030949\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  45 loss :  2.2670641037134023 acc:  0.4388495634504165\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  46 loss :  2.2490947402440584 acc:  0.4372864703123953\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.14415152640995627 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'SiLU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.2680783994408866, 'dropout_StationIdEmbedding': 0.0739238728613087, 'dropout_timeStampEmbedding': 0.02209788354660225, 'dropout_transformers': 0.337638725755541, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 69, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 10, 'factor': 0.017659676725530205, 'patience': 2, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.2702315615474546, 'dropout_lstm': 0.14415152640995627, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'alpha': 0.999167930780396, 'centered': False, 'eps': 2.695980735175652e-09, 'lr': 0.036935167045001105, 'momentum': 0.3891524761786034, 'optimizer': 'RMSprop', 'weight_decay': 0.007137477686874513, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m loss is undifined\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.020742256607691828 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Softsign', 'batch_size': 128, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.18102681845824922, 'dropout_StationIdEmbedding': 0.10392545818255872, 'dropout_timeStampEmbedding': 0.15437432061990405, 'dropout_transformers': 0.29882918903011946, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 78, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.020742256607691828, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9024997607854329, 'beta_2': 0.9575548291052323, 'eps': 3.30971932219932e-07, 'lr': 0.00042685753975095584, 'optimizer': 'AdamW', 'weight_decay': 4.769814423250419e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  6.377861888468766 acc:  0.2588035638523547\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  4.013160617411637 acc:  0.36326284527610925\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  3.1998174050275017 acc:  0.40470714333564073\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  2.859230410151121 acc:  0.42000312618627605\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  2.662421504990393 acc:  0.4281535404059576\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  2.526163521934958 acc:  0.43349038697720116\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  2.4270212770510122 acc:  0.43353504678114463\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  2.330848998382312 acc:  0.4338030056048054\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  2.2441759209672942 acc:  0.43657191344929996\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  2.177238975252424 acc:  0.4352991090369113\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  2.105619553758317 acc:  0.4361253154098654\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  2.0404709357173503 acc:  0.4352767791349396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.008118261989633554 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Softsign', 'batch_size': 128, 'concatenate_features': True, 'd_model': 648, 'dropout': 0.16644297114258483, 'dropout_StationIdEmbedding': 0.11797401955244144, 'dropout_timeStampEmbedding': 0.14776856522258514, 'dropout_transformers': 0.2745678392768168, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 79, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3017648723625681, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.008118261989633554, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9073516314833748, 'beta_2': 0.9583504918664006, 'eps': 3.632032183754977e-07, 'lr': 0.000292092262624945, 'optimizer': 'AdamW', 'weight_decay': 8.406124772483723e-08, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  6.713554097824738 acc:  0.2064176138266753\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  5.034677369253976 acc:  0.2594288011075631\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  4.608875771530536 acc:  0.273273340330036\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  4.4906218492684244 acc:  0.27767233101846683\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  4.457627238345747 acc:  0.2786995065091664\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  4.447366988959432 acc:  0.27903445503874236\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  4.44197169872893 acc:  0.2792577540584597\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  4.453089870324655 acc:  0.27923542415648794\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  4.453422686632941 acc:  0.2792577540584597\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  4.437963305401201 acc:  0.2793024138624031\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  4.43874351517493 acc:  0.2792577540584597\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  4.433477005036939 acc:  0.2792577540584597\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  4.441267538471382 acc:  0.2793024138624031\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.09006872349014237 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Softsign', 'batch_size': 128, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.48146394546781046, 'dropout_StationIdEmbedding': 0.37022445255740244, 'dropout_timeStampEmbedding': 0.001576203477589161, 'dropout_transformers': 0.06945179989196446, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 55, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.09006872349014237, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 4, 'alpha': 0.9493078422155424, 'centered': True, 'eps': 1.2815905764013671e-08, 'lr': 1.1795758089441892e-05, 'momentum': 0.3973259665301577, 'optimizer': 'RMSprop', 'weight_decay': 1.9495491873470937e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.648957934335013 acc:  0.05225197061384901\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  6.97069521485088 acc:  0.1118504789763973\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  6.530262216229305 acc:  0.15588504566464953\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  6.170477862670043 acc:  0.18185472165777192\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  5.879418065614789 acc:  0.20112542705937522\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  5.599837998363459 acc:  0.21284862559453363\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  5.369990299795275 acc:  0.22356697854096422\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  5.1521716920014855 acc:  0.2396891677645535\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  4.972863237434458 acc:  0.2515910055154858\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  4.776626631478283 acc:  0.2605899560100931\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  4.624982726908176 acc:  0.27197820601567557\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  4.480588409388177 acc:  0.2807315275885939\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  4.342909224679537 acc:  0.28975280798517294\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  13 loss :  4.199844010522432 acc:  0.29732264475358955\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  14 loss :  4.105064398774477 acc:  0.3063662550521403\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  15 loss :  3.9841565194531023 acc:  0.31453899917379363\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  16 loss :  3.878725194485388 acc:  0.32228747515798406\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  17 loss :  3.79279928118269 acc:  0.3296116830047116\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  18 loss :  3.716233188860884 acc:  0.33749413840073245\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  19 loss :  3.6401247220618704 acc:  0.34452805752182747\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  20 loss :  3.5750961014043505 acc:  0.3496862648772972\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  21 loss :  3.479658855456058 acc:  0.35544737958600364\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  22 loss :  3.4258491123948143 acc:  0.3608512158631624\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  23 loss :  3.3816713662905116 acc:  0.36437934037469577\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  24 loss :  3.3206560589442744 acc:  0.37105598106424315\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  25 loss :  3.281037831974921 acc:  0.37268606390817943\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  26 loss :  3.2233007243860547 acc:  0.37697340508675165\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  27 loss :  3.1821021788588193 acc:  0.3798762923430766\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  28 loss :  3.1315023364307724 acc:  0.3830917982270058\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  29 loss :  3.1038613274832754 acc:  0.38706652077797377\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  30 loss :  3.0561751940540063 acc:  0.39037134626978987\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  31 loss :  3.029250802280747 acc:  0.39314025411428444\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  32 loss :  2.995828058118018 acc:  0.3949936359779381\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  33 loss :  2.957351180994622 acc:  0.39718196637116765\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  34 loss :  2.923341000191519 acc:  0.398477100685528\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  35 loss :  2.8850224953945554 acc:  0.4017372663734006\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  36 loss :  2.869578082984853 acc:  0.40383627715874326\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  37 loss :  2.834444988553769 acc:  0.40772168010182436\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  38 loss :  2.8138774399445436 acc:  0.40682848402295513\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  39 loss :  2.7944136824563284 acc:  0.408659535984637\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  40 loss :  2.7747668194993635 acc:  0.41243328941785945\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  41 loss :  2.747288256048042 acc:  0.4130808565750396\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  42 loss :  2.715120010286848 acc:  0.41529151687024096\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  43 loss :  2.7076078441655524 acc:  0.4146886095170042\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  44 loss :  2.693268027261039 acc:  0.41437599088939997\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  45 loss :  2.6687920940256564 acc:  0.41922157961726547\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  46 loss :  2.6424001533294392 acc:  0.41890896098966124\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  47 loss :  2.628407547407061 acc:  0.42096331197106046\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  48 loss :  2.6075927475902523 acc:  0.4221244668735904\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  49 loss :  2.610659115782408 acc:  0.42196815755978834\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  50 loss :  2.5793243301248996 acc:  0.42279436393274233\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  51 loss :  2.5661728226135825 acc:  0.42529531295357614\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  52 loss :  2.542194571450492 acc:  0.4245360962865373\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  53 loss :  2.5330767988044527 acc:  0.42701471540539937\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  54 loss :  2.516419132179189 acc:  0.42522832324766097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1990058380600325 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'LogSigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 432, 'dropout': 0.28625512985266344, 'dropout_StationIdEmbedding': 0.2868159256091363, 'dropout_timeStampEmbedding': 0.058309692541478206, 'dropout_transformers': 0.10218858329978486, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 47, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.3635282361292788, 'scheduler': 'StepLR', 'step_size': 1, 'dropout_lstm': 0.1990058380600325, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9297688430477632, 'beta_2': 0.951051691380568, 'eps': 1.0322456175370109e-06, 'lr': 0.003596473300952738, 'optimizer': 'AdamW', 'weight_decay': 4.616716870529124e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.081336521240602 acc:  0.16879172900430967\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  5.716614298073642 acc:  0.222673782462095\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  4.984891385917204 acc:  0.2504745104168993\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  4.636011066206967 acc:  0.26023267757854546\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  4.49005582533687 acc:  0.26443069914923073\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  4.445582050875009 acc:  0.2646763280709198\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  4.42257757933743 acc:  0.26570350356161937\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  4.425512175962149 acc:  0.26612777169908225\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  4.432402883667543 acc:  0.2660607819931671\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  4.438448029828359 acc:  0.2658821427773932\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  4.397069284714848 acc:  0.2658821427773932\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2394864782197647 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 648, 'dropout': 0.04781246254922128, 'dropout_StationIdEmbedding': 0.22059608669842368, 'dropout_timeStampEmbedding': 0.1624345622398177, 'dropout_transformers': 0.026182522295456034, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 77, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 1, 'factor': 0.025681708553783655, 'patience': 1, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.1549368317282937, 'dropout_lstm': 0.2394864782197647, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8849779365933899, 'beta_2': 0.957263514555617, 'eps': 2.53010705914709e-06, 'lr': 0.013297716341973785, 'optimizer': 'AdamW', 'weight_decay': 5.290132749821607e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  6.680663499487451 acc:  0.2223165040305473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  4.611268603658101 acc:  0.24902306678873679\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  3.7276569676686484 acc:  0.2963177991648617\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  3.3091634871011757 acc:  0.3174642163320903\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  3.1592554299228164 acc:  0.33191166290779983\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  3.113978072821376 acc:  0.3395484893821316\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  3.0837704819369027 acc:  0.3398387781077641\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  3.0749495144349983 acc:  0.33970479869593373\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  3.0712590906993453 acc:  0.34030770604917043\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  3.0737228048853127 acc:  0.34024071634325526\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  3.0936781009995795 acc:  0.3401960565393118\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  3.0936718963714966 acc:  0.3401960565393118\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  3.0932372707918465 acc:  0.3401960565393118\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  13 loss :  3.0956572164972145 acc:  0.3401960565393118\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  14 loss :  3.0891670950924057 acc:  0.34024071634325526\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'SELU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 576, 'dropout': 0.35517325406828515, 'dropout_StationIdEmbedding': 0.0338387158261461, 'dropout_timeStampEmbedding': 0.2994051668846006, 'dropout_transformers': 0.19996992503119904, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 60, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.061941791384783146, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 4, 'alpha': 0.92879834111521, 'centered': False, 'eps': 5.830483708495168e-06, 'lr': 3.146608365264491e-06, 'momentum': 0.02799926162679206, 'optimizer': 'RMSprop', 'weight_decay': 0.0006512454362373307, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.061941791384783146 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  8.122256311319642 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  8.05166454638465 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  7.986280457448151 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  7.933377637701519 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  7.873404850394039 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  7.823244935375149 acc:  0.001496103432105933\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  7.77035544282299 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  7.716384063332768 acc:  0.0027465779425228324\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  7.676770218348099 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  7.6309798531613104 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  7.602573370529433 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  7.573338573261843 acc:  0.0056271352968760464\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  7.537675655494302 acc:  0.006274702454056227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  13 loss :  7.510953854706328 acc:  0.006922269611236407\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  14 loss :  7.474712953729145 acc:  0.007547506866444857\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  15 loss :  7.453673209174204 acc:  0.008530022553200992\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  16 loss :  7.422250820418536 acc:  0.009132929906437711\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  17 loss :  7.4031117649401645 acc:  0.009981466181363464\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  18 loss :  7.371906385583393 acc:  0.011321260299667284\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  19 loss :  7.357571601867676 acc:  0.01230377598642342\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  20 loss :  7.339677778341002 acc:  0.013487260790925128\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  21 loss :  7.310192867860955 acc:  0.01496103432105933\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  22 loss :  7.2864487373222735 acc:  0.016591117164995645\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  23 loss :  7.276969384338896 acc:  0.017908581381327737\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  24 loss :  7.2401380700580145 acc:  0.01940468481343367\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  25 loss :  7.239985716544975 acc:  0.02134738628497421\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  26 loss :  7.215529255947824 acc:  0.022508541187504186\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  27 loss :  7.210527323060116 acc:  0.02400464461961012\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  28 loss :  7.196028871051336 acc:  0.02536676863988567\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  29 loss :  7.1730855683148915 acc:  0.026773552464104684\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  30 loss :  7.156334141553459 acc:  0.027666748542973896\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  31 loss :  7.147754515631724 acc:  0.02927450148493848\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  32 loss :  7.108819985793809 acc:  0.03032400687760981\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  33 loss :  7.112134796077922 acc:  0.03240068776098073\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  34 loss :  7.093516745809781 acc:  0.03351718285956724\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  35 loss :  7.089789503711765 acc:  0.03572784315476855\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  36 loss :  7.0703322362091585 acc:  0.0373802559006766\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  37 loss :  7.05926403756869 acc:  0.038563740705178304\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  38 loss :  7.034466711141295 acc:  0.040796730902351336\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  39 loss :  7.021077592494124 acc:  0.04148895786347498\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  40 loss :  7.028881800376762 acc:  0.043186030413326484\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  41 loss :  7.008636531183275 acc:  0.04465980394346069\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  42 loss :  6.99572665004407 acc:  0.045932608355849315\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  43 loss :  6.994490251702778 acc:  0.047585021101757365\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  44 loss :  6.956121533603992 acc:  0.0490811245338633\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  45 loss :  6.9635362786761785 acc:  0.05064421767188442\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  46 loss :  6.920995760772188 acc:  0.05138110443695152\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  47 loss :  6.93537927886187 acc:  0.0530558470848313\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  48 loss :  6.917526140051373 acc:  0.05399370296764397\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  49 loss :  6.923998469013279 acc:  0.05511019806623049\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  50 loss :  6.90303157547773 acc:  0.05662863140030815\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  51 loss :  6.9159806138378075 acc:  0.05803541522452717\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  52 loss :  6.88780374850257 acc:  0.05941986914677445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  53 loss :  6.880399194814391 acc:  0.06024607551972847\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  54 loss :  6.880726693040233 acc:  0.061407230422258444\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  55 loss :  6.867880223161083 acc:  0.06254605542281669\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  56 loss :  6.856706449540995 acc:  0.06435477748252685\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  57 loss :  6.841677002987619 acc:  0.06591787062054798\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  58 loss :  6.837394972979012 acc:  0.0664537882678695\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  59 loss :  6.832174672918804 acc:  0.06774892258222986\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3620687895634662 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Softsign', 'batch_size': 128, 'concatenate_features': True, 'd_model': 864, 'dropout': 0.15264521577592885, 'dropout_StationIdEmbedding': 0.09257820445673795, 'dropout_timeStampEmbedding': 0.25366459898702465, 'dropout_transformers': 0.5076449951348454, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 66, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.2999990737302809, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.3620687895634662, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9511006928012369, 'beta_2': 0.954996327858048, 'eps': 2.651662343920685e-07, 'lr': 1.2732979423880814e-06, 'optimizer': 'AdamW', 'weight_decay': 0.0006292089957419837, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  8.26911686383761 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  8.253533928210919 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  8.249050367795505 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  8.246727642646203 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  8.246940994262696 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  8.249335560431847 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'RReLU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1104, 'dropout': 0.11007253643316839, 'dropout_StationIdEmbedding': 0.4510045081743991, 'dropout_timeStampEmbedding': 0.3172203591504018, 'dropout_transformers': 0.2918492291883989, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 33, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8955151012913805, 'beta_2': 0.9504008807508265, 'eps': 7.473758783181554e-07, 'lr': 2.528325314832884e-05, 'optimizer': 'AdamW', 'weight_decay': 1.5309113475345312e-08, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.675854065838982 acc:  0.0034834647075899336\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  7.275645264056551 acc:  0.014760065203313757\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  7.113557815551758 acc:  0.06317129267802514\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  6.879986001663849 acc:  0.10055154857870174\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  6.597066919342811 acc:  0.12029118192171136\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  6.305310613968793 acc:  0.13375611281066477\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  6.013883983387666 acc:  0.15412098340888283\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  5.7618738382804295 acc:  0.17151597704486077\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  8 loss :  5.531744203647645 acc:  0.1869236094053547\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  9 loss :  5.3273615877167515 acc:  0.20146037558895116\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  10 loss :  5.136042667036297 acc:  0.21461268785030033\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  11 loss :  4.961151086983561 acc:  0.22620190697362838\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  12 loss :  4.8184426011157635 acc:  0.23596007413527453\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  13 loss :  4.688630404592562 acc:  0.2440881584529844\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  14 loss :  4.548310167649213 acc:  0.2545385525757542\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  15 loss :  4.449693771971374 acc:  0.25951812071545005\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  16 loss :  4.314532231883843 acc:  0.2664627202286582\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  17 loss :  4.229668242590768 acc:  0.27099569032891946\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  18 loss :  4.135966831896486 acc:  0.2770024339593149\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  19 loss :  4.060372837451326 acc:  0.28370140455083404\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  20 loss :  3.9865773044714405 acc:  0.29129357122122235\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  21 loss :  3.9133261872940706 acc:  0.29660808789049414\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  22 loss :  3.856954438345773 acc:  0.3020119241676529\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  23 loss :  3.7779374563393473 acc:  0.3087555545631155\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  24 loss :  3.7302114362476253 acc:  0.3130652256436594\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  25 loss :  3.691640437150202 acc:  0.3205010830002456\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  26 loss :  3.6350350740576993 acc:  0.32498939329656346\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  27 loss :  3.5902576366392505 acc:  0.3286738271218989\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  28 loss :  3.547231602067707 acc:  0.3360873545765134\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  29 loss :  3.510524092602129 acc:  0.34068731438268984\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  30 loss :  3.4781403281107672 acc:  0.34280865507000424\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  31 loss :  3.438558630582665 acc:  0.3477212335037849\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  32 loss :  3.399576866326212 acc:  0.3528571109572829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13567017543400267 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'Tanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 936, 'dropout': 0.2144262302829353, 'dropout_StationIdEmbedding': 0.7438218963442336, 'dropout_timeStampEmbedding': 0.10865370973419583, 'dropout_transformers': 0.17973301367981903, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 53, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 5, 'factor': 0.27395867139810964, 'patience': 4, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.009191231847049753, 'dropout_lstm': 0.13567017543400267, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'alpha': 0.9957518132404564, 'centered': False, 'eps': 9.074941891790476e-07, 'lr': 0.015637712543671915, 'momentum': 0.22449799860618114, 'optimizer': 'RMSprop', 'weight_decay': 2.5044459760886222e-05, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m loss is undifined\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0009188326006648317 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'ReLU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 552, 'dropout': 0.3200467844444552, 'dropout_StationIdEmbedding': 0.33205066692000035, 'dropout_timeStampEmbedding': 0.1524203744540469, 'dropout_transformers': 0.0016516744885342605, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 41, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.0009188326006648317, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 12, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 4, 'amsgrad': False, 'beta_1': 0.9237934647699764, 'beta_2': 0.9603204025088408, 'eps': 9.798426465484697e-08, 'lr': 0.0003416372305808973, 'optimizer': 'AdamW', 'weight_decay': 0.008069193667814516, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.994993469931862 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  7.787747253071178 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  7.595497304742986 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  7.578171469948509 acc:  0.0025902686287207198\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  7.5018346959894355 acc:  0.0017194024518232365\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Hardshrink', 'batch_size': 64, 'concatenate_features': True, 'd_model': 720, 'dropout': 0.47488466896183584, 'dropout_StationIdEmbedding': 0.2595047942208853, 'dropout_timeStampEmbedding': 0.0030906655757370616, 'dropout_transformers': 0.4298392081369931, 'early_stopping': 6, 'encoder_only': False, 'epochs_classifcation_only': 21, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8973377305984398, 'scheduler': 'StepLR', 'step_size': 29, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'lr': 5.394247126015418e-07, 'momentum': 0.11853627431223135, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 2.919470342488512e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  8.070110477939728 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  8.069357256735525 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  8.070815578583748 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  8.070866184849892 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  8.071175243008522 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  8.068607404155117 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  8.069700604100381 acc:  0.0008262063729540227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20720656406138455 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'LeakyReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 816, 'dropout': 0.24487312738527295, 'dropout_StationIdEmbedding': 0.4782462609563159, 'dropout_timeStampEmbedding': 0.4465247279357142, 'dropout_transformers': 0.24187457152905742, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.20720656406138455, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9450418529054735, 'beta_2': 0.965252582715933, 'eps': 2.7647566945256997e-08, 'lr': 2.678227992161398e-06, 'optimizer': 'AdamW', 'weight_decay': 5.811893997859784e-06, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  8.117569656015556 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  8.077181272417585 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  8.035919603900375 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  8.003533425732194 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  7.961379505763544 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  7.922243907072834 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  6 loss :  7.876921359623704 acc:  0.005448496081102204\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  7 loss :  7.826553362552251 acc:  0.005269856865328361\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.04588539207539638 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Mish', 'batch_size': 128, 'concatenate_features': False, 'd_model': 1056, 'dropout': 0.40500501796957167, 'dropout_StationIdEmbedding': 0.40069081027562425, 'dropout_timeStampEmbedding': 0.054204397348860206, 'dropout_transformers': 0.507200548196927, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 2, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.8667331256154139, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.04588539207539638, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 5, 'amsgrad': False, 'beta_1': 0.9069226788355222, 'beta_2': 0.9702066855498683, 'eps': 3.963272655257734e-06, 'lr': 0.0010873151281478677, 'optimizer': 'AdamW', 'weight_decay': 0.044452372252998903, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  5.867896494112517 acc:  0.26990152513230464\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  3.4517531495345266 acc:  0.35468816291896477\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Softplus', 'batch_size': 128, 'concatenate_features': True, 'd_model': 744, 'dropout': 0.16828977497640757, 'dropout_StationIdEmbedding': 0.5275672792888184, 'dropout_timeStampEmbedding': 0.255465140910663, 'dropout_transformers': 0.3186637733374214, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 57, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 10, 'factor': 0.8623210500755677, 'patience': 10, 'scheduler': 'ReduceLROnPlateau', 'threshold': 8.393184938349315e-06, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'alpha': 0.9708199552772591, 'centered': True, 'eps': 1.1075566123276954e-07, 'lr': 4.958819789945677e-05, 'momentum': 0.3808687155186945, 'optimizer': 'RMSprop', 'weight_decay': 2.1762477794129237e-09, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.485147050710824 acc:  0.005336846571243553\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  7.264512744316688 acc:  0.004465980394346068\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  7.202344964100765 acc:  0.03257932697675457\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13540938818987527 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Hardtanh', 'batch_size': 32, 'concatenate_features': False, 'd_model': 600, 'dropout': 0.4561195515382004, 'dropout_StationIdEmbedding': 0.9417777919007059, 'dropout_timeStampEmbedding': 0.173417021958978, 'dropout_transformers': 0.6362686627523595, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 64, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.13540938818987527, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 4, 'lr': 1.7055595170546112e-05, 'momentum': 0.3830425719103891, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 2.398977035981425e-09, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  8.112507612345604 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  8.110068529011818 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  8.110512269941788 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  8.108899462822428 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Hardsigmoid', 'batch_size': 64, 'concatenate_features': True, 'd_model': 936, 'dropout': 0.2799242543542327, 'dropout_StationIdEmbedding': 0.0386155069040552, 'dropout_timeStampEmbedding': 0.37828697971916725, 'dropout_transformers': 0.117164417380415, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 68, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 21, 'eta_min': 9.15341714389996e-06, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8635109006281019, 'beta_2': 0.9564845063877521, 'eps': 9.256577028073751e-08, 'lr': 0.0007266834770204199, 'optimizer': 'AdamW', 'weight_decay': 4.8192916351369436e-08, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  0 loss :  7.501266737907163 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  1 loss :  7.347215046421174 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  2 loss :  7.298147155392554 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  3 loss :  7.290869875877134 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  4 loss :  7.289702397008096 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m epoch:  5 loss :  7.269704852565642 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2697655062947037 and num_layers=1\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=147718)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Softmin', 'batch_size': 128, 'concatenate_features': True, 'd_model': 840, 'dropout': 0.623608665410623, 'dropout_StationIdEmbedding': 0.1564696070676831, 'dropout_timeStampEmbedding': 0.1023317236799374, 'dropout_transformers': 0.15929640622293462, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 78, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.6433319532151986, 'scheduler': 'StepLR', 'step_size': 10, 'dropout_lstm': 0.2697655062947037, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'RReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 36, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9612234038792027, 'beta_2': 0.9623928139360105, 'eps': 9.72651506065075e-09, 'lr': 0.025347935396950034, 'optimizer': 'AdamW', 'weight_decay': 3.2666748081056375e-07, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanh', 'dropout_gcn': 0.9894712551099907, 'hidden_channels': 512, 'layer_type': 'GraphSAGE', 'norm': 'LayerNorm', 'num_layers_gcn': 2, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=147718)\u001b[0m loss is undifined\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 02:41:01,860\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 02:41:16,737\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 02:41:16,738\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_3        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_3\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_3`\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.38031071144816575 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'ReLU6', 'batch_size': 64, 'concatenate_features': False, 'd_model': 456, 'dropout': 0.0012980306555653853, 'dropout_StationIdEmbedding': 0.10456912036775422, 'dropout_timeStampEmbedding': 0.5254810160750509, 'dropout_transformers': 0.4484911681975673, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 8, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.38031071144816575, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'lr': 0.011109562390026308, 'momentum': 0.09445856056773963, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 8.65962469596313e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.140402308965134 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.12464802952136 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  8.115220829591912 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  8.098896172087072 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  8.08287504163839 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  8.073831040980453 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  8.06185421701205 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  8.04357148833194 acc:  0.0023669696090034163\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.484035234259669 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Sigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 504, 'dropout': 0.08794049450462536, 'dropout_StationIdEmbedding': 0.20865629698406893, 'dropout_timeStampEmbedding': 0.1322336147870886, 'dropout_transformers': 0.2581026005192587, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 31, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.0009871197075032479, 'max_lr': 0.07635522331092133, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 9, 'dropout_lstm': 0.484035234259669, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'LeakyReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 4, 'amsgrad': False, 'beta_1': 0.885400090675543, 'beta_2': 0.9673373506900346, 'eps': 4.858946471998355e-09, 'lr': 0.00017703926163231486, 'optimizer': 'AdamW', 'weight_decay': 0.0005334299895800831, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.459433671047813 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.379312183982448 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.406506970054225 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.37391132053576 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.395470513795551 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.407405747865376 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.475888493186549 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'CELU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1128, 'dropout': 0.3794736514078232, 'dropout_StationIdEmbedding': 0.2831505455159269, 'dropout_timeStampEmbedding': 0.46072963792558486, 'dropout_transformers': 0.7762152524010135, 'early_stopping': 5, 'encoder_only': False, 'epochs_classifcation_only': 37, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 3, 'alpha': 0.9520295006346334, 'centered': True, 'eps': 1.3224368591670442e-08, 'lr': 0.011778938887567073, 'momentum': 0.4630914023055783, 'optimizer': 'RMSprop', 'weight_decay': 0.3136568930440908, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'RReLU', 'dropout_gcn': 0.5700377284419751, 'hidden_channels': 1024, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 5, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.305441014310146 acc:  0.003103856374070518\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.019828370276917 acc:  0.0025902686287207198\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  8.019319595174586 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  8.019433914346898 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  8.010004439252489 acc:  0.0036397740213920463\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.87381082900027 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.818281589670384 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  7.850242959692123 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  7.875070835681671 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  7.882081468054589 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'GELU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 216, 'dropout': 0.3261789051355585, 'dropout_StationIdEmbedding': 0.6700150419413546, 'dropout_timeStampEmbedding': 0.08239052987264821, 'dropout_transformers': 0.3741388122684646, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 45, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 20, 'eta_min': 0.3018332817437602, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.5866157179760317, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 5, 'amsgrad': False, 'beta_1': 0.9151395203704776, 'beta_2': 0.9723896620714999, 'eps': 1.4729887865514226e-06, 'lr': 2.7781862337894983e-05, 'optimizer': 'AdamW', 'weight_decay': 3.2043231485854965e-09, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5866157179760317 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.169504349973021 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.3936777956345505 acc:  0.03097157403478999\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  6.798426992752972 acc:  0.18652167116986357\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  5.878395024467917 acc:  0.2126923162807315\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  5.279356479644775 acc:  0.22434852510997477\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  5.082611893405433 acc:  0.21514860549762185\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23713305944913743 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 696, 'dropout': 0.541300256763616, 'dropout_StationIdEmbedding': 0.32440931108325116, 'dropout_timeStampEmbedding': 0.3325215479777458, 'dropout_transformers': 0.34721351770104, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 62, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5687294813995353, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.23713305944913743, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardswish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 1, 'lr': 3.3272871705909365e-06, 'momentum': 0.39267756241044116, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 0.016307081781112134, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Tanhshrink', 'dropout_gcn': 0.7702759895140173, 'hidden_channels': 2048, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 2, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.020785875409564 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.020754778496572 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  8.020906733575268 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4727041511204779 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1392, 'dropout': 0.23486814482870977, 'dropout_StationIdEmbedding': 0.012869712632046393, 'dropout_timeStampEmbedding': 0.20990781763196148, 'dropout_transformers': 0.39982692079034005, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 71, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.4727041511204779, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8640403458355227, 'beta_2': 0.9594584700146656, 'eps': 2.2922850836244756e-08, 'lr': 2.8664721598807104e-05, 'optimizer': 'AdamW', 'weight_decay': 1.0190736848145976e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.789859985138153 acc:  0.00714556863095371\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.233793135289545 acc:  0.02407163432552531\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.008068741618336 acc:  0.05515485787017395\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  6.7622723312644695 acc:  0.10533014760065203\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  6.51518282523522 acc:  0.14228613536386575\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  6.258257008932687 acc:  0.16651407900319318\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  6.02914826853292 acc:  0.1955206216644709\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  5.771256636906337 acc:  0.2108389344170779\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  5.5140855062258 acc:  0.224661143737579\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  5.273860084426986 acc:  0.24015809570595986\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  5.030562254098745 acc:  0.25147935600562715\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  4.859471702909136 acc:  0.2648996270906371\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  4.687740674385657 acc:  0.2761762275863609\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  4.50453299409026 acc:  0.28660429180715896\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  4.330409243390276 acc:  0.2956032423017663\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  4.246118345460691 acc:  0.3054283991693276\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  4.079436895730612 acc:  0.31302056583971594\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  3.981575810825908 acc:  0.3221758256481254\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  3.8570581099370145 acc:  0.32760199182725586\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  3.7754533957768155 acc:  0.33791840653819527\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  3.6884113375123566 acc:  0.34363486144295824\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  3.616556892861853 acc:  0.3497532545832124\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  3.5382127178298846 acc:  0.3542415648795302\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  3.454745659461388 acc:  0.36011432909809526\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  3.4004125345003353 acc:  0.36679096978764264\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  3.3090630794738556 acc:  0.3709889913583279\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  3.279325710309969 acc:  0.3758345800861934\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  3.2380669933932644 acc:  0.38027823057856774\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  3.184783682122931 acc:  0.3848781903847442\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  3.1586065008923723 acc:  0.3863519639148784\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  3.104966655477777 acc:  0.39101891342697004\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  3.034396828471364 acc:  0.3945247080365317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  3.0126920063178857 acc:  0.3955518835272313\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  2.995948316334011 acc:  0.39881204921510394\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  2.941933000004375 acc:  0.39992854431369046\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  2.9042393360938226 acc:  0.4021838644128352\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  2.9031692218113614 acc:  0.4052877207869057\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  2.8988946617900075 acc:  0.40618091686577495\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  2.851872355787904 acc:  0.4109595158877253\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  2.8063282749869605 acc:  0.41124980461335775\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  2.8020380810424164 acc:  0.4138847330460219\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  2.778101442577122 acc:  0.41395172275193715\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  2.7421786384982663 acc:  0.4164303418707992\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  2.7391292215227248 acc:  0.4181274144206507\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  2.7210593156881266 acc:  0.41971283746064353\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  2.705372720331579 acc:  0.42154388942232546\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  2.664134585774028 acc:  0.42333028158006386\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  2.643217408573711 acc:  0.4236652301096398\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  2.660680919260412 acc:  0.4238661992273854\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  2.6102714655282613 acc:  0.4261661791304736\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  2.6034009840104964 acc:  0.4261885090324454\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  2.5914232947609643 acc:  0.42723801442511666\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  2.5476577265279277 acc:  0.4292477056025724\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  2.5623279901651235 acc:  0.4306991492307349\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  2.539593400655093 acc:  0.43150302570171717\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  2.5357964639063484 acc:  0.4318826340352366\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  2.512460733627106 acc:  0.43308844874171004\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  2.513147949338793 acc:  0.43429426344818345\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  2.4920465329310275 acc:  0.4324855413884733\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  2.472854191606695 acc:  0.43532143893888303\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  2.4527669036305033 acc:  0.4343165933501552\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  2.453039115125483 acc:  0.43717482080253667\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  2.433956771463781 acc:  0.43893888305830336\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  63 loss :  2.4211488987182403 acc:  0.43737578992028225\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  64 loss :  2.419457296391467 acc:  0.4391845119799924\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  65 loss :  2.4051424298253092 acc:  0.43994372864703124\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  66 loss :  2.397324968884875 acc:  0.4407252752160418\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  67 loss :  2.4438954833504205 acc:  0.43916218207802066\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  68 loss :  2.3810851207146277 acc:  0.44010003796083336\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  69 loss :  2.3627810886689833 acc:  0.4421320590402608\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  70 loss :  2.342743725209803 acc:  0.442199048746176\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.748792574455236 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1368, 'dropout': 0.21633943701146666, 'dropout_StationIdEmbedding': 0.06006319940401399, 'dropout_timeStampEmbedding': 0.24817736841872917, 'dropout_transformers': 0.21707783273911457, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 75, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.748792574455236, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.858421889895238, 'beta_2': 0.9604391015598143, 'eps': 1.7901681033341197e-08, 'lr': 2.7271004275205055e-05, 'optimizer': 'AdamW', 'weight_decay': 1.3929402018660987e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.761166375833792 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.21886828896049 acc:  0.010896992162204407\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  6.990608191990352 acc:  0.07007123238728982\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  6.717974219288859 acc:  0.11160485005470826\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  6.444596333937212 acc:  0.15079382801509503\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  6.134482076951674 acc:  0.17863921577384276\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  5.842527079415488 acc:  0.19922738539177812\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  5.57309541502199 acc:  0.22012817363731774\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  5.2695352681033265 acc:  0.23821539423441931\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  5.034614089485649 acc:  0.2555657280664538\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  4.8478559547370965 acc:  0.26900832905343547\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  4.652619268510725 acc:  0.2802402697452158\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  4.4633120623501865 acc:  0.28801107563137796\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  4.296869429675016 acc:  0.2999575731862537\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  4.155021492417876 acc:  0.3114798026036666\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  4.020986520327055 acc:  0.31911662907799837\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  3.927044406637445 acc:  0.3276243217292276\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  3.7921922023479757 acc:  0.3362659937922873\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  3.685011240152212 acc:  0.34539892369872494\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  3.609226396867445 acc:  0.351852265368555\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  3.552526357290628 acc:  0.3590424938034522\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  3.438462175689377 acc:  0.3641337114530067\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  3.3955271944299446 acc:  0.3682424134158051\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  3.27430958514447 acc:  0.3738918786146529\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  3.235975175470739 acc:  0.3767724359690061\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  3.208812418517533 acc:  0.37922872518589645\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  3.1283457579312626 acc:  0.3836723756782708\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  3.1064315475783983 acc:  0.389701449210638\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  3.0463202483170515 acc:  0.39316258401625614\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  2.9981753776123474 acc:  0.39521693499765537\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  2.9470426436070793 acc:  0.39823147176383894\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  2.93679954455449 acc:  0.4014469776477681\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  2.904672809414097 acc:  0.4053100506888775\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  2.8686966762676107 acc:  0.4072974119643615\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  2.8394709150274315 acc:  0.4102449590246299\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  2.8303734739343605 acc:  0.4127012482415202\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  2.7665437985133456 acc:  0.41435366098742826\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  2.742644331671975 acc:  0.4158274345175625\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  2.7164121757854116 acc:  0.41964584775472835\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  2.725618679206688 acc:  0.42015943550007817\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  2.6670160743740055 acc:  0.42105263157894735\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  2.654204523646748 acc:  0.42250407520710986\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  2.6434967184400224 acc:  0.4244244467766787\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  2.61495135047219 acc:  0.4254292923654065\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  2.5956946219597663 acc:  0.4271486948172298\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  2.5899147653913164 acc:  0.4295156644262332\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  2.5517906584106127 acc:  0.429448674720318\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  2.570274716490632 acc:  0.4312573967800281\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  2.5146345425319003 acc:  0.4324632114865016\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  2.500080387075464 acc:  0.4327981600160775\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  2.515171895493994 acc:  0.43349038697720116\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  2.4754315256238817 acc:  0.4336020364870598\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  2.46196579016172 acc:  0.4352767791349396\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  2.448159948095575 acc:  0.436482593841413\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  2.428837540266397 acc:  0.43679521246901726\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  2.4162742899848033 acc:  0.4374204497242257\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  2.4499026845385146 acc:  0.4388272335484447\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  2.4047069949703617 acc:  0.43721948060648014\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  2.3844250815731662 acc:  0.4403679967844941\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  2.3876260444000885 acc:  0.43996605854900295\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  2.3519400674980004 acc:  0.4409709041377308\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  2.3594328406807428 acc:  0.44173012080476964\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  2.331864842168101 acc:  0.44076993501998524\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7504566065967552 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1392, 'dropout': 0.2132341800917258, 'dropout_StationIdEmbedding': 0.055069988690378546, 'dropout_timeStampEmbedding': 0.28081094060414435, 'dropout_transformers': 0.40518460279781665, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 75, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7504566065967552, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8643925986139109, 'beta_2': 0.9503202673300509, 'eps': 1.7039507347789476e-08, 'lr': 4.313868257479694e-06, 'optimizer': 'AdamW', 'weight_decay': 1.4980452342895956e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.04369711042284 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.9989510816294 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.930481737310236 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.799376447717626 acc:  0.006051403434338924\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.6176435563947775 acc:  0.005738784806734698\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.480077450092022 acc:  0.006230042650112766\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.378244413362516 acc:  0.00710090882701025\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  7.303836759153779 acc:  0.007949445101936002\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  7.249109108131249 acc:  0.008641672063059644\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  7.196235546698937 acc:  0.009266909318268093\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  7.162779537947862 acc:  0.010941651966147868\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  7.121152691074185 acc:  0.013509590692896858\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  7.083504726836732 acc:  0.01632315834133488\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  7.058888171936249 acc:  0.01998526226469866\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  7.030744899402965 acc:  0.023870665207779737\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  7.005885230911361 acc:  0.029721099524373087\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  6.980486069525872 acc:  0.03592881227251413\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  6.931820315914554 acc:  0.040729741196436145\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  6.911795879577423 acc:  0.05006364022061943\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  6.871668482160235 acc:  0.05448496081102204\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  6.839020538996984 acc:  0.05796842551861197\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  6.800483790310946 acc:  0.06426545787463993\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  6.761667755100277 acc:  0.06864211866109908\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  6.742568799665758 acc:  0.07688185248866758\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  6.703404696671279 acc:  0.08204005984413729\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  6.676980562143393 acc:  0.08585847308130318\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  6.653921047290722 acc:  0.08987785543621464\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  6.598452581392301 acc:  0.09776031083223545\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  6.566219319830408 acc:  0.10539713730656722\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  6.536267377279855 acc:  0.10993010740682849\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  6.515979513421759 acc:  0.11647276868454548\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  6.472448969220782 acc:  0.12372998682535784\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  6.437140644847096 acc:  0.1303842976129335\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  6.39841984702157 acc:  0.1367259897729049\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  6.37135923492325 acc:  0.14154924859879864\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  6.324007411103149 acc:  0.14771230154299622\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  6.295336629960921 acc:  0.15427729272268495\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  6.276513983319689 acc:  0.15633164370408414\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  6.240123361974329 acc:  0.16396847017841593\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  6.20797907222401 acc:  0.1706451108679633\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  6.156252044064182 acc:  0.1742625549873836\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  6.100105889193662 acc:  0.17676350400821741\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  6.105501178261283 acc:  0.181765402049885\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  6.072158986871893 acc:  0.18283723734452806\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  5.998035707673826 acc:  0.18748185695464797\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  6.009256079480364 acc:  0.19002746577942523\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  5.91262826052579 acc:  0.19217113636871133\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  5.902180154840429 acc:  0.19424781725208226\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  5.890824591363226 acc:  0.19833418931290892\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  5.838671864329518 acc:  0.19978563294107138\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  5.76276978912887 acc:  0.20210794274613134\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  5.759845243467318 acc:  0.2047205412768238\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  5.747130327291422 acc:  0.20947681039680235\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  5.693706385739199 acc:  0.21115155304468214\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  5.656135399024803 acc:  0.21387580108523324\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  5.63071741757693 acc:  0.21626510059620838\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  5.5603718457522096 acc:  0.21809615255789028\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  5.561756190720138 acc:  0.21963691579393965\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  5.496971760596429 acc:  0.22329901971730345\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  5.481420446942736 acc:  0.22374561775673804\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  5.402080359158816 acc:  0.2270951030524976\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  5.4183094184715435 acc:  0.23028827903445503\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  5.340414380693769 acc:  0.23162807315275885\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  63 loss :  5.33481757624166 acc:  0.2343746510952817\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  64 loss :  5.294821859239699 acc:  0.23526784717415092\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  65 loss :  5.271759199929404 acc:  0.23792510550878682\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  66 loss :  5.227302711326759 acc:  0.23971149766652525\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  67 loss :  5.21412628680676 acc:  0.2421677868834156\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  68 loss :  5.155590347476773 acc:  0.24355224080566287\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  69 loss :  5.113035158677534 acc:  0.24605318982649665\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  70 loss :  5.081414407783455 acc:  0.24708036531719627\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  71 loss :  5.066733180226146 acc:  0.2498492731616908\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  72 loss :  5.075920735205804 acc:  0.25185896433914656\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  73 loss :  5.00823871239082 acc:  0.2532210883594221\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  74 loss :  5.00560574764972 acc:  0.2559453363999732\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9180716770322955 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1320, 'dropout': 0.2937572585945335, 'dropout_StationIdEmbedding': 0.14329899549129785, 'dropout_timeStampEmbedding': 0.24963007890636787, 'dropout_transformers': 0.22764380063168463, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 71, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.9180716770322955, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8502403679384819, 'beta_2': 0.9593259292545429, 'eps': 1.653602809193038e-08, 'lr': 1.999907349664514e-05, 'optimizer': 'AdamW', 'weight_decay': 8.133674275845041e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.9972980960722895 acc:  0.0032824955898443607\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.609290538295623 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.247208256875315 acc:  0.00777080588616216\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.151393785784322 acc:  0.01685907598865641\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.055059549885412 acc:  0.030257017171694617\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  6.939060543429467 acc:  0.042315164236429004\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  6.791184917573006 acc:  0.07335372797713419\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  6.708912452574699 acc:  0.09318268092803073\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  6.57174345754808 acc:  0.10689324073867315\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  6.460606633463214 acc:  0.12763771967041065\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  6.3763051740584835 acc:  0.1504142196815756\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  6.257902837568714 acc:  0.1616684902753277\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  6.144585107987927 acc:  0.17678583391018912\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  6.056237602233887 acc:  0.19228278587857\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  5.963803638950471 acc:  0.19822253980305027\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  5.792663217359974 acc:  0.21166514079003193\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  5.661623705587079 acc:  0.21890002902887257\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  5.57521895439394 acc:  0.22640287609137397\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  5.471447507796749 acc:  0.23569211531161377\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  5.371974249809019 acc:  0.24346292119777593\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  5.2359994334559286 acc:  0.2481968604157828\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  5.1166578861974905 acc:  0.25797735747940065\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  5.089159439456078 acc:  0.2636714824821919\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  4.96719954552189 acc:  0.27164325748609963\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  4.901047454341765 acc:  0.2752160418015765\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  4.840900711859426 acc:  0.2800839604314137\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  4.707283655289681 acc:  0.2870732197485653\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  4.664731456387427 acc:  0.29323627269276287\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  4.532947974051199 acc:  0.2962731393609182\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  4.461942698878627 acc:  0.30221289328539847\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  4.392212010968116 acc:  0.30491481142397786\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  4.287079029698526 acc:  0.31000602907353236\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  4.2064117508549845 acc:  0.31610209231181474\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  4.169799104813607 acc:  0.3170176182926557\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  4.098773700960221 acc:  0.32094768103968024\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  4.0327196382707164 acc:  0.32697675457204745\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  3.971272102479012 acc:  0.3288747962396445\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  3.90148882250632 acc:  0.33284951879061253\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  3.9039692509558894 acc:  0.3372038496750999\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  3.852085768791937 acc:  0.3381417055579126\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  3.7806279843853368 acc:  0.3427639952660608\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  3.7555653264445645 acc:  0.34629211977759417\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  3.637196134751843 acc:  0.347631913895898\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  3.6567395733248804 acc:  0.350445481544336\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  3.6410971195467057 acc:  0.35292410066319807\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  3.572996513305172 acc:  0.357323091351629\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  3.4995269221644247 acc:  0.3584619163521872\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  3.497734491286739 acc:  0.36127548400062526\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  3.468598634965958 acc:  0.36310653596230713\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  3.4460732813804382 acc:  0.3676618359645401\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  3.4139856000100415 acc:  0.3695822075341089\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  3.3708189241347775 acc:  0.37165888841747985\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  3.3568147059409847 acc:  0.3736909094969073\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  3.3550301213418283 acc:  0.37556662126253265\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  3.3092157456182663 acc:  0.37750932273407317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  3.272810782155683 acc:  0.3805238595002568\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  3.23346473170865 acc:  0.3813054060692674\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  3.2111288301406367 acc:  0.38338208695263826\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  3.202272424390239 acc:  0.3851908090123484\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  3.226569172643846 acc:  0.3866422526405109\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  3.159577598879414 acc:  0.38784806734698435\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  3.164966244851389 acc:  0.3887635933278253\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  3.081305233124764 acc:  0.39218006832950003\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  63 loss :  3.092796867124496 acc:  0.3939441305852667\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  64 loss :  3.070429039001465 acc:  0.395328584507514\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  65 loss :  3.0158747442307012 acc:  0.39740526539088494\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  66 loss :  3.00064323025365 acc:  0.39970524529397317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  67 loss :  3.0048147924484745 acc:  0.39952660607819934\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  68 loss :  2.99553853542574 acc:  0.40071009088270104\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  69 loss :  3.00506837906376 acc:  0.4027644418641002\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  70 loss :  2.940231796233885 acc:  0.40497510215930155\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.626037335541467 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1392, 'dropout': 0.39893655006454704, 'dropout_StationIdEmbedding': 0.03937634339952692, 'dropout_timeStampEmbedding': 0.1959278187612626, 'dropout_transformers': 0.5318811969083641, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 65, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.626037335541467, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8733727036005741, 'beta_2': 0.9530214850132347, 'eps': 5.326440476770292e-09, 'lr': 8.43784429544044e-07, 'optimizer': 'AdamW', 'weight_decay': 6.936782733401724e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.059258349114955 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.050868822875636 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  8.043586096950083 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  8.033892879272972 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  8.026288093801318 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  8.0189220625595 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  8.007996551151383 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  8.000217325860561 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  7.990629206822571 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  7.979012958164321 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  7.96689948289754 acc:  0.0016077529419645847\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  7.954280011480747 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  7.939680112806778 acc:  0.0024786191188620682\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  7.9230216868096885 acc:  0.0031708460799857088\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  7.90249638584073 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  7.877990315080355 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  7.850945435422759 acc:  0.005761114708706429\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  7.816894904195263 acc:  0.007011589219123328\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  7.776869491491904 acc:  0.007860125494049082\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  7.732452730892756 acc:  0.008664001965031374\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  7.6892439373378645 acc:  0.008820311278833487\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  7.637118507363943 acc:  0.008038764709822925\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  7.598053940181626 acc:  0.007681486278275238\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8650828676885423 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Hardswish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1272, 'dropout': 0.7045868659766934, 'dropout_StationIdEmbedding': 0.25997619658098026, 'dropout_timeStampEmbedding': 0.41481858473695277, 'dropout_transformers': 0.47035257882989645, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 69, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8650828676885423, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8869391769498158, 'beta_2': 0.9619919102981779, 'eps': 2.86454790422147e-08, 'lr': 4.426161064719228e-06, 'optimizer': 'AdamW', 'weight_decay': 1.0093987311866204e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.193831010298295 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.98452549380856 acc:  0.002099010785342652\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.804132458213326 acc:  0.003505794609561664\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.654387897544807 acc:  0.00582810441462162\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.52007217340536 acc:  0.009959136279391734\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.405759754714432 acc:  0.015251323046691825\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.2973979403088975 acc:  0.019739633343009624\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  7.205116195278568 acc:  0.024384252953129536\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  7.123983993396893 acc:  0.030614295603242303\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  7.059707908363609 acc:  0.03952392648996271\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  6.978105138231824 acc:  0.04899180492597637\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  6.869955523030741 acc:  0.05933054953888752\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  6.800519376367956 acc:  0.07790902797936718\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  6.639256133899822 acc:  0.09416519661478687\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  6.518308302739284 acc:  0.11196212848625595\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  6.365806126094364 acc:  0.12643190496393722\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  6.261917571087817 acc:  0.14338030056048054\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  6.138119340776564 acc:  0.15628698390014067\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  6.008663317540309 acc:  0.16928298684768775\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  5.965897383389773 acc:  0.1799343500882031\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  5.876844452811288 acc:  0.18826340352365853\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  5.765164765444669 acc:  0.19786526137150257\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  5.698098976295311 acc:  0.2053011187280888\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  5.5758055373505275 acc:  0.21184378000580578\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  5.499960055718055 acc:  0.21865440010718354\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  5.465997685919275 acc:  0.22403590648237054\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  5.3724246925407355 acc:  0.23035526874037024\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  5.3297090697121785 acc:  0.23598240403724627\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  5.258578233785562 acc:  0.24111828149074427\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  5.17224671290471 acc:  0.2449813545318536\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  5.149807616547271 acc:  0.25190362414309003\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  5.05241031580038 acc:  0.2556550476743407\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  5.025502474991591 acc:  0.26029966728446063\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  4.95429174716656 acc:  0.26541321483598684\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  4.915015610781583 acc:  0.2696112364066722\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  4.856685113239955 acc:  0.27298305160440345\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  4.815384534689096 acc:  0.27760534131255166\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  4.77999794566548 acc:  0.28077618739253735\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  4.664185964144194 acc:  0.2849295491592792\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  4.631623061386855 acc:  0.28818971484715183\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  4.59428752385653 acc:  0.29245472612375234\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  4.526866791131613 acc:  0.29562557220373803\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  4.535291039860332 acc:  0.29908670700935625\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  4.493817894608824 acc:  0.30301676975638075\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  4.40348241379211 acc:  0.30674586338565973\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  4.385483216572474 acc:  0.30902351338677625\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  4.324248979141662 acc:  0.312105039858875\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  4.2807586276447855 acc:  0.3148292878994261\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  4.277197215940569 acc:  0.318893330058281\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  4.228598299560013 acc:  0.32112632025545407\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  4.219744899056175 acc:  0.3234932898644575\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  4.1519778325007515 acc:  0.32447580555121364\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  4.12198223934307 acc:  0.32874081682781414\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  4.077938211547745 acc:  0.3312194359466762\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  4.0662646960545255 acc:  0.3329611683004712\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  4.052043046151008 acc:  0.33595337516468304\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  4.014022610404274 acc:  0.33738248889087374\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  3.995102675644668 acc:  0.34021838644128355\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  3.9410479985750637 acc:  0.34258535605028695\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  3.894575210718008 acc:  0.34508630507112076\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  3.895405129119233 acc:  0.34606882075787687\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  3.877370727645767 acc:  0.3475649241899828\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  3.8250658628823873 acc:  0.3511600384074314\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  63 loss :  3.8217050145556044 acc:  0.3528794408592546\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  64 loss :  3.782446356086464 acc:  0.3552240805662863\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  65 loss :  3.74231090245547 acc:  0.35663086439050534\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  66 loss :  3.7483627529411048 acc:  0.3585065761561307\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  67 loss :  3.712662760194365 acc:  0.3596230712547172\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  68 loss :  3.7135429665758894 acc:  0.36174441194203155\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7497613309921367 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'PReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1320, 'dropout': 0.13591267613015862, 'dropout_StationIdEmbedding': 0.021355715096755643, 'dropout_timeStampEmbedding': 0.3141526519353306, 'dropout_transformers': 0.4009762494255571, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 80, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7497613309921367, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8574505286970864, 'beta_2': 0.9680012490499907, 'eps': 5.882632088579272e-09, 'lr': 1.88043262679481e-05, 'optimizer': 'AdamW', 'weight_decay': 2.236058148816801e-08, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.826978847270704 acc:  0.010651363240515374\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.245127495918565 acc:  0.03838510148940446\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  6.829291827806079 acc:  0.0947011142621084\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  6.429971880585183 acc:  0.15429962262465668\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  5.989630011201815 acc:  0.1936002500949021\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  5.631206876449003 acc:  0.22381260746265325\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  5.284807634717636 acc:  0.2449813545318536\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  5.01849681184492 acc:  0.267802514346962\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  4.773312783423271 acc:  0.2830315074916821\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  4.549835601835761 acc:  0.2991536967152714\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  4.388028301355493 acc:  0.3118817408391577\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  4.222109885616157 acc:  0.3243864859433267\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  4.037503368071928 acc:  0.33523881830158764\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  3.896965678411586 acc:  0.3435902016390148\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  3.7952021132898697 acc:  0.35178527566263984\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  3.6312586988201576 acc:  0.36165509233414467\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  3.558746965786883 acc:  0.36681329968961435\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  3.4619933521474593 acc:  0.37536565214478707\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  3.381863168177714 acc:  0.37907241587209434\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  3.3341892839388083 acc:  0.3836053859723556\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  3.2345065287961305 acc:  0.38836165509233417\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  3.2011353095979183 acc:  0.39278297568273673\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  3.1366140241841323 acc:  0.39506062568385325\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  3.076412537625728 acc:  0.3997275751959449\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  3.063149863527021 acc:  0.40033048254918163\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  2.9961149383137244 acc:  0.4036353080409977\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  2.9434583751299908 acc:  0.40749838108210706\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  2.8983846402350273 acc:  0.4086148761806936\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  2.864870200630363 acc:  0.4096197217694214\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  2.8493504160233125 acc:  0.4133264854967287\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  2.812076979921064 acc:  0.4136837639282764\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  2.7536593775712808 acc:  0.41734586785164013\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  2.767591028723098 acc:  0.4176361565772726\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  2.7267370151199457 acc:  0.418931290891633\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  2.704424008158327 acc:  0.42065069334345623\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  2.665090064056047 acc:  0.4224147555992229\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  2.6445371904445967 acc:  0.4234419310899225\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  2.6541002178920134 acc:  0.4228836835406293\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  2.616549147904374 acc:  0.42375454971752674\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  2.591568721159724 acc:  0.4241788178549896\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  2.545623519038426 acc:  0.4259428801107563\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  2.546181536812819 acc:  0.42603219971864326\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  2.5231783235346086 acc:  0.42824286001384454\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  2.4923512162143036 acc:  0.4283098497197597\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  2.4679784019484776 acc:  0.4279972310921555\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  2.459050568005511 acc:  0.428287519817788\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  2.45885095341515 acc:  0.4303418707991872\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  2.435841559453775 acc:  0.4294710046222897\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  2.4181292284535996 acc:  0.432262242368756\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  2.423323021590255 acc:  0.4313913761918585\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  2.3897803002641402 acc:  0.4327758301141058\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  2.4019859501423726 acc:  0.4352767791349396\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  2.3369054575912824 acc:  0.43366902619297504\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  2.343203895874606 acc:  0.4347408614876181\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  2.335099613393536 acc:  0.43547774825268515\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  2.2977704892631707 acc:  0.43699618158676284\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  2.3084097409066353 acc:  0.4361699752138088\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  2.2966776722260103 acc:  0.4359243462921198\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5846808633499627 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1032, 'dropout': 0.04206424576531012, 'dropout_StationIdEmbedding': 0.1969024329519362, 'dropout_timeStampEmbedding': 0.04114825969916583, 'dropout_transformers': 0.16057233067894292, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 76, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.000444893292663368, 'max_lr': 0.0840626223586766, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 23, 'dropout_lstm': 0.5846808633499627, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8725586338848395, 'beta_2': 0.9789791962061831, 'eps': 3.153177313595816e-09, 'lr': 0.00015376743967275276, 'optimizer': 'AdamW', 'weight_decay': 0.003587017774694503, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  6.860105525181946 acc:  0.15662193242971664\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  6.1241057571752116 acc:  0.19458276578165823\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  5.270810139245827 acc:  0.18335082508987785\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'SiLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 48, 'dropout': 0.23682486461811514, 'dropout_StationIdEmbedding': 0.06454844274578705, 'dropout_timeStampEmbedding': 0.37825295767676975, 'dropout_transformers': 0.20653395037789302, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 58, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.5359932806822093, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Softplus', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8450229318380051, 'beta_2': 0.9556847894445372, 'eps': 1.289920689646375e-08, 'lr': 3.457327757156022e-05, 'optimizer': 'AdamW', 'weight_decay': 8.691594068762584e-09, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5359932806822093 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.052920606059413 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.996616926500874 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.9272722151971635 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.850446845639136 acc:  0.0014514436281624723\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.764176485615392 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.683235746814359 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.601924914698447 acc:  0.004443650492374339\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  7.524986870058121 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  7.470863508409069 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  7.422743274319556 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7127836068323692 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'LogSigmoid', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1440, 'dropout': 0.339943726147545, 'dropout_StationIdEmbedding': 0.1603580960400004, 'dropout_timeStampEmbedding': 0.22571627244022935, 'dropout_transformers': 0.32817603885627034, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 73, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7127836068323692, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.824913797527221, 'beta_2': 0.9521636125462684, 'eps': 2.488835076286207e-08, 'lr': 4.628359076506855e-06, 'optimizer': 'AdamW', 'weight_decay': 2.1676028811482392e-07, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.102220404239102 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.797550518094129 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.57164721088555 acc:  0.004979568139695867\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  7.435675391714081 acc:  0.0064756715718018\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  7.311198467516717 acc:  0.009244579416296363\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  7.209133479431386 acc:  0.012616394614027644\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  7.138787979388055 acc:  0.019784293146953087\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  7.071776532034837 acc:  0.028961882857334257\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  6.983794150461677 acc:  0.04276176227586361\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  6.891665960996206 acc:  0.055757765223410666\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  6.7955169131737625 acc:  0.07221490297657593\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  6.677001418048189 acc:  0.0894089274948083\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  6.574361906706832 acc:  0.10177969318714691\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  6.442450308617745 acc:  0.11537860348793069\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  6.358292106453699 acc:  0.13080856575039634\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  6.213607049170341 acc:  0.14398320791371727\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  6.143537637841611 acc:  0.15418797311479804\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  6.067200245748039 acc:  0.1651296250809459\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  5.999759240914847 acc:  0.17466449322287475\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  5.900902227591012 acc:  0.18350713440367997\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  5.818135727452868 acc:  0.19165754862336154\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  5.729675016330399 acc:  0.19864680794051315\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  5.658253214741481 acc:  0.2061273251010428\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  5.578253425714624 acc:  0.21430006922269612\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  5.507889598380518 acc:  0.22041846236295023\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  5.4835900168382485 acc:  0.2268718040327803\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  5.377209539631851 acc:  0.2333474756045821\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  5.303266110311028 acc:  0.23980081727441216\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  5.293340624743745 acc:  0.24598620012058148\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  5.178075746725534 acc:  0.25092110845633386\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  5.150179757416703 acc:  0.2565035839492665\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  5.069865459704217 acc:  0.2611035437554429\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  5.025374856613975 acc:  0.2637161422861354\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  4.946124459040984 acc:  0.2693656074849831\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  4.876551231355157 acc:  0.27293839180046\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  4.820922735083194 acc:  0.2780072795480428\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  4.786648368107453 acc:  0.28329946631534286\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  4.719147296352241 acc:  0.2869392403367349\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  4.681048496988893 acc:  0.2909586226916464\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  4.6326308723624425 acc:  0.294553736909095\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  4.538588487464963 acc:  0.2966750775964094\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  4.5346298072174305 acc:  0.300761449657236\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  4.504514808873184 acc:  0.30520510014961033\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  4.449439174346342 acc:  0.3077953687783311\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  4.375855808039658 acc:  0.3112118437800058\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  4.361860326228251 acc:  0.3144050197619632\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  4.331524670579051 acc:  0.3159457829980126\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  4.245093154543229 acc:  0.31898264966616796\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  4.239444454207675 acc:  0.3215952481968604\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  4.215016294071693 acc:  0.3245651251591006\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  4.139260579611509 acc:  0.3278476207489449\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  51 loss :  4.062061781191644 acc:  0.32972333251457026\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  52 loss :  4.120364007149034 acc:  0.3320233124176585\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  53 loss :  4.067282108860161 acc:  0.334546591340464\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  54 loss :  4.019171274345339 acc:  0.33731549918495857\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  55 loss :  3.967358398073502 acc:  0.3378514168322801\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  56 loss :  3.998799580654115 acc:  0.34216108791282407\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  57 loss :  3.894318018250793 acc:  0.3442600986981667\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  58 loss :  3.8697449942581525 acc:  0.3460911506598486\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  59 loss :  3.828314036813401 acc:  0.3487484089944845\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  60 loss :  3.8185607986595795 acc:  0.3491503472299757\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  61 loss :  3.817745265159898 acc:  0.35267847174150907\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  62 loss :  3.7889407063258513 acc:  0.35236585311390484\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  63 loss :  3.723232893543389 acc:  0.35567067860572094\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  64 loss :  3.7232071479768245 acc:  0.357323091351629\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  65 loss :  3.636473424562061 acc:  0.3600250094902083\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  66 loss :  3.6236799673269724 acc:  0.36129781390259696\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  67 loss :  3.626205012998508 acc:  0.36230265949132484\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  68 loss :  3.595308056314483 acc:  0.3641783712569502\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  69 loss :  3.576813115418412 acc:  0.36522787664962153\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  70 loss :  3.5371281809479225 acc:  0.3673492173369359\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  71 loss :  3.548742807548465 acc:  0.3682200835138334\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  72 loss :  3.5328590414906276 acc:  0.3696268673380524\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6344844716753606 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'SELU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1200, 'dropout': 0.10530849752579123, 'dropout_StationIdEmbedding': 0.004648442177951087, 'dropout_timeStampEmbedding': 0.4944041311982972, 'dropout_transformers': 0.058679930965360616, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 51, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.19425452486587952, 'scheduler': 'StepLR', 'step_size': 22, 'dropout_lstm': 0.6344844716753606, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9157157310582519, 'beta_2': 0.9607815413789651, 'eps': 7.839760337087477e-09, 'lr': 1.3483795641215889e-05, 'optimizer': 'AdamW', 'weight_decay': 2.888055197848342e-05, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.063434221073539 acc:  0.005247526963356631\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  7.513524215378447 acc:  0.013576580398812049\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  7.183442749663027 acc:  0.03108322354464864\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  6.913594659930932 acc:  0.07297411964361476\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  6.604136789630273 acc:  0.11394948976173995\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  6.300416692288336 acc:  0.1484268584060916\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  5.984659823115001 acc:  0.17997900989214657\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  5.729282941646918 acc:  0.20536810843400397\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  5.427889566935465 acc:  0.22796596922939508\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  5.121976852416992 acc:  0.2472590045329701\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  4.927328625125085 acc:  0.26326954424670074\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  4.703776222503114 acc:  0.2795033829801487\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  4.56498358064069 acc:  0.2927896746533283\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  4.354734924738993 acc:  0.30591965701270574\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  4.192635242096678 acc:  0.31936225799968737\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  4.055711286510536 acc:  0.3272447133957082\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  3.9450706407695475 acc:  0.3362213339883438\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  3.7964529762724917 acc:  0.3443047585021102\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  3.733836837871346 acc:  0.35294643056516983\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  3.6329609933727514 acc:  0.35761338007726146\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  3.5279890748555074 acc:  0.3641337114530067\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  3.523602121604417 acc:  0.369827836455798\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  3.4238555517025335 acc:  0.37185985753522544\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  23 loss :  3.3726726691879914 acc:  0.3731549918495858\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  24 loss :  3.416445836335599 acc:  0.3742714869481723\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  25 loss :  3.3967370872725984 acc:  0.37498604381126766\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  26 loss :  3.3678757744634935 acc:  0.37637049773351494\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  27 loss :  3.3644045641322338 acc:  0.377442333028158\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  28 loss :  3.356224248509207 acc:  0.3788267869504053\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  29 loss :  3.312804153579438 acc:  0.379184065381953\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  30 loss :  3.2771127038373207 acc:  0.38056851930420027\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  31 loss :  3.3225142327611317 acc:  0.3807024987160306\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  32 loss :  3.2790501196227386 acc:  0.3817743340106737\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  33 loss :  3.2913618073491993 acc:  0.38239957126588214\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  34 loss :  3.2469799818392997 acc:  0.3826452001875712\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  35 loss :  3.236793947790911 acc:  0.38394033450193155\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  36 loss :  3.2442618173039603 acc:  0.38534711832615054\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  37 loss :  3.225149286007453 acc:  0.38644128352276536\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  38 loss :  3.2528988130078345 acc:  0.3866199227385392\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  39 loss :  3.181352112821476 acc:  0.3873568095036063\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  40 loss :  3.212723559248233 acc:  0.3883839849943059\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  41 loss :  3.1380892028351743 acc:  0.3893218408771186\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  42 loss :  3.2060028521600596 acc:  0.3901033874461291\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  43 loss :  3.1609732119623057 acc:  0.3912198825447156\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  44 loss :  3.1602057811028943 acc:  0.3916218207802068\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  45 loss :  3.1083764216143215 acc:  0.3916218207802068\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  46 loss :  3.1509039287795564 acc:  0.3916664805841502\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  47 loss :  3.1456712555742548 acc:  0.3918674497018958\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  48 loss :  3.1058450516112552 acc:  0.3920907487216131\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  49 loss :  3.1446643832201016 acc:  0.391934439407811\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  50 loss :  3.1619079926770604 acc:  0.3922470580354152\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9999884604343798 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'RReLU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1344, 'dropout': 0.44031019592152043, 'dropout_StationIdEmbedding': 0.13560210590149924, 'dropout_timeStampEmbedding': 0.18474624694175346, 'dropout_transformers': 0.25764684879082145, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 61, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 7, 'factor': 0.23634776462298565, 'patience': 3, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.024117131735883056, 'dropout_lstm': 0.9999884604343798, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8547843145683762, 'beta_2': 0.9647424675391205, 'eps': 1.3947327261047364e-07, 'lr': 3.807521477669775e-07, 'optimizer': 'AdamW', 'weight_decay': 2.6331477326483065e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.472260315101463 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.42440763886992 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  8.37315059875275 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  8.31939817308546 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  8.287404107047127 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  8.252193630992116 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  8.240209652827335 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  8.233344718292877 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  8.225445480613441 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  8.218463997740846 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  8.197439353782814 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  8.200930201923931 acc:  0.0008038764709822924\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  8.175795214993137 acc:  0.0008708661768974834\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  8.170217123898594 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  8.16491758906758 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  8.153946202951712 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  8.145949560445505 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  8.13765832260772 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  8.144528809127275 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  19 loss :  8.142099260450243 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  20 loss :  8.137890759047929 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  21 loss :  8.134763754331148 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  22 loss :  8.133424322088281 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardswish', 'batch_size': 16, 'concatenate_features': True, 'd_model': 1392, 'dropout': 0.26994384071160216, 'dropout_StationIdEmbedding': 0.34490922319938555, 'dropout_timeStampEmbedding': 0.025699444898742818, 'dropout_transformers': 0.09594281093674678, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 56, 'input_size': 2, 'learnable_pos_encoding': False, 'T_max': 7, 'eta_min': 0.00011531436667335876, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8690907919429511, 'beta_2': 0.9718100178402834, 'eps': 2.129778984661896e-07, 'lr': 7.804132949827923e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0002913967594942029, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Mish', 'dropout_gcn': 0.8694470040881741, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 7, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  7.592907971098223 acc:  0.04662483531697296\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  6.780105325101896 acc:  0.1473326932094768\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  2 loss :  5.864943509793464 acc:  0.20161668490275328\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  3 loss :  5.115409896573947 acc:  0.24326195208003037\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  4 loss :  4.6627985848725295 acc:  0.2665966996404886\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  5 loss :  4.347649661639265 acc:  0.29852845946006296\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  6 loss :  4.1242246245609895 acc:  0.3056293682870732\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  7 loss :  3.900954532259293 acc:  0.3282718888864078\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  8 loss :  3.8060125121633517 acc:  0.3403523658531139\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  9 loss :  3.621855160662236 acc:  0.33907956144072526\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  10 loss :  3.42607288142197 acc:  0.3574794006654311\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  11 loss :  3.3720174509150382 acc:  0.3664560212580667\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  12 loss :  3.322783501093624 acc:  0.3825112207757408\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  13 loss :  3.2906171583947335 acc:  0.3903043565638747\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  14 loss :  3.0715025836274825 acc:  0.3875354487193801\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  15 loss :  3.207074724990903 acc:  0.39077328450528104\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  16 loss :  3.0732414167345934 acc:  0.3970926467632807\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  17 loss :  3.0864451786943974 acc:  0.3953509144094857\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  18 loss :  3.048430757668182 acc:  0.3901033874461291\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8860686225732174 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Tanhshrink', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1152, 'dropout': 0.06670883122058396, 'dropout_StationIdEmbedding': 0.23220397307259277, 'dropout_timeStampEmbedding': 0.5666722094324743, 'dropout_transformers': 0.6111331274044083, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 70, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8860686225732174, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardtanh', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 2, 'lr': 3.734533104079965e-05, 'momentum': 0.4964813497282795, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 1.2190803582560416e-06, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  0 loss :  8.070689743864323 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m epoch:  1 loss :  8.069126466077245 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.42729860920615326 and num_layers=1\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=183394)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Tanh', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1272, 'dropout': 0.5230184003523776, 'dropout_StationIdEmbedding': 0.08866550197650655, 'dropout_timeStampEmbedding': 0.13104041522686613, 'dropout_transformers': 0.0382403423304013, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 67, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.03014888867201773, 'max_lr': 0.35456745319479893, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 12, 'dropout_lstm': 0.42729860920615326, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 3, 'alpha': 0.9216496905883678, 'centered': False, 'eps': 5.0370463085408695e-09, 'lr': 0.12927564949871456, 'momentum': 0.24688802877421226, 'optimizer': 'RMSprop', 'weight_decay': 1.1819073094071588e-07, 'positive_function': 'exp', 'epochs_complete_problem': 50, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=183394)\u001b[0m loss is undifined\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 06:14:49,636\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 06:15:04,347\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 06:15:04,348\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_4        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_4\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_4`\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.48496243866799893 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'LeakyReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 264, 'dropout': 0.18921447977489503, 'dropout_StationIdEmbedding': 0.8783451120581629, 'dropout_timeStampEmbedding': 0.4411108462953692, 'dropout_transformers': 0.4326701753045321, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 48, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.48496243866799893, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8027430683522431, 'beta_2': 0.9689786117017483, 'eps': 4.353000287425135e-08, 'lr': 1.751970616992533e-06, 'optimizer': 'AdamW', 'weight_decay': 6.286975977639781e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.512047232868515 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.490784858988825 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.46561635988895 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  8.450360619019126 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  8.425761704132936 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  8.408574968854957 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  8.387044175762997 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  8.36542661613393 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  8.348945029428073 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  8.328465060652974 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  8.308605104963355 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  8.292262496235214 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  8.27447828845443 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  8.255166882666472 acc:  0.0011611549025299778\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  8.225517174907933 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  8.214366725672072 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  8.197309556408463 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  8.181826029982522 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  8.164688743163492 acc:  0.0016524127459080454\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  8.150320320485909 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  8.13969636186261 acc:  0.0018310519616818882\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  8.119869633255718 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  8.102746214822075 acc:  0.0018533818636536185\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  8.090905635156364 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  8.079669667181568 acc:  0.0019873612754840006\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  8.06558785928744 acc:  0.002009691177455731\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  8.047477980640448 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  8.034938821168703 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  8.018942209047692 acc:  0.0021660004912578434\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  8.015428596567885 acc:  0.002277650001116495\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  7.984750533772406 acc:  0.0024562892168903377\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  7.9859827612047996 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  7.9782242151064295 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  7.960391463520371 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  7.948203171525046 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  7.937493172761436 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  7.935162874025719 acc:  0.002724248040551102\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  7.908718603793706 acc:  0.002791237746466293\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  7.907359399528147 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  39 loss :  7.9032672543392 acc:  0.0029028872563249446\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  40 loss :  7.887448845622695 acc:  0.0029475470602684053\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  41 loss :  7.871259542269128 acc:  0.002925217158296675\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  42 loss :  7.858081510133832 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  43 loss :  7.850083257550391 acc:  0.0030591965701270572\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  44 loss :  7.848430058666479 acc:  0.0030145367661835966\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  45 loss :  7.840044057257821 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9507139578736439 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'ReLU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1224, 'dropout': 0.5831576399529182, 'dropout_StationIdEmbedding': 0.2990453422552868, 'dropout_timeStampEmbedding': 0.271409010561531, 'dropout_transformers': 0.6896369677433796, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 77, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.19222104919759714, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.9507139578736439, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9835849021157268, 'beta_2': 0.963711335805969, 'eps': 7.199556483162474e-08, 'lr': 6.9435874884811615e-06, 'optimizer': 'AdamW', 'weight_decay': 6.642973029331114e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.071886517924646 acc:  0.0009825156867561352\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.002387339068997 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.985435538138113 acc:  0.0012504745104168992\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.983993951735958 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.983418224703881 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  7.981033417486375 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  7.983908133352957 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Hardshrink', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1080, 'dropout': 0.01818215807187984, 'dropout_StationIdEmbedding': 0.11732043996121594, 'dropout_timeStampEmbedding': 0.34546239200053797, 'dropout_transformers': 0.311123427646334, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 74, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8915785285274265, 'beta_2': 0.9989488772635665, 'eps': 2.385510423325791e-08, 'lr': 0.00021897164080009272, 'optimizer': 'AdamW', 'weight_decay': 4.926066601088997e-05, 'positive_function': 'abs', 'epochs_complete_problem': 0, 'reg': True, 'transformers_model': True, 'activation_gcn': 'ReLU6', 'dropout_gcn': 0.1302383445414188, 'hidden_channels': 512, 'layer_type': 'GCNConv', 'norm': 'LayerNorm', 'num_layers_gcn': 2, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.466196364715319 acc:  0.03637541031194873\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  6.822341834797578 acc:  0.10941651966147868\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  6.1197423173599885 acc:  0.1715383069468325\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  5.3092862457788295 acc:  0.22088739030435656\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  4.752447857576258 acc:  0.2577763883616551\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  4.408903973443167 acc:  0.29234307661389364\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  4.058050924990358 acc:  0.3242971663354398\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  3.8425048499548136 acc:  0.34664939820914187\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  3.648299858349712 acc:  0.3565192148806467\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  3.4488252190982593 acc:  0.3698501663577697\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  3.3930744844324447 acc:  0.37578992028224995\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  3.2546352518706763 acc:  0.3824442310698256\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  3.1845424896528742 acc:  0.39213540852555656\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  3.137018842857425 acc:  0.40006252372552087\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  3.015986136027745 acc:  0.40542170019873613\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  3.0640053288275455 acc:  0.4033450193153652\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  2.921164931369429 acc:  0.41256726882968986\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  2.9203695469543716 acc:  0.4127682379474354\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  2.9024412451671955 acc:  0.41493423843869326\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  2.879628720403719 acc:  0.41803809481276377\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  2.8584926789548217 acc:  0.41980215706853047\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  2.7811884168817214 acc:  0.4222361163834491\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  2.777144235723159 acc:  0.4239555188352723\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  2.7581377229770694 acc:  0.42214679677556216\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  2.7296639029719247 acc:  0.42105263157894735\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  2.766214597125013 acc:  0.42310698256034657\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  2.6982378869497476 acc:  0.42779626197440995\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  2.7056620932426774 acc:  0.4273719938369471\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  2.652778600444313 acc:  0.4285108188375053\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  2.674916804337702 acc:  0.43114574727016947\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  2.6433039502937254 acc:  0.428287519817788\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  2.595924302309501 acc:  0.42906906638679854\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  2.585906369345529 acc:  0.42784092177835337\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  2.5894976153093228 acc:  0.42877877766116607\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7719569484872553 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Hardtanh', 'batch_size': 64, 'concatenate_features': True, 'd_model': 984, 'dropout': 0.29896751712271796, 'dropout_StationIdEmbedding': 0.3931028815211049, 'dropout_timeStampEmbedding': 0.6232814553531789, 'dropout_transformers': 0.4870216677368089, 'early_stopping': 1, 'encoder_only': False, 'epochs_classifcation_only': 80, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7719569484872553, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8798492922675848, 'beta_2': 0.9811305851691509, 'eps': 1.2869855665917602e-08, 'lr': 4.774731308457301e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0015817620111417982, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.500497995246767 acc:  0.007301877944755822\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.2017967838267385 acc:  0.021704664716521896\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.103982116539441 acc:  0.045843288747962396\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  6.992234162635204 acc:  0.05859366277382042\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  6.903273073166453 acc:  0.07004890248531809\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  6.7911562520171955 acc:  0.07281781032981265\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  6.666176526334273 acc:  0.08518857602215127\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  6.546968881996515 acc:  0.0950807225956278\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  6.440686865002697 acc:  0.10407967309023514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  6.324582025018662 acc:  0.11196212848625595\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  6.174012928108894 acc:  0.12241252260902574\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  6.036722015960054 acc:  0.1299600294754706\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  5.870483043930293 acc:  0.1427550633052721\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  5.724061446664221 acc:  0.15302681821226805\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  5.610616316970106 acc:  0.16265100596208382\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  5.4720680626275024 acc:  0.17444119420315746\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  5.3689366110956485 acc:  0.18158676283411115\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  5.245611877341545 acc:  0.19313132215349574\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  5.13596062385599 acc:  0.20235357166782036\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  4.974525921007726 acc:  0.21101757363285176\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  4.856901538309627 acc:  0.21992720451957215\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  4.793773591206336 acc:  0.22622423687560012\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  4.6663573437336225 acc:  0.2338610633499319\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  4.5911414485951365 acc:  0.24248040551101982\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  4.493648021008956 acc:  0.24830850992564144\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  4.402573895079927 acc:  0.2540249648304044\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  4.3243581774347115 acc:  0.25699484179264453\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  4.269374485415314 acc:  0.26378313199205056\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  4.198275459998565 acc:  0.2701471540539937\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  4.112214616455957 acc:  0.27689078444945625\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  4.058264610030888 acc:  0.2824062702364737\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  3.99011934739757 acc:  0.28705088984659355\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  3.950845373862701 acc:  0.29341491190853675\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  3.8925659743903194 acc:  0.2972556550476743\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  3.8245886395739013 acc:  0.30085076926512294\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  3.7731105494873685 acc:  0.30359734720764575\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  3.729328865780256 acc:  0.3116807717214121\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  3.6691482915928226 acc:  0.3144050197619632\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  3.645101207713182 acc:  0.3192506084898287\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  39 loss :  3.600764113571007 acc:  0.325525310943885\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  40 loss :  3.549146616022 acc:  0.3265748163365563\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  41 loss :  3.513623730674464 acc:  0.33186700310385636\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  42 loss :  3.4862686676504726 acc:  0.3327601991827256\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  43 loss :  3.4434895665233674 acc:  0.3387892727150928\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  44 loss :  3.4177344282260114 acc:  0.34104459281423755\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  45 loss :  3.399569181871664 acc:  0.3438804903646473\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  46 loss :  3.3377289759551045 acc:  0.3485251099747672\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  47 loss :  3.326367574212439 acc:  0.3494629658575799\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  48 loss :  3.270780361135593 acc:  0.35243284281982\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  49 loss :  3.2556050035966004 acc:  0.35709979233191164\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  50 loss :  3.2474080355379593 acc:  0.3625706183149856\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  51 loss :  3.2185511776290014 acc:  0.36274925753075943\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  52 loss :  3.2005568224722176 acc:  0.36714824821919034\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  53 loss :  3.159863800278509 acc:  0.3678181452783422\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  54 loss :  3.1553674056267864 acc:  0.36911327959270257\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  55 loss :  3.1184641016715484 acc:  0.37121229037804526\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  56 loss :  3.1101379481909786 acc:  0.3746510952816917\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  57 loss :  3.0741608080439544 acc:  0.37538798204675883\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  58 loss :  3.055022343291038 acc:  0.37925105508786816\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  59 loss :  3.043424135727408 acc:  0.37929571489181163\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  60 loss :  3.0440088042414 acc:  0.3809704575396914\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  61 loss :  2.9965493654081334 acc:  0.38570439675769824\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  62 loss :  3.008272594182279 acc:  0.38740146930754976\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  63 loss :  2.9803476795476143 acc:  0.39072862470133757\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  64 loss :  2.9727589222773205 acc:  0.3903266864658464\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7105133455623256 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Mish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1416, 'dropout': 0.3709266463526089, 'dropout_StationIdEmbedding': 0.5398274661428972, 'dropout_timeStampEmbedding': 0.3955817697346448, 'dropout_transformers': 0.3637237029431211, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 63, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.897258964909519, 'patience': 6, 'scheduler': 'ReduceLROnPlateau', 'threshold': 8.080584549844031e-06, 'dropout_lstm': 0.7105133455623256, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Tanhshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 4, 'lr': 0.00039835427073885897, 'momentum': 0.05340950004697964, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.06994766340182877, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.337263000594985 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.307118555882594 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.274600929313607 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  8.24173864618048 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  8.20883445472984 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  8.175687136349978 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  8.152125198524315 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  8.112987164850836 acc:  0.0010718352946430564\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  8.087325302870957 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  8.060667251373504 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  8.032926292686195 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  8.010881030476178 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  7.9853972955183545 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  7.956760299789322 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  7.933464727201662 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  7.911459946132206 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  7.8898544978428555 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  7.862157728288557 acc:  0.004890248531808946\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  7.838482283212088 acc:  0.005225197061384901\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  7.823553728890586 acc:  0.005716454904762968\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  7.801479046161358 acc:  0.006140723042225845\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  7.780130996570721 acc:  0.006319362257999687\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  7.7684126267066365 acc:  0.006564991179688721\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  7.744041236130507 acc:  0.006721300493490834\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  7.74301941078026 acc:  0.006810620101377755\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  7.716902165979772 acc:  0.006899939709264676\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  7.69566145810214 acc:  0.007011589219123328\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  7.688194494981032 acc:  0.0071678985329254406\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  7.678085317144861 acc:  0.007368867650671014\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  7.6617501032102355 acc:  0.007413527454614474\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  7.653081440425419 acc:  0.007391197552642744\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  7.63649312266103 acc:  0.007458187258557935\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  7.619432552711113 acc:  0.007346537748699283\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  7.614075760741334 acc:  0.0075028470625013955\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  7.602969209631007 acc:  0.007659156376303508\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  7.6026564478040575 acc:  0.007681486278275238\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  7.57018719186316 acc:  0.0077261460822186994\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  7.578632137992165 acc:  0.007949445101936002\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  7.560411813375834 acc:  0.007927115199964273\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  39 loss :  7.5481946151573345 acc:  0.008105754415738116\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  40 loss :  7.547400754648489 acc:  0.008239733827568497\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  41 loss :  7.542301888232465 acc:  0.00850769265122926\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  42 loss :  7.53143107474267 acc:  0.008597012259116183\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  43 loss :  7.520526022344202 acc:  0.008775651474890026\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  44 loss :  7.51599774660764 acc:  0.008753321572918294\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  45 loss :  7.507624319383314 acc:  0.008864971082776946\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  46 loss :  7.514554904057429 acc:  0.008931960788692137\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  47 loss :  7.489987946890451 acc:  0.009132929906437711\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  48 loss :  7.475537990356659 acc:  0.009199919612352902\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  49 loss :  7.482407206421965 acc:  0.009356228926155015\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  50 loss :  7.472871813740763 acc:  0.009512538239957126\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  51 loss :  7.468307851911424 acc:  0.009847486769533082\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  52 loss :  7.4637347501474665 acc:  0.009802826965589621\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  53 loss :  7.46223775156728 acc:  0.009892146573476543\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  54 loss :  7.4604026087514175 acc:  0.010048455887278655\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  55 loss :  7.461336736078863 acc:  0.010115445593193845\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  56 loss :  7.464146207262586 acc:  0.010539713730656722\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  57 loss :  7.425332702956833 acc:  0.010807672554317487\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  58 loss :  7.438827841431944 acc:  0.010696023044458835\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  59 loss :  7.449637416359428 acc:  0.010785342652345755\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  60 loss :  7.428875713081626 acc:  0.010896992162204407\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  61 loss :  7.442656947182608 acc:  0.01103097157403479\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  62 loss :  7.417001207391698 acc:  0.01103097157403479\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3566787514886083 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Softplus', 'batch_size': 32, 'concatenate_features': True, 'd_model': 912, 'dropout': 0.1543828633140444, 'dropout_StationIdEmbedding': 0.1915331084813851, 'dropout_timeStampEmbedding': 0.21685185271604293, 'dropout_transformers': 0.15329681094697212, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 20, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.6773168859133127, 'scheduler': 'StepLR', 'step_size': 3, 'dropout_lstm': 0.3566787514886083, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'alpha': 0.9429014819244373, 'centered': False, 'eps': 5.4517615313317995e-08, 'lr': 2.3035100635708954e-06, 'momentum': 9.186930080154476e-05, 'optimizer': 'RMSprop', 'weight_decay': 0.010984999828302106, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.040915456436972 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.000836376015467 acc:  0.0027689078444945625\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.96505323439154 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.93165348140338 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.907843961060502 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  7.890013705683119 acc:  0.002925217158296675\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  7.867895421181016 acc:  0.0028805573543532145\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  7.8542284856315785 acc:  0.002925217158296675\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Hardsigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 120, 'dropout': 0.26181015714226535, 'dropout_StationIdEmbedding': 0.24841424792751132, 'dropout_timeStampEmbedding': 0.081298679338424, 'dropout_transformers': 0.26875295260934684, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 59, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 30, 'eta_min': 0.00600322394822414, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.5663061603452897, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8121711918173192, 'beta_2': 0.9869372623089461, 'eps': 4.997066548310436e-07, 'lr': 0.0014979404787010763, 'optimizer': 'AdamW', 'weight_decay': 8.1472503649447e-06, 'positive_function': 'exp', 'epochs_complete_problem': 6, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5663061603452897 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.259811984575712 acc:  0.05310050688877476\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  6.188090698535626 acc:  0.16238304713842305\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  5.191818420703594 acc:  0.22055244177478062\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  4.436965441703796 acc:  0.26385012169796573\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  3.928424211648794 acc:  0.30382064622736304\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  3.590215800358699 acc:  0.3307951678092133\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  3.346536452953632 acc:  0.34843579036688027\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  3.1650021663078896 acc:  0.362124020275551\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  3.040695260121272 acc:  0.3763928276354867\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  2.933615726691026 acc:  0.38257821048165597\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  2.8478934856561513 acc:  0.3907509546033093\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  2.779959805195148 acc:  0.3939441305852667\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  2.712554847277128 acc:  0.40012951343143605\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  2.6636774613307073 acc:  0.4035013286291673\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  2.62176639850323 acc:  0.40926244333787376\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  2.582916853978084 acc:  0.4088158452984391\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Softshrink', 'batch_size': 128, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.41470194870064825, 'dropout_StationIdEmbedding': 0.4746244819494172, 'dropout_timeStampEmbedding': 0.7207617239408708, 'dropout_transformers': 0.5259967874782697, 'early_stopping': 7, 'encoder_only': True, 'epochs_classifcation_only': 72, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9981087774916896, 'beta_2': 0.9964612903860228, 'eps': 3.3245299374898253e-09, 'lr': 0.0006324927249037488, 'optimizer': 'AdamW', 'weight_decay': 0.00012980940840553882, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'ReLU', 'dropout_gcn': 0.679969928167736, 'hidden_channels': 64, 'layer_type': 'GraphSAGE', 'norm': 'InstanceNorm', 'num_layers_gcn': 4, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.476247345108583 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.2142416482948395 acc:  0.0201639014804725\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.097275958003768 acc:  0.029966728446062123\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  6.962122262242329 acc:  0.037916173547998124\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  6.863709202731949 acc:  0.04861219659245696\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  6.700064498257924 acc:  0.06149655003014537\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  6.525685844651187 acc:  0.07205859366277383\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  6.409473108958049 acc:  0.08389344170779091\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  6.26287368981235 acc:  0.09284773239845477\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  6.12891983124147 acc:  0.10117678583391018\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  6.0191734095653855 acc:  0.11238639662371883\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  5.895706981061453 acc:  0.1251144407476051\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  5.806999057172293 acc:  0.12748141035660854\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  5.727470196873309 acc:  0.1404104235982404\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  5.628140966576266 acc:  0.14349195007033919\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  5.540899305458528 acc:  0.14554630105173838\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  5.461383584034012 acc:  0.1538083647812786\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  5.377164116824966 acc:  0.15847531429337025\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  5.27212880031172 acc:  0.1645490476296809\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  5.235567483557276 acc:  0.1685907598865641\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  5.158604512731713 acc:  0.17421789518344014\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  5.061263785304793 acc:  0.17718777214568027\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  4.971537187875035 acc:  0.1755130294978005\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  4.940033079629921 acc:  0.18366344371748208\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  4.894394127719374 acc:  0.18513721724761628\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  4.819597295967929 acc:  0.19063037313266196\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  4.758268735494958 acc:  0.19054105352477502\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  4.732884510453925 acc:  0.19715070450840722\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  4.671891545674887 acc:  0.1957439206841882\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  4.611979317952351 acc:  0.1961235290177076\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  4.571298875004413 acc:  0.1988477770582587\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  4.505983769175518 acc:  0.20547975794386264\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  4.465643204838397 acc:  0.20427394323738918\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  4.396932645016406 acc:  0.2086282741218766\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  4.391899870102664 acc:  0.2108389344170779\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  4.339478992554079 acc:  0.2089855525534243\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  4.286973941757019 acc:  0.21336221333988345\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  4.244601588651358 acc:  0.2122233883393252\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  4.228582715413657 acc:  0.2159971417725476\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  39 loss :  4.172519675220352 acc:  0.21769421432239913\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  40 loss :  4.157536555485553 acc:  0.21713596677310587\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  41 loss :  4.110434693026256 acc:  0.2180514927539468\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  42 loss :  4.089790981936168 acc:  0.2203961324609785\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  43 loss :  4.0328944935856095 acc:  0.21986021481365697\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  44 loss :  4.026536927165755 acc:  0.22640287609137397\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  45 loss :  3.97712147379496 acc:  0.2246834736395507\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  46 loss :  3.9683544291071144 acc:  0.22472813344349418\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  47 loss :  3.9099974833339095 acc:  0.23069021726994618\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  48 loss :  3.9127399375639764 acc:  0.2290824643279816\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  49 loss :  3.876062005399221 acc:  0.2308465265837483\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  50 loss :  3.8400946065603967 acc:  0.2248174530513811\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  51 loss :  3.850069738296141 acc:  0.22562132952236338\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  52 loss :  3.796581314270755 acc:  0.2312931246231829\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  53 loss :  3.7951438628047347 acc:  0.23185137217247617\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  54 loss :  3.764015068490821 acc:  0.2320076814862783\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  55 loss :  3.739170720778316 acc:  0.2336377643302146\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  56 loss :  3.737209012709468 acc:  0.23609405354710492\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  57 loss :  3.709188800260245 acc:  0.23582609472344415\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  58 loss :  3.6779387428099852 acc:  0.23138244423106982\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  59 loss :  3.644451345305845 acc:  0.2315834133488154\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  60 loss :  3.6585967339665055 acc:  0.23301252707500614\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  61 loss :  3.6109675154628524 acc:  0.23397271285979054\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  62 loss :  3.6157804454665587 acc:  0.23513386776232054\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  63 loss :  3.6149936440479324 acc:  0.2355581358997834\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  64 loss :  3.5999088086277604 acc:  0.23712122903780453\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  65 loss :  3.5825369472963264 acc:  0.23450863050711207\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  66 loss :  3.561262848865555 acc:  0.23455329031105554\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  67 loss :  3.5389901356524733 acc:  0.2371882187437197\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  68 loss :  3.516667664769184 acc:  0.23732219815555008\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  69 loss :  3.5160003943615648 acc:  0.2392425697251189\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  70 loss :  3.496018605059888 acc:  0.23707656923386106\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  71 loss :  3.4804182483489257 acc:  0.23774646629301296\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3936608039544467 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Sigmoid', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1248, 'dropout': 0.3378364401700178, 'dropout_StationIdEmbedding': 0.6271969873068627, 'dropout_timeStampEmbedding': 0.2435602882649876, 'dropout_transformers': 0.571146930296943, 'early_stopping': 4, 'encoder_only': False, 'epochs_classifcation_only': 67, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 1.0212463224330208e-05, 'max_lr': 0.20911668943063563, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 2, 'dropout_lstm': 0.3936608039544467, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 6, 'amsgrad': False, 'beta_1': 0.8447917293198515, 'beta_2': 0.9595394544281279, 'eps': 3.536604334770625e-08, 'lr': 1.4432643295325132e-05, 'optimizer': 'AdamW', 'weight_decay': 1.525851714934616e-06, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.135195872362923 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5147370506522114 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'Softmin', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1104, 'dropout': 0.22555105167793071, 'dropout_StationIdEmbedding': 0.057793441448606354, 'dropout_timeStampEmbedding': 0.11579851747214598, 'dropout_transformers': 0.19413105209070972, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 53, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.5147370506522114, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 3, 'alpha': 0.9787207652151018, 'centered': True, 'eps': 2.5263767063959107e-07, 'lr': 3.394482902763441e-05, 'momentum': 0.33355430267137515, 'optimizer': 'RMSprop', 'weight_decay': 1.036799336866004e-06, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.015030369391808 acc:  0.1607083044905433\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  5.287693698589618 acc:  0.27023647366188064\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  4.328094405394334 acc:  0.3299019717303441\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  3.7455423538501447 acc:  0.3635977938056852\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  3.3674745853130634 acc:  0.38514614920840495\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  3.1079805465844963 acc:  0.40035281245115334\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  2.923987399614774 acc:  0.4103789384364603\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  2.7815703226969792 acc:  0.4176361565772726\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  2.6703746758974516 acc:  0.4207846727552866\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  2.5818268262423003 acc:  0.4249603644240002\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  2.4971510520348184 acc:  0.4279302413862403\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  2.4329840605075543 acc:  0.43114574727016947\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  2.370580394451435 acc:  0.4325525310943885\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  2.317272265140827 acc:  0.4317486546234062\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  2.2673883511469914 acc:  0.43346805707522945\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  2.218391749492058 acc:  0.4340263046245227\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  2.1783484844061043 acc:  0.4344059129580421\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  2.137234467726487 acc:  0.4343165933501552\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  2.098140770655412 acc:  0.4343612531540987\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  2.0622311372023363 acc:  0.4355893977625438\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  2.0283646684426526 acc:  0.4349864904093071\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  1.99365280683224 acc:  0.43391465511466404\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  1.9632729814602778 acc:  0.43413795413438133\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  1.9321171127832852 acc:  0.4324185516825581\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  1.9032197209504935 acc:  0.43290980952593616\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.456481359098961 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'ReLU6', 'batch_size': 16, 'concatenate_features': True, 'd_model': 1176, 'dropout': 0.5070853730140505, 'dropout_StationIdEmbedding': 0.16587801342984249, 'dropout_timeStampEmbedding': 0.29205325348036293, 'dropout_transformers': 0.12497726841988827, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 78, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7103881081913198, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.456481359098961, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.935144399029113, 'beta_2': 0.9656618270983361, 'eps': 4.8574369406385944e-08, 'lr': 0.00010406861423571612, 'optimizer': 'AdamW', 'weight_decay': 1.6717006529001255e-07, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.844898043180767 acc:  0.015764910792041623\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.288737668489155 acc:  0.04530737110064087\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  6.967266584697523 acc:  0.0794721211173883\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  6.74008960723877 acc:  0.1091262309358462\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  6.430073110680831 acc:  0.13058526673067905\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  6.369275886134098 acc:  0.14061139271598597\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  6.21610285608392 acc:  0.1515307147801621\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  5.938185556311357 acc:  0.15936851037223945\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  6.028225175957931 acc:  0.1635888618448965\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  5.957670570674695 acc:  0.16602282115981512\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  5.993946040304084 acc:  0.16854610008262064\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  5.886453513095254 acc:  0.16995288390683966\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  5.789887789676064 acc:  0.17017618292655695\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  5.785146479857596 acc:  0.17091306969162406\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  5.8208005102057205 acc:  0.17198490498626712\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  5.955370054746929 acc:  0.17227519371189962\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  5.967831410859761 acc:  0.17269946184936247\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  5.880429626766004 acc:  0.1729227608690798\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  5.9303835642965215 acc:  0.17287810106513632\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  5.943599204013222 acc:  0.17296742067302326\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  5.820853434110942 acc:  0.17314605988879708\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  5.875408473767732 acc:  0.1733023692025992\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  5.904096545671162 acc:  0.17341401871245785\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  5.891531467437744 acc:  0.17341401871245785\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  5.969725899947317 acc:  0.17343634861442958\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  5.975935589639764 acc:  0.17345867851640132\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  5.848273417824193 acc:  0.17345867851640132\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  5.825634200949418 acc:  0.17343634861442958\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'GELU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1296, 'dropout': 0.12256149644960407, 'dropout_StationIdEmbedding': 0.004789601402590812, 'dropout_timeStampEmbedding': 0.006715849422762182, 'dropout_transformers': 0.386798439479885, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 29, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 3, 'factor': 0.18525657105878968, 'patience': 1, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0009261398986921457, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'lr': 3.059789487637234e-07, 'momentum': 0.167309414056598, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 7.819027376326033e-05, 'positive_function': 'exp', 'epochs_complete_problem': 50, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.109095770553504 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.111121135051024 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.109406529858125 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  8.109154120503858 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6479502864819442 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1344, 'dropout': 0.19405620811699947, 'dropout_StationIdEmbedding': 0.12029553523734873, 'dropout_timeStampEmbedding': 0.33094222517985805, 'dropout_transformers': 0.7549187860890786, 'early_stopping': 1, 'encoder_only': False, 'epochs_classifcation_only': 42, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'dropout_lstm': 0.6479502864819442, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'SELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 4, 'amsgrad': False, 'beta_1': 0.9006984236608723, 'beta_2': 0.9742574372367876, 'eps': 7.950082241770404e-08, 'lr': 7.348729687445295e-06, 'optimizer': 'AdamW', 'weight_decay': 2.493938682682645e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Sigmoid', 'dropout_gcn': 0.5299446358194301, 'hidden_channels': 2048, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 9, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.143794032889353 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.98302495983285 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.840869339419083 acc:  0.0026125985306924503\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.699779087389019 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.561500999289499 acc:  0.005694125002791238\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  7.474786221141547 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  7.4243793756189485 acc:  0.0057834446106781595\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  7.38256746614483 acc:  0.007190228434897171\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  7.295765312624649 acc:  0.008105754415738116\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  7.320246454695581 acc:  0.006207712748141036\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10470707377267989 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1056, 'dropout': 0.6293800358023907, 'dropout_StationIdEmbedding': 0.024550087264256136, 'dropout_timeStampEmbedding': 0.5318561847851061, 'dropout_transformers': 0.8262808500245482, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 65, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.2041077143474148, 'scheduler': 'StepLR', 'step_size': 23, 'dropout_lstm': 0.10470707377267989, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.830053753345513, 'beta_2': 0.9540680567416152, 'eps': 1.3428144563166173e-07, 'lr': 6.600719555550121e-07, 'optimizer': 'AdamW', 'weight_decay': 3.1402550329808313e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.238884074871356 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.20557924417349 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.173183954679049 acc:  0.0006029073532367192\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  8.143801579108604 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  8.112053401653583 acc:  0.0008708661768974834\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  8.080414948096642 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  8.051134571662317 acc:  0.001049505392671326\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  8.023255979097806 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  7.997594176805936 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  7.971620163550743 acc:  0.0012951343143603599\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  7.94566090290363 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  7.9216103113614595 acc:  0.0013844539222472813\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  7.897769165039063 acc:  0.0014514436281624723\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  7.8714996888087345 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  7.850752562742967 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  7.82670032794659 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  7.807738340817965 acc:  0.0018087220597101578\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  7.785339524195744 acc:  0.0019650313735122705\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  7.764625589664166 acc:  0.002076680883370922\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  7.744835343727699 acc:  0.002143670589286113\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  7.7262352576622595 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  7.707079175802377 acc:  0.002232990197173034\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  7.689559467022235 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'SiLU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 624, 'dropout': 0.46235501041049154, 'dropout_StationIdEmbedding': 0.09031967887517603, 'dropout_timeStampEmbedding': 0.5952318343725602, 'dropout_transformers': 0.299104380959662, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 39, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.1643022465642971, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8798163581990404, 'beta_2': 0.9616400310192474, 'eps': 2.005068622312937e-08, 'lr': 2.6322560422675635e-06, 'optimizer': 'Adam', 'weight_decay': 0.00022895110865179532, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1643022465642971 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.021060694181003 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.020760345458985 acc:  0.0006922269611236406\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.020595594552846 acc:  0.000781546569010562\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  8.020387854942909 acc:  0.0008931960788692137\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  8.020163858853854 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  8.020004573235145 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  8.019789006159856 acc:  0.0011388250005582475\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  8.019576835632325 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  8.019430586007925 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  8.019220586923453 acc:  0.0012728044123886295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  8.0190230516287 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  8.018864881075345 acc:  0.0014067838242190116\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  8.018657823709342 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  8.018465746366061 acc:  0.0014737735301342026\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  8.018297422849216 acc:  0.0015184333340776633\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  8.01806403673612 acc:  0.0015407632360493937\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  8.017904582390418 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  8.017711866818942 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  8.017560305962196 acc:  0.0017194024518232365\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  8.017369571098914 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  8.01720308157114 acc:  0.0017640622557666972\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  8.017002413823054 acc:  0.0018757117656253489\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  8.016806448422946 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  8.016616718585675 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  8.01646387393658 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  8.01628836118258 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  8.016127219566933 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  8.015915870666504 acc:  0.0022553200991447648\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  8.015734973320594 acc:  0.002277650001116495\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  8.015552219977746 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  8.01539068222046 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  8.015187417543851 acc:  0.0024786191188620682\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  8.01503123503465 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  8.014872925098127 acc:  0.0025902686287207198\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  8.014669234936054 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  8.01450493152325 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  8.01432914000291 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  8.014095115661622 acc:  0.0027689078444945625\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  8.013974079718956 acc:  0.0027689078444945625\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8633564207247018 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'CELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 528, 'dropout': 0.794232607505785, 'dropout_StationIdEmbedding': 0.4210913947066786, 'dropout_timeStampEmbedding': 0.17741066482794376, 'dropout_transformers': 0.22589320678744376, 'early_stopping': 9, 'encoder_only': True, 'epochs_classifcation_only': 46, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8633564207247018, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 4, 'alpha': 0.9001533125079709, 'centered': True, 'eps': 2.2772687555266254e-06, 'lr': 0.00029935152808090805, 'momentum': 0.19280486949470169, 'optimizer': 'RMSprop', 'weight_decay': 1.9016187326978194e-05, 'positive_function': 'exp', 'epochs_complete_problem': 16, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  7.41056944499506 acc:  0.013777549516557623\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  6.801354078488929 acc:  0.09851952749927428\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  5.957427390267916 acc:  0.15610834468436682\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  5.220211020139891 acc:  0.2064846035325905\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  4.6831383370907504 acc:  0.23124846481923944\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  4.352227950764593 acc:  0.2566822231650403\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  4.029932525670417 acc:  0.2805305584708483\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  3.823168571864333 acc:  0.304736172208204\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  3.6198019402049413 acc:  0.30654489426791415\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  3.5022385142673955 acc:  0.3206573923140477\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  3.415679851425028 acc:  0.3343902820266619\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  3.31493900201031 acc:  0.3430542839916933\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  3.225737368949106 acc:  0.34700667664068957\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  3.1502468184890033 acc:  0.36047160752964297\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  14 loss :  3.093958754405797 acc:  0.36489292812004553\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  15 loss :  3.051630381111787 acc:  0.37107831096621485\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  16 loss :  2.9968772758947355 acc:  0.374048187928455\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  17 loss :  2.984667771330504 acc:  0.378022910479423\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  18 loss :  2.904477785680896 acc:  0.3803228903825112\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  19 loss :  2.8755516404303436 acc:  0.3828015095013733\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  20 loss :  2.846548312178282 acc:  0.38878592322979705\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  21 loss :  2.836874393659217 acc:  0.38746845901346494\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  22 loss :  2.7662691156440804 acc:  0.3934752026438604\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  23 loss :  2.792728929876167 acc:  0.39503829578188154\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  24 loss :  2.7517681344647276 acc:  0.39622178058638324\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  25 loss :  2.7512848533202554 acc:  0.3986780698032736\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  26 loss :  2.706367922720508 acc:  0.4034120090212804\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  27 loss :  2.6871322761072176 acc:  0.40088873009847487\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  28 loss :  2.65635585562091 acc:  0.4039479266686019\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  29 loss :  2.622455280517863 acc:  0.4065158653953509\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  30 loss :  2.5991238389059763 acc:  0.4096197217694214\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  31 loss :  2.593056068242153 acc:  0.4091954536319586\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  32 loss :  2.574626410118887 acc:  0.40845856686689147\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  33 loss :  2.568911106786995 acc:  0.41049058794631893\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  34 loss :  2.540756895163349 acc:  0.4100439899068843\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  35 loss :  2.5127753587526698 acc:  0.41475559922291944\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  36 loss :  2.4844539143214717 acc:  0.41227698010405733\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  37 loss :  2.4744649256501243 acc:  0.41198669137842486\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  38 loss :  2.489161471340144 acc:  0.4168769399102338\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  39 loss :  2.462638750254551 acc:  0.41571578500770384\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  40 loss :  2.445159142262468 acc:  0.41529151687024096\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  41 loss :  2.4225472991711627 acc:  0.41618471294911014\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  42 loss :  2.4282472880087167 acc:  0.4141526918696827\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  43 loss :  2.4372056978885257 acc:  0.4177924658910747\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  44 loss :  2.395603510820977 acc:  0.41589442422347767\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  45 loss :  2.3805800208421513 acc:  0.4193555590290959\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  46 loss :  3.5308023568625764 acc:  0.4170109193220642\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  47 loss :  3.4588596352906986 acc:  0.4148672487327781\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  48 loss :  3.417522138524278 acc:  0.4160507335372798\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  49 loss :  3.3657329706388097 acc:  0.4195565281468414\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  50 loss :  3.3520261171822234 acc:  0.41770314628318783\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  51 loss :  3.3196546652606713 acc:  0.4178371256950182\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  52 loss :  3.327566503364349 acc:  0.41765848647924436\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  53 loss :  3.277559275939086 acc:  0.41868566196994395\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  54 loss :  3.281975255948361 acc:  0.4215215595203537\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  55 loss :  3.277527548442377 acc:  0.4177924658910747\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  56 loss :  3.2543512437945212 acc:  0.4201371055981064\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  57 loss :  3.261006491206517 acc:  0.4207623428533149\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  58 loss :  3.1991812781752826 acc:  0.4201147756961347\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  59 loss :  3.2188147161608542 acc:  0.42000312618627605\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  60 loss :  3.1813519379802955 acc:  0.4207623428533149\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  61 loss :  3.166047185380882 acc:  0.42163320903021234\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': False, 'd_model': 192, 'dropout': 0.3790077124974481, 'dropout_StationIdEmbedding': 0.211855333048019, 'dropout_timeStampEmbedding': 0.06763651735033571, 'dropout_transformers': 0.34639986451800575, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 69, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 19, 'eta_min': 4.7733323352901595e-05, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 2, 'lr': 0.01591651318321042, 'momentum': 0.32672622245520316, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 9.558377001205394e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.061816663049452 acc:  0.0009155259808409441\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.958005225858209 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.863549666697753 acc:  0.005962083826452002\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.744618453127046 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.662357434214161 acc:  0.005314516669271822\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  7.572128293234543 acc:  0.005582475492932586\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  7.502763681571577 acc:  0.007033919121095058\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  7.428222810755895 acc:  0.006386351963914879\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  7.406939626406025 acc:  0.00911060000446598\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  7.377618118371378 acc:  0.009802826965589621\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  7.347550421453721 acc:  0.010026125985306925\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  7.344926098871498 acc:  0.0072795480427840925\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  7.338717252848535 acc:  0.007391197552642744\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  7.3197237845905665 acc:  0.007413527454614474\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m GCNConv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3281658900891189 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'PReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 960, 'dropout': 0.0709098155711059, 'dropout_StationIdEmbedding': 0.30945856059094634, 'dropout_timeStampEmbedding': 0.9294054882340348, 'dropout_transformers': 0.012087171029021349, 'early_stopping': 6, 'encoder_only': False, 'epochs_classifcation_only': 76, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 1.5884807139281368e-05, 'max_lr': 0.07091185906973357, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 5, 'dropout_lstm': 0.3281658900891189, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.839472343702114, 'beta_2': 0.9517423218372957, 'eps': 1.992314286269397e-07, 'lr': 3.805466860391014e-05, 'optimizer': 'AdamW', 'weight_decay': 4.559441511587964e-07, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'PReLU', 'dropout_gcn': 0.919152667349318, 'hidden_channels': 1024, 'layer_type': 'GCNConv', 'norm': 'LayerNorm', 'num_layers_gcn': 7, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.8104073483011 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.79557939197706 acc:  0.02409396422749704\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.810966429503067 acc:  0.017930911283299468\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28580213789945247 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'LogSigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1440, 'dropout': 0.30684583624769574, 'dropout_StationIdEmbedding': 0.2655651355688701, 'dropout_timeStampEmbedding': 0.13842146147581633, 'dropout_transformers': 0.42152062585316596, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 12, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.28580213789945247, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'ELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9228975514913261, 'beta_2': 0.9580603442310848, 'eps': 7.153323289813479e-09, 'lr': 0.003161554982354393, 'optimizer': 'AdamW', 'weight_decay': 1.5957521151853145e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  9.729491505256066 acc:  0.0032378357859009\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  8.93027351819552 acc:  0.025098809816224907\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  8.171822177446806 acc:  0.03974722550968001\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.449608028852023 acc:  0.07346537748699283\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.07744401051448 acc:  0.0789585333720385\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  6.890328810765193 acc:  0.0861710917089074\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  6.776701277952927 acc:  0.10215930152066632\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  6.693147450227004 acc:  0.095147712301543\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  6.6483891303722675 acc:  0.10698256034656008\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  6.570549289996808 acc:  0.1122970770158319\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  6.447203947947576 acc:  0.12216689368733671\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  6.343081279901358 acc:  0.13366679320277783\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m {'activation': 'Hardshrink', 'activation_transformers': 'SELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 696, 'dropout': 0.9065393445926437, 'dropout_StationIdEmbedding': 0.055148270186013496, 'dropout_timeStampEmbedding': 0.2071029054944667, 'dropout_transformers': 0.4883602010689975, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 61, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.42046869798079084, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.6104251002465972, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8528235842538338, 'beta_2': 0.9547362483269606, 'eps': 3.5770231179550053e-08, 'lr': 0.00029221588143049513, 'optimizer': 'Adam', 'weight_decay': 0.20523053066253258, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6104251002465972 and num_layers=1\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  0 loss :  8.03023234535666 acc:  0.0913962887702923\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  1 loss :  7.705863131194556 acc:  0.14230846526583749\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  2 loss :  7.6544465938536055 acc:  0.14672978585624008\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  3 loss :  7.654393504647648 acc:  0.14789094075877007\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  4 loss :  7.6493695523558545 acc:  0.14827054909228948\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  5 loss :  7.654211388916528 acc:  0.14844918830806333\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  6 loss :  7.647995111321201 acc:  0.1483598687001764\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  7 loss :  7.636520105249741 acc:  0.148225889288346\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  8 loss :  7.645323436801173 acc:  0.14831520889623295\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  9 loss :  7.646690697229209 acc:  0.1483375387982047\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  10 loss :  7.645583469326756 acc:  0.1483598687001764\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  11 loss :  7.64380584845022 acc:  0.1483375387982047\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  12 loss :  7.639350855049967 acc:  0.1483375387982047\n",
            "\u001b[36m(eval_config pid=236102)\u001b[0m epoch:  13 loss :  7.6415513623662354 acc:  0.1483598687001764\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 09:24:55,526\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 09:25:10,292\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 09:25:10,293\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_5        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_5\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_5`\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6676595277172814 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'RReLU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1008, 'dropout': 0.16821195820533483, 'dropout_StationIdEmbedding': 0.14841863350246676, 'dropout_timeStampEmbedding': 0.3632658260507174, 'dropout_transformers': 0.5511763209829913, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 73, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.6676595277172814, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 2, 'amsgrad': True, 'beta_1': 0.9093179418325481, 'beta_2': 0.9564538859282321, 'eps': 4.289354539422935e-07, 'lr': 6.059474741974039e-05, 'optimizer': 'AdamW', 'weight_decay': 1.0038778269415936e-07, 'positive_function': 'exp', 'epochs_complete_problem': 23, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.37901013814486 acc:  0.07773038876359332\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.164171006129338 acc:  0.1942031574481388\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  5.360526202275203 acc:  0.244534756492419\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  4.875951084723839 acc:  0.2785208672933926\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  4.523144160784208 acc:  0.3000245628921689\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  4.254289766458364 acc:  0.3206127325101043\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  4.035704689759474 acc:  0.335462117321305\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  3.8658965807694656 acc:  0.34685036732688745\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  3.723159749691303 acc:  0.3568988232141661\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  3.6009683994146493 acc:  0.36225799968738137\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  3.5041546711554896 acc:  0.36759484625862493\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  3.4061297545066247 acc:  0.37556662126253265\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  3.332135360057537 acc:  0.37989862224504833\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  3.259919045521663 acc:  0.38646361342473706\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  3.1967013615828295 acc:  0.38858495411205146\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  3.1345741308652437 acc:  0.39220239823147174\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  3.0881219973930945 acc:  0.3950159658799098\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  3.0364886173835166 acc:  0.39765089431257394\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  2.9927958800242496 acc:  0.40035281245115334\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  2.9515833121079664 acc:  0.404684813433669\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  2.917008720911466 acc:  0.4053323805908492\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  2.881198338361887 acc:  0.40673916441506824\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  2.8475327235001786 acc:  0.40964205167139317\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  2.8152969965567958 acc:  0.41167407275082063\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  2.7833609764392557 acc:  0.41243328941785945\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  2.7582550599024844 acc:  0.4136614340263046\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  2.7333662913395806 acc:  0.4125449389277181\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  2.7082460531821617 acc:  0.4144429805953152\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  2.685627891467168 acc:  0.41801576491079206\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  2.658628401389489 acc:  0.41772547618515954\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  2.6415828503095184 acc:  0.41962351785275664\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  2.617176921551044 acc:  0.4217001987361276\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  2.5927831172943114 acc:  0.42156621932429716\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  2.5755061553074765 acc:  0.42161087912824063\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  2.554794909403874 acc:  0.4213652502065516\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  2.5378578406113843 acc:  0.4242011477569613\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  2.524883301441486 acc:  0.42257106491302504\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  2.5051547307234543 acc:  0.42522832324766097\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  2.487354696713961 acc:  0.42549628207132173\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  39 loss :  2.4730089939557587 acc:  0.4261661791304736\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  40 loss :  2.457288621022151 acc:  0.42647879775807784\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  41 loss :  2.442684105726389 acc:  0.42670209677779514\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  42 loss :  2.4279673062838043 acc:  0.4292923654065159\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  43 loss :  2.4134487610596875 acc:  0.42900207668088336\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  44 loss :  2.3990478680684015 acc:  0.43018556148538506\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  45 loss :  2.3854991390154914 acc:  0.4295379943282049\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  46 loss :  2.373472837301401 acc:  0.42958265413214836\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  47 loss :  2.362603492003221 acc:  0.43038653060313065\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  48 loss :  2.345123026004204 acc:  0.43002925217158294\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  49 loss :  2.3305983919363755 acc:  0.4316593350155193\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  50 loss :  2.320332171366765 acc:  0.4302525511913003\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  51 loss :  2.307474481142484 acc:  0.4313690462898868\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  52 loss :  2.296289573265956 acc:  0.429448674720318\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'ReLU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1368, 'dropout': 0.5624398422114418, 'dropout_StationIdEmbedding': 0.35466211127264585, 'dropout_timeStampEmbedding': 0.48452930264041183, 'dropout_transformers': 0.18011858070552153, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 44, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 8, 'factor': 0.43227729393732117, 'patience': 6, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.027386100625346726, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'alpha': 0.9570807031054822, 'centered': False, 'eps': 7.349415435916268e-09, 'lr': 1.4219526344956858e-06, 'momentum': 0.44916068013737803, 'optimizer': 'RMSprop', 'weight_decay': 0.0015297187478221102, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.00710559801291 acc:  0.0009378558828126744\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.922955276401899 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.825460193721392 acc:  0.004711609316035103\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.725067571829293 acc:  0.004934908335752406\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  7.636036516145896 acc:  0.005113547551526249\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  7.5622240750844245 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.50487728701293 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.455378998326891 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.423642646265394 acc:  0.004488310296317799\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  7.409595460382127 acc:  0.004175691668713575\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9790457332190934 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Tanhshrink', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1176, 'dropout': 0.2572423849012085, 'dropout_StationIdEmbedding': 0.7291587657077927, 'dropout_timeStampEmbedding': 0.653891060993218, 'dropout_transformers': 0.09311329840059308, 'early_stopping': 1, 'encoder_only': False, 'epochs_classifcation_only': 48, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5125915866913783, 'scheduler': 'StepLR', 'step_size': 9, 'dropout_lstm': 0.9790457332190934, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 12, 'num_layers_transformer': 5, 'lr': 0.0025721432851743384, 'momentum': 0.16851136418441132, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 2.44946659037716e-09, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'activation_gcn': 'CELU', 'dropout_gcn': 0.6476946755203802, 'hidden_channels': 128, 'layer_type': 'GraphSAGE', 'norm': 'BatchNorm', 'num_layers_gcn': 3, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.35224014081453 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  8.136648077713815 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.92219335656417 acc:  0.005470825983073934\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.8320473721152855 acc:  0.005426166179130474\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  7.737622025138453 acc:  0.006966929415179867\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  7.680378979130795 acc:  0.00966884755375924\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.58886345311215 acc:  0.011477569613469397\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.589624098727578 acc:  0.013420271085009938\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.53044985219052 acc:  0.012504745104168992\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  7.510919435400712 acc:  0.015854230399928546\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  7.51047110808523 acc:  0.01933769510751848\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  7.457834926404451 acc:  0.02199495344215439\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  7.4620928513376334 acc:  0.02286581961905187\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  7.404537818306371 acc:  0.025344438737913942\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  7.401557204597875 acc:  0.02320076814862783\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  7.3629434635764675 acc:  0.027019181385793716\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  7.389090282038638 acc:  0.03592881227251413\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  7.346259287783974 acc:  0.04068508139249269\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  7.347825035295989 acc:  0.04428019560994127\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  7.318964802591425 acc:  0.04508407208092356\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  7.366483352058812 acc:  0.04539669070852779\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  7.276342798534192 acc:  0.04387825737445013\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  7.270138434359902 acc:  0.045619989728245096\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  7.320340071226421 acc:  0.04287341178572226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7974220468877724 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.14314346166955466, 'dropout_StationIdEmbedding': 0.17727136502200258, 'dropout_timeStampEmbedding': 0.10401683259798905, 'dropout_transformers': 0.4469283567262584, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 55, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7974220468877724, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.86529213639288, 'beta_2': 0.9659153731645884, 'eps': 2.6910702033406116e-07, 'lr': 0.00011208769197689375, 'optimizer': 'AdamW', 'weight_decay': 6.27327345792811e-09, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.528120492054866 acc:  0.03644240001786392\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.68277802834144 acc:  0.13737355693008507\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  6.010977198527409 acc:  0.20518946921823014\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  5.386584197557889 acc:  0.24589688051269454\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  4.851180498416607 acc:  0.2804858986669049\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  4.401645357792194 acc:  0.31007301877944754\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  4.043458714851966 acc:  0.3333184467320188\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  3.7538298826951246 acc:  0.3521202241922158\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  3.531991773385268 acc:  0.36641136145412323\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  3.3436224662340606 acc:  0.37867047763660316\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  3.1953474613336414 acc:  0.38941116048500546\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  3.0731226976101214 acc:  0.3981198222539803\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  2.9612736848684458 acc:  0.4051314114731036\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  2.8759795665740966 acc:  0.4106915570640645\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  2.797330669256357 acc:  0.41573811490967555\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  2.7261640512026273 acc:  0.41848469285219836\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  2.6653798268391538 acc:  0.4216555389321841\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  2.613181284757761 acc:  0.42411182814907444\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  2.561364692908067 acc:  0.4268137462876538\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  2.5161571741104125 acc:  0.42980595315186565\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  2.4712567879603458 acc:  0.4326418507022754\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  2.432030859360328 acc:  0.43384766540874886\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  2.3973787087660567 acc:  0.43462921197775944\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  2.3638155817985536 acc:  0.43487484089944844\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  2.3321573284956125 acc:  0.4360136659000067\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  2.30139669913512 acc:  0.43777772815577337\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  2.269852751951951 acc:  0.43715249090056496\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  2.2457884091597338 acc:  0.4381350065873211\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  2.220008949133066 acc:  0.4376660786459147\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  2.1938284589694095 acc:  0.4384476252149253\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  2.16821132348134 acc:  0.4392068418819641\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  2.1446945217939524 acc:  0.43780005805774513\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  2.1235268666194034 acc:  0.4388495634504165\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  2.102924725642571 acc:  0.43972042962731395\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  2.078352934580583 acc:  0.43876024384252954\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  2.0614928383093614 acc:  0.4390282026661903\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  2.041391545992631 acc:  0.43855927472478395\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  2.021635314134451 acc:  0.438804903646473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9173466203406977 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'Hardswish', 'batch_size': 128, 'concatenate_features': True, 'd_model': 336, 'dropout': 0.09855337001364473, 'dropout_StationIdEmbedding': 0.5748062449705604, 'dropout_timeStampEmbedding': 0.0894199242841272, 'dropout_transformers': 0.605230251754783, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 36, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 8, 'eta_min': 0.03614893051563325, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.9173466203406977, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'GELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8290402123059228, 'beta_2': 0.9775379365381849, 'eps': 1.3310756323321625e-08, 'lr': 0.00012974228292840007, 'optimizer': 'Adam', 'weight_decay': 7.749580630890602e-09, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.66655413554265 acc:  0.008284393631511958\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.097377384625949 acc:  0.23971149766652525\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  4.546730223068824 acc:  0.27291606189848827\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  4.169201940756578 acc:  0.26088024473572563\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  4.0869096554242645 acc:  0.25272983051604403\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  3.8596809754004844 acc:  0.20733313980751625\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.806981315373564 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 32, 'concatenate_features': True, 'd_model': 768, 'dropout': 0.04103687552901361, 'dropout_StationIdEmbedding': 0.4395743172978708, 'dropout_timeStampEmbedding': 0.036792508767713644, 'dropout_transformers': 0.6496266306883016, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 56, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.806981315373564, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8150818212122708, 'beta_2': 0.9731752652478046, 'eps': 1.1805766476111629e-07, 'lr': 0.00021509996998583062, 'optimizer': 'AdamW', 'weight_decay': 0.025623470556296005, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.652510905934271 acc:  0.030346336779581536\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.823022165031077 acc:  0.10291851818770516\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  6.062534924979522 acc:  0.18078288636312886\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  5.4056768907564825 acc:  0.22361163834490766\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  4.9486077277459835 acc:  0.25730746042024877\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  4.731089641000623 acc:  0.2730947011142621\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  4.380782020426242 acc:  0.2937721903400844\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  4.088587119200519 acc:  0.3103856374070518\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  3.934735926512246 acc:  0.3184244021168747\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  3.74057451586857 acc:  0.3399727575195945\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  3.5956318356166377 acc:  0.343902820266619\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  3.4729883715371104 acc:  0.3504231516423643\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  3.3691105062716473 acc:  0.366098742826519\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  3.2874245933283155 acc:  0.37246276488846214\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  3.147414773424095 acc:  0.3754996315566175\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  3.076879109177634 acc:  0.3835383962664404\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  3.1168579832415713 acc:  0.38742379920952147\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  2.989197450263478 acc:  0.3867092423464261\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  3.000370257368712 acc:  0.391688810486122\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  2.958389242118764 acc:  0.3977402139204609\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  2.8933407770139037 acc:  0.396154790880468\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  2.8871622887727257 acc:  0.4017372663734006\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  2.784985816367319 acc:  0.40499743206127325\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  2.795154492431712 acc:  0.40484112274747114\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  2.7890258927211584 acc:  0.407833329611683\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  2.702565233284068 acc:  0.41167407275082063\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  2.6880828665795726 acc:  0.40926244333787376\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  2.6369535365951395 acc:  0.41165174284884887\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  2.6221843155745033 acc:  0.41256726882968986\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  2.639531373977661 acc:  0.4185516825581136\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  2.5619035613871066 acc:  0.4208516624612018\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  2.5947865281149607 acc:  0.41651966147868613\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  2.495570904740663 acc:  0.41897595069557647\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  2.5363438731042023 acc:  0.41919924971529376\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  2.5247556060274072 acc:  0.4193332291271241\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  2.4794490170256 acc:  0.42140991001049505\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  2.478516702340028 acc:  0.42074001295134317\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  2.4676408043531612 acc:  0.4196681776567001\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  2.4175131009003827 acc:  0.421499229618382\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  39 loss :  2.379376912785468 acc:  0.4241564879530179\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  40 loss :  2.3923777854331187 acc:  0.42589822030681285\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  41 loss :  2.3878622311297977 acc:  0.4252506531496327\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  42 loss :  2.3329174908522132 acc:  0.42216912667753387\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  43 loss :  2.32983860679876 acc:  0.4269700556014559\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  44 loss :  2.3313538381986527 acc:  0.4244244467766787\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  45 loss :  2.353910399374561 acc:  0.42435745707076344\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  46 loss :  2.3116658825740637 acc:  0.4269030658955407\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  47 loss :  2.279818969352223 acc:  0.42705937520934284\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  48 loss :  2.2377627486380463 acc:  0.42663510707187996\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  49 loss :  2.3102053682380745 acc:  0.42551861197329344\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  50 loss :  2.2553055319830637 acc:  0.4257642408949825\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  51 loss :  2.211718553694609 acc:  0.42589822030681285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5555528912478276 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 16, 'concatenate_features': False, 'd_model': 288, 'dropout': 0.1397743165799917, 'dropout_StationIdEmbedding': 0.18181095374153725, 'dropout_timeStampEmbedding': 0.8256580178311448, 'dropout_transformers': 0.7200530998825372, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 54, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.5555528912478276, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8632594503835318, 'beta_2': 0.9701106869242241, 'eps': 1.1557901385771028e-06, 'lr': 0.000459284499588945, 'optimizer': 'AdamW', 'weight_decay': 3.910575904830193e-09, 'positive_function': 'sig', 'epochs_complete_problem': 32, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.959890730240765 acc:  0.008463032847285801\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.369899184763932 acc:  0.015050353928946252\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.19243544089694 acc:  0.027153160797624098\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.042164502023649 acc:  0.0351026058995601\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  6.945774935874619 acc:  0.04825491816090927\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  6.871201992034912 acc:  0.06194314806957998\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  6.751658720128677 acc:  0.07415760444811648\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  6.539598256600003 acc:  0.08391577160976263\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  6.5043103594739895 acc:  0.10416899269812206\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  6.337864170555307 acc:  0.1147310363307505\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  6.25124067018012 acc:  0.11526695397807203\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  6.069851490629821 acc:  0.12710180202308913\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  6.096021856580462 acc:  0.13549784516445973\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  5.9111795104852245 acc:  0.14572494026751223\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  5.8210592830882355 acc:  0.1558627157626778\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  5.728694663328283 acc:  0.16258401625616864\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  5.592591986936681 acc:  0.1639461402764442\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  5.595485737343796 acc:  0.16905968782797043\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  5.424655559684048 acc:  0.1814081236183373\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  5.491846240869089 acc:  0.18672264028760913\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  5.347805952825466 acc:  0.1979545809793895\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  5.257801618896613 acc:  0.20092445794162964\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  5.190738311334818 acc:  0.20139338588303599\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  5.132144479190602 acc:  0.21077194471116273\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  5.155342649011051 acc:  0.21948060648013756\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  4.934195514486618 acc:  0.21867673000915527\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  4.980125206859172 acc:  0.22738539177813008\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  4.938170180601232 acc:  0.23372708393810152\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  4.888425742878633 acc:  0.23593774423330283\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  4.888134249118196 acc:  0.24176584864792444\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  4.768020303309465 acc:  0.247102695219168\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  4.658825645927622 acc:  0.2532880780653373\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  4.757352804937282 acc:  0.2527521604180158\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  4.6501423551254915 acc:  0.2554317486546234\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  4.6306591735166664 acc:  0.2651452560123261\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  4.673311508002401 acc:  0.2648772971886653\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  4.451880420957293 acc:  0.26773552464104683\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  4.492489089484976 acc:  0.2722684947413081\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  4.358714386194694 acc:  0.2733180001339794\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  39 loss :  4.503323514922326 acc:  0.2756626398410111\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  40 loss :  4.30188340098918 acc:  0.27898979523479894\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  41 loss :  4.431302916102049 acc:  0.2813121050398589\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  42 loss :  4.24461909702846 acc:  0.2833217962173146\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  43 loss :  4.298718023700874 acc:  0.2855994462184311\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  44 loss :  4.290163472920907 acc:  0.28604604425786573\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  45 loss :  4.196686438151768 acc:  0.2911149320054485\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  46 loss :  4.185215110538387 acc:  0.29283433445727175\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  47 loss :  4.110116405647342 acc:  0.2947323761248688\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  48 loss :  4.042341444672656 acc:  0.29709934573387226\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  49 loss :  4.2077120692790055 acc:  0.3007391197552643\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  50 loss :  4.128952463133996 acc:  0.30286046044257864\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  51 loss :  4.082419145007093 acc:  0.3062099457383382\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  52 loss :  3.993441665873808 acc:  0.30676819328763144\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  53 loss :  4.031078617111976 acc:  0.31123417368197753\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  54 loss :  5.17314903676009 acc:  0.30942545162226737\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  55 loss :  5.020356691184164 acc:  0.3112118437800058\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  56 loss :  4.901320048740932 acc:  0.3132438648594333\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  57 loss :  4.900315823675204 acc:  0.3122390192707054\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  58 loss :  4.992988181715252 acc:  0.3151642364290021\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  59 loss :  5.001511405496037 acc:  0.3174642163320903\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  60 loss :  4.876992470076104 acc:  0.3188486702543376\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  61 loss :  4.866027172874002 acc:  0.32072438201996295\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  62 loss :  5.015563530080459 acc:  0.3219748565303798\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  63 loss :  4.922408859268958 acc:  0.32387289819797693\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  64 loss :  4.807199075442402 acc:  0.32472143447290264\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  65 loss :  4.810210560550209 acc:  0.3269097648661322\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  66 loss :  4.8383618222565214 acc:  0.3282048991804926\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  67 loss :  4.8469049008954475 acc:  0.33133108545653484\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  68 loss :  4.831178006003885 acc:  0.3331621374182167\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  69 loss :  4.837575934514278 acc:  0.33383203447736864\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  70 loss :  4.775772950228522 acc:  0.3360873545765134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  71 loss :  4.73126447300951 acc:  0.3374271486948172\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  72 loss :  4.759783304038168 acc:  0.3366232722238349\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  73 loss :  4.807933925580578 acc:  0.33787374673425186\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  74 loss :  4.64681306005526 acc:  0.3391912109505839\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  75 loss :  4.660507678985596 acc:  0.3403970256570574\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  76 loss :  4.69404740894542 acc:  0.33986110800973585\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  77 loss :  4.6462924260051315 acc:  0.3422727374226827\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  78 loss :  4.640161253824956 acc:  0.3430542839916933\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  79 loss :  4.548954114192674 acc:  0.3430542839916933\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  80 loss :  4.505985650695672 acc:  0.3435902016390148\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  81 loss :  4.732529359705308 acc:  0.346805707522944\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  82 loss :  4.515127722956553 acc:  0.3449746555612621\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  83 loss :  4.626270027721629 acc:  0.34843579036688027\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  84 loss :  4.481697515279305 acc:  0.3499765536029297\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  85 loss :  4.636897063054958 acc:  0.3504901413482795\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1128, 'dropout': 0.02872526563508271, 'dropout_StationIdEmbedding': 0.48168654612734446, 'dropout_timeStampEmbedding': 0.10396939670496755, 'dropout_transformers': 0.5882554780053237, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 50, 'input_size': 2, 'learnable_pos_encoding': False, 'base_lr': 0.007060092348477847, 'max_lr': 0.1959699540419694, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 22, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8676448243058204, 'beta_2': 0.9671430898993892, 'eps': 8.427482768295967e-07, 'lr': 0.08118068981591323, 'optimizer': 'AdamW', 'weight_decay': 2.8666606362955618e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'GELU', 'dropout_gcn': 0.2788434631677166, 'hidden_channels': 512, 'layer_type': 'GCNConv', 'norm': 'InstanceNorm', 'num_layers_gcn': 8, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6925845555252007 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 64, 'concatenate_features': True, 'd_model': 888, 'dropout': 0.23038104592408168, 'dropout_StationIdEmbedding': 0.37824620541798815, 'dropout_timeStampEmbedding': 0.556171862073551, 'dropout_transformers': 0.6258576086909705, 'early_stopping': 7, 'encoder_only': False, 'epochs_classifcation_only': 59, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.12889488100863017, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.6925845555252007, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'alpha': 0.9380614590332889, 'centered': True, 'eps': 2.7652696346231813e-08, 'lr': 0.004579984015833657, 'momentum': 0.08043679108743235, 'optimizer': 'RMSprop', 'weight_decay': 8.291479566103543e-05, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  6.35236905003322 acc:  0.17001987361275483\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  4.600183215760093 acc:  0.2178281937342295\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  4.0196848734644535 acc:  0.23774646629301296\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  3.8878046610883175 acc:  0.23919790992117546\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  3.864528852564688 acc:  0.23922023982314716\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  3.864498409606118 acc:  0.2392425697251189\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  3.861455637080069 acc:  0.23922023982314716\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m loss is undifined\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7793811260972364 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'LeakyReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 432, 'dropout': 0.3447829323125935, 'dropout_StationIdEmbedding': 0.23056574861372098, 'dropout_timeStampEmbedding': 0.39104866879312883, 'dropout_transformers': 0.4656398232078552, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 63, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7793811260972364, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'lr': 1.9836763426450555e-06, 'momentum': 0.410560820313398, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.000352682807235384, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.062653736895825 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  8.066188168812948 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  8.068040537546915 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  8.06241151510951 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  8.063443804361734 acc:  0.0004689279414063372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7493994813432109 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Mish', 'batch_size': 128, 'concatenate_features': True, 'd_model': 72, 'dropout': 0.2081011915750497, 'dropout_StationIdEmbedding': 0.10584970923744956, 'dropout_timeStampEmbedding': 0.23603122081229674, 'dropout_transformers': 0.6769297756991051, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 33, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 9, 'factor': 0.8002633200469347, 'patience': 9, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.0024560988206451776, 'dropout_lstm': 0.7493994813432109, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8410972314233909, 'beta_2': 0.963365380453122, 'eps': 3.589701122163516e-09, 'lr': 8.81995693471003e-05, 'optimizer': 'Adam', 'weight_decay': 0.0005390963526518113, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.968245520958534 acc:  0.0031708460799857088\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.754098719816941 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.571145226405217 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.430386748680702 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  7.355628791222205 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  7.319050821891198 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.29811272254357 acc:  0.0033271553937878214\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.286491478406466 acc:  0.00326016568787263\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.278920943920429 acc:  0.003126186276042248\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Hardtanh', 'batch_size': 64, 'concatenate_features': True, 'd_model': 480, 'dropout': 0.003950246091029563, 'dropout_StationIdEmbedding': 0.01970301287523811, 'dropout_timeStampEmbedding': 0.3051400563604007, 'dropout_transformers': 0.44323202055637817, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 58, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.9753335494552355, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Mish', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8223854928426003, 'beta_2': 0.9685017556445132, 'eps': 2.862543172425694e-07, 'lr': 0.0024804393797994563, 'optimizer': 'AdamW', 'weight_decay': 2.152267734971646e-09, 'positive_function': 'sig', 'epochs_complete_problem': 46, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9753335494552355 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  5.732600860253066 acc:  0.22524172118884397\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  3.6409438955569695 acc:  0.2976575932831655\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  3.1208380467877417 acc:  0.33186700310385636\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  2.83414418540315 acc:  0.3586628854699328\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  2.636648019630752 acc:  0.36761717616059664\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  2.4689917585806933 acc:  0.37829086930308375\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  2.332380659565954 acc:  0.3740928477323985\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  2.2372386284217147 acc:  0.3795860036174441\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  2.0898773427494985 acc:  0.38659759283656747\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  2.003453396037667 acc:  0.38161802469687156\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  1.916038296893685 acc:  0.380010271754907\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m GraphSAGE\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'Softplus', 'batch_size': 32, 'concatenate_features': False, 'd_model': 1224, 'dropout': 0.43946636613546325, 'dropout_StationIdEmbedding': 0.04361604974666561, 'dropout_timeStampEmbedding': 0.26364882585276483, 'dropout_transformers': 0.5098832538607492, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 39, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.783495839207017, 'scheduler': 'StepLR', 'step_size': 18, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8083991339632046, 'beta_2': 0.9660630414962572, 'eps': 6.196229293156739e-08, 'lr': 0.000787029105982129, 'optimizer': 'AdamW', 'weight_decay': 6.903816400561451e-09, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softmin', 'dropout_gcn': 0.4036868286560899, 'hidden_channels': 256, 'layer_type': 'GraphSAGE', 'norm': 'GraphNorm', 'num_layers_gcn': 5, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.586122708571585 acc:  0.008172744121653306\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.243910222304494 acc:  0.011097961279949982\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  6.962121827978837 acc:  0.08255364758948708\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  6.44713884654798 acc:  0.14748900252327893\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  5.828361671849301 acc:  0.18623138244423107\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  5.4065143685591845 acc:  0.21682334814550164\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  5.085841653221532 acc:  0.229462072661501\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  4.892646741867066 acc:  0.2512337270839381\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  4.697303681624563 acc:  0.27369760846749885\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  4.612124832052934 acc:  0.27157626778018445\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  4.331747167988827 acc:  0.29153920014291135\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  4.214358894448531 acc:  0.2935488913203671\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  4.169599902002435 acc:  0.2980595315186566\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  4.074130848834389 acc:  0.31159145211352524\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  4.048389530181884 acc:  0.3109215550543733\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  4.025516816189414 acc:  0.3115021325056383\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  3.866986550782856 acc:  0.32168456780474736\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  3.9556271502846165 acc:  0.324609784963044\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  3.8719887934233013 acc:  0.33255923006498\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  3.7776247024536134 acc:  0.33573007614496575\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  3.7925282628912673 acc:  0.3423173972266262\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  3.7361657669669706 acc:  0.347966862425474\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  3.6649373054504393 acc:  0.3423397271285979\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  3.71373206941705 acc:  0.3438135006587321\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  3.678711464530543 acc:  0.3455775629144988\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  3.6651424433055677 acc:  0.3512493580153183\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  3.5610847422951144 acc:  0.3501105330147601\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  3.5899603241368343 acc:  0.34901636781814527\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  3.5592934407685934 acc:  0.3537949668400956\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  3.5757617097151906 acc:  0.35701047272402475\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  3.527234212975753 acc:  0.3593327825290847\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  3.5285270590531197 acc:  0.35774735948909187\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  3.543047799562153 acc:  0.3591094835093674\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  3.489634591654727 acc:  0.35821628743049816\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  3.483486466658743 acc:  0.35893084429359357\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  3.4426969201941238 acc:  0.36174441194203155\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  3.4961767196655273 acc:  0.36525020655159324\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  3.441528666646857 acc:  0.36346381439385483\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  3.4141221447994834 acc:  0.3657414643949713\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8371274296683918 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Hardsigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1296, 'dropout': 0.0850547714230167, 'dropout_StationIdEmbedding': 0.2826457984476207, 'dropout_timeStampEmbedding': 0.4324662733899777, 'dropout_transformers': 0.24037013476907143, 'early_stopping': 7, 'encoder_only': False, 'epochs_classifcation_only': 52, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8371274296683918, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8587365476729337, 'beta_2': 0.9607861888411813, 'eps': 1.0703283003693741e-08, 'lr': 3.063295314996003e-07, 'optimizer': 'AdamW', 'weight_decay': 3.735596068166369e-08, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.124269798022357 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  8.100787771850072 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  8.08082518858068 acc:  0.0006252372552084496\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  8.0570474993281 acc:  0.0008262063729540227\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  8.035624339800922 acc:  0.0010048455887278656\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  8.014211290022907 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.994096531587489 acc:  0.001362124020275551\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.974068721803296 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.954323956946365 acc:  0.00194270147154054\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  7.934571053801465 acc:  0.002344639707031686\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  7.915822814492619 acc:  0.002523278922805529\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  7.896197583495068 acc:  0.002969876962240136\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  7.880285647736878 acc:  0.0032378357859009\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  7.863223528661647 acc:  0.0033271553937878214\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  7.843031863204572 acc:  0.0034611348056182035\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  7.828117210324071 acc:  0.003684433825335507\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  7.810836836069572 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  7.793325324018462 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  7.779361340178161 acc:  0.00390773284505281\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  7.757903952558501 acc:  0.003840743139137619\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  7.7444922783795525 acc:  0.003818413237165889\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  7.727046008871383 acc:  0.00388540294308108\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  7.7123386719647575 acc:  0.003974722550968001\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  7.695933935021152 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  7.682989749587884 acc:  0.003997052452939732\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  7.664646365061528 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  7.6506313436171585 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  7.635270715761585 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  7.6216956026413865 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  7.607788995534432 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  7.593648614001875 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  7.578851435364795 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  7.567772544732614 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  7.5513775769402 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  7.541078811934014 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  7.52400122169687 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  7.511785535251393 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  7.500596807784393 acc:  0.004309671080543956\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  7.489213911425166 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  39 loss :  7.475768321702461 acc:  0.004398990688430878\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  40 loss :  7.465324165440407 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  41 loss :  7.457306661525695 acc:  0.004398990688430878\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  42 loss :  7.445411950600247 acc:  0.004443650492374339\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  43 loss :  7.43416553785821 acc:  0.004465980394346068\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  44 loss :  7.423625501264043 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  45 loss :  7.409797644414821 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  46 loss :  7.4019801636703875 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  47 loss :  7.394074215608485 acc:  0.004711609316035103\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  48 loss :  7.382258258947806 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  49 loss :  7.37747994591208 acc:  0.004867918629837215\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  50 loss :  7.370840866024754 acc:  0.004890248531808946\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  51 loss :  7.362342285508869 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4519857731800705 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Softshrink', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1416, 'dropout': 0.057200208245928724, 'dropout_StationIdEmbedding': 0.07242704379271506, 'dropout_timeStampEmbedding': 0.06121609413872914, 'dropout_transformers': 0.4132641473989971, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 70, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 25, 'eta_min': 0.0027280909463625025, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.4519857731800705, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 2, 'alpha': 0.9912484729167507, 'centered': False, 'eps': 6.198526123708583e-07, 'lr': 5.636483529357195e-05, 'momentum': 0.346409223583691, 'optimizer': 'RMSprop', 'weight_decay': 3.129572597498784e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.055309264459343 acc:  0.10937185985753523\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.029104370937169 acc:  0.16937230645557466\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  5.359456699585246 acc:  0.2287921756023491\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  4.68026710447864 acc:  0.26744523591541436\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  4.143817322276463 acc:  0.29325860259473463\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  3.7896478265245386 acc:  0.30591965701270574\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  3.8234189759905095 acc:  0.2913382310251658\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9111685055502249 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Hardshrink', 'batch_size': 64, 'concatenate_features': True, 'd_model': 672, 'dropout': 0.11608960109022144, 'dropout_StationIdEmbedding': 0.3313240807004375, 'dropout_timeStampEmbedding': 0.01888233950632834, 'dropout_transformers': 0.9462678346226849, 'early_stopping': 8, 'encoder_only': True, 'epochs_classifcation_only': 67, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.9111685055502249, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 1, 'lr': 0.10625506248268199, 'momentum': 0.33939904054899034, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 2.8476802917942196e-06, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  7.561540163480318 acc:  0.05794609561664024\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  6.827279304290985 acc:  0.11671839760623451\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  6.280373970111767 acc:  0.16530826429671974\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  5.848354022819679 acc:  0.1973740035281245\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  5.323691321419669 acc:  0.22374561775673804\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  4.771129541463785 acc:  0.2607909251278387\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  4.290862066762431 acc:  0.2890605810240493\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  3.930374654022964 acc:  0.31022932809324966\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  3.7091156602739455 acc:  0.32920974476922044\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  3.5372371123387265 acc:  0.3451979545809794\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  3.3866796826982832 acc:  0.3633298349820244\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  3.287244506649204 acc:  0.37203849675099926\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  3.193807706966267 acc:  0.37654913694928877\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  3.111520210346142 acc:  0.38157336489292815\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  3.0404762738234514 acc:  0.3819083134225041\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  2.9857724980040863 acc:  0.39454703793850343\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  2.9242259822525343 acc:  0.38829466538641894\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  2.873757274000795 acc:  0.3929839448004823\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  2.8367726369337602 acc:  0.3980305026460934\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  2.809334241426908 acc:  0.39463635754639037\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  2.747709687773164 acc:  0.39608780117455283\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  2.755343047055331 acc:  0.3990800080387647\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  2.6879488521522577 acc:  0.40171493647142886\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  2.6627687224141368 acc:  0.40816827814125894\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  2.640250187653762 acc:  0.4020275550990331\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  2.6291926807456916 acc:  0.40108969921622045\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  2.5918660480659326 acc:  0.40539937029676437\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  2.540571177756036 acc:  0.4035013286291673\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  2.5409925125695607 acc:  0.40455083402183867\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  2.5336600550404795 acc:  0.40582363843422725\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  2.4818505040415517 acc:  0.4064712055914075\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  2.482294700362466 acc:  0.4052430609829623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49918763640664365 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Softmin', 'batch_size': 128, 'concatenate_features': True, 'd_model': 864, 'dropout': 0.14917661543852637, 'dropout_StationIdEmbedding': 0.8238426599593924, 'dropout_timeStampEmbedding': 0.19787889535725717, 'dropout_transformers': 0.3308422612571747, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 64, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.00036922382080356434, 'max_lr': 0.10734852933029443, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 25, 'dropout_lstm': 0.49918763640664365, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8767780074760605, 'beta_2': 0.9591230180008555, 'eps': 2.1258327457565617e-09, 'lr': 0.0012521059176644326, 'optimizer': 'Adam', 'weight_decay': 1.1560643392418431e-06, 'positive_function': 'relu', 'epochs_complete_problem': 21, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  6.865080129183256 acc:  0.25487350110533014\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  5.160398501616258 acc:  0.2851528481789965\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  5.341884345274705 acc:  0.2906683339660139\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  6.191592986767109 acc:  0.26769086483710336\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m GAT\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'ReLU6', 'batch_size': 32, 'concatenate_features': False, 'd_model': 744, 'dropout': 0.31927197226046844, 'dropout_StationIdEmbedding': 0.7711524576324957, 'dropout_timeStampEmbedding': 0.5135006518462428, 'dropout_transformers': 0.3828635507478771, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 60, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.43806953847537455, 'scheduler': 'ExponentialLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8465602810945871, 'beta_2': 0.9762751442290083, 'eps': 1.04226439326792e-07, 'lr': 0.0049170284704256545, 'optimizer': 'AdamW', 'weight_decay': 7.057879568166178e-05, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Sigmoid', 'dropout_gcn': 0.48352739696165487, 'hidden_channels': 512, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 1, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  9.240909625637915 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.689574613878804 acc:  0.0003126186276042248\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.426230636719734 acc:  0.003706763727307237\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.324171146269768 acc:  0.0033941450997030122\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6932986004019901 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Sigmoid', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1344, 'dropout': 0.28831747197292956, 'dropout_StationIdEmbedding': 0.6773714722636933, 'dropout_timeStampEmbedding': 0.16480278848759067, 'dropout_transformers': 0.28781813764833997, 'early_stopping': 10, 'encoder_only': True, 'epochs_classifcation_only': 49, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.6932986004019901, 'lstm_layer_with_layer_norm': True, 'activation_lstm': 'Sigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8909514190846709, 'beta_2': 0.9696918477138865, 'eps': 2.4547074716140227e-06, 'lr': 1.0282087948458245e-05, 'optimizer': 'AdamW', 'weight_decay': 1.687709251382846e-08, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.118472669377674 acc:  0.003550454413505125\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  7.721066914457182 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.488974323485817 acc:  0.005135877453497979\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.400655376178593 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  7.363688082668368 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  7.343554723196189 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.321392653374699 acc:  0.005716454904762968\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.31814096493428 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.29989674371048 acc:  0.0056271352968760464\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  7.29796991667934 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  7.288969796463098 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  7.290754153075831 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  7.284071008586351 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  7.278865124260247 acc:  0.0041310318647701134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  7.2660140511709885 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  7.271398893281734 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  7.263927598239324 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m {'activation': 'Softshrink', 'activation_transformers': 'Softsign', 'batch_size': 16, 'concatenate_features': True, 'd_model': 552, 'dropout': 0.3912300220586564, 'dropout_StationIdEmbedding': 0.13071550179170677, 'dropout_timeStampEmbedding': 0.47109212130984746, 'dropout_transformers': 0.3517978813456328, 'early_stopping': 4, 'encoder_only': False, 'epochs_classifcation_only': 75, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.6113946715141367, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': True, 'beta_1': 0.8332348672283685, 'beta_2': 0.9794007557844995, 'eps': 6.607239911852249e-07, 'lr': 2.1657567195736806e-05, 'optimizer': 'AdamW', 'weight_decay': 0.012074339319989844, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6113946715141367 and num_layers=1\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  0 loss :  8.277191999579678 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  1 loss :  8.07288722831662 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  2 loss :  7.8712977802052215 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  3 loss :  7.714090395374458 acc:  0.004934908335752406\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  4 loss :  7.596345248342562 acc:  0.004823258825893754\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  5 loss :  7.495501922960041 acc:  0.005582475492932586\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  6 loss :  7.495824833877948 acc:  0.0056271352968760464\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  7 loss :  7.431319561325202 acc:  0.006810620101377755\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  8 loss :  7.412263994457341 acc:  0.007636826474331778\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  9 loss :  7.4263102066617055 acc:  0.00908827010249425\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  10 loss :  7.3797762213634845 acc:  0.009490208337985397\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  11 loss :  7.357156713469689 acc:  0.011901837750932273\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  12 loss :  7.34809085701694 acc:  0.01299600294754706\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  13 loss :  7.318172026081245 acc:  0.015764910792041623\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  14 loss :  7.272289332221536 acc:  0.01748431324386486\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  15 loss :  7.2508926471742265 acc:  0.01819887010696023\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  16 loss :  7.227732097401338 acc:  0.01958332402920751\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  17 loss :  7.219577428673496 acc:  0.024428912757072995\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  18 loss :  7.193964946169813 acc:  0.026929861777906794\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  19 loss :  7.207409245627267 acc:  0.0278900475626912\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  20 loss :  7.133773515204422 acc:  0.033360873545765134\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  21 loss :  7.06953240242325 acc:  0.036598709331666035\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  22 loss :  7.049219948904855 acc:  0.031328852466337674\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  23 loss :  7.063889154866964 acc:  0.0437889377665632\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  24 loss :  7.041716980333088 acc:  0.04633454659134047\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  25 loss :  6.954221252633744 acc:  0.04841122747471139\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  26 loss :  6.9877364134588165 acc:  0.052497599535538036\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  27 loss :  6.936017461183693 acc:  0.05839269365607485\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  28 loss :  6.938850218508424 acc:  0.0632829421878838\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  29 loss :  6.877643845662349 acc:  0.06640912846392605\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  30 loss :  6.867399135557544 acc:  0.07187995444699997\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  31 loss :  6.819087445235052 acc:  0.07482750150726838\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  32 loss :  6.779358919929056 acc:  0.08000803876470983\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  33 loss :  6.774567752325234 acc:  0.08324587455061072\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  34 loss :  6.71765945739105 acc:  0.08784583435678717\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  35 loss :  6.730360179388223 acc:  0.09115065984860327\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  36 loss :  6.687249420069847 acc:  0.09595158877252528\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  37 loss :  6.6441775570396615 acc:  0.09970301230377598\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  38 loss :  6.604246552250967 acc:  0.10564276622825626\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  39 loss :  6.549760858551795 acc:  0.1083223544648639\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  40 loss :  6.562506535473992 acc:  0.11234173681977536\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  41 loss :  6.527557433152399 acc:  0.11504365495835474\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  42 loss :  6.559963126142486 acc:  0.11776790299890584\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  43 loss :  6.478328937242011 acc:  0.11968827456847464\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  44 loss :  6.4819270983463575 acc:  0.12466784270817051\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  45 loss :  6.413134895452933 acc:  0.12772703927829757\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  46 loss :  6.364965579088996 acc:  0.1300270191813858\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  47 loss :  6.442174683098032 acc:  0.13424737065404282\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  48 loss :  6.385013115506212 acc:  0.13737355693008507\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  49 loss :  6.255057815744095 acc:  0.14105799075542058\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  50 loss :  6.234223954817828 acc:  0.1437152490900565\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  51 loss :  6.198696813663514 acc:  0.1463725074246924\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  52 loss :  6.166843590616178 acc:  0.14876180693566754\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  53 loss :  6.152408074931938 acc:  0.15039188977960385\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  54 loss :  6.196759917155034 acc:  0.15434428242860013\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  55 loss :  6.123852737811434 acc:  0.15776075743027487\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  56 loss :  6.060742646706204 acc:  0.1618247995891298\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  57 loss :  6.1688064967884735 acc:  0.1652189446888328\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  58 loss :  5.993569730710583 acc:  0.16466069713953957\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  59 loss :  6.070902415684292 acc:  0.16604515106178683\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  60 loss :  6.114887734421161 acc:  0.16854610008262064\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  61 loss :  6.009519512913808 acc:  0.1716052966527477\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  62 loss :  6.00667566010932 acc:  0.1735256682223165\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  63 loss :  5.9007803592361325 acc:  0.1762275863608959\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  64 loss :  5.932224053294719 acc:  0.17948775204876852\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  65 loss :  5.922632630131826 acc:  0.18091686577495925\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  66 loss :  5.947219528070017 acc:  0.18247995891298038\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  67 loss :  5.796790259225028 acc:  0.18486925842395552\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  68 loss :  5.7993361008267446 acc:  0.18605274322845722\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  69 loss :  5.864260825790277 acc:  0.18855369224929103\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  70 loss :  5.664940621672558 acc:  0.19100998146618137\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  71 loss :  5.763645484667866 acc:  0.19382354911461938\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  72 loss :  5.762721354220094 acc:  0.19614585891967934\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  73 loss :  5.644063677106585 acc:  0.1985351584306545\n",
            "\u001b[36m(eval_config pid=282961)\u001b[0m epoch:  74 loss :  5.7302801128195116 acc:  0.19947301431346717\n",
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 12:15:48,311\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 12:16:03,790\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 12:16:03,792\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_6        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_6\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_6`\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7285644466682207 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'Hardswish', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1080, 'dropout': 0.6982788545664582, 'dropout_StationIdEmbedding': 0.621152124953612, 'dropout_timeStampEmbedding': 0.1175394105594772, 'dropout_transformers': 0.8938253628636652, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 54, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 0, 'factor': 0.5839932175187988, 'patience': 4, 'scheduler': 'ReduceLROnPlateau', 'threshold': 2.6073916866169487e-05, 'dropout_lstm': 0.7285644466682207, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 72, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 6, 'alpha': 0.976122219792859, 'centered': False, 'eps': 2.0314563783269275e-06, 'lr': 0.0007494851094505996, 'momentum': 0.05318765580598933, 'optimizer': 'RMSprop', 'weight_decay': 0.047018482691796405, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.635608679811719 acc:  0.03032400687760981\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.5060004180585835 acc:  0.01958332402920751\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.50230104822508 acc:  0.016591117164995645\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4022500782633984 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Softmin', 'activation_transformers': 'PReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1032, 'dropout': 0.17382228778505543, 'dropout_StationIdEmbedding': 0.0012113331169516517, 'dropout_timeStampEmbedding': 0.28275818844789413, 'dropout_transformers': 0.4712260195060145, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 57, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.21555833725608312, 'scheduler': 'StepLR', 'step_size': 27, 'dropout_lstm': 0.4022500782633984, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 192, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 2, 'lr': 8.330030652151283e-06, 'momentum': 0.4577617790866179, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 5.823050087710426e-08, 'positive_function': 'abs', 'epochs_complete_problem': 42, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.020934224752855 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.0206249696422 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  8.020755283495518 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  8.02079319579439 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m GCNConv\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'LeakyReLU', 'activation_transformers': 'CELU', 'batch_size': 64, 'concatenate_features': False, 'd_model': 1248, 'dropout': 0.41857592377860064, 'dropout_StationIdEmbedding': 0.9992517453967049, 'dropout_timeStampEmbedding': 0.3326713947103078, 'dropout_transformers': 0.2615123560582785, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 41, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 12, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8843581897050788, 'beta_2': 0.9734899088637147, 'eps': 3.5627483414665463e-06, 'lr': 2.7590007495743843e-06, 'optimizer': 'AdamW', 'weight_decay': 0.0010418247918815352, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'activation_gcn': 'swish', 'dropout_gcn': 0.2030528186185816, 'hidden_channels': 64, 'layer_type': 'GCNConv', 'norm': 'BatchNorm', 'num_layers_gcn': 6, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.07227906379991 acc:  0.0004689279414063372\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.00277702316983 acc:  0.0005582475492932586\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.9398366622342404 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  7.876204679940493 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  7.823907040457689 acc:  0.0011611549025299778\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  7.777820496158745 acc:  0.0011834848045017081\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  7.73022641480424 acc:  0.0014067838242190116\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  7.693378528565851 acc:  0.0015854230399928544\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  7.650017159585734 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  7.618457732309822 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  7.585296583539657 acc:  0.002054350981399192\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  7.556407895706992 acc:  0.002344639707031686\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  7.529347022981134 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  7.51051716040109 acc:  0.002858227452381484\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  7.486667895135079 acc:  0.003103856374070518\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  7.469088874700415 acc:  0.0031708460799857088\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  7.452187625506452 acc:  0.003304825491816091\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  7.4254415927042485 acc:  0.0035281245115333943\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  7.416641162551996 acc:  0.0035951142174485856\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  7.405448302057863 acc:  0.0037514235312506978\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  7.393718319084808 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  7.385013394683372 acc:  0.004175691668713575\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  7.365415529440377 acc:  0.004041712256883192\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  7.3591573620570525 acc:  0.003997052452939732\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  7.355781613415434 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  7.341273366039946 acc:  0.003997052452939732\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  7.3468797989474 acc:  0.004019382354911462\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  7.331814383732453 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  7.338896369206086 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  7.33028180362614 acc:  0.004220351472657035\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  7.3317299835554515 acc:  0.004198021570685304\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  7.316594396838705 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  7.31571517099861 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  7.320146243990832 acc:  0.004354330884487417\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  7.310133213305291 acc:  0.004443650492374339\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  7.301768051758978 acc:  0.004443650492374339\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  7.308032330665879 acc:  0.004465980394346068\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  7.303676266706627 acc:  0.0045106401982895295\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  38 loss :  7.300301726537806 acc:  0.00455530000223299\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  39 loss :  7.302349956891009 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  40 loss :  7.297743429664437 acc:  0.004644619610119911\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8529788182319261 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'GELU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 600, 'dropout': 0.7737635793072686, 'dropout_StationIdEmbedding': 0.17519000252911243, 'dropout_timeStampEmbedding': 0.4092491115886116, 'dropout_transformers': 0.21433876172616176, 'early_stopping': 3, 'encoder_only': False, 'epochs_classifcation_only': 62, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.8529788182319261, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8511654164329339, 'beta_2': 0.9709067987954072, 'eps': 3.1628252883785764e-08, 'lr': 9.136265427713556e-07, 'optimizer': 'Adam', 'weight_decay': 3.602206475017811e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.608632095043475 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.597873981182392 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  8.583227715125451 acc:  0.000513587745349798\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  8.569037254040058 acc:  0.0005805774512649889\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  8.554274074847882 acc:  0.0006698970591519103\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  8.540134716033936 acc:  0.000714556863095371\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  8.527931528825027 acc:  0.0008485362749257531\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  8.513457826467661 acc:  0.0009601857847844048\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  8.503212686685416 acc:  0.001116495098586517\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  8.48953888966487 acc:  0.0012281446084451688\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  8.477287710629977 acc:  0.0014067838242190116\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  8.463767770620493 acc:  0.001429113726190742\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  8.450555236522968 acc:  0.0015184333340776633\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  8.440495879833515 acc:  0.0016747426478797758\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  8.426772631131685 acc:  0.0017863921577384275\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  8.409799319047194 acc:  0.0019203715695688096\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  8.400479096632738 acc:  0.0021883303932295735\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  8.385743911449726 acc:  0.002411629412946877\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  8.372831359276404 acc:  0.0024786191188620682\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  8.359439923213078 acc:  0.0027019181385793717\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  8.345665660271278 acc:  0.0028358975504097538\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  8.336934874607966 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  8.324930191040039 acc:  0.0032155058839291695\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  8.31149649986854 acc:  0.0033494852957595515\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  8.296150552309477 acc:  0.003416475001674743\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  8.28384986290565 acc:  0.003572784315476855\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  8.27200243289654 acc:  0.0037290936292789676\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  8.261968979468712 acc:  0.0037737534332224283\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  8.247681559049166 acc:  0.0038630730411093497\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  8.23603908098661 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  8.222937804002028 acc:  0.00390773284505281\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  8.21129542864286 acc:  0.003997052452939732\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  8.197839186741756 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  8.186121955284705 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  8.172355402432956 acc:  0.004242681374628765\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  8.16205942447369 acc:  0.004242681374628765\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  8.14926763681265 acc:  0.004287341178572226\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  8.138149364177997 acc:  0.004265011276600496\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  38 loss :  8.123905996175912 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  39 loss :  8.110068284548246 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  40 loss :  8.102926107553335 acc:  0.0045106401982895295\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  41 loss :  8.087553497461172 acc:  0.004599959806176451\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  42 loss :  8.075886264214148 acc:  0.00457762990420472\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  43 loss :  8.066306679065411 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  44 loss :  8.055154495972854 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  45 loss :  8.043417978286744 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  46 loss :  8.03571331684406 acc:  0.004778599021950294\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  47 loss :  8.018451422911424 acc:  0.0048455887278654845\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  48 loss :  8.009976695134089 acc:  0.004890248531808946\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  49 loss :  8.002928748497595 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  50 loss :  7.989854464164147 acc:  0.005024227943639327\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  51 loss :  7.984621066313523 acc:  0.005046557845611058\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  52 loss :  7.9741256016951345 acc:  0.005091217649554518\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  53 loss :  7.963624928547786 acc:  0.005269856865328361\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  54 loss :  7.953743017636812 acc:  0.005269856865328361\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  55 loss :  7.94444272334759 acc:  0.0051805372574414395\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  56 loss :  7.937461713644175 acc:  0.00520286715941317\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8131903964889645 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'ReLU6', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': True, 'd_model': 936, 'dropout': 0.9981029205156808, 'dropout_StationIdEmbedding': 0.2033947301535048, 'dropout_timeStampEmbedding': 0.45583779151986803, 'dropout_transformers': 0.7113105692359017, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 65, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 17, 'eta_min': 0.00021331642528687843, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.8131903964889645, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'LogSigmoid', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8716061299135273, 'beta_2': 0.962573402846431, 'eps': 4.079150547378938e-09, 'lr': 1.622441544049761e-05, 'optimizer': 'AdamW', 'weight_decay': 4.015798996419644e-06, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.891806999329598 acc:  0.00453297010026126\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.455219610275761 acc:  0.010740682848402296\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.2825483229852495 acc:  0.02594734609115066\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  7.152921673559374 acc:  0.04405689659022397\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  6.95252419440977 acc:  0.08550119464975549\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  6.655070637118432 acc:  0.1348056182033361\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  6.1541990034041865 acc:  0.17988969028425966\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  5.4675010927261845 acc:  0.224661143737579\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  4.867289978458035 acc:  0.2514123662997119\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  4.396007622441938 acc:  0.27709175356720184\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  4.03514756079643 acc:  0.30299443985440905\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  3.769619471027005 acc:  0.3227564030993904\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  3.6029381290558846 acc:  0.32523502221825246\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  3.3887616449786773 acc:  0.33972712859790544\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  3.2433624313723657 acc:  0.3512270281133466\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  3.099061259915752 acc:  0.35678717370430746\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  3.0386641794635403 acc:  0.3709443315543845\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  2.9879417996252737 acc:  0.3746734251836634\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  2.845999103976834 acc:  0.3768394256749213\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  2.7882882010552192 acc:  0.37967532322533104\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  2.7086722958472467 acc:  0.3889868923475426\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  2.589812478711528 acc:  0.3951276153897684\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  2.553274826849661 acc:  0.4002411629412947\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  2.4951776427607384 acc:  0.40682848402295513\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  2.44038651527897 acc:  0.41140611392715987\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  2.3960695958906606 acc:  0.41102650559364046\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  2.3500873634892123 acc:  0.4181944041265659\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  2.335082240258494 acc:  0.4204720541276824\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  2.2662330419786514 acc:  0.42158854922626887\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  2.260192370414734 acc:  0.4236652301096398\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  2.2550223450506888 acc:  0.4267467565817386\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  2.210863208770752 acc:  0.4297612933479222\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  2.2156534825601883 acc:  0.42897974677891165\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  2.197940267285993 acc:  0.4307214791327066\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  2.171776923825664 acc:  0.43014090168144165\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  2.129755776928317 acc:  0.43112341736819776\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  2.1698394483135592 acc:  0.4300739119755264\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  2.131392393573638 acc:  0.43023022128932853\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'SiLU', 'batch_size': 128, 'concatenate_features': True, 'd_model': 168, 'dropout': 0.19423095381915984, 'dropout_StationIdEmbedding': 0.40575419834473314, 'dropout_timeStampEmbedding': 0.04755486230518166, 'dropout_transformers': 0.5322875429640814, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 71, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 4.3181652588848135e-07, 'max_lr': 0.06352084361072614, 'mode': 'exp_range', 'scheduler': 'CyclicLR', 'step_size_up': 16, 'dropout_lstm': 0.5321682289139822, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 48, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.9056036179761526, 'beta_2': 0.9532761994201512, 'eps': 8.280690093245792e-08, 'lr': 0.009946581026051383, 'optimizer': 'AdamW', 'weight_decay': 1.6541841611454316e-07, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5321682289139822 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.112470403630683 acc:  0.00037960833351941584\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.3238808550733205 acc:  0.036531719625750844\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  6.431374367247236 acc:  0.14916374517115868\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  4.973196557227602 acc:  0.22758636089587567\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  4.123810671745463 acc:  0.2691423084652658\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  3.855647508134233 acc:  0.2763995266060782\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  3.7233513010309096 acc:  0.27488109327200055\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  3.7441188223818513 acc:  0.28041890896098964\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  3.7895849714887904 acc:  0.27374226827144227\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  3.821441650390625 acc:  0.2801509501373289\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  3.9687378660161445 acc:  0.2666190295424603\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  4.035825942425018 acc:  0.2628899359131813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7999477690446972 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'ELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 96, 'dropout': 0.4916265034111731, 'dropout_StationIdEmbedding': 0.5093633260296117, 'dropout_timeStampEmbedding': 0.23955233203332024, 'dropout_transformers': 0.7369323958193752, 'early_stopping': 6, 'encoder_only': True, 'epochs_classifcation_only': 68, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.7999477690446972, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 5, 'alpha': 0.9190346505446495, 'centered': True, 'eps': 2.8605143217570725e-08, 'lr': 1.3991877761774403e-05, 'momentum': 0.14893249973402697, 'optimizer': 'RMSprop', 'weight_decay': 5.429837114510171e-07, 'positive_function': 'abs', 'epochs_complete_problem': 37, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.055588368769293 acc:  0.0004912578433780676\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.015623125996623 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.943168026584011 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  7.803447499975458 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  7.660284559209864 acc:  0.001027175490699596\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  7.558984686444689 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  7.493149317227877 acc:  0.0016970725498515061\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  7.444392027554812 acc:  0.0018980416675970792\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  7.408065025623028 acc:  0.0022999799030882255\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  7.376175997140524 acc:  0.0024339593149186075\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  7.349439864392047 acc:  0.002657258334635911\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  7.326759031602553 acc:  0.0029475470602684053\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  7.308372921043342 acc:  0.0030368666681553267\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  7.285624537434611 acc:  0.0036174441194203157\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  7.286596614997704 acc:  0.004376660786459147\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  7.269393917563912 acc:  0.004644619610119911\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  7.259697097164768 acc:  0.004756269119978563\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  7.251459014999283 acc:  0.004823258825893754\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  7.241925386282114 acc:  0.004934908335752406\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  7.244145956906405 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  7.231064069521177 acc:  0.004912578433780675\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  7.232057938208947 acc:  0.0048455887278654845\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  7.224491236093161 acc:  0.00455530000223299\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  7.2257289119533725 acc:  0.004242681374628765\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  7.223019943370685 acc:  0.004332000982515687\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Hardswish', 'activation_transformers': 'Tanh', 'batch_size': 32, 'concatenate_features': False, 'd_model': 240, 'dropout': 0.3565262322345777, 'dropout_StationIdEmbedding': 0.5408675033441696, 'dropout_timeStampEmbedding': 0.1434803658242147, 'dropout_transformers': 0.5576083230456509, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 43, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 6, 'num_layers_transformer': 2, 'lr': 0.00016479515113953583, 'momentum': 0.06016097756926758, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 0.06382469242115874, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.075600062575296 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.075218646325798 acc:  0.00042426813746287653\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m GAT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6726020993135349 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'ELU', 'activation_transformers': 'LogSigmoid', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1128, 'dropout': 0.869414927497665, 'dropout_StationIdEmbedding': 0.23601656858465375, 'dropout_timeStampEmbedding': 0.0032633030339148383, 'dropout_transformers': 0.05808652889000432, 'early_stopping': 2, 'encoder_only': False, 'epochs_classifcation_only': 24, 'input_size': 2, 'learnable_pos_encoding': False, 'gamma': 0.5933965392884422, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.6726020993135349, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.8009660756300333, 'beta_2': 0.985718006037852, 'eps': 2.5686189920203655e-09, 'lr': 6.894282909620469e-05, 'optimizer': 'AdamW', 'weight_decay': 0.006158378750125147, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'SiLU', 'dropout_gcn': 0.8741515301478306, 'hidden_channels': 1024, 'layer_type': 'GAT', 'norm': 'InstanceNorm', 'num_layers_gcn': 10, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.697440791676063 acc:  0.006743630395462564\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.235400181690245 acc:  0.07857892503851908\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  6.841804406115117 acc:  0.12017953241185271\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8865671310543172 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'CELU', 'activation_transformers': 'SELU', 'batch_size': 16, 'concatenate_features': True, 'd_model': 1368, 'dropout': 0.6402435004726911, 'dropout_StationIdEmbedding': 0.26657991713671453, 'dropout_timeStampEmbedding': 0.2171513140168797, 'dropout_transformers': 0.13938663616720098, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 79, 'input_size': 2, 'learnable_pos_encoding': True, 'cooldown': 4, 'factor': 0.12105520029752503, 'patience': 10, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.00036144919635293046, 'dropout_lstm': 0.8865671310543172, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': True, 'beta_1': 0.9416612409919667, 'beta_2': 0.9646237783716565, 'eps': 2.1929131358148982e-08, 'lr': 4.240603395805862e-05, 'optimizer': 'AdamW', 'weight_decay': 2.1799650013456092e-06, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.888871428841039 acc:  0.01230377598642342\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.319431360144364 acc:  0.0395909161958779\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  6.933335655613949 acc:  0.09034678337762098\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  6.540802910453395 acc:  0.13328718486925842\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  6.156086111068726 acc:  0.16606748096375856\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  5.741147774144223 acc:  0.19239443538842865\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  5.466975786811427 acc:  0.215550543733113\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  5.266258761757299 acc:  0.2374785074693522\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  4.961720318543284 acc:  0.2545385525757542\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  4.923160309540598 acc:  0.27260344327088404\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  4.721554756164551 acc:  0.286849920728848\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  4.574913986105668 acc:  0.2975236138713351\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  4.473066159298545 acc:  0.30205658397159635\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  4.354498506847181 acc:  0.3058303374048188\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  4.365443954969708 acc:  0.30926914230846525\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  4.342020438846789 acc:  0.31125650358394924\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  4.318356850272731 acc:  0.31159145211352524\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  4.397396822979576 acc:  0.31337784427126364\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  4.216263535148219 acc:  0.31485161780139787\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  4.36044182024504 acc:  0.31719625750842956\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  4.29108879942643 acc:  0.3176875153518076\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  4.131228572443912 acc:  0.31862537123462026\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  4.310887833645469 acc:  0.3197195364312351\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  4.154408362037257 acc:  0.3204117633923587\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  4.154315712577418 acc:  0.3215952481968604\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  4.216529509895726 acc:  0.32273407319741865\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  4.26050601507488 acc:  0.32449813545318534\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  4.264824287514937 acc:  0.3244534756492419\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  4.2088831148649515 acc:  0.3243194962374115\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  4.1819335862209925 acc:  0.3245204653551571\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  4.071342139495046 acc:  0.32483308398276134\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  3.9886120520139996 acc:  0.3249670633945917\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  4.190494424418399 acc:  0.3252796820221959\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  4.0555835799167035 acc:  0.32536900163008287\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  4.044993458296124 acc:  0.32523502221825246\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  4.185111643138685 acc:  0.3253913315320546\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  4.155032536858006 acc:  0.3257486099636023\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  4.143062912790399 acc:  0.3257486099636023\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  38 loss :  4.2099103927612305 acc:  0.3261058883951499\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  39 loss :  4.2527567512110656 acc:  0.3259049192774044\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  40 loss :  4.153973662225824 acc:  0.32603889868923475\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  41 loss :  4.205052413438496 acc:  0.326351517316839\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  42 loss :  4.103642556541844 acc:  0.32632918741486727\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  43 loss :  4.139974594116211 acc:  0.32632918741486727\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  44 loss :  4.0266000973550895 acc:  0.3263738472188107\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  45 loss :  4.160906716396934 acc:  0.3264408369247259\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  46 loss :  4.0414808925829435 acc:  0.3263068575128955\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  47 loss :  4.263396647101954 acc:  0.32641850702275416\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6530071716302206 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Softplus', 'activation_transformers': 'Hardswish', 'batch_size': 128, 'concatenate_features': True, 'd_model': 840, 'dropout': 0.07991189862618484, 'dropout_StationIdEmbedding': 0.3012024150538483, 'dropout_timeStampEmbedding': 0.365765290576924, 'dropout_transformers': 0.3641449571799821, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 47, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.5149354217727644, 'scheduler': 'StepLR', 'step_size': 14, 'dropout_lstm': 0.6530071716302206, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'Hardshrink', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 5, 'max_len': 100, 'nb_batchs': 60, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8958303830087536, 'beta_2': 0.9567207186565265, 'eps': 2.4698628288045266e-07, 'lr': 5.945264842115342e-06, 'optimizer': 'AdamW', 'weight_decay': 1.1846883967484644e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.395894826468774 acc:  0.0008708661768974834\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.076363054372496 acc:  0.00390773284505281\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.799881943201615 acc:  0.01239309559431034\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  7.57802891327163 acc:  0.024987160306366257\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  7.383161189192433 acc:  0.037960833351941586\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  7.18906417135465 acc:  0.052117991202018626\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  7.046799627401061 acc:  0.0687984279749012\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  6.884860717644126 acc:  0.08579148337538799\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  6.770003480426336 acc:  0.0988321461268785\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  6.629430803201966 acc:  0.11162717995667999\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  6.466703641212593 acc:  0.12301542996226246\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  6.349244521836103 acc:  0.13509590692896858\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  6.2400361400539595 acc:  0.1475559922291941\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  6.145626553034378 acc:  0.15977044860773063\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  6.007125151359428 acc:  0.16716164616037335\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  5.964721259424242 acc:  0.17453051381104437\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  5.81174903804973 acc:  0.17988969028425966\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  5.7729547145002975 acc:  0.18819641381774335\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  5.721742120839782 acc:  0.19355559029095862\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  5.662115484981213 acc:  0.20036621039233637\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  5.596541404724121 acc:  0.2064176138266753\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  5.517854836027501 acc:  0.21244668735904249\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  5.452577566696426 acc:  0.21887769912690083\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  5.3452461856906694 acc:  0.2228300917758971\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  5.3179674471839 acc:  0.22910479422995333\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  5.232471692360054 acc:  0.23421834178147957\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  5.161088401988401 acc:  0.23897461090145813\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  5.113589804051286 acc:  0.2414532300203202\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  5.089410022153693 acc:  0.2452716432574861\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  5.083899174706411 acc:  0.24833083982761317\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  5.044931322841321 acc:  0.2499832525735212\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  5.032787573539604 acc:  0.2517919746332314\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  4.955861180515613 acc:  0.25400263492843267\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  4.987363475864217 acc:  0.25657057365518166\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  4.906226384437691 acc:  0.259026862872072\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  4.906835749997931 acc:  0.260433646696291\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  4.867233106645487 acc:  0.2619520800303687\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  4.886245929588706 acc:  0.2637384721881071\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  38 loss :  4.8407754493972 acc:  0.2664180604247147\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  39 loss :  4.835165629952641 acc:  0.26731125650358395\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  40 loss :  4.769801766185437 acc:  0.26871804032780294\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  41 loss :  4.7404976618492 acc:  0.27141995846638234\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  42 loss :  4.742968696658894 acc:  0.2724694638590537\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  43 loss :  4.77638474157301 acc:  0.2728937319965165\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  44 loss :  4.742511830087436 acc:  0.2746577942522832\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  45 loss :  4.705596657122596 acc:  0.275171381997633\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  46 loss :  4.709491794392214 acc:  0.27642185650804996\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5716689527608813 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'RReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1200, 'dropout': 0.24879735946171516, 'dropout_StationIdEmbedding': 0.8680940493691933, 'dropout_timeStampEmbedding': 0.18624064977254484, 'dropout_transformers': 0.6641887724303077, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 72, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.5716689527608813, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 84, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 4, 'amsgrad': False, 'beta_1': 0.818161808879219, 'beta_2': 0.9665781557047406, 'eps': 4.982400883965902e-08, 'lr': 0.0004017445004897519, 'optimizer': 'Adam', 'weight_decay': 8.868956217206096e-07, 'positive_function': 'relu', 'epochs_complete_problem': 6, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.478825368076922 acc:  0.008753321572918294\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.154862288969109 acc:  0.0345890181542103\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  6.599725424525249 acc:  0.10662528191501239\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  6.031697261764343 acc:  0.15436661233057186\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  5.546584858951799 acc:  0.1957439206841882\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  5.115219541342862 acc:  0.23529017707612263\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  4.834146005561553 acc:  0.2555657280664538\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  4.5838456010243975 acc:  0.2761985574883326\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  4.368814543069127 acc:  0.28977513788714465\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  4.213315394987543 acc:  0.2989973874014693\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  4.045381324837007 acc:  0.3175312060380055\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  3.93970692301371 acc:  0.32273407319741865\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  3.797778497259301 acc:  0.33501551928187034\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  3.6629366012940925 acc:  0.3425406962463435\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  3.6193883849913817 acc:  0.3489270482102584\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  3.521318136927593 acc:  0.3495522854654668\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  3.466646487454334 acc:  0.35625125605698593\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  3.435248593249953 acc:  0.35998034968626486\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  3.440981198506183 acc:  0.36703659870933164\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  3.3144096782408563 acc:  0.36759484625862493\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  3.3506642134792832 acc:  0.36795212469017263\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  3.2727413120039976 acc:  0.3699841457696001\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  3.204956594719944 acc:  0.37496371390929595\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  3.14355402682201 acc:  0.37771029185181876\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  3.1947034956460976 acc:  0.3790500859701226\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  3.1596555106611137 acc:  0.37793359087153605\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  3.132223040224558 acc:  0.3809481276377197\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  3.130234726940293 acc:  0.38195297322644756\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  3.041358416339001 acc:  0.38161802469687156\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  3.021183642996363 acc:  0.38409664381573366\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  2.9940829908991433 acc:  0.38467722126699866\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  2.9922835884324037 acc:  0.38724515999374765\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  2.9954403394676117 acc:  0.3901703771520443\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  2.932603540190731 acc:  0.3908626041131679\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  34 loss :  2.9529919509428093 acc:  0.3895228099948641\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  35 loss :  2.9205867870744453 acc:  0.39159949087823503\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  36 loss :  2.933302732835333 acc:  0.39077328450528104\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  37 loss :  2.9069572069558753 acc:  0.39191210950583927\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  38 loss :  2.832436555839447 acc:  0.3920460889176697\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  39 loss :  2.851975538644446 acc:  0.3930286046044258\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  40 loss :  2.818880856755268 acc:  0.39251501685907597\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  41 loss :  2.8378003993666314 acc:  0.3916664805841502\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  42 loss :  2.820403799953231 acc:  0.3938548109773798\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  43 loss :  2.7891463141843498 acc:  0.3924256972511891\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  44 loss :  2.8506736410669533 acc:  0.39508295558582496\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  45 loss :  2.8034143620226755 acc:  0.39483732666413596\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  46 loss :  2.786918433315783 acc:  0.394167429604984\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  47 loss :  2.7642616593694114 acc:  0.39470334725230555\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  48 loss :  2.7578632055994974 acc:  0.39727128597905453\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  49 loss :  2.714644305677299 acc:  0.39758390460665877\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  50 loss :  2.7455669052629585 acc:  0.39506062568385325\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  51 loss :  2.711237999330084 acc:  0.3987003997052453\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  52 loss :  2.672905864485775 acc:  0.3944130585266731\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  53 loss :  2.6871443139501365 acc:  0.39794118303820647\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  54 loss :  2.679396749979042 acc:  0.3975169149007436\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'SELU', 'activation_transformers': 'Hardshrink', 'batch_size': 128, 'concatenate_features': False, 'd_model': 384, 'dropout': 0.03149136586843543, 'dropout_StationIdEmbedding': 0.15861903802321128, 'dropout_timeStampEmbedding': 0.0922427553815913, 'dropout_transformers': 0.31007141622070783, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 1, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 25, 'eta_min': 0.1360615059611034, 'scheduler': 'CosineAnnealingLR', 'lstm_model': False, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'alpha': 0.9016259578112159, 'centered': True, 'eps': 1.7128503423118e-07, 'lr': 7.615727857893126e-07, 'momentum': 0.4261493850531214, 'optimizer': 'RMSprop', 'weight_decay': 0.0022328080173205315, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.179859300760123 acc:  0.0004465980394346069\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m GraphSAGE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7276233255277926 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'ReLU', 'activation_transformers': 'ReLU', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1416, 'dropout': 0.22228639024716934, 'dropout_StationIdEmbedding': 0.10971197929876407, 'dropout_timeStampEmbedding': 0.3222707154597041, 'dropout_transformers': 0.39271621728371553, 'early_stopping': 1, 'encoder_only': False, 'epochs_classifcation_only': 52, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'dropout_lstm': 0.7276233255277926, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 12, 'num_layers_transformer': 1, 'lr': 0.033617422096279076, 'momentum': 0.19225390445007326, 'nesterov': True, 'optimizer': 'SGD', 'weight_decay': 8.263987570378271e-07, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softplus', 'dropout_gcn': 0.07404274949465145, 'hidden_channels': 2048, 'layer_type': 'GraphSAGE', 'norm': 'LayerNorm', 'num_layers_gcn': 9, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.02365252786054 acc:  0.005001898041667597\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.7146798293747585 acc:  0.003438804903646473\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3510214778367106 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Sigmoid', 'activation_transformers': 'Hardtanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1296, 'dropout': 0.11903135394656124, 'dropout_StationIdEmbedding': 0.0878556598123226, 'dropout_timeStampEmbedding': 0.6977913756529432, 'dropout_transformers': 0.4441800721114561, 'early_stopping': 9, 'encoder_only': True, 'epochs_classifcation_only': 74, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.0023825539308145183, 'max_lr': 0.2417778788122593, 'mode': 'triangular', 'scheduler': 'CyclicLR', 'step_size_up': 8, 'dropout_lstm': 0.3510214778367106, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 4, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8670226986493064, 'beta_2': 0.971778584754757, 'eps': 1.7233729079557205e-07, 'lr': 0.00015359095307671152, 'optimizer': 'AdamW', 'weight_decay': 6.255719186284025e-08, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.204725081179323 acc:  0.10642431279726682\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23974620679000014 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'PReLU', 'activation_transformers': 'LeakyReLU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1152, 'dropout': 0.00020035101392942845, 'dropout_StationIdEmbedding': 0.03822377555890902, 'dropout_timeStampEmbedding': 0.9945591160555007, 'dropout_transformers': 0.11062839502517029, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 34, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.23974620679000014, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.889898900589533, 'beta_2': 0.9614086272391106, 'eps': 1.9514414505961705e-06, 'lr': 3.386664318693659e-06, 'optimizer': 'AdamW', 'weight_decay': 3.602725746465123e-05, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  12.310759176755084 acc:  0.0007592166670388317\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  12.171656406125543 acc:  0.0011611549025299778\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  12.041409087580675 acc:  0.001630082843936315\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  11.896340945579487 acc:  0.0021213406873143827\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  11.763379070345916 acc:  0.0025009490208337984\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  11.647745793092184 acc:  0.0030815264720987874\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  11.54173001230762 acc:  0.0036621039233637764\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  11.417050628022775 acc:  0.004153361766741844\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  11.317675606498506 acc:  0.0049572382377241365\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  11.225316276763404 acc:  0.006029073532367193\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  11.124488649421565 acc:  0.006877609807292946\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  11.069531456718233 acc:  0.007569836768416586\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  10.991354670604514 acc:  0.008664001965031374\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  10.9136723406488 acc:  0.009356228926155015\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  10.862026092060452 acc:  0.010160105397137307\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  10.766172611513618 acc:  0.011432909809525936\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  16 loss :  10.737626406067577 acc:  0.012482415202197263\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  17 loss :  10.685361036375248 acc:  0.013866869124444544\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  18 loss :  10.648367658007745 acc:  0.015251323046691825\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  19 loss :  10.560888684661695 acc:  0.016658106870910835\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  20 loss :  10.532568169705694 acc:  0.01824352991090369\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  21 loss :  10.465247894798576 acc:  0.019806623048924814\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  22 loss :  10.387484449248074 acc:  0.02201728334412612\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  23 loss :  10.328211725757109 acc:  0.023558046580175514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  24 loss :  10.301717321299973 acc:  0.02588035638523547\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  25 loss :  10.232382683780607 acc:  0.02871625393564522\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  26 loss :  10.198892870428843 acc:  0.03188710001563093\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  27 loss :  10.14201649074448 acc:  0.03396378089900185\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  28 loss :  10.083801940832725 acc:  0.03713462697898756\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  29 loss :  10.040347978389462 acc:  0.04102002992206864\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  30 loss :  9.960502017143718 acc:  0.04398990688430878\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  31 loss :  9.93475238437759 acc:  0.04791996963133332\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  32 loss :  9.87001599679446 acc:  0.05102382600540384\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  33 loss :  9.819377377046553 acc:  0.05457428041890896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5984912469305215 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Hardtanh', 'activation_transformers': 'Softplus', 'batch_size': 64, 'concatenate_features': True, 'd_model': 792, 'dropout': 0.554402115029295, 'dropout_StationIdEmbedding': 0.9708884108804527, 'dropout_timeStampEmbedding': 0.5518884414527024, 'dropout_transformers': 0.15775173013744181, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 29, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.7436442480648722, 'scheduler': 'ExponentialLR', 'dropout_lstm': 0.5984912469305215, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'RReLU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': True, 'beta_1': 0.8556593759718351, 'beta_2': 0.9500484337849381, 'eps': 6.627517235019971e-09, 'lr': 2.9000965635502274e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0003587457439928636, 'positive_function': 'exp', 'epochs_complete_problem': 45, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  7.701443038620315 acc:  0.002679588236607641\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  7.361327554796126 acc:  0.004086372060826653\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  7.292015862631631 acc:  0.004108701962798384\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  7.269559143306492 acc:  0.004666949512091642\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  7.2588652764166985 acc:  0.004309671080543956\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  7.262927138722026 acc:  0.004421320590402608\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Hardsigmoid', 'activation_transformers': 'Hardsigmoid', 'batch_size': 128, 'concatenate_features': False, 'd_model': 24, 'dropout': 0.5902320465531741, 'dropout_StationIdEmbedding': 0.00018276572767558785, 'dropout_timeStampEmbedding': 0.7468873506630933, 'dropout_transformers': 0.1898212356144767, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 55, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 132, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.9111107450965328, 'beta_2': 0.9944199895378764, 'eps': 1.5568698597669735e-08, 'lr': 1.7533979987754298e-06, 'optimizer': 'AdamW', 'weight_decay': 2.1083346392857033e-05, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.07105781848614 acc:  0.00013397941183038205\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.068403574136587 acc:  0.0001563093138021124\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  8.066063154660739 acc:  0.00017863921577384274\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  8.063596762143648 acc:  0.00022329901971730344\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  8.060939803490271 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  8.058512130150428 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  8.055475891553439 acc:  0.0002456289216890338\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  8.05338186117319 acc:  0.0002679588236607641\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  8 loss :  8.050981925084042 acc:  0.00029028872563249445\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  9 loss :  8.048899008677555 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  10 loss :  8.046702487652118 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  11 loss :  8.044802632698646 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  12 loss :  8.042721326534565 acc:  0.0003572784315476855\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  13 loss :  8.040656984769381 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  14 loss :  8.038812523621779 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  15 loss :  8.036236271491418 acc:  0.00033494852957595514\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m GAT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41775579499746784 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'SiLU', 'activation_transformers': 'Hardswish', 'batch_size': 32, 'concatenate_features': True, 'd_model': 1008, 'dropout': 0.2801632291540205, 'dropout_StationIdEmbedding': 0.4591933754349636, 'dropout_timeStampEmbedding': 0.2643943131049443, 'dropout_transformers': 0.5806967525231004, 'early_stopping': 6, 'encoder_only': False, 'epochs_classifcation_only': 60, 'input_size': 2, 'learnable_pos_encoding': False, 'cooldown': 1, 'factor': 0.36347237537102384, 'patience': 7, 'scheduler': 'ReduceLROnPlateau', 'threshold': 0.08994590584201007, 'dropout_lstm': 0.41775579499746784, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 108, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 2, 'alpha': 0.9588217578087365, 'centered': False, 'eps': 2.206698910102262e-09, 'lr': 0.04569972124520867, 'momentum': 0.27889369622408344, 'optimizer': 'RMSprop', 'weight_decay': 7.545111873315641e-05, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'Softsign', 'dropout_gcn': 0.7258942541676093, 'hidden_channels': 128, 'layer_type': 'GAT', 'norm': 'GraphNorm', 'num_layers_gcn': 1, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6329342251839823 and num_layers=1\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=325129)\u001b[0m {'activation': 'Tanhshrink', 'activation_transformers': 'Mish', 'batch_size': 64, 'concatenate_features': True, 'd_model': 1368, 'dropout': 0.31169826214676205, 'dropout_StationIdEmbedding': 0.13160859652748813, 'dropout_timeStampEmbedding': 0.29653531065964284, 'dropout_transformers': 0.27556631911990104, 'early_stopping': 1, 'encoder_only': True, 'epochs_classifcation_only': 77, 'input_size': 2, 'learnable_pos_encoding': True, 'gamma': 0.0011398799035657325, 'scheduler': 'StepLR', 'step_size': 7, 'dropout_lstm': 0.6329342251839823, 'lstm_layer_with_layer_norm': True, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 180, 'nb_of_pos_ids': 3043, 'normalize_features': 'after', 'num_heads': 3, 'num_layers_transformer': 2, 'lr': 0.0017645426016499638, 'momentum': 0.4264976557791812, 'nesterov': False, 'optimizer': 'SGD', 'weight_decay': 1.178830112551214e-08, 'positive_function': 'relu', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  0 loss :  8.261014330986491 acc:  0.0004019382354911462\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  1 loss :  8.230989541421389 acc:  0.0007368867650671013\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  2 loss :  8.20589766688853 acc:  0.0013174642163320902\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  3 loss :  8.174270304887655 acc:  0.0023223098050599556\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  4 loss :  8.14517664243389 acc:  0.003930062747024541\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  5 loss :  8.109410544347497 acc:  0.006230042650112766\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  6 loss :  8.082139446748702 acc:  0.010539713730656722\n",
            "\u001b[36m(eval_config pid=325129)\u001b[0m epoch:  7 loss :  8.062283641133229 acc:  0.010539713730656722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-07 14:01:59,436\tWARNING experiment_state.py:323 -- Experiment checkpoint syncing has been triggered multiple times in the last 30.0 seconds. A sync will be triggered whenever a trial has checkpointed more than `num_to_keep` times since last sync or if 300 seconds have passed since last sync. If you have set `num_to_keep` in your `CheckpointConfig`, consider increasing the checkpoint frequency or keeping more checkpoints. You can supress this warning by changing the `TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S` environment variable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1\n",
            "loading already preprocessed data: \n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/list_users\n",
            "/content/drive/MyDrive/telecomDataset6month-splited-100-without-repeated-elements_3/vocab\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'convex hull' option for the 'clip' parameter is deprecated and will be removed in a future release. Use 'convex_hull' instead.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'as_gdf' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:15: FutureWarning: The 'return_input' parameter currently defaults to True but will default to False in a future release. Set it explicitly to avoid this warning.\n",
            "  cells, generators = voronoi_frames(coordinates, clip=\"convex hull\")\n",
            "<ipython-input-48-a5533dccde58>:16: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "2024-03-07 14:02:26,262\tINFO worker.py:1724 -- Started a local Ray instance.\n",
            "2024-03-07 14:02:40,934\tINFO tune.py:220 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
            "2024-03-07 14:02:40,935\tINFO tune.py:592 -- [output] This will use the new output engine with verbosity 0. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "| Configuration for experiment     xp_num_7        |\n",
            "+--------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator |\n",
            "| Scheduler                        FIFOScheduler   |\n",
            "| Number of trials                 20              |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "View detailed results here: /content/tuning/xp_num_7\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /root/ray_results/xp_num_7`\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.activation_relu_or_gelu was not True\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.47297946496673576 and num_layers=1\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'Tanh', 'activation_transformers': 'Tanh', 'batch_size': 128, 'concatenate_features': True, 'd_model': 960, 'dropout': 0.45725375589169126, 'dropout_StationIdEmbedding': 0.019039350643153267, 'dropout_timeStampEmbedding': 0.8800060290461524, 'dropout_transformers': 0.07657673102719267, 'early_stopping': 4, 'encoder_only': True, 'epochs_classifcation_only': 80, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.47297946496673576, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 6, 'max_len': 100, 'nb_batchs': 120, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 6, 'num_layers_transformer': 5, 'amsgrad': False, 'beta_1': 0.8357575159138049, 'beta_2': 0.9638104898314652, 'eps': 8.467320827795803e-09, 'lr': 0.0005690481895893917, 'optimizer': 'AdamW', 'weight_decay': 0.00011981508075403076, 'positive_function': 'abs', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  0 loss :  6.723028375321076 acc:  0.23301252707500614\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  1 loss :  3.9705037830256615 acc:  0.35002121340687314\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  2 loss :  3.0944251813808408 acc:  0.3811044369515218\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  3 loss :  2.7828931267521964 acc:  0.4011343590201639\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  4 loss :  2.6095740755065147 acc:  0.41676529040037513\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  5 loss :  2.496331273006792 acc:  0.4221244668735904\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  6 loss :  2.3693840684009198 acc:  0.4270370453073711\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  7 loss :  2.2955926997320995 acc:  0.4277739320724382\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  8 loss :  2.2066391816660134 acc:  0.43014090168144165\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  9 loss :  2.128504810213041 acc:  0.43170399481946276\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  10 loss :  2.0638400115886655 acc:  0.4310340977603108\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  11 loss :  1.9991301548581164 acc:  0.4283098497197597\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  12 loss :  1.9453760004844987 acc:  0.4302525511913003\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  13 loss :  1.8811956533864767 acc:  0.4321952526628408\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  14 loss :  1.826164040244928 acc:  0.42913605609271377\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  15 loss :  1.7842054156696094 acc:  0.42692539579751243\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5106880460589658 and num_layers=1\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'GELU', 'activation_transformers': 'Softshrink', 'batch_size': 64, 'concatenate_features': True, 'd_model': 888, 'dropout': 0.519654137315249, 'dropout_StationIdEmbedding': 0.07186650563184206, 'dropout_timeStampEmbedding': 0.16745292021889577, 'dropout_transformers': 0.4974269998477895, 'early_stopping': 5, 'encoder_only': True, 'epochs_classifcation_only': 68, 'input_size': 2, 'learnable_pos_encoding': True, 'T_max': 9, 'eta_min': 0.013620024809027471, 'scheduler': 'CosineAnnealingLR', 'dropout_lstm': 0.5106880460589658, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 24, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 1, 'amsgrad': False, 'beta_1': 0.9223522397587934, 'beta_2': 0.9588926512353584, 'eps': 4.1642074338271694e-08, 'lr': 0.0002467082635844658, 'optimizer': 'Adam', 'weight_decay': 6.5846585921587555e-06, 'positive_function': 'exp', 'epochs_complete_problem': 19, 'reg': True, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  0 loss :  7.907570320626964 acc:  0.0064533416698300695\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  1 loss :  7.293242205744204 acc:  0.05761114708706429\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  2 loss :  6.6332628623298975 acc:  0.14958801330862156\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  3 loss :  5.773975890615712 acc:  0.1751557510662528\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  4 loss :  5.266205207161281 acc:  0.18879932117098006\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  5 loss :  4.909868344016697 acc:  0.1979545809793895\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  6 loss :  4.880870383718739 acc:  0.18837505303351718\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  7 loss :  4.5835496239040205 acc:  0.19389053882053459\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  8 loss :  4.586005304170691 acc:  0.19880311725431526\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  9 loss :  4.595715833746868 acc:  0.18888864077886697\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  10 loss :  4.496070571567701 acc:  0.19214880646673962\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  11 loss :  4.289145065390545 acc:  0.18681195989549607\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  12 loss :  4.168992726699166 acc:  0.18759350646450662\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  13 loss :  4.160383753154589 acc:  0.20056717951008196\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  14 loss :  3.8710368094236953 acc:  0.2076680883370922\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  15 loss :  3.8197137998498003 acc:  0.2192126476564768\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  16 loss :  3.5724744693092676 acc:  0.22667083491503473\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  17 loss :  3.6008027636486553 acc:  0.23441931089922516\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  18 loss :  3.4698829028917397 acc:  0.2382823839403345\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  19 loss :  3.454410729200944 acc:  0.24451242659044728\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  20 loss :  3.5538847653762153 acc:  0.24127459080454636\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  21 loss :  3.5225115444349204 acc:  0.23042225844628542\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  22 loss :  3.549601585968681 acc:  0.22198155550097134\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  23 loss :  3.6395280672156294 acc:  0.20219726235401828\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  24 loss :  3.7538525436235513 acc:  0.1967710961748878\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'Mish', 'activation_transformers': 'Softmin', 'batch_size': 32, 'concatenate_features': False, 'd_model': 1224, 'dropout': 0.10375445633112801, 'dropout_StationIdEmbedding': 0.2162202583477274, 'dropout_timeStampEmbedding': 0.12507717185144088, 'dropout_transformers': 0.5177438239980385, 'early_stopping': 2, 'encoder_only': True, 'epochs_classifcation_only': 19, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'lstm_model': False, 'max_len': 100, 'nb_batchs': 96, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 24, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.8252846138933905, 'beta_2': 0.9677885247286593, 'eps': 2.8453859938423464e-08, 'lr': 8.130473767265106e-06, 'optimizer': 'AdamW', 'weight_decay': 1.0836672927347303e-07, 'positive_function': 'sig', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmin has been deprecated. Change the call to include dim=X as an argument.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  0 loss :  8.05355120207134 acc:  0.0005359176473215282\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  1 loss :  7.944669362118369 acc:  0.0013397941183038206\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  2 loss :  7.851455723611932 acc:  0.002545608824777259\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  3 loss :  7.7583009719848635 acc:  0.004064042158854923\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  4 loss :  7.6610903237995345 acc:  0.007078578925038519\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  5 loss :  7.550861900731137 acc:  0.009333899024183284\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  6 loss :  7.486959261643259 acc:  0.010227095103052497\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  7 loss :  7.393215184462698 acc:  0.010673693142487105\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  8 loss :  7.34486003173025 acc:  0.012929013241631869\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  9 loss :  7.299941479532342 acc:  0.01491637451711587\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  10 loss :  7.2638982321086685 acc:  0.017640622557666973\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  11 loss :  7.240370554673044 acc:  0.01875711765625349\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  12 loss :  7.210776800858347 acc:  0.02139204608891767\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  13 loss :  7.201557410390754 acc:  0.026505593640443918\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  14 loss :  7.17464852082102 acc:  0.02909586226916464\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  15 loss :  7.134135100716039 acc:  0.03369582207534109\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  16 loss :  7.132151468176591 acc:  0.0366433691356095\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  17 loss :  7.1070913415206105 acc:  0.042516133354174576\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  18 loss :  7.087165576533267 acc:  0.045642319630216824\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m GCNConv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7663443880786416 and num_layers=1\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'Softsign', 'activation_transformers': 'GELU', 'batch_size': 64, 'concatenate_features': True, 'd_model': 504, 'dropout': 0.1611289472808294, 'dropout_StationIdEmbedding': 0.1905259635966413, 'dropout_timeStampEmbedding': 0.0742556468227499, 'dropout_transformers': 0.7958061391173161, 'early_stopping': 10, 'encoder_only': False, 'epochs_classifcation_only': 46, 'input_size': 2, 'learnable_pos_encoding': False, 'scheduler': None, 'dropout_lstm': 0.7663443880786416, 'lstm_layer_with_layer_norm': False, 'activation_lstm': 'GELU', 'lstm_layer_with_perceptron': True, 'lstm_model': True, 'num_layers_lstm': 3, 'max_len': 100, 'nb_batchs': 156, 'nb_of_pos_ids': 3043, 'normalize_features': 'before', 'num_heads': 12, 'num_layers_transformer': 2, 'amsgrad': False, 'beta_1': 0.8414817558186823, 'beta_2': 0.9555569901737565, 'eps': 1.134557639865927e-08, 'lr': 0.052657538045344315, 'optimizer': 'AdamW', 'weight_decay': 2.556462947812415e-07, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'activation_gcn': 'SELU', 'dropout_gcn': 0.2034016205880249, 'hidden_channels': 256, 'layer_type': 'GCNConv', 'norm': 'InstanceNorm', 'num_layers_gcn': 4, 'use_gcn': True}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3771393692002015 and num_layers=1\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'LogSigmoid', 'activation_transformers': 'Sigmoid', 'batch_size': 128, 'concatenate_features': True, 'd_model': 1320, 'dropout': 0.051143762192593006, 'dropout_StationIdEmbedding': 0.37233317315623277, 'dropout_timeStampEmbedding': 0.34507038426161707, 'dropout_transformers': 0.41721749831833316, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 66, 'input_size': 2, 'learnable_pos_encoding': True, 'base_lr': 0.04016026631212392, 'max_lr': 0.16261453880976653, 'mode': 'triangular2', 'scheduler': 'CyclicLR', 'step_size_up': 11, 'dropout_lstm': 0.3771393692002015, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 2, 'max_len': 100, 'nb_batchs': 168, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 4, 'alpha': 0.9316564273067711, 'centered': False, 'eps': 3.5253345000905124e-06, 'lr': 8.264875019620823e-05, 'momentum': 0.2079035196341558, 'optimizer': 'RMSprop', 'weight_decay': 2.2636268490910553e-09, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m loss is undifined\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.04863489924196046 and num_layers=1\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(eval_config pid=351644)\u001b[0m {'activation': 'RReLU', 'activation_transformers': 'Tanhshrink', 'batch_size': 128, 'concatenate_features': True, 'd_model': 744, 'dropout': 0.18397777982436023, 'dropout_StationIdEmbedding': 0.14949347815709124, 'dropout_timeStampEmbedding': 0.15176209383182665, 'dropout_transformers': 0.3343336144074971, 'early_stopping': 3, 'encoder_only': True, 'epochs_classifcation_only': 70, 'input_size': 2, 'learnable_pos_encoding': True, 'scheduler': None, 'dropout_lstm': 0.04863489924196046, 'lstm_layer_with_layer_norm': False, 'activation_lstm': None, 'lstm_layer_with_perceptron': False, 'lstm_model': True, 'num_layers_lstm': 1, 'max_len': 100, 'nb_batchs': 144, 'nb_of_pos_ids': 3043, 'normalize_features': None, 'num_heads': 3, 'num_layers_transformer': 3, 'amsgrad': False, 'beta_1': 0.9665370508517013, 'beta_2': 0.9575836482210145, 'eps': 3.5296129260855e-07, 'lr': 1.2253304990255833e-05, 'optimizer': 'AdamW', 'weight_decay': 1.4896539037074301e-06, 'positive_function': 'exp', 'reg': False, 'transformers_model': True, 'use_gcn': False}\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m CUDA is available. Using GPU.\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  0 loss :  8.089272557772123 acc:  0.002277650001116495\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  1 loss :  7.710772749093863 acc:  0.006564991179688721\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  2 loss :  7.41291251549354 acc:  0.011455239711497667\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  3 loss :  7.201604975186862 acc:  0.02197262354018266\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  4 loss :  7.033450794219971 acc:  0.039992854431369046\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  5 loss :  6.862494956530058 acc:  0.0610052921867673\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  6 loss :  6.675756483811599 acc:  0.08503226670834915\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  7 loss :  6.489254958813007 acc:  0.10908157113190273\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  8 loss :  6.292531028160682 acc:  0.13054060692673558\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  9 loss :  6.1079884859231806 acc:  0.1514413951722752\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  10 loss :  5.933213883179885 acc:  0.17093539959359577\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  11 loss :  5.756353469995352 acc:  0.18982649666167967\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  12 loss :  5.593198273732112 acc:  0.206774892258223\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  13 loss :  5.4394403897798975 acc:  0.21961458589196794\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  14 loss :  5.282137276576115 acc:  0.23144943393698503\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  15 loss :  5.142485468204205 acc:  0.2418774981577831\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  16 loss :  5.009320259094238 acc:  0.2519706138490052\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  17 loss :  4.880906974352323 acc:  0.26032199718643234\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  18 loss :  4.763159685868484 acc:  0.27041511287765446\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  19 loss :  4.64594438626216 acc:  0.2775383516066364\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  20 loss :  4.537965103296133 acc:  0.28604604425786573\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  21 loss :  4.433954442464389 acc:  0.29446441730120804\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  22 loss :  4.343534453098591 acc:  0.3025478418149744\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  23 loss :  4.2555549786641045 acc:  0.30880021436705896\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  24 loss :  4.171270073377169 acc:  0.3153205457428042\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  25 loss :  4.093192997345557 acc:  0.3210146707455954\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  26 loss :  4.018307671180138 acc:  0.326351517316839\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  27 loss :  3.946608147254357 acc:  0.33168836388808254\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  28 loss :  3.8811045738366934 acc:  0.3353504678114463\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  29 loss :  3.8184705789272604 acc:  0.3401290668333966\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  30 loss :  3.765076129253094 acc:  0.34450572761985576\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  31 loss :  3.7006334744966947 acc:  0.3488823884063149\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  32 loss :  3.65959186737354 acc:  0.35232119330996137\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  33 loss :  3.605106289570148 acc:  0.35607261684121205\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  34 loss :  3.560711062871493 acc:  0.35951142174485856\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  35 loss :  3.513338013795706 acc:  0.3633075050800527\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  36 loss :  3.474230880003709 acc:  0.36556282517919747\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  37 loss :  3.437323893033541 acc:  0.37027443449523256\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  38 loss :  3.401331830024719 acc:  0.3727977134180381\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  39 loss :  3.360711227930509 acc:  0.3766831163611192\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  40 loss :  3.3224487121288595 acc:  0.37851416832280105\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  41 loss :  3.290991335648757 acc:  0.3817296742067302\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  42 loss :  3.2604286744044377 acc:  0.384811200678829\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  43 loss :  3.231949470593379 acc:  0.38769175803318223\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  44 loss :  3.2048762431511513 acc:  0.38983542862246834\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  45 loss :  3.1747662305831907 acc:  0.39135386195654603\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  46 loss :  3.1512229937773486 acc:  0.3934305428399169\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  47 loss :  3.1271816272002 acc:  0.39526159480159884\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  48 loss :  3.103031459221473 acc:  0.3980305026460934\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  49 loss :  3.0805426120758055 acc:  0.3992586472545386\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  50 loss :  3.058027746127202 acc:  0.40071009088270104\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  51 loss :  3.0342871134097757 acc:  0.40151396735368333\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  52 loss :  3.0113418304003203 acc:  0.4037022977469129\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  53 loss :  2.9958691101807813 acc:  0.40477413304155596\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  54 loss :  2.9769372976743256 acc:  0.40696246343478554\n",
            "\u001b[36m(eval_config pid=351644)\u001b[0m epoch:  55 loss :  2.954783588189345 acc:  0.40718576245450283\n"
          ]
        }
      ],
      "source": [
        "run_all_xp(xps_name=\"hyperparameter_tuning_projet_long\", algo=None, xp_size=20, xps_number=10, accuracy_target=0.98, max_num_epochs=None, storage_path='/content/tuning',drive_path=\"/content/drive/MyDrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN5SCJEQbdUL"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Load the tuner from the pickle file\n",
        "with open('/content/drive/MyDrive/hyperparameter_tuning_projet_long/xp_num_9/tuner.pkl', 'rb') as f:\n",
        "    tuner = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yHiQRawJBHs"
      },
      "outputs": [],
      "source": [
        "torch.tensor([1,2,3]).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2HKIDeUJOYr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo8GkX4lh116",
        "outputId": "f0bf337d-3e2a-4469-94b8-c91fba198b7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tuner['_tune_config'].search_alg._hpopt_trials.best_trial['misc']['vals']['num_layers']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5K5mhJLjWxb",
        "outputId": "aa018970-ceb2-4401-e397-6525d68f350d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_dynamic_trials', '_exp_key', '_ids', '_insert_trial_docs', '_trials', 'aname', 'argmin', 'assert_valid_trial', 'asynchronous', 'attachments', 'average_best_error', 'best_trial', 'count_by_state_synced', 'count_by_state_unsynced', 'delete_all', 'fmin', 'idxs', 'idxs_vals', 'insert_trial_doc', 'insert_trial_docs', 'losses', 'miscs', 'new_trial_docs', 'new_trial_ids', 'refresh', 'results', 'source_trial_docs', 'specs', 'statuses', 'tids', 'trial_attachments', 'trials', 'vals', 'view']\n"
          ]
        }
      ],
      "source": [
        "\"print(dir(tuner['_tune_config'].search_alg._hpopt_trials))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXU5DJC8p169"
      },
      "source": [
        "## check performance on new station"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HClPVCKb59Zl"
      },
      "outputs": [],
      "source": [
        "def evaluate_repeat(model,dataloader,device,reg=True):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    acc=0\n",
        "    nb_points=0\n",
        "    repeat=0\n",
        "    not_repeat=0\n",
        "    correct_not_repeat=0\n",
        "    correct_repeat=0\n",
        "    incorrect_not_repeat_as_repeat=0\n",
        "    incorrect_not_repeat=0\n",
        "    valid_results={}\n",
        "    for dict_batch in dataloader:\n",
        "      for key in dict_batch:\n",
        "        if key!=\"lengths\":\n",
        "          dict_batch[key]=dict_batch[key].to(device)\n",
        "      with autocast(device_type=device.type):\n",
        "        out=model(dict_batch,reg=reg)\n",
        "        target_pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id_target\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "        acc+=(out[\"next_station\"].data.argmax(dim=1)==target_pos_ids.data).sum().item()\n",
        "        nb_points+=out[\"next_station\"].data.shape[0]\n",
        "        pred=out[\"next_station\"].data.argmax(dim=1)\n",
        "        pos_ids=torch.nn.utils.rnn.pack_padded_sequence(dict_batch[\"pos_id\"], lengths=dict_batch[\"lengths\"],batch_first=True, enforce_sorted=False)\n",
        "        for i in range(len(target_pos_ids.data)):\n",
        "          if target_pos_ids.data[i]==pos_ids.data[i]:\n",
        "            repeat+=1\n",
        "\n",
        "            if target_pos_ids.data[i]==pred[i]:\n",
        "              correct_repeat+=1\n",
        "          else:\n",
        "            not_repeat+=1\n",
        "            if target_pos_ids.data[i]==pred[i]:\n",
        "              correct_not_repeat+=1\n",
        "            if target_pos_ids.data[i]!=pred[i]:\n",
        "              incorrect_not_repeat+=1\n",
        "\n",
        "          if pred[i]==pos_ids.data[i] and target_pos_ids.data[i]!=pos_ids.data[i]:\n",
        "            incorrect_not_repeat_as_repeat+=1\n",
        "    print(nb_points,\"repeat: \",repeat,\" not_repeat: \",not_repeat,\" correct_repeat/repeat: \",correct_repeat/repeat,\" correct_not_repeat/not_repeat: \",correct_not_repeat/not_repeat,incorrect_not_repeat_as_repeat/incorrect_not_repeat)\n",
        "    return valid_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKyqswVm-Flq",
        "outputId": "4f8a2d24-1d1d-4d5e-da84-30957736cbd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.6509191238701378  correct_not_repeat/not_repeat:  0.2762021385930769 0.4746223564954683\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=768,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=0,\n",
        "                                         num_layers_transformer=6,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufqL-c1e27Vm",
        "outputId": "5e436410-45a5-4c71-da92-f5b40a030112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.572683570872406  correct_not_repeat/not_repeat:  0.24545712973693992 0.38929461542920074\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=600,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=12,\n",
        "                                         num_layers_transformer=0,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqLMoo9hpA82",
        "outputId": "cc34ad4e-47d5-4efd-d99e-5c06837a607e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.5703307491790515  correct_not_repeat/not_repeat:  0.22293411471430757 0.40792435839711844\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=600,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=10,\n",
        "                                         num_layers_transformer=0,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYc14HpTkU2z",
        "outputId": "36544e2a-7d0b-4787-df90-4160a18680cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.44894038389925184  correct_not_repeat/not_repeat:  0.29502962979160746 0.2873538261112317\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=600,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=2,\n",
        "                                         num_layers_transformer=0,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "tI1PRax29Fqw",
        "outputId": "d9d5ea9f-4378-49ec-be25-2fe2ce5e37f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-d5fdb97ca0b4>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/acc.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mevaluate_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-17df1714a1da>\u001b[0m in \u001b[0;36mevaluate_repeat\u001b[0;34m(model, dataloader, device, reg)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpos_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pos_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lengths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pos_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0mtarget_pos_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpos_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mrepeat\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=888,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=2,\n",
        "                                         num_layers_transformer=5,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucdMSE-0T3-s",
        "outputId": "4f766291-2702-431e-d059-241a1a1ccfb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.7462507193879279  correct_not_repeat/not_repeat:  0.23080623646979073 0.5669490561746645\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=1008,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=6,\n",
        "                                         num_layers_transformer=6,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEt-Bw9FgvDq",
        "outputId": "70b7fed7-4cc6-495a-de11-57721bf5d02d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.4839957344527574  correct_not_repeat/not_repeat:  0.35011261507511315 0.2974764468371467\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=1008,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=2,\n",
        "                                         num_layers_transformer=0,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkaphByRZOIo",
        "outputId": "13cfb863-5bb6-43a5-f104-7ce207f93c1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.6290835844138258  correct_not_repeat/not_repeat:  0.26852681988148086 0.44345460524349045\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=1008,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=6,\n",
        "                                         num_layers_transformer=6,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test_0.5/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGE1rXtIIEpE",
        "outputId": "775055f6-3dae-4158-fdc4-078b4adba7b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.5781001387995531  correct_not_repeat/not_repeat:  0.3046073779274453 0.4137291280148423\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=888,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=2,\n",
        "                                         num_layers_transformer=5,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "QPBs0PUrKUra",
        "outputId": "196fe7cd-25e3-479d-8c4b-b6a83ccd3977"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-cfd962976380>:15: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n",
            "  delaunay = weights.Rook.from_dataframe(cells)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Transformer_encoder_LSTM_decoder:\n\tMissing key(s) in state_dict: \"transformer_model.transformer.encoder.layers.5.self_attn.in_proj_weight\", \"transformer_model.transformer.encoder.layers.5.self_attn.in_proj_bias\", \"transformer_model.transformer.encoder.layers.5.self_attn.out_proj.weight\", \"transformer_model.transformer.encoder.layers.5.self_attn.out_proj.bias\", \"transformer_model.transformer.encoder.layers.5.linear1.weight\", \"transformer_model.transformer.encoder.layers.5.linear1.bias\", \"transformer_model.transformer.encoder.layers.5.linear2.weight\", \"transformer_model.transformer.encoder.layers.5.linear2.bias\", \"transformer_model.transformer.encoder.layers.5.norm1.weight\", \"transformer_model.transformer.encoder.layers.5.norm1.bias\", \"transformer_model.transformer.encoder.layers.5.norm2.weight\", \"transformer_model.transformer.encoder.layers.5.norm2.bias\", \"transformer_model.transformer.decoder.layers.5.self_attn.in_proj_weight\", \"transformer_model.transformer.decoder.layers.5.self_attn.in_proj_bias\", \"transformer_model.transformer.decoder.layers.5.self_attn.out_proj.weight\", \"transformer_model.transformer.decoder.layers.5.self_attn.out_proj.bias\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer_model.transformer.decoder.layers.5.linear1.weight\", \"transformer_model.transformer.decoder.layers.5.linear1.bias\", \"transformer_model.transformer.decoder.layers.5.linear2.weight\", \"transformer_model.transformer.decoder.layers.5.linear2.bias\", \"transformer_model.transformer.decoder.layers.5.norm1.weight\", \"transformer_model.transformer.decoder.layers.5.norm1.bias\", \"transformer_model.transformer.decoder.layers.5.norm2.weight\", \"transformer_model.transformer.decoder.layers.5.norm2.bias\", \"transformer_model.transformer.decoder.layers.5.norm3.weight\", \"transformer_model.transformer.decoder.layers.5.norm3.bias\", \"transformer_lstm__list.2.layer_normalisation.weight\", \"transformer_lstm__list.2.layer_normalisation.bias\", \"transformer_lstm__list.2.lstm.weight_ih_l0\", \"transformer_lstm__list.2.lstm.weight_hh_l0\", \"transformer_lstm__list.2.lstm.bias_ih_l0\", \"transformer_lstm__list.2.lstm.bias_hh_l0\", \"transformer_lstm__list.2.mlp.linear_perceptron_in.weight\", \"transformer_lstm__list.2.mlp.linear_perceptron_in.bias\", \"transformer_lstm__list.2.mlp.linear_perceptron_out.weight\", \"transformer_lstm__list.2.mlp.linear_perceptron_out.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-10bf83ce1050>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                                          ).to(device)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/acc.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mevaluate_repeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer_encoder_LSTM_decoder:\n\tMissing key(s) in state_dict: \"transformer_model.transformer.encoder.layers.5.self_attn.in_proj_weight\", \"transformer_model.transformer.encoder.layers.5.self_attn.in_proj_bias\", \"transformer_model.transformer.encoder.layers.5.self_attn.out_proj.weight\", \"transformer_model.transformer.encoder.layers.5.self_attn.out_proj.bias\", \"transformer_model.transformer.encoder.layers.5.linear1.weight\", \"transformer_model.transformer.encoder.layers.5.linear1.bias\", \"transformer_model.transformer.encoder.layers.5.linear2.weight\", \"transformer_model.transformer.encoder.layers.5.linear2.bias\", \"transformer_model.transformer.encoder.layers.5.norm1.weight\", \"transformer_model.transformer.encoder.layers.5.norm1.bias\", \"transformer_model.transformer.encoder.layers.5.norm2.weight\", \"transformer_model.transformer.encoder.layers.5.norm2.bias\", \"transformer_model.transformer.decoder.layers.5.self_attn.in_proj_weight\", \"transformer_model.transformer.decoder.layers.5.self_attn.in_proj_bias\", \"transformer_model.transformer.decoder.layers.5.self_attn.out_proj.weight\", \"transformer_model.transformer.decoder.layers.5.self_attn.out_proj.bias\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.in_proj_weight\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.in_proj_bias\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.out_proj.weight\", \"transformer_model.transformer.decoder.layers.5.multihead_attn.out_proj.bias\", \"transformer_model.transformer.decoder.layers.5...."
          ]
        }
      ],
      "source": [
        "model=Transformer_encoder_LSTM_decoder(d_model=888,\n",
        "                                         nb_of_pos_ids=len(vocab)+1,\n",
        "                                         output_regression_size=2,\n",
        "                                         output_classfication_size=len(vocab)+1,\n",
        "                                         num_layers_lstm=3,\n",
        "                                         num_layers_transformer=6,\n",
        "                                         encoder_only=False,\n",
        "                                         nhead=12,\n",
        "                                         learnable_pos_encoding=True,\n",
        "                                         new_station_binary_classification=False,\n",
        "                                         use_gcn=True,\n",
        "                                         vocab=vocab,\n",
        "                                         hidden_dim1=128,\n",
        "                                         hidden_dim2=256,\n",
        "                                         max_len=100,\n",
        "                                         dropout=0.1,\n",
        "                                         batch_first = True,\n",
        "                                         concatenate_features = False,\n",
        "                                         keep_input_positions = False,device=device\n",
        "                                         ).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"test/acc.pth\"))\n",
        "evaluate_repeat(model,test_dataloader,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7cIy9KQFjv8",
        "outputId": "3ea5d475-a56f-4118-d568-2c020806ed64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.8564101696062832  correct_not_repeat/not_repeat:  0.09422492401215805 0.8021341316208778\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.643730131126935, 2.2387092113494873, 4.385555267333984)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K06MhCDWcaF9",
        "outputId": "4a84b9d7-b594-41b9-bca7-acacf62010b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.6269508107925116  correct_not_repeat/not_repeat:  0.24020904856661782 0.4275024463247568\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5190344566683142, 3.329756021499634, 2.0473709106445312)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vonRxU5b96oc",
        "outputId": "baba1be5-861e-44f1-95fb-808d9cd6b5b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.7019025694844104  correct_not_repeat/not_repeat:  0.2555815529946863 0.5174044590664747\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5773612306040138, 2.5278093814849854, 2.7385761737823486)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz2zFYSsAroq",
        "outputId": "10b15668-6b3b-44d9-eb4f-c28a02cbd09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.7179745421307424  correct_not_repeat/not_repeat:  0.2436203013273272 0.5562012142237641\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.5856108172094187, 2.1441447734832764, 1.2037302255630493)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNlGehwEQtfH",
        "outputId": "378de12f-1ebf-44f6-b4b6-e57d19a2bb65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.8789227800534886  correct_not_repeat/not_repeat:  0.11254947409853272 0.8136211314803864\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6650741059388481, 1.82258939743042, 2.1341636180877686)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejz7LOwNTZ-k",
        "outputId": "5d16ae15-48ea-4ff8-a2e7-718c1be73c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.8187565591252243  correct_not_repeat/not_repeat:  0.1462683956178522 0.7372573126376722\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.6311055788439596, 2.027265787124634, 2.6414260864257812)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9yHv6HjJ-N",
        "outputId": "ba6f7b9e-b88f-407c-d22b-1e6913f0e56b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.3789143166661024  correct_not_repeat/not_repeat:  0.3284642802475345 0.28316509280364704\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.3648367472709855, 2.700303077697754, 3.602348566055298)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkLWBTILrc94",
        "outputId": "c04e1913-1724-4df4-e563-1801d24ca813"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "163887 repeat:  118156  not_repeat:  45731  correct_repeat/repeat:  0.4562527506009005  correct_not_repeat/not_repeat:  0.30379829874702063 0.3240153275959545\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.4137118868488654, 2.806699752807617, 3.5753602981567383)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion_classification=torch.nn.CrossEntropyLoss(ignore_index=len(vocab))\n",
        "criterion_regression=mse_loss = nn.MSELoss(reduction='none')\n",
        "evaluate(model,test_dataloader,criterion_classification,criterion_regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCR7Ctsbp_nT"
      },
      "source": [
        "## clean cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtscCJTUkD0R",
        "outputId": "eaa048c3-ab0a-4750-88ca-b84b3ba8b9c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1772397056"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "torch.cuda.memory_allocated()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IV_LSRYqGMO2",
        "f5D9IoBtGX6R",
        "dDvAwpD4GrJu",
        "S_mzoE-MHqLa",
        "ptycyS7FWE4b",
        "7oeWr0HDhJfo",
        "bcCkeqmkhRnT",
        "3Bbp1dVXWQs3",
        "svMRI0xeji-7",
        "zZpbR8rG8kBn",
        "QXU5DJC8p169"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1puaDQhXsRO88rJp6bn4k43jsziFxI2eO",
      "authorship_tag": "ABX9TyNrI7ickSz1W7dUjCmzSAUj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}